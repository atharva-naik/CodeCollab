{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1615abb",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# SQL Together Lab: Learning SQL Syntax\n",
    "\n",
    "_Authors: Dave Yerrington (SF)_\n",
    "\n",
    "---\n",
    "\n",
    "> **This is a hybrid lecture/lab. Each exercise should be completed by a student in front of the class.**\n",
    "\n",
    "\n",
    "### Learning Objectives\n",
    "*After this lesson, you will be able to:*\n",
    "- Sort results by column using `ORDER BY`.\n",
    "- Simplify your syntax using aliases (`AS`).\n",
    "- Match patterns using `LIKE`.\n",
    "- Select distinct items using `DISTINCT`.\n",
    "- Aggregate values using `GROUP BY`.\n",
    "- Filter on aggregations using `HAVING`.\n",
    "- Apply `IF/THEN` logic using `CASE`.\n",
    "- Use `EXTRACT` to get date parts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67eff37b",
   "metadata": {},
   "source": [
    "### Lesson Guide\n",
    "- [Install `psycopg2`](#install-psycopg2)\n",
    "- [Connect to a Remote Database](#connect-to-remote)\n",
    "- [Some Notes on Syntax](#syntax-notes)\n",
    "- [ORDER BY](#order-by)\n",
    "- [Alias `AS`](#alias-as)\n",
    "- [LIKE](#like-operator)\n",
    "- [DISTINCT](#distinct)\n",
    "- [LIMIT](#limit)\n",
    "- [GROUP BY](#group-by)\n",
    "- [HAVING](#having)\n",
    "- [CASE Statements](#case)\n",
    "- [Working with Dates](#dates)\n",
    "- [Additional Exercises](#additional-exercises)\n",
    "- [Conclusion](#conclusion)\n",
    "- [Additional Resources](#additional-resources)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1dad6c",
   "metadata": {},
   "source": [
    "<a id='install-psycopg2'></a>\n",
    "## Install `psycopg2`\n",
    "\n",
    "---\n",
    "\n",
    "Either:\n",
    "\n",
    "`> conda install psycopg2`\n",
    "> _conda may ask you to update using this method_\n",
    "\n",
    "Or:\n",
    "\n",
    "`> pip install psycopg2`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5262899",
   "metadata": {},
   "source": [
    "<a id='connect-to-remote'></a>\n",
    "## Connect to a Remote Database\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff80f828",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "\n",
    "conn_str = \"host='dsi.c20gkj5cvu3l.us-east-1.rds.amazonaws.com' dbname='northwind' user='dsi_student' password='gastudents'\"\n",
    "conn = psycopg2.connect(conn_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749a3cbc",
   "metadata": {},
   "source": [
    "<a id='syntax-notes'></a>\n",
    "\n",
    "## Some Notes on Syntax\n",
    "\n",
    "---\n",
    "\n",
    "The [Northwind Database Schema](https://northwinddatabase.codeplex.com/) will come in handy for writing solutions to the problems below. \n",
    "\n",
    "1. You should wrap column names in double quotes (**\"column_name\"**).\n",
    "2. You can comment out a line by including a double dash in front (**--**).\n",
    "3. You should wrap a string in single quotes (**'string'**).\n",
    "\n",
    "```*.sql\n",
    "SELECT \"ProductID\" as \"PID\"\n",
    "FROM Products\n",
    "WHERE \"ProductName\" like '%a' \n",
    "--AND \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56af617",
   "metadata": {},
   "source": [
    "<a id='order-by'></a>\n",
    "\n",
    "## `ORDER BY`\n",
    "\n",
    "---\n",
    "\n",
    "    The `ORDER BY` keyword is used to sort a result set by one or more columns. It sorts records in ascending order by default. To sort the records in descending order, you can use the `DESC` keyword.\n",
    "\n",
    "### SQL `ORDER BY` Syntax\n",
    "\n",
    "```*.sql\n",
    "SELECT column_name1, column_name2  \n",
    "FROM table_name  \n",
    "ORDER BY column_name1 ASC, column_name2 DESC;\n",
    "``` "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3019f27c",
   "metadata": {},
   "source": [
    "### Exercise #1:\n",
    "\n",
    "Select the `ProductID`, `ProductName`, `SupplierID`, and `UnitPrice` for all `Products` with a `UnitPrice > 25`, ordered by `SupplierID` descending and then `UnitPrice` ascending."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21454033",
   "metadata": {},
   "outputs": [],
   "source": [
    "SQL_STRING = '''\n",
    "\n",
    "SELECT \"ProductID\" as \"PID\",\"ProductName\",\"SupplierID\",\"UnitPrice\"\n",
    "FROM Products \n",
    "WHERE Products.\"UnitPrice\" > 25 \n",
    "ORDER BY \"SupplierID\" DESC,\"UnitPrice\" ASC\n",
    "\n",
    "'''\n",
    "\n",
    "df = pd.read_sql(SQL_STRING, con=conn)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d44b69c",
   "metadata": {},
   "source": [
    "<a id='alias-as'></a>\n",
    "## Alias `AS`\n",
    "\n",
    "---\n",
    "\n",
    "SQL aliases are used to give a database table — or a column in a table — a temporary name. Aliases are often created for two purposes:\n",
    "1. To make output column names more readable (substitute names). \n",
    "2. To make queries more concise (shorten query arguments).\n",
    "\n",
    "### SQL Alias Syntax for Columns\n",
    "\n",
    "```*.sql\n",
    "SELECT column_name AS alias_name  \n",
    "FROM table_name;\n",
    "```\n",
    "\n",
    "### SQL Alias Syntax for Tables\n",
    "\n",
    "```*.sql\n",
    "SELECT column_name(s)  \n",
    "FROM table_name AS alias_name;\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487659f3",
   "metadata": {},
   "source": [
    "### Exercise #2\n",
    "\n",
    "Select `SupplierID` and `CompanyName` from the `Suppliers` table, aliasing these columns as `Supplier No.` and `Company Name`, respectively. Additionally, alias the `Suppliers` table as `S`. Order by `CompanyName` ascending."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24be79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "SQL_STRING = '''\n",
    "\n",
    "SELECT \"SupplierID\" AS \"Supplier No.\", \"CompanyName\" AS \"Company Name\"  \n",
    "FROM Suppliers AS S\n",
    "ORDER BY \"CompanyName\" ASC\n",
    "\n",
    "'''\n",
    "\n",
    "df = pd.read_sql(SQL_STRING, con=conn)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca40c364",
   "metadata": {},
   "source": [
    "**Aliases can be useful when:**\n",
    "\n",
    "- More than one table is involved in a query.\n",
    "- Functions are used in the query.\n",
    "- Column names are long and/or not very readable.\n",
    "- Two or more columns are combined together."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d22a062e",
   "metadata": {},
   "source": [
    "<a id='like-operator'></a>\n",
    "## SQL's `LIKE` Operator\n",
    "\n",
    "---\n",
    "\n",
    "The `LIKE` operator is used in a `WHERE` clause to search for a specific pattern within a column.\n",
    "\n",
    "\n",
    "### SQL `LIKE` Syntax\n",
    "\n",
    "```*.sql\n",
    "\n",
    "SELECT column_name(s) \n",
    "FROM table_name  \n",
    "WHERE column_name LIKE pattern;\n",
    "\n",
    "```\n",
    "\n",
    "> **Tip**: The `\"%\"` sign is used to define wildcards (missing letters) both before and after the pattern. Also, notice that PostgreSQL is case sensitive."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a2c994",
   "metadata": {},
   "source": [
    "### Exercise #3\n",
    "\n",
    "In descending order, select all products from the `Products` table with a `ProductName` that contains \"ch.\" Alias this column as `Ch Products`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0c2b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "SQL_STRING = '''\n",
    "\n",
    "SELECT \"ProductName\" AS \"Ch Products\"\n",
    "FROM Products\n",
    "WHERE \"ProductName\" LIKE '%ch%'\n",
    "ORDER BY \"ProductName\" DESC\n",
    "'''\n",
    "\n",
    "df = pd.read_sql(SQL_STRING, con=conn)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a2724f",
   "metadata": {},
   "source": [
    "### Exercise #4\n",
    "\n",
    "In ascending order, select cities from the `Suppliers` table with a `City` that starts with \"S.\" Alias this column as `S Cities`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c97ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "SQL_STRING = '''\n",
    "\n",
    "SELECT \"City\" AS \"S Cities\"\n",
    "FROM Suppliers\n",
    "WHERE \"City\" LIKE 'S%'\n",
    "ORDER BY \"S Cities\";\n",
    "'''\n",
    "\n",
    "df = pd.read_sql(SQL_STRING, con=conn)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e28f00",
   "metadata": {},
   "source": [
    "<a id='distinct'></a>\n",
    "## The `DISTINCT` operator\n",
    "\n",
    "---\n",
    "\n",
    "The `SELECT DISTINCT` statement is used to return _only_ distinct (unique) values. In a table, a column may contain many duplicate values; sometimes you'll only want to list the unique ones.\n",
    "\n",
    "### `SELECT DISTINCT` Syntax\n",
    "\n",
    "```*.sql\n",
    "\n",
    "SELECT DISTINCT column_name1, column_name2 \n",
    "FROM table_name;\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7481851",
   "metadata": {},
   "source": [
    "### Exercise #5\n",
    "\n",
    "`SELECT DISTINCT` `SupplierID`, `ProductName`, and `UnitPrice` from the `Products` table, ordering by `UnitPrice` ascending (i.e., the cheapest product for each supplier)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be58cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "SQL_STRING = '''\n",
    "\n",
    "SELECT DISTINCT \"SupplierID\", \"ProductName\", \"UnitPrice\"\n",
    "FROM Products as P\n",
    "ORDER BY P.\"UnitPrice\" ASC\n",
    "\n",
    "'''\n",
    "\n",
    "df = pd.read_sql(SQL_STRING, con=conn)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6027322e",
   "metadata": {},
   "source": [
    "<a id='limit'></a>\n",
    "\n",
    "## The `LIMIT` operator\n",
    "\n",
    "---\n",
    "\n",
    "Sometimes, we may want to only retrieve a fixed number of records from a database. This is where the `LIMIT` operator comes in handy.\n",
    "\n",
    "\n",
    "### `LIMIT` Syntax\n",
    "\n",
    "```*.sql\n",
    "\n",
    "SELECT column_name1, column_name2  \n",
    "FROM table_name\n",
    "LIMIT number_of_records;\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca0afeb",
   "metadata": {},
   "source": [
    "### Exercise #6\n",
    "\n",
    "In ascending order, return the five highest-priced products that contain an \"a\" in the product name. Alias the column as `Top 5 A Products`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1072af72",
   "metadata": {},
   "outputs": [],
   "source": [
    "SQL_STRING = '''\n",
    "\n",
    "SELECT sub.\"Top 5 A Products\", sub.\"UnitPrice\"\n",
    "FROM \n",
    "        (SELECT \"ProductName\" AS \"Top 5 A Products\", \"UnitPrice\"\n",
    "        FROM products\n",
    "        WHERE \"ProductName\" LIKE '%a%'\n",
    "        ORDER BY \"UnitPrice\" DESC  \n",
    "        LIMIT 5) AS sub\n",
    "        \n",
    "ORDER BY \"UnitPrice\" ASC\n",
    "\n",
    "'''\n",
    "\n",
    "# In this solution, we use a subquery. \n",
    "# First, create a query to get one subset.\n",
    "# Then, query the subset for a sub-subset.\n",
    "\n",
    "df = pd.read_sql(SQL_STRING, con=conn)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "981755f7",
   "metadata": {},
   "source": [
    "_**Tip:** If you are finding this one a bit tricky to execute in one query, check out [SQL Subqueries](https://www.tutorialspoint.com/sql/sql-sub-queries.htm)._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e45c36",
   "metadata": {},
   "source": [
    "<a id='group-by'></a>\n",
    "## `GROUP BY` Operator\n",
    "\n",
    "---\n",
    "\n",
    "A table may contain several records that have a common key. \n",
    "\n",
    "The `GROUP BY` statement is used in conjunction with aggregate functions to group a result set by one or more columns. For example, we may want to know the total number of items purchased in each order.\n",
    "\n",
    "### `GROUP BY` Syntax\n",
    "\n",
    "```*.sql\n",
    "SELECT column_name, aggregate_function(column_name)  \n",
    "FROM table_name  \n",
    "WHERE column_name operator value  \n",
    "GROUP BY column_name;\n",
    "```\n",
    "\n",
    "The aggregate functions you can use with `GROUP BY` are:\n",
    "- **`COUNT`**\n",
    "- **`MIN`**\n",
    "- **`MAX`**\n",
    "- **`SUM`**\n",
    "- **`AVG`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bafd375d",
   "metadata": {},
   "source": [
    "### Exercise #7\n",
    "\n",
    "From the `Order_details` table, show the count of orders per `OrderID`, as well as the `SUM` of the revenue (`UnitPrice * Quantity`). Order by revenue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646459e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "SQL_STRING = '''\n",
    "\n",
    "SELECT  \"OrderID\", COUNT(\"OrderID\"), SUM(\"UnitPrice\"*\"Quantity\") AS \"revenue\"\n",
    "FROM order_details\n",
    "GROUP BY \"OrderID\"\n",
    "ORDER BY 3 DESC;\n",
    "'''\n",
    "\n",
    "df = pd.read_sql(SQL_STRING, con=conn)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f0ea62",
   "metadata": {},
   "source": [
    "<a id='having'></a>\n",
    "## The `HAVING` operator\n",
    "\n",
    "---\n",
    "\n",
    "The `HAVING` clause was added to SQL because the `WHERE` keyword could not be used with aggregate functions. `HAVING` allows us to apply a filter while querying with them. For example, if we only wanted to show companies that had revenues greater than $10,000 (as calculated by an aggregate function).\n",
    "\n",
    "### `HAVING` Syntax\n",
    "\n",
    "``` *.sql\n",
    "\n",
    "SELECT column_name, aggregate_function(column_name)\n",
    "FROM table_name\n",
    "WHERE column_name operator value\n",
    "GROUP BY column_name\n",
    "HAVING aggregate_function(column_name) operator value;\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c42b502",
   "metadata": {},
   "source": [
    "### Exercise #8\n",
    "\n",
    "Show the revenue of all orders with more than one item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6765fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "SQL_STRING = '''\n",
    "\n",
    "SELECT  \"OrderID\",COUNT(\"OrderID\") AS OrderCount,SUM(\"UnitPrice\"*\"Quantity\") AS \"revenue\"\n",
    "FROM order_details\n",
    "GROUP BY \"OrderID\"\n",
    "HAVING COUNT(\"OrderID\") > 1\n",
    "ORDER BY \"revenue\" DESC;\n",
    "'''\n",
    "\n",
    "df = pd.read_sql(SQL_STRING, con=conn)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718b461f",
   "metadata": {},
   "source": [
    "<a id='case'></a>\n",
    "## `CASE` statements\n",
    "\n",
    "---\n",
    "\n",
    "The `CASE` statement is SQL’s way of applying `IF/THEN` logic. The `CASE` statement is followed by at least one pair of `WHEN` and `THEN` statements. It must end with an `END` statement. The `ELSE` statement is optional and provides a way to capture values not specified in the `WHEN/THEN` statements.\n",
    "\n",
    "### `CASE` Syntax\n",
    "\n",
    "```*.sql\n",
    "SELECT \n",
    "    CASE WHEN column_name operator value THEN 'string value1'\n",
    "        WHEN column_name operator value THEN 'string value2'\n",
    "        ELSE 'string value3' END AS 'alias'         \n",
    "FROM table_name\n",
    "```\n",
    "\n",
    "### A Pseudocode Example\n",
    "\n",
    "```*.sql\n",
    "SELECT name\n",
    "    CASE WHEN age < 1 THEN 'infant'\n",
    "         WHEN age < 2 THEN 'toddler'\n",
    "         WHEN age < 5 THEN 'child'\n",
    "         ELSE 'old as dirt' END AS 'Persons Age'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9a5100",
   "metadata": {},
   "source": [
    "### Exercise #9\n",
    "\n",
    "Select `CompanyName`, `City`, and `Country` from the `Suppliers` table. Add a new column, `D_F`, which contains a value of \"domestic\" if the supplier is from the United States and \"foreign\" if not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc5bdeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "SQL_STRING = '''\n",
    "\n",
    "SELECT \"CompanyName\", \"City\", \"Country\", \"D_F\"\n",
    "FROM (SELECT \"CompanyName\", \"City\", \"Country\",\n",
    "    CASE \n",
    "        WHEN \"Country\" = 'USA' \n",
    "        THEN 'domestic'\n",
    "        ELSE 'foreign'\n",
    "    END AS \"D_F\"\n",
    "FROM Suppliers) AS origin\n",
    "'''\n",
    "\n",
    "df = pd.read_sql(SQL_STRING, con=conn)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22450c7c",
   "metadata": {},
   "source": [
    "<a id='dates'></a>\n",
    "## Working With Dates\n",
    "\n",
    "---\n",
    "\n",
    "Take some time to look over the [PostgreSQL date documentation](https://www.postgresql.org/docs/8.1/static/functions-datetime.html).\n",
    "\n",
    "### Extracting Date Parts From a Date Object\n",
    "```*.sql\n",
    "SELECT my_date,\n",
    "       EXTRACT('year'   FROM my_date) AS year,\n",
    "       EXTRACT('month'  FROM my_date) AS month,\n",
    "       EXTRACT('day'    FROM my_date) AS day,\n",
    "       EXTRACT('hour'   FROM my_date) AS hour,\n",
    "       EXTRACT('minute' FROM my_date) AS minute,\n",
    "       EXTRACT('second' FROM my_date) AS second,\n",
    "       EXTRACT('decade' FROM my_date) AS decade,\n",
    "       EXTRACT('dow'    FROM my_date) AS day_of_week\n",
    "  FROM table_name\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa5011c",
   "metadata": {},
   "source": [
    "### Exercise #10\n",
    "\n",
    "Select `OrderDate` and `Freight` from the `Orders` table, along with three new columns for `Year`, `Month`, and `Day`. Make sure these are [_**cast**_ as integers, not floats](http://www.postgresqltutorial.com/postgresql-cast/).\n",
    "\n",
    "After extracting the dates as integers, pull out the `Year`, `Month`, and `SUM` of `Freight`, aliased as `FreightPerMonth`, grouping by the year and month, but only where the freight per month is greater than 5,000.\n",
    "\n",
    "Order this DataFrame by year and month descending."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c3f7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "SQL_STRING = '''\n",
    "\n",
    "SELECT \"year\", \"month\", SUM(\"Freight\") as \"FreightPerMonth\"\n",
    "FROM (SELECT \"OrderDate\",\n",
    "    CAST(EXTRACT(\"year\" from \"OrderDate\") AS Int) AS year,\n",
    "    CAST(EXTRACT('month' from \"OrderDate\") AS Int) AS month,\n",
    "    CAST(EXTRACT(day FROM \"OrderDate\") AS Int) AS day,\n",
    "    \"Freight\"\n",
    "FROM Orders) as sub\n",
    "GROUP BY year, month\n",
    "HAVING SUM(\"Freight\") > 5000\n",
    "ORDER BY year DESC, month DESC\n",
    "\n",
    "'''\n",
    "# Total freight per month\n",
    "df = pd.read_sql(SQL_STRING, con=conn)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22dc7f9b",
   "metadata": {},
   "source": [
    "<a id='additional-exercises'></a>\n",
    "\n",
    "### Exercise #11\n",
    "\n",
    "From the `Orders` table, find the average number of days it took to ship a package per `ShipCountry`. Only include orders that have a ship date, and only show the top five results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01828734",
   "metadata": {},
   "outputs": [],
   "source": [
    "SQL_STRING = '''\n",
    "\n",
    "SELECT AVG(\"ShippedDate\" - \"OrderDate\") as \"avg_shipping_time\", \"ShipCountry\"\n",
    "FROM orders\n",
    "WHERE \"ShippedDate\" IS NOT NULL\n",
    "GROUP BY \"ShipCountry\"\n",
    "ORDER BY \"avg_shipping_time\" DESC\n",
    "'''\n",
    "\n",
    "df = pd.read_sql(SQL_STRING, con=conn)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f63daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "SQL_STRING = '''\n",
    "\n",
    "SELECT \"ShippedDate\",\"OrderDate\",(\"ShippedDate\"-\"OrderDate\") AS diff\n",
    "FROM orders\n",
    "'''\n",
    "\n",
    "df = pd.read_sql(SQL_STRING, con=conn)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34bf578f",
   "metadata": {},
   "source": [
    "### Exercise #12\n",
    "\n",
    "In the `Orders` table, find the top five countries by average freight cost of products shipped in 1998."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a5f375",
   "metadata": {},
   "outputs": [],
   "source": [
    "SQL_STRING = '''\n",
    "\n",
    "SELECT \"ShipCountry\", AVG(\"Freight\") \"AvgFreight\"\n",
    "FROM orders\n",
    "WHERE CAST(EXTRACT(year FROM \"OrderDate\") AS Int) = 1998\n",
    "GROUP BY \"ShipCountry\"\n",
    "ORDER BY \"AvgFreight\" DESC\n",
    "LIMIT 5\n",
    "'''\n",
    "\n",
    "df = pd.read_sql(SQL_STRING, con=conn)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d80948a",
   "metadata": {},
   "source": [
    "### Exercise #13\n",
    "\n",
    "From the `Employees` table, find the two women who were hired the most recently. Exclude entries where gender is ambiguous.  \n",
    "_**Tip:** You may want to investigate the \"TitleOfCourtesy\" column._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4003ab18",
   "metadata": {},
   "outputs": [],
   "source": [
    "SQL_STRING = '''\n",
    "\n",
    "SELECT DISTINCT \"TitleOfCourtesy\"\n",
    "FROM employees\n",
    "'''\n",
    "\n",
    "df = pd.read_sql(SQL_STRING, con=conn)\n",
    "df"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
