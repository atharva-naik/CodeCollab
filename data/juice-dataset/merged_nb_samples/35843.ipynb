{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa75dfd9",
   "metadata": {},
   "source": [
    "# Model Analytics Project 2018\n",
    "\n",
    "**Author: Herman Dempere**\n",
    "\n",
    "Data filtering and several models evaluated.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24644646",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set dataset to use here\n",
    "dataset       = ma_grades_fill\n",
    "dataset_clean = ma_grades\n",
    "dataset_all   = ma_grades_all\n",
    "x_labels      = s1_mates_tag\n",
    "y_labels      = s2_mates_tag\n",
    "X_real    = raw_grades_mates[x_labels]\n",
    "Y_real    = raw_grades_mates[y_labels]\n",
    "\n",
    "# dataset       = law_grades_fill\n",
    "# dataset_clean = law_grades\n",
    "# dataset_all   = law_grades_all\n",
    "# x_labels      = s1_dret_tag\n",
    "# y_labels      = s2_dret_tag\n",
    "# X_real    = raw_grades_dret[x_labels]\n",
    "# Y_real    = raw_grades_dret[y_labels]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52fc2308",
   "metadata": {},
   "source": [
    "### Linear: LR Weighted Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812f3bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrs = dataset_clean[x_labels + y_labels].corr()[x_labels]\n",
    "\n",
    "def predict_student_subject(sid, subj):\n",
    "    pred = 0\n",
    "    tw = 0\n",
    "    \n",
    "    for s, c in corrs.loc[subj].iteritems():\n",
    "        g = X_real.loc[sid][s]\n",
    "        \n",
    "        if np.isnan(g):\n",
    "            continue\n",
    "            \n",
    "        w = g * c\n",
    "        pred += w\n",
    "        tw += c\n",
    "\n",
    "    if tw == 0:\n",
    "        return np.nan\n",
    "    return pred / tw\n",
    "\n",
    "def predict_row(row):\n",
    "    sid = row.name\n",
    "    pred_row = pd.Series(index=row.index)\n",
    "    for subj, _ in row.iteritems():\n",
    "        pred_row[subj] = predict_student_subject(sid, subj)\n",
    "        \n",
    "    return pred_row\n",
    "\n",
    "corr_pred = Y_real.apply(predict_row, axis=1)\n",
    "\n",
    "prediction_metrics(Y_real, corr_pred)\n",
    "plot_real_vs_predicted(Y_real, corr_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c98e033",
   "metadata": {},
   "source": [
    "### Non-Linear: KNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316095c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "knn = KNeighborsRegressor(weights=\"distance\", n_jobs=-1)\n",
    "knn_pred = fit_and_predict_model_loo(knn, dataset, x_labels, y_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c53173c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_metrics(Y_real, knn_pred)\n",
    "plot_real_vs_predicted(Y_real, knn_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35e9918",
   "metadata": {},
   "source": [
    "### Linear Model: Bayesian Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccaa5082",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "br = linear_model.BayesianRidge()\n",
    "br_pred = fit_and_predict_model_loo(br, dataset, x_labels, y_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa596184",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_metrics(Y_real, br_pred)\n",
    "# plot_real_vs_predicted(Y_real, br_pred)\n",
    "sns.set_style(\"white\")\n",
    "sns.set_context(\"poster\", font_scale=1.1)\n",
    "\n",
    "_x = Y_real.stack()\n",
    "_y = br_pred.stack()[_x.index]\n",
    "\n",
    "\n",
    "f = plt.figure(figsize=[10,6])\n",
    "ax1 = f.add_subplot(111, aspect='equal')\n",
    "\n",
    "# plt.axhspan(0,5, color=\"red\", alpha=0.1)\n",
    "plt.xlim(0,10)\n",
    "plt.ylim(0,10)\n",
    "\n",
    "# ax1.add_patch(patches.Rectangle((0, 0), 5, 5, color=\"green\", alpha=0.05))\n",
    "# ax1.add_patch(patches.Rectangle((5, 5), 5, 5, color=\"green\", alpha=0.05))\n",
    "# ax1.add_patch(patches.Rectangle((5, 0), 5, 5, color=\"red\", alpha=0.05))\n",
    "# ax1.add_patch(patches.Rectangle((0, 5), 5, 5, color=\"red\", alpha=0.05))\n",
    "\n",
    "marker_alpha = 0.6\n",
    "\n",
    "plt.scatter(_x.where(_x < 5), _y.where(_y >= 5), marker=\".\", color=\"#c03d3e\", alpha=marker_alpha)\n",
    "plt.scatter(_x.where(_x < 5), _y.where(_y < 5), marker=\".\", color=\"#3a923a\", alpha=marker_alpha)\n",
    "plt.scatter(_x.where(_x >= 5), _y.where(_y >= 5), marker=\".\", color=\"#3a923a\", alpha=marker_alpha)\n",
    "plt.scatter(_x.where(_x >= 5), _y.where(_y < 5), marker=\".\", color=\"#c03d3e\", alpha=marker_alpha)\n",
    "\n",
    "# plt.scatter(_x[_x < 5], _y[_x < 5], marker=\".\", color=\"red\", alpha=0.5)\n",
    "# plt.scatter(_x[_x >= 5], _y[_x >= 5], marker=\".\", color=\"green\", alpha=0.5)\n",
    "\n",
    "sns.regplot(_x,_y, marker=\".\", scatter_kws={'alpha':0}, line_kws={'color':\"black\", 'alpha':.5})\n",
    "\n",
    "# plt.plot([0,10],[0,10], color=\"black\", alpha=0.3)\n",
    "# plt.plot([0,10],[5,5], color=\"black\", alpha=0.1)\n",
    "# plt.plot([5,5],[0,10], color=\"black\", alpha=0.1)\n",
    "\n",
    "plt.xlabel(\"Ground truth\")\n",
    "plt.ylabel(\"BR Prediction\")\n",
    "\n",
    "plt.xticks(range(0,11,2))\n",
    "\n",
    "# plt.figure(figsize=[7,7])\n",
    "# _x.hist(density=True, range=[0,10], ec=\"black\", fill=False)\n",
    "# _y.hist(density=True, range=[0,10], ec=\"black\", fc=\"black\", alpha=0.1)\n",
    "# plt.ylabel(\"Density\")\n",
    "# plt.xlabel(\"Grade bin\")\n",
    "# plt.grid(False)\n",
    ";\n",
    "# _y[_x < 5 & _y >= 5].count()\n",
    "\n",
    "# print \"valid pass\", _x.where(_x >= 5).where(_y >= 5).count()\n",
    "# print \"valid fail\", _x.where(_x < 5).where(_y < 5).count()\n",
    "\n",
    "# print \"total\", _x.count()\n",
    "\n",
    "# sns.despine()\n",
    "\n",
    "# plt.figure(figsize=[6.75,1])\n",
    "# sns.distplot(_y.dropna())\n",
    "\n",
    "# sns.despine(left=True)\n",
    "# plt.yticks([])\n",
    "# plt.xticks(rotation=90)\n",
    "\n",
    "# plt.figure(figsize=[6.75,1])\n",
    "# sns.distplot(_x.dropna())\n",
    "\n",
    "# sns.despine(left=True)\n",
    "# plt.yticks([])\n",
    "\n",
    "# sns.jointplot(_x, _y, marker=\".\", kind=\"reg\", color=\"gray\", size=7)\n",
    "\n",
    "# plt.figure(figsize=[2,7])\n",
    "# sns.set_style(\"white\")\n",
    "# dat = pd.DataFrame([br_pred.stack().ravel(), Y_real.stack().ravel()])\n",
    "# dat = dat.transpose()\n",
    "# dat.columns = ['pred', 'real']\n",
    "# sns.violinplot(x='pred', y='real', data=dat, split=True, orient=\"v\")\n",
    "# sns.despine(left=True, bottom=True)\n",
    "\n",
    "# plt.yticks([])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee33a9d",
   "metadata": {},
   "source": [
    "### Ensemble Model: AdaBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed29f33",
   "metadata": {},
   "source": [
    "# Data Exploration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09a3f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ds = ma_grades_all.copy()\n",
    "\n",
    "# _ds = _ds[s1_mates_tag + s2_mates_tag]\n",
    "\n",
    "# _ds['mean'] = _ds.mean(axis=1)\n",
    "\n",
    "_x = _ds.iloc[:,0:10].mean(axis=1)\n",
    "_y = _ds.iloc[:,10:20].mean(axis=1)\n",
    "_z = _ds.iloc[:,20:30].mean(axis=1)\n",
    "\n",
    "\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "f = plt.figure(figsize=[7,7])\n",
    "ax1 = f.add_subplot(111, aspect='equal')\n",
    "\n",
    "plt.ylim([0,10])\n",
    "plt.xlim([0,10])\n",
    "\n",
    "plt.xlabel(\"Mean grade First year\")\n",
    "plt.ylabel(\"Mean grade Second / Third year\")\n",
    "\n",
    "plt.scatter(_x, _y, color=\"darkgreen\", marker=\"x\", alpha=.6)\n",
    "plt.scatter(_x, _z, color=\"orange\", alpha=.6)\n",
    "\n",
    "plt.legend(['2nd year', '3rd year'])\n",
    "\n",
    "# for x,(y,z) in zip(_x, zip(_y, _z)):\n",
    "#     plt.plot([x, z], [y, z], alpha=0.1)\n",
    "\n",
    "plt.plot([0,10],[0,10], color=\"black\", alpha=.3)\n",
    "plt.plot([0,10],[5,5], color=\"red\", alpha=.3)\n",
    "plt.plot([5,5],[0,10], color=\"red\", alpha=.3)\n",
    "\n",
    "ax1.add_patch(\n",
    "    patches.Rectangle(\n",
    "        (0, 0), 5, 5, color=\"red\", alpha=0.05\n",
    "    )\n",
    ")\n",
    "# plt.axhspan(0,5, color='red', alpha=0.05)\n",
    "\n",
    "\n",
    "# plt.figure(figsize=[7,7])\n",
    "# plt.hist(_ds.iloc[:,0:10].stack().ravel(), density=True, range=[0,10])\n",
    "# plt.hist(_ds.iloc[:,0:10].stack().ravel(), histtype=\"step\", density=True, range=[0,10])\n",
    "# plt.hist(_y.dropna(), density=True, range=[0,10])\n",
    "# plt.hist(_z.dropna(), density=True, range=[0,10])\n",
    "\n",
    "# plt.figure(figsize=[16,8])\n",
    "# sns.violinplot(data=cs_grades_all.iloc[:,20:30])\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e50f62",
   "metadata": {},
   "source": [
    "## Helper Functions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36620c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn import metrics\n",
    "\n",
    "def train_and_predict(model, X_train, Y_train, X_test, Y_test):\n",
    "    columns = Y_test.columns\n",
    "    \n",
    "    Y_pred = pd.DataFrame(index=Y_test.index)\n",
    "    \n",
    "    for subject in columns:\n",
    "        subject = [subject]\n",
    "        model.fit(X_train, Y_train[subject])\n",
    "        partial_pred = pd.DataFrame(model.predict(X_test), index=Y_test[subject].index, columns=subject)\n",
    "        Y_pred[subject] = partial_pred\n",
    "        \n",
    "        \n",
    "    return Y_pred\n",
    "  \n",
    "\n",
    "def fit_and_predict_model(model, XY, X_labels, Y_labels, train_size=0.2):\n",
    "    ''' Split in train and test, train model and run predictions for all output vectors '''\n",
    "    train, test = train_test_split(XY, random_state=0, train_size=train_size)\n",
    "    X_train = train[X_labels]\n",
    "    Y_train = train[Y_labels]\n",
    "    X_test = test[X_labels]\n",
    "    Y_test = test[Y_labels]\n",
    "    \n",
    "    Y_pred = train_and_predict(model, X_train, Y_train, X_test, Y_test)\n",
    "\n",
    "    # # Quantize prediction to nearest .5\n",
    "    # Y_pred = (Y_pred * 2).round(0) / 2\n",
    "\n",
    "    return X_test, Y_test, Y_pred\n",
    "\n",
    "\n",
    "def fit_and_predict_model_loo(model, XY, X_labels, Y_labels):\n",
    "    ''' Fit model on N-1 samples and Predict last sample '''\n",
    "    \n",
    "    loo = LeaveOneOut()\n",
    "    \n",
    "    X = XY[X_labels]\n",
    "    Y = XY[Y_labels]\n",
    "    \n",
    "    nsplits = loo.get_n_splits(X)\n",
    "    \n",
    "    Y = XY[Y_labels]\n",
    "    \n",
    "    Y_pred = pd.DataFrame(columns=Y.columns)\n",
    "    split = 1\n",
    "    \n",
    "    for train_idx, test_idx in loo.split(X):\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        Y_train, Y_test = Y.iloc[train_idx], Y.iloc[test_idx]\n",
    "        \n",
    "        Y_pred_sample = train_and_predict(model, X_train, Y_train, X_test, Y_test)\n",
    "        \n",
    "        Y_pred = pd.concat([Y_pred, Y_pred_sample])\n",
    "        \n",
    "        split += 1\n",
    "        \n",
    "    return Y_pred\n",
    "\n",
    "def plot_real_vs_predicted(Y_real, Y_pred):\n",
    "    f = plt.figure(figsize=[12,8])\n",
    "    plt.title(\"Real vs Predicted Scatter\")\n",
    "\n",
    "    plt.plot([0,10], [0,10], color=\"green\", alpha=0.3)\n",
    "    plt.plot([0,10], [5,5], color=\"red\", alpha=0.3)\n",
    "\n",
    "    plt.xlabel(\"Real Grade\")\n",
    "    plt.ylabel(\"Predicted Grade\")\n",
    "    \n",
    "    _x = Y_real.stack()\n",
    "    _y = Y_pred.stack()[_x.index]\n",
    "\n",
    "    plt.scatter(_x.ravel(), _y.ravel(), alpha=0.5, marker=\".\")\n",
    "\n",
    "    f = plt.figure(figsize=[12,3])\n",
    "    plt.title(\"Histogram\")\n",
    "\n",
    "    plt.hist(Y_real.stack(), alpha=0.4, color=\"blue\", bins=20, range=[0,10], density=True)\n",
    "    plt.hist(Y_pred.stack(), alpha=0.4, color=\"yellow\", bins=20, range=[0,10], density=True)\n",
    "    \n",
    "    plt.legend(['Real Grade', 'Predicted Grade'])\n",
    "    \n",
    "def prediction_metrics(Y_real, Y_pred, verbose=True):\n",
    "    err     = (Y_real - Y_pred)\n",
    "    bias    = err.mean().mean()\n",
    "    err_std = err.std().mean()\n",
    "    mae     = (err).abs().mean().mean()\n",
    "    rmse    = np.sqrt((err*err).mean()).mean()    \n",
    "    \n",
    "    if verbose:\n",
    "        print \"BIAS     \", bias\n",
    "        print \"ERR STD  \", err_std\n",
    "        print \"MAE      \", mae\n",
    "        print \"RMSE     \", rmse\n",
    "\n",
    "    return bias, err_std, mae, rmse\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e45e2a1",
   "metadata": {},
   "source": [
    "## Baseline model: Mean Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66223353",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = cs_grades_all\n",
    "# labels_x = s1_info_tag\n",
    "# labels_y = s2_info_tag\n",
    "\n",
    "dataset = ma_grades_all\n",
    "labels_x = s1_mates_tag\n",
    "labels_y = s2_mates_tag\n",
    "\n",
    "# dataset = lw_grades_all\n",
    "# labels_x = s1_dret_tag\n",
    "# labels_y = s2_dret_tag\n",
    "\n",
    "item_mean = dataset[labels_y].mean()\n",
    "user_mean = dataset[labels_x].mean(axis=1)\n",
    "\n",
    "def predict_ss_mean_item(sid, subj):\n",
    "    return item_mean[subj]\n",
    "\n",
    "def predict_ss_mean_user(sid, subj):\n",
    "    return user_mean[sid]\n",
    "    \n",
    "def predict_row(row, fn):\n",
    "    sid = row.name\n",
    "    pred_row = pd.Series(index=row.index)\n",
    "    for subj, _ in row.iteritems():\n",
    "        pred_row[subj] = fn(sid, subj)\n",
    "        \n",
    "    return pred_row\n",
    "\n",
    "Y_pred = dataset[labels_y].apply(lambda x: predict_row(x, predict_ss_mean_item), axis=1)\n",
    "print \"Item Mean\"\n",
    "prediction_metrics(dataset[labels_y], Y_pred)\n",
    "\n",
    "print \"\"\n",
    "\n",
    "Y_pred = dataset[labels_y].apply(lambda x: predict_row(x, predict_ss_mean_user), axis=1)\n",
    "print \"User Mean\"\n",
    "prediction_metrics(dataset[labels_y], Y_pred);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0673d7ee",
   "metadata": {},
   "source": [
    "## Various Models Evaluated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69368a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "ada = AdaBoostRegressor()\n",
    "ada_pred = fit_and_predict_model_loo(ada, dataset, x_labels, y_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f195247",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_metrics(Y_real, ada_pred)\n",
    "plot_real_vs_predicted(Y_real, ada_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af86f577",
   "metadata": {},
   "source": [
    "### Ensemble Model: RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876df795",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf = RandomForestRegressor()\n",
    "rf_pred  = fit_and_predict_model_loo(rf, dataset, x_labels, y_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5d91fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_metrics(Y_real, rf_pred)\n",
    "plot_real_vs_predicted(Y_real, rf_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75240f71",
   "metadata": {},
   "source": [
    "### Ensemble Model: GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57465c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "gb = GradientBoostingRegressor()\n",
    "gb_pred  = fit_and_predict_model_loo(gb, dataset, x_labels, y_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de5d18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_metrics(Y_real, gb_pred)\n",
    "plot_real_vs_predicted(Y_real, gb_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d858d168",
   "metadata": {},
   "source": [
    "## Visualization of Predicted Grades by Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdffb746",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Informatica\n",
    "s1_info = [364288, 364289, 364290, 364291, 364292, 364293, 364294, 364298, 364299, 364301]\n",
    "s1_info_tag = ['P1', 'DDB', 'IO', 'ALGE', 'CAL', 'MD', 'FIS', 'ALGO', 'P2', 'ED']\n",
    "s2_info = [364297, 364300, 364303, 364305, 364302, 364296, 364295, 364306, 364304, 364307]\n",
    "s2_info_tag = ['ELEC', 'AA', 'DS', 'EC', 'ICC', 'EMP', 'PIE', 'PAE', 'PIS', 'SO1']\n",
    "s3_info = [364314, 364308, 364322, 364315, 364309, 364311, 364323, 364328, 364310, 364312]\n",
    "s3_info_tag = ['IA', 'SO2', 'TNUI', 'VA', 'XAR', 'BD', 'FHIC', 'GiVD', 'LIL', 'SWD']\n",
    "\n",
    "info_ids = s1_info + s2_info + s3_info\n",
    "info_tags = s1_info_tag + s2_info_tag + s3_info_tag\n",
    "\n",
    "# Matematiques\n",
    "s1_mates = [360142, 360140, 360136, 360138, 360134, 360135, 360139, 360143, 360137, 360141]\n",
    "s1_mates_tag = ['ADIP', 'ELPR', 'IACD', 'LIRM', 'MAVE', 'ALLI', 'ARIT', 'FISI', 'IACI', 'PRCI']\n",
    "s2_mates = [360144, 360148, 360151, 360150, 360146, 360145, 360152, 360161, 360153, 360155]\n",
    "s2_mates_tag = ['CDDV', 'ESAL', 'GELI', 'GRAF', 'MNU1', 'CIDV', 'GEPR', 'HIMA', 'MMSD', 'TOPO']\n",
    "s3_mates = [360158, 360149, 360156, 360147, 360162, 360159, 360154, 360163, 360160, 360157]\n",
    "s3_mates_tag = ['ANMA', 'EQAL', 'GDCS', 'MNU2', 'PROB', 'ANCO', 'EQDI', 'ESTA', 'MODE', 'TGGS']\n",
    "\n",
    "mates_ids = s1_mates + s2_mates + s3_mates\n",
    "mates_tags = s1_mates_tag + s2_mates_tag + s3_mates_tag\n",
    "\n",
    "# Dret\n",
    "s1_dret      = [362441, 362442, 362444, 362451, 362446, 362443, 362452, 362449, 362450, 362447] \n",
    "s1_dret_tag  = ['TTC', 'CP', 'FDD', 'DRO', 'PIC', 'EC', 'SDL', 'FDPTD', 'HD', 'DCP']\n",
    "s2_dret      = [362448, 362453, 362454, 362456, 362459, 362461, 362469, 362458]\n",
    "s2_dret_tag  = ['OTE', 'PD', 'DOC', 'DIC', 'DFT', 'FDA', 'DPC', 'IDCE']\n",
    "s3_dret      = [362507, 362460, 362462, 362466, 362465, 362470, 362467, 362463]\n",
    "s3_dret_tag  = ['DR', 'PST', 'CAA', 'DEM', 'DTS', 'DPP', 'DS', 'BPU']\n",
    "\n",
    "dret_ids     = s1_dret + s2_dret + s3_dret\n",
    "dret_tags    = s1_dret_tag + s2_dret_tag + s3_dret_tag\n",
    "\n",
    "# Educacio\n",
    "s1_edu       = [361020, 361032, 361039, 361041, 361044, 361046, 361047, 361049, 361094]\n",
    "s1_edu_tag   = ['PIP', 'PED', 'PDAA', 'AT', 'SOC', 'LCAT', 'LESP', 'DIDA', 'LENG']\n",
    "s2_edu       = [361029, 361036, 361051, 361069, 361072, 361087, 361091, 361099, 361704]\n",
    "s2_edu_tag   = ['INCL', 'SEOE', 'DIDC', 'DIDM', 'CINA', 'PLST', 'EDFI', 'PRAC', 'DGEO']\n",
    "\n",
    "edu_ids      = s1_edu + s2_edu\n",
    "dret_tags    = s1_edu_tag + s2_edu_tag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2c3ce4",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45bd906e",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_grades_mates = pd.read_csv(\"data/grades_mates_2010-2016.csv\", index_col=0)\n",
    "raw_grades_info  = pd.read_csv(\"data/grades_info_2011-2017.csv\", index_col=0)\n",
    "raw_grades_edu   = pd.read_csv(\"data/grades_edu_2009-2014.csv\", index_col=0)\n",
    "raw_grades_dret  = pd.read_csv(\"data/grades_dret_2009-2015.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0721d20",
   "metadata": {},
   "source": [
    "# Prepare Data for Models\n",
    "\n",
    "## Data Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16d2ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_dataset(grades, t1, t2, t3, th1=8, th2=7, th3=0, gt=11, fill=\"row\"):\n",
    "    ''' Pivots raw datasets and cleans / fills missing data, returns tuple of filtered, all and filled'''\n",
    "    _grades = grades.copy()\n",
    "    _grades_all = _grades.copy()\n",
    "\n",
    "    # Separate by year, apply threshold, rejoin\n",
    "    _grades_first = _grades[t1]\n",
    "    _grades_first = _grades_first.dropna(thresh=th1)\n",
    "\n",
    "    _grades_second = _grades[t2]\n",
    "    _grades_second = _grades_second.dropna(thresh=th2)\n",
    "\n",
    "    _grades_third = _grades[t3]\n",
    "    _grades_third = _grades_third.dropna(thresh=th3)\n",
    "\n",
    "    # # Join back as \"inner\"\n",
    "    _grades = _grades_first.join(_grades_second, how=\"inner\").join(_grades_third, how=\"inner\")\n",
    "\n",
    "    print \"all samples      \", _grades_all.count().sum()\n",
    "    print \"cleaned samples  \", _grades.count().sum()\n",
    "    print \"total students   \", _grades_all.shape[0]\n",
    "    print \"sampled students \", _grades.shape[0]\n",
    "\n",
    "    if fill != 'row':\n",
    "        # Fill with column mean\n",
    "        _grades_fill = _grades.fillna(_grades.mean().round(1))\n",
    "        \n",
    "    else:\n",
    "        # Fill with row mean\n",
    "        _row_mean = pd.DataFrame({col: _grades.mean(axis=1).round(1) for col in _grades.columns})\n",
    "        _grades_fill = _grades.fillna(_row_mean)\n",
    "    \n",
    "    return _grades, _grades_all, _grades_fill\n",
    "\n",
    "print \"Matematiques\"\n",
    "ma_grades, ma_grades_all, ma_grades_fill = filter_dataset(raw_grades_mates,\n",
    "    s1_mates_tag, s2_mates_tag, s3_mates_tag, fill=\"col\")\n",
    "\n",
    "print \"\\nInformatica\"\n",
    "cs_grades, cs_grades_all, cs_grades_fill = filter_dataset(raw_grades_info,\n",
    "    s1_info_tag, s2_info_tag, s3_info_tag, fill=\"col\")\n",
    "\n",
    "print \"\\nEducacio\"\n",
    "edu_grades, edu_grades_all, edu_grades_fill = filter_dataset(raw_grades_edu,\n",
    "    s1_edu_tag, s2_edu_tag, [], fill=\"col\")\n",
    "\n",
    "print \"\\nDret\"\n",
    "law_grades, law_grades_all, law_grades_fill = filter_dataset(raw_grades_dret,\n",
    "    s1_dret_tag, s2_dret_tag, s3_dret_tag, fill=\"col\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4a410a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = linear_model.BayesianRidge()\n",
    "\n",
    "X_train, Y_train = cs_grades[s1_info_tag], cs_grades[s2_info_tag]\n",
    "\n",
    "cs_grades_fill = cs_grades_fill.fillna(cs_grades.mean())\n",
    "\n",
    "X_test, Y_test = cs_grades_fill[s1_info_tag], cs_grades_fill[s2_info_tag]\n",
    "X_test, Y_test = cs_grades_fill[s1_info_tag], cs_grades_fill[s2_info_tag]\n",
    "\n",
    "Y_pred = train_and_predict(model, X_train, Y_train, X_test, Y_test)\n",
    "Y_pred = (Y_pred * 4).round(0) / 4\n",
    "\n",
    "# for subj in Y_pred.columns:\n",
    "\n",
    "#     plt.figure(figsize=[16,2])\n",
    "#     plt.title(subj)\n",
    "#     # Y_test['ELEC'].plot()\n",
    "#     plt.scatter(range(len(Y_test)), Y_test[subj].sort_values())\n",
    "#     plt.scatter(range(len(Y_pred)), Y_pred[subj].sort_values())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65fd0cbb",
   "metadata": {},
   "source": [
    "## Pass or Fail Future Subject KNN Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af32caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "csg_train, csg_test = train_test_split(cs_grades, random_state=0)\n",
    "X_train = csg_train[s1_info_tag]\n",
    "Y_train = csg_train[s2_info_tag]\n",
    "X_test = csg_test[s1_info_tag]\n",
    "Y_test = csg_test[s2_info_tag]\n",
    "\n",
    "# Convert to two factor\n",
    "Y_train = Y_train.apply(lambda x : x >= 5)\n",
    "Y_test = Y_test.apply(lambda x : x >= 5)\n",
    "\n",
    "knn = KNeighborsClassifier(weights=\"distance\")\n",
    "knn.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred = pd.DataFrame(knn.predict(X_test), index=X_test.index, columns=Y_test.columns)\n",
    "\n",
    "def eval_class(Y_test, Y_pred):\n",
    "    err = Y_test != Y_pred\n",
    "    \n",
    "    matrixes = []\n",
    "    for col in Y_pred.columns:\n",
    "        cm = metrics.confusion_matrix(Y_test[col], Y_pred[col]).ravel()\n",
    "        if cm.shape[0] == 1:\n",
    "            cm = np.array( [0, 0, 0, cm[0] ])\n",
    "        matrixes += [cm]\n",
    "\n",
    "    tn, fp, fn, tp = sum(matrixes)\n",
    "\n",
    "    prec   = float(tp) / (tp + tn)\n",
    "    recall  = float(tp) / (tp + fn)\n",
    "    f1     = 2. / (1./recall + 1./prec)\n",
    "\n",
    "    mean_error = err[err == True].count() / err.count()\n",
    "    \n",
    "    cm = [[tp, fp],\n",
    "          [fn, tn]]\n",
    "    \n",
    "    cm = pd.DataFrame(cm, index=['Pred True', 'Pred False'], columns=['Real True','Real False'])\n",
    "\n",
    "    print \"Precision\", prec.mean()\n",
    "    print \"Recall\", recall.mean()\n",
    "    print \"F1\", f1.mean()\n",
    "    print \"Mean Error\", mean_error.mean()\n",
    "    \n",
    "    return cm\n",
    "\n",
    "print \"Classification Report\"\n",
    "print metrics.classification_report(Y_test, Y_pred)\n",
    "\n",
    "eval_class(Y_test, Y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d56f18",
   "metadata": {},
   "source": [
    "## Pass or Fail Future Subject Random Forest Clasifier"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
