{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a552f5c",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\">Peter Norvig, Feb 2017</div>\n",
    "\n",
    "# BASIC Interpreter\n",
    "\n",
    "[Years ago](http://norvig.com/lispy.html), I showed how to write an Interpreter for a dialect of Lisp. Some readers appreciated it, and some asked about an interpreter for a language that isn't just a bunch of parentheses. In 2014 I saw a [celebration](http://time.com/69316/basic/) of the 50th anniversary of the 1964 [Dartmouth BASIC](http://web.archive.org/web/20120716185629/http://www.bitsavers.org/pdf/dartmouth/BASIC_Oct64.pdf) interpreter, and thought that I could show how to implement such an interpreter.  I never quite finished in 2014, but in 2017 I rediscovered my unfinished file and completed it. For those of you unfamiliar with BASIC, here is a sample program:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c5fad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "program = '''\n",
    "10 REM POWER TABLE\n",
    "11 DATA 8,  4\n",
    "15 READ N0, P0\n",
    "20 PRINT \"N\",\n",
    "25 FOR P = 2 to P0\n",
    "30   PRINT \"N ^\" P,\n",
    "35 NEXT P\n",
    "40 PRINT \"SUM\"\n",
    "45 LET S = 0\n",
    "50 FOR N = 2 TO N0\n",
    "55   PRINT N,\n",
    "60   FOR P = 2 TO P0\n",
    "65     LET S = S + N ^ P\n",
    "70     PRINT N ^ P,\n",
    "75   NEXT P\n",
    "80   PRINT S\n",
    "85 NEXT N\n",
    "99 END\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7367b1fa",
   "metadata": {},
   "source": [
    "Of course I don't have to build everything from scratch in assembly language, and I don't have to worry about every byte of storage, like [Kemeny](http://www.dartmouth.edu/basicfifty/basic.html), [Gates](http://www.pagetable.com/?p=774), and [Woz](http://www.retrothing.com/2008/07/restoring-wozs.html) did, so my job is much easier.  The interpreter consists of three phases: \n",
    "* **Tokenization**: breaking a text into a list of tokens, for example: `\"10 READ N\"` becomes `['10', 'READ', 'N']`.\n",
    "* **Parsing**: building an executable representation from the tokens, so this statement becomes: `Stmt(num=10, typ='READ', args=['N'])`.\n",
    "* **Execution**: follow the flow of the program and do what each statement says; in this case an assignment: `variables['N'] = data.popleft()`.\n",
    "\n",
    "\n",
    "\n",
    "# Tokenization\n",
    "\n",
    "One way to turn a line of text into a list of tokens is with the `findall` method of a regular expression that defines all the legal tokens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb496386",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "\n",
    "tokenize = re.compile(\n",
    "    r'''\\d* \\.? \\d+ (?: E -? \\d+)?                 | # number \n",
    "    SIN|COS|TAN|ATN|EXP|ABS|LOG|SQR|RND|INT|FN[A-Z]| # functions (including user-defined FNA-FNZ)\n",
    "    LET|READ|DATA|PRINT|GOTO|IF|FOR|NEXT|END|STOP  | # keywords\n",
    "    DEF|GOSUB|RETURN|DIM|REM|TO|THEN|STEP          | # more keywords\n",
    "    [A-Z]\\d? | # variable names (letter optionally followed by a digit)\n",
    "    \" .*? \"  | # labels (strings in double quotes)\n",
    "    <>|>=|<= | # multi-character relational operators\n",
    "    \\S         # any non-space single character ''', \n",
    "    re.VERBOSE).findall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604883af",
   "metadata": {},
   "source": [
    "The only complicated part is the syntax for numbers: optional digits followed by an optional decimal point, some digits, and optionally a power of 10 marked by `\"E\"` and followed by an (optional) minus sign and some digits. \n",
    "Example usage of `tokenize`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98dd9f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenize('10 READ N')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629f408c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenize('100 PRINT \"SIN(X)^2 = \", SIN(X) ^ 2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e984658",
   "metadata": {},
   "source": [
    "That looks good. Note that  my tokens are just strings; it will be the parser's job, not the tokenizer's, to recognize that `'2'` is a number and  `'X'` is the name of a variable.  (In some interpreters, the tokenizer makes  distinctions like these.)\n",
    "\n",
    "There's one important complication: spaces don't matter in BASIC programs, so the following should all be equivalent:\n",
    "\n",
    "    10 GOTO 99\n",
    "    10GOTO99\n",
    "    10 GO TO 99\n",
    "    \n",
    "The problem is that  `tokenize` gets the last one wrong:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037dfae3",
   "metadata": {},
   "source": [
    "# Running the First Sample Program\n",
    "\n",
    "Let's re-examine, parse, and run our first sample program:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8af960",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(program)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b30686",
   "metadata": {},
   "outputs": [],
   "source": [
    "parse(program)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b4df26",
   "metadata": {},
   "outputs": [],
   "source": [
    "run(program)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2433e92c",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Running More Programs\n",
    "\n",
    "Rather than put together a suite of unit tests for `execute`, I'll run integration tests&mdash;additional whole programs. I've also added a few assertions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec67b4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear equation solver (page 3 and 19 of the manual)\n",
    "\n",
    "run('''\n",
    "10 READ A1, A2, A3, A4\n",
    "15 LET D = A1 * A4 - A3 * A2\n",
    "20 IF D = 0 THEN 65\n",
    "30 READ B1, B2\n",
    "37   LET X1 = (B1*A4 - B2 * A2) / D\n",
    "42   LET X2 = ( A1 * B2 - A3 * B1)/D\n",
    "55   PRINT X1, X2\n",
    "60 GOTO 30\n",
    "65 PRINT \"NO UNIQUE SOLUTION\"\n",
    "70 DATA 1, 2, 4\n",
    "80 DATA 2, -7, 5\n",
    "85 DATA 1, 3, 4, -7\n",
    "90 END\n",
    "''')\n",
    "\n",
    "assert variables['D'] != 0\n",
    "assert variables['X1'] == -11/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6104cb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find max(sin(x)) for 0 <= x <= 3 (page 25)\n",
    "\n",
    "run('''\n",
    "5 PRINT \"X VALUE\", \"SINE\", \"RESOLUTION\"\n",
    "10 READ D\n",
    "20   LET M = -1\n",
    "30   FOR X = 0 TO 3 STEP D\n",
    "40   IF SIN(X) <= M THEN 80\n",
    "50     LET X0 = X\n",
    "60     LET M = SIN(X)\n",
    "80   NEXT X\n",
    "85   PRINT X0, M, D\n",
    "90 GO TO 10\n",
    "95 DATA .1, .01, .001, .0001\n",
    "99 END\n",
    "''')\n",
    "\n",
    "assert abs(variables['X0'] - math.pi / 2) < 0.00001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc9e708",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing (page 32)\n",
    "\n",
    "run('''\n",
    "10 FOR I = 1 TO 12\n",
    "20   PRINT I,\n",
    "30 NEXT I\n",
    "40 END''')\n",
    "\n",
    "assert variables['I'] == 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38e461a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Powers (page 33)\n",
    "\n",
    "run('''\n",
    " 5 PRINT \"THIS PROGRAM COMPUTES AND PRINTS THE NTH POWERS\"\n",
    " 6 PRINT \"OF THE NUMBERS LESS THAN OR EQUAL TO N FOR VARIOUS\"\n",
    " 7 PRINT \"N FROM 1 TO 7\"\n",
    " 8 PRINT\n",
    "10 FOR N = 1 TO 7\n",
    "15   PRINT \"N = \"; N; \"I^N:\"\n",
    "20   FOR I = 1 TO N\n",
    "30     PRINT I^N,\n",
    "40   NEXT I\n",
    "50   PRINT\n",
    "60   PRINT\n",
    "70 NEXT N\n",
    "80 END''')\n",
    "\n",
    "assert variables['N'] ** variables['I'] == 7 ** 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896a33be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cubes (page 35; but with STEP -2 because I haven't tested negative step yet)\n",
    "\n",
    "run('''\n",
    "10 FOR I = 100 TO 0 STEP -2\n",
    "20   PRINT I*I*I;\n",
    "30 NEXT I\n",
    "40 END\n",
    "''')\n",
    "\n",
    "assert variables['I'] == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b8c9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sales ledger (page 37; cleaned up a bit)\n",
    "\n",
    "run('''\n",
    "10  FOR I = 1 TO 3\n",
    "20    READ P(I)\n",
    "30  NEXT I\n",
    "40  FOR I = 1 TO 3\n",
    "50    FOR J = 1 TO 5\n",
    "60      READ S(I, J)\n",
    "70    NEXT J\n",
    "80  NEXT I\n",
    "90  FOR J = 1 TO 5\n",
    "100   LET S = 0\n",
    "110   FOR I = 1 TO 3\n",
    "120     LET S = S + P(I) * S(I, J)\n",
    "130   NEXT I\n",
    "140   PRINT \"TOTAL SALES FOR SALESMAN\"J, \"$\"S\n",
    "150 NEXT J\n",
    "190 DIM S(3, 5)\n",
    "200 DATA 1.25, 4.30, 2.50\n",
    "210 DATA 40, 20, 37, 29, 42\n",
    "220 DATA 10, 16, 3, 21, 8\n",
    "230 DATA 35, 47, 29, 16, 33\n",
    "300 END\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09da526",
   "metadata": {},
   "source": [
    "We can look at the variables that have been stored for this program:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f118266d",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d276a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random number generator (page 40)\n",
    "\n",
    "run('''\n",
    "10 FOR I = 1 TO 100\n",
    "20   PRINT INT(10 * RND(X));\n",
    "30 NEXT I\n",
    "40 END\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c92d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEF example: table of SIN(X) and COS(X) in degrees (page 41, expanded some)\n",
    "\n",
    "run('''\n",
    " 5 PRINT \"D\"; \"SIN(D)\", \"COS(D)\", \"SIN(D)^2 + COS(D)^2\"\n",
    "20 LET P = 3.1415926535897932 / 180\n",
    "30 FOR X = 0 TO 90 STEP 15\n",
    "40   PRINT X; FNS(X), FNC(X), FNS(X)^2 + FNC(X)^2\n",
    "50 NEXT X\n",
    "97 DEF FNS(D) = SIN(D * P)\n",
    "98 DEF FNC(D) = COS(D * P)\n",
    "99 END\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2cab3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GOSUB (page 43)\n",
    "\n",
    "run('''\n",
    "100 LET X = 3\n",
    "110 GOSUB 400\n",
    "120 PRINT U, V, W\n",
    "200 LET X = 5\n",
    "210 GOSUB 400\n",
    "215 PRINT U, V, W\n",
    "220 LET Z = U + 2*V + 3*W\n",
    "230 PRINT \"Z = \" Z\n",
    "240 STOP\n",
    "400 LET U = X*X\n",
    "410 LET V = X*X*X\n",
    "420 LET W = X*X*X*X + X*X*X + X*X + X\n",
    "430 RETURN\n",
    "440 END\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0794bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum of non-negative multiples of 0.1 less than or equal to 2, two ways (page 47)\n",
    "\n",
    "run('''\n",
    " 5 LET S = 0\n",
    "10 LET N = 0\n",
    "20 LET S = S + N/10\n",
    "30   IF N >= 20 THEN 60\n",
    "40   LET N = N + 1\n",
    "50 GOTO 20\n",
    "60 PRINT S\n",
    "70 END\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fadd5875",
   "metadata": {},
   "outputs": [],
   "source": [
    "run('''\n",
    "20 FOR N = 1 TO 20\n",
    "40   LET S = S + N/10\n",
    "50 NEXT N\n",
    "60 PRINT S\n",
    "70 END\n",
    "''')\n",
    "\n",
    "assert variables['S'] == sum(N/10 for N in range(1, 21))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac3168c",
   "metadata": {},
   "source": [
    "# Checking for Syntax Errors\n",
    "\n",
    "Here we show a collection of syntax errors, and the messages they generate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6936ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "run('''\n",
    "10 X = 1\n",
    "20 GO TO JAIL\n",
    "30 FOR I = 1 \n",
    "40 IF X > 0 & X < 10 GOTO 999\n",
    "50 LET Z = (Z + 1\n",
    "60 PRINT \"OH CANADA\", EH?\n",
    "70 LET Z = +3\n",
    "80 LET X = Y ** 2\n",
    "90 LET A(I = 1\n",
    "100 IF A = 0 THEN 900 + 99\n",
    "110 NEXT A(I)\n",
    "120 DEF F(X) = X ^ 2 + 1\n",
    "130 IF X != 0 THEN 999\n",
    "140 DEF FNS(X + 2*P1) = SIN(X)\n",
    "150 DEF FNY(M, B) = M * X + B\n",
    "160 LET 3 = X\n",
    "170 LET SIN = 7 * DEADLY\n",
    "180 LET X = A-1(I)\n",
    "STOP\n",
    "200 STOP IT, ALREADY\n",
    "998 PRINT \"PROGRAM STILL EXECUTES: 2 + 2 = \" 2 + 2\n",
    "999 END\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685ef098",
   "metadata": {},
   "source": [
    "# Final Program\n",
    "\n",
    "Now for a final, longer example, Conway's Game of [Life](https://en.wikipedia.org/wiki/Conway's_Game_of_Life),\n",
    "which shows that BASIC is capable of handling a non-trivial problem&mdash;but I wouldn't want to rely on it for anything much bigger. This should give us some added confidence in the validity of the interpreter, but I would say the interpreter needs more work before I would trust it. I hope you found working through the interpreter informative, and maybe you have ideas for how to improve it, or to develop an interpreter for another language."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1742f566",
   "metadata": {},
   "source": [
    "Note that `varname` means an unsubscripted variable name (a letter  by itself, like `X`, or followed by a digit, like `X3`), and that `variable` is a `varname` optionally followed by index expressions in parentheses, like `A(I)` or `M(2*I, 3)`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc74e470",
   "metadata": {},
   "outputs": [],
   "source": [
    "def variable(): \n",
    "    \"Parse a possibly subscripted variable e.g. 'X3' or 'A(I)' or 'M(2*I, 3)'.\"\n",
    "    V = varname()\n",
    "    if pop('('):\n",
    "        indexes = list_of(expression)()\n",
    "        pop(')') or fail('expected \")\" to close subscript')\n",
    "        return Subscript(V, indexes) # E.g. 'A(I)' => Subscript('A', ['I'])\n",
    "    else: \n",
    "        return V                     # E.g. 'X3' "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31726e7f",
   "metadata": {},
   "source": [
    "`list_of` is tricky because it works at two different times. When I write `list_of(number)` in the grammar, this returns an object of class `list_of`. When this object is called (just as other grammatical categories like `variable` are called), the effect is that it will parse a list of `number`. That list can be empty (if there are no more tokens on the line), or can be a single number, or can be several numbers separated by comma tokens. I could have defined `list_of` as a function that returns a function, but I thought that it would be clearer to define it as a class, so I can clearly separate what happens at the two different times: first the `__init__` method determines what category to parse, and later the `__call__` method does the actual parsing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4939673",
   "metadata": {},
   "outputs": [],
   "source": [
    "class list_of:\n",
    "    \"list_of(category) is a callable that parses a comma-separated list of <category>\"\n",
    "    def __init__(self, category): self.category = category\n",
    "    def __call__(self):\n",
    "        result = ([self.category()] if tokens else [])\n",
    "        while pop(','):\n",
    "            result.append(self.category())\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d5e39c",
   "metadata": {},
   "source": [
    "# Parsing: Top Level `parse`, and Handling Errors\n",
    "\n",
    "Most of the parsing action happens inside the function `statement()`, but at the very top level, `parse(program)` takes a program text (that is, a string), and parses each line by calling `parse_line`, sorting the resulting list of lines by line number. If we didn't have to handle errors, this would be simple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111ed365",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(program): return sorted(map(parse_line, lines(program)))\n",
    "\n",
    "def parse_line(line): global tokens; tokens = tokenizer(line); return statement()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30297b6",
   "metadata": {},
   "source": [
    "To handle syntactic errors, I add to `parse_line` a `try/except` that catches exceptions raised by calls to `fail`. I acknowledge the interpreter isn't very thorough about handling all errors, and the error messages could be more helpful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22e3450",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_line(line):\n",
    "    \"Return a Stmt(linenumber, statement_type, arguments).\"\n",
    "    global tokens\n",
    "    tokens = tokenizer(line)\n",
    "    try:\n",
    "        stmt = statement()\n",
    "        if tokens: fail('extra tokens at end of line')\n",
    "        return stmt\n",
    "    except SyntaxError as err:\n",
    "        print(\"Error in line '{}' at '{}': {}\".format(line, ' '.join(tokens), err))\n",
    "        return Stmt(0, 'REM', []) # Have to return something: a dummy statement\n",
    "    \n",
    "def fail(message): raise SyntaxError(message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6236994f",
   "metadata": {},
   "source": [
    "# Parsing: Building A Representation of the Program\n",
    "\n",
    "A program is represented by various data structures: a list of statements, where each statement contains various components: subscripted variable references, user-defined functions, function calls, operation calls, variable names, numbers, and labels. Here I define these data structures with `namedtuple`s:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3cc9820",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple, defaultdict, deque\n",
    "\n",
    "Stmt      = namedtuple('Stmt',      'num, typ, args')     # Statement: '20 GOTO 99' => Stmt(20, 'GOTO', 99)\n",
    "Subscript = namedtuple('Subscript', 'var, indexes')       # Subscripted reference: 'A(I)' => Subscript('A', ['I'])\n",
    "Funcall   = namedtuple('Funcall',   'f, x')               # Function call: 'SQR(X)' => Funcall('SQR', 'X')\n",
    "Opcall    = namedtuple('Opcall',    'x, op, y')           # Infix operation: 'X + 1' => Opcall('X', '+', 1)\n",
    "ForState  = namedtuple('ForState',  'continu, end, step') # Data used to control a FOR loop variable\n",
    "\n",
    "class Function(namedtuple('_', 'parm, body')):\n",
    "    \"User-defined callable function; 'DEF FNC(X) = X ^ 3' => functions['FNC'] = Function('X', Opcall('X', '^', 3))\"\n",
    "    def __call__(self, value):                           \n",
    "        variables[self.parm] = value # Global assignment to the parameter\n",
    "        return evalu(self.body)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "793f44fc",
   "metadata": {},
   "source": [
    "The first four namedtuples should be self-explanatory. The next one, `ForState`, is used to represent the state of a `FOR` loop variable while the program is running, but does not appear in the static representation of the program.\n",
    "`Function` is used to represent the definition of a user defined function. When the user writes `\"DEF FNC(X) = X ^ 3\"`, we create an object with `Function(parm='X', body=Opcall('X', '^', 3))`, and whenever the program calls, say, `FNC(2)` in an expression, the call returns 8, and also assigns 2 to the *global* variable `X` (whereas in modern languages, it would temporarily bind a new *local* variable named `X`). BASIC has no local variables. Note the technique of making `Function` be a subclass of a `namedtuple`; we are then free to add the `__call__` method to the subclass."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae29122",
   "metadata": {},
   "source": [
    "# Parsing: Grammar of `PRINT` Statements\n",
    "\n",
    "On page 26 of the manual, it appears that the grammar rule for `PRINT` should be `[list_of(expression)]`. But in section 3.1, **More about PRINT**, some complications are introduced:\n",
    "\n",
    "* Labels (strings enclosed in double quotes) are allowed, as well as expressions.\n",
    "* The `\",\"` is not a separator. A line can end with `\",\"`.\n",
    "* Optionally, `\";\"` can be used instead of `\",\"`.\n",
    "* Optionally, the `\",\"` or `\";\"` can be omitted&mdash;we can have a label immediately followed by an expression.\n",
    "\n",
    "The effect of a comma is to advance the output to the next column that is a multiple of 15 (and to a new line if this goes past column 75). The effect of a semicolon is similar, but works in multiples of 3, not 15. (Note that column numbering starts at 0, not 1.) Normally, at the end of a `PRINT` statement we advance to a new line, but this is not done if the statement ends in `\",\"` or `\";\"`. Here are some examples:\n",
    "\n",
    "* `10 PRINT X, Y`\n",
    "<br>Prints the value of `X` in column 0 and `Y` in column 15. Advances to new line.\n",
    "\n",
    "* `20 PRINT \"X =\", X`\n",
    "<br>Prints the string `\"X =\"` in column 0 and the value of `X` in column 15. Advances to new line.\n",
    "\n",
    "* `30 PRINT \"X = \" X`\n",
    "<br>Prints the string `\"X =\"` in column 0 and the value of `X` immediately after. Advances to new line.\n",
    "\n",
    "* `40 PRINT X; Y,`\n",
    "<br>Prints the value of `X` in column 0, and the value of `Y` in the column that is the first available multiple of 3 after that.\n",
    "For example, if `X` is `'0'`, then print `Y` in column 3, but if `X` is `'12345'`, then we've gone past column 3, so print `Y` in column 6.\n",
    "Then, because the statement ends in a comma, advance to the next column that is a multiple of 15, but not to a new line.\n",
    "\n",
    "That explanation was long, but the implementation is short (at least for the parsing part; later we will see the execution part):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6914932c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def labels_and_expressions():\n",
    "    \"Parse a sequence of label / comma / semicolon / expression (for PRINT statement).\"\n",
    "    result = []\n",
    "    while tokens:\n",
    "        item = pop(is_label) or pop(',') or pop(';') or expression()\n",
    "        result.append(item)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0818e4e0",
   "metadata": {},
   "source": [
    "# Parsing: Grammar of Expressions\n",
    "\n",
    "Now for the single most complicated part of the grammar: the `expression`.  The biggest complication is operator precedence: the string `\"A + B * X + C\"` should be parsed as if it were `\"A + (B * X) + C\"`, and not as `\"(A + B) * (X + C),\"` because multiplication binds more tightly than addition. There are [many schemes](https://en.wikipedia.org/wiki/Operator-precedence_parser) for parsing expressions, I'll use  [an approach](https://groups.google.com/forum/#!topic/comp.compilers/ruJLlQTVJ8o) attributed to Keith Clarke.\n",
    "\n",
    "Like all our grammatical categories, calling `expression()` pops off some tokens and returns a data object. The first thing it does is parse one of five types of simple \"primary\" expressions: \n",
    "a number like `1.23`; \n",
    "a possibly-subscripted variable like `X` or `A(I)`;\n",
    "a function call like `SIN(X)`;\n",
    "a unary negation like `-X`;\n",
    "or a parenthesied expression like `(X + 1)`. \n",
    "\n",
    "Next, `expression` looks for infix operators. To parse `'X + 1'` as an expression, first `primary()` would parse `'X'`, then it would pop off the `'+'` operator, then a recursive call to `expression()` would parse `1`, and the results can then be combined into an `Opcall('X', '+', 1)`. If there are multiple infix operators, they can all be handled, as in `'X+1+Y+2'`, which gets parsed as `Opcall(Opcall(Opcall('X', '+', 1), '+', 'Y'), '+', 2)`.\n",
    "\n",
    "When there are multiple infix operators of *different* precedence, as in `\"A + B * X + C\"`, the trick is to know which operators are parsed by the top-level call to `expression`, and which by recursive calls. When we first call `expression()`, the optional parameter `prec` gets the default value, 1, which is the precedence of addition and subtraction. When `expression` makes a recursive call, it passes the precedence of the current operator, and we only parse off operator/expression pairs at an equal or higher precedence. So, in parsing `\"A + B * X + C\"`, when we pop off the `'*'` operator (which has precedence 2), we then recursively call `expression(2)`, which parses off an expression containing operators of precedence 2 or higher, which means the recursive call will parse `X`, but it won't pop off the `'+'`, because that is at a lower precedence. So we correctly get the structure `\"(A + ((B * X) + C)\"`.\n",
    "\n",
    "The function `associativity` ensures that the operator `'^'` is right associative, meaning `10^2^3` = `(10^(2^3))`, whereas the other operators are left associative, so `10-2-3` = `((10-2)-3)`.\n",
    "\n",
    "Here is the implementation of `expression`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b87f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expression(prec=1): \n",
    "    \"Parse an expression: a primary and any [op expression]* pairs with precedence(op) >= prec.\"\n",
    "    exp = primary()                         # 'A' => 'A'\n",
    "    while precedence(peek()) >= prec:\n",
    "        op = pop()\n",
    "        rhs = expression(precedence(op) + associativity(op))\n",
    "        exp = Opcall(exp, op, rhs)          # 'A + B' => Opcall('A', '+', 'B')\n",
    "    return exp\n",
    "\n",
    "def primary():\n",
    "    \"Parse a primary expression (no infix op except maybe within parens).\"\n",
    "    if is_number(peek()):                   # '1.23' => 1.23 \n",
    "        return number()\n",
    "    elif is_varname(peek()):                # X or A(I) or M(I+1, J)\n",
    "        return variable()\n",
    "    elif is_funcname(peek()):               # SIN(X) => Funcall('SIN', 'X')\n",
    "        return Funcall(pop(), primary())\n",
    "    elif pop('-'):                          # '-X' => Funcall('NEG', 'X')\n",
    "        return Funcall('NEG', primary())\n",
    "    elif pop('('):                          # '(X + 1)' => Opcall('X', '+', 1)\n",
    "        exp = expression()\n",
    "        pop(')') or fail('expected \")\" to end expression')\n",
    "        return exp\n",
    "    else:\n",
    "        return fail('unknown expression')\n",
    "\n",
    "def precedence(op): return (3 if op == '^' else 2 if op in ('*', '/') else 1 if op in ('+', '-') else 0)\n",
    "\n",
    "def associativity(op): return (0 if op == '^' else 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4060f34",
   "metadata": {},
   "source": [
    "# Parsing: The Complete Parser in Action\n",
    "\n",
    "I've now written all the grammatical categories, so I can now safely instantiate the global variable `grammar` by calling `Grammar()`, and parse a program:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c48c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar = Grammar()\n",
    "\n",
    "parse(program)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc60c75",
   "metadata": {},
   "source": [
    "Here are some more tests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636d1096",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_parse(text, result, category=expression):\n",
    "    \"Test that text can be parsed as a category to yield the semantic result, with no tokens left over.\"\n",
    "    global tokens\n",
    "    tokens = tokenizer(text)\n",
    "    return category() == result and not tokens\n",
    "    \n",
    "def test_parser():\n",
    "    assert is_funcname('SIN') and is_funcname('FNZ') # Function names are three letters\n",
    "    assert not is_funcname('X') and not is_funcname('')\n",
    "    assert is_varname('X') and is_varname('A2') # Variables names are one letter and an optional digit\n",
    "    assert not is_varname('FNZ') and not is_varname('A10') and not is_varname('')\n",
    "    assert is_relational('>') and is_relational('>=') and not is_relational('+')\n",
    "    \n",
    "    assert test_parse('A + B * X + C', Opcall(Opcall('A', '+', Opcall('B', '*', 'X')), '+', 'C'))\n",
    "    assert test_parse('A + B + X + C', Opcall(Opcall(Opcall('A', '+', 'B'), '+', 'X'), '+', 'C'))\n",
    "    assert test_parse('SIN(X)^2',      Opcall(Funcall('SIN', 'X'), '^', 2))\n",
    "    assert test_parse('10 ^ 2 ^ 3',    Opcall(10, '^', Opcall(2, '^', 3))) # right associative\n",
    "    assert test_parse('10 - 2 - 3',    Opcall(Opcall(10, '-', 2), '-', 3)) # left associative\n",
    "    assert test_parse('A(I)+M(I, J)',  Opcall(Subscript(var='A', indexes=['I']), '+', \n",
    "                                              Subscript(var='M', indexes=['I', 'J'])))\n",
    "    assert test_parse('X * -1',        Opcall('X', '*', Funcall('NEG', 1.0)))\n",
    "    assert test_parse('X--Y--Z',       Opcall(Opcall('X', '-', Funcall('NEG', 'Y')), '-', Funcall('NEG', 'Z')))\n",
    "    assert test_parse('((((X))))',     'X')\n",
    "    return 'ok'\n",
    "\n",
    "test_parser()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8ec7d3",
   "metadata": {},
   "source": [
    "# Execution\n",
    "\n",
    "Now that we can parse programs, we're ready to execute them. I'll first define `run` to  `parse` and `execute` a program:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39d84ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = [] # Global variable to hold a list of tokens\n",
    "\n",
    "def tokenizer(line):\n",
    "    \"Return a list of the tokens on this line, handling spaces properly, and upper-casing.\"\n",
    "    return tokenize(remove_spaces(line).upper())\n",
    "\n",
    "def peek(): \n",
    "    \"Return the first token in the global `tokens`, or None if we are at the end of the line.\"\n",
    "    return (tokens[0] if tokens else None)\n",
    "\n",
    "def pop(constraint=None):\n",
    "    \"\"\"Remove and return the first token in `tokens`, or return None if first token fails a constraint.\n",
    "    `constraint` can be None, a literal string (e.g. pop('=')), or a predicate (e.g. pop(is_varname)).\"\"\"\n",
    "    if constraint is None or (peek() == constraint) or (callable(constraint) and constraint(peek())):\n",
    "        return tokens.pop(0)\n",
    "    \n",
    "def remove_spaces(line): \n",
    "    \"Remove white space from line, except space inside double quotes.\"\n",
    "    return ''.join(tokenize(line))\n",
    "\n",
    "def lines(text): \n",
    "    \"A list of the non-empty lines in a text.\"\n",
    "    return [line for line in text.splitlines() if line]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78938134",
   "metadata": {},
   "source": [
    "(Note: if I expected program lines to contain many tokens, I would use a `deque` instead of a `list` of tokens.) \n",
    "\n",
    "We can test `tokenizer` and the related functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42fc02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_tokenizer():\n",
    "    global tokens\n",
    "    assert tokenizer('X-1') == ['X', '-', '1'] # Numbers don't have a leading minus sign, so this isn't ['X', '-1']\n",
    "    assert tokenizer('PRINT \"HELLO WORLD\"') == ['PRINT', '\"HELLO WORLD\"']\n",
    "    assert tokenizer('10 GOTO 99') == tokenizer('10GOTO99') == tokenizer('10 GO TO 99') == ['10', 'GOTO', '99']\n",
    "    assert (tokenizer('100 PRINT \"HELLO WORLD\", SIN(X) ^ 2') == \n",
    "            ['100', 'PRINT', '\"HELLO WORLD\"', ',', 'SIN', '(', 'X', ')', '^', '2'])\n",
    "    assert (tokenizer('100IFX1+123.4+E1-12.3E4 <> 1.2E-34*-12E34+1+\"HI\" THEN99') ==\n",
    "            ['100', 'IF', 'X1', '+', '123.4', '+', 'E1', '-', '12.3E4', '<>', \n",
    "             '1.2E-34', '*', '-', '12E34', '+', '1', '+', '\"HI\"', 'THEN', '99'])\n",
    "    assert remove_spaces('10 GO TO 99') == '10GOTO99'\n",
    "    assert remove_spaces('100 PRINT \"HELLO WORLD\", SIN(X) ^ 2') == '100PRINT\"HELLO WORLD\",SIN(X)^2'\n",
    "    assert lines('one line') == ['one line']\n",
    "    assert lines(program) == [\n",
    "     '10 REM POWER TABLE',\n",
    "     '11 DATA 8,  4',\n",
    "     '15 READ N0, P0',\n",
    "     '20 PRINT \"N\",',\n",
    "     '25 FOR P = 2 to P0',\n",
    "     '30   PRINT \"N ^\" P,',\n",
    "     '35 NEXT P',\n",
    "     '40 PRINT \"SUM\"',\n",
    "     '45 LET S = 0',\n",
    "     '50 FOR N = 2 TO N0',\n",
    "     '55   PRINT N,',\n",
    "     '60   FOR P = 2 TO P0',\n",
    "     '65     LET S = S + N ^ P',\n",
    "     '70     PRINT N ^ P,',\n",
    "     '75   NEXT P',\n",
    "     '80   PRINT S',\n",
    "     '85 NEXT N',\n",
    "     '99 END']\n",
    "    assert [tokenizer(line) for line in lines(program)] == [\n",
    "     ['10', 'REM', 'P', 'O', 'W', 'E', 'R', 'T', 'A', 'B', 'L', 'E'],\n",
    "     ['11', 'DATA', '8', ',', '4'],\n",
    "     ['15', 'READ', 'N0', ',', 'P0'],\n",
    "     ['20', 'PRINT', '\"N\"', ','],\n",
    "     ['25', 'FOR', 'P', '=', '2', 'TO', 'P0'],\n",
    "     ['30', 'PRINT', '\"N ^\"', 'P', ','],\n",
    "     ['35', 'NEXT', 'P'],\n",
    "     ['40', 'PRINT', '\"SUM\"'],\n",
    "     ['45', 'LET', 'S', '=', '0'],\n",
    "     ['50', 'FOR', 'N', '=', '2', 'TO', 'N0'],\n",
    "     ['55', 'PRINT', 'N', ','],\n",
    "     ['60', 'FOR', 'P', '=', '2', 'TO', 'P0'],\n",
    "     ['65', 'LET', 'S', '=', 'S', '+', 'N', '^', 'P'],\n",
    "     ['70', 'PRINT', 'N', '^', 'P', ','],\n",
    "     ['75', 'NEXT', 'P'],\n",
    "     ['80', 'PRINT', 'S'],\n",
    "     ['85', 'NEXT', 'N'],\n",
    "     ['99', 'END']]\n",
    "\n",
    "    tokens = tokenizer('10 GO TO 99') \n",
    "    assert peek() == '10'\n",
    "    assert pop()  == '10'\n",
    "    assert peek() == 'GOTO'\n",
    "    assert pop()  == 'GOTO'\n",
    "    assert peek() == '99'\n",
    "    assert pop(str.isalpha) == None    # '99' is not alphabetic\n",
    "    assert pop('98.6') == None         # '99' is not '98.6'\n",
    "    assert peek() == '99'\n",
    "    assert pop(str.isnumeric)  == '99' # '99' is numeric\n",
    "    assert peek() is None and not tokens \n",
    "    \n",
    "    return 'ok'\n",
    "    \n",
    "test_tokenizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0df6fdc",
   "metadata": {},
   "source": [
    "# Parsing: Grammar of Statements\n",
    "\n",
    "Parsing is the process of transforming the text of a program into an internal representation, which can then be executed.\n",
    "For BASIC, the representation will be an ordered list of statements, and we'll need various data types to represent the parts of the statements.\n",
    "I'll start by showing the grammar of BASIC statements, as seen on pages 56-57 of [the manual](http://web.archive.org/web/20120716185629/http://www.bitsavers.org/pdf/dartmouth/BASIC_Oct64.pdf) (see also pages 26-30 for a simpler introduction). A statement starts with a line number, and then can be one of the following 15 types of statements, each \n",
    "type introduced by a distinct keyword:\n",
    "\n",
    "- **`LET`**  `<variable>` **=** `<expression>`\n",
    "- **`READ`** `<list of variable>`\n",
    "- **`DATA`** `<list of number>`\n",
    "- **`PRINT`** `<sequence of label and expression>`\n",
    "- **`GOTO`** `<linenumber>`\n",
    "- **`IF`** `<expression> <relational> <expression>` **`THEN`** `<linenumber>`\n",
    "- **`FOR`** `<varname>` **=** `<expression>` **`TO`** `<expression> [`**`STEP`** `<expression>]`\n",
    "- **`NEXT`** `<varname>`\n",
    "- **`END`**\n",
    "- **`STOP`**\n",
    "- **`DEF`** `<funcname>`**(**`<varname>`**) = **`<expression>`\n",
    "- **`GOSUB`** `<linenumber>`\n",
    "- **`RETURN`**\n",
    "- **`DIM`** `<list of variable>`\n",
    "- **`REM`** `<any string of characters whatsoever>`\n",
    "              \n",
    "The notation `<variable>` means any variable and `<list of variable>` means zero or more variables, separated by commas.  `[STEP <expression>]` means that the literal string `\"STEP\"`, followed by an expression, is optional. \n",
    "\n",
    "Rather than use one of the many [language parsing frameworks](https://wiki.python.org/moin/LanguageParsing), I will show how to build a parser from scratch. First I'll translate the grammar above into  Python. Not character-for-character (because it would take a lot of work to get Python to understand how to handle those characters), but almost word-for-word (because I can envision a straightforward way to get Python to handle the following format):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c881b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Grammar(): \n",
    "    return {\n",
    "    'LET':    [variable, '=', expression],\n",
    "    'READ':   [list_of(variable)],\n",
    "    'DATA':   [list_of(number)],\n",
    "    'PRINT':  [labels_and_expressions],\n",
    "    'GOTO':   [linenumber],\n",
    "    'IF':     [expression, relational, expression, 'THEN', linenumber],\n",
    "    'FOR':    [varname, '=', expression, 'TO', expression, step],\n",
    "    'NEXT':   [varname],\n",
    "    'END':    [],\n",
    "    'STOP':   [],\n",
    "    'DEF':    [funcname, '(', varname, ')', '=', expression],\n",
    "    'GOSUB':  [linenumber],\n",
    "    'RETURN': [],\n",
    "    'DIM':    [list_of(variable)], \n",
    "    'REM':    [anycharacters]\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711926e3",
   "metadata": {},
   "source": [
    "# Parsing Strategy\n",
    "\n",
    "The grammar of BASIC is designed so that at every point, the next token tells us unambiguously how to parse. For example, the first token after the line number defines the type of statement; also, in an expression we know that all three-letter names are functions while all 1-letter names are variables. So in writing the various grammatical category functions, a common pattern is to either `peek()` at the next token or try a `pop(`*constraint*`)`, and from that decide what to parse next, and never have to back up or undo a `pop()`. Here is my strategy for parsing statements:\n",
    "\n",
    "* The  grammatical categories, like `variable` and `expression` (and also `statement`), will be defined as functions\n",
    "(with no argument) that pop tokens from the global variable `tokens`, and return a data object. For example, calling `linenumber()` will pop a token, convert it to an `int`, and return that. \n",
    "\n",
    "* Consider parsing the statement `\"20 LET X = X + 1\"`. \n",
    "\n",
    "* First tokenize to get: `tokens = ['20', 'LET', 'X', '=', 'X', '+', '1']`.\n",
    "\n",
    "* Then call `statement()` (defined below).\n",
    "\n",
    "  * `statement` first  calls `linenumber()`, getting back the integer `20` (and removing `'20'` from `tokens`).\n",
    "\n",
    "  * Then it calls `pop()` to get  `'LET'` (and removing `'LET'` from `tokens`).\n",
    "  * Then it indexes into the grammar with `'LET'`, retrieving the grammar rule `[variable, '=', expression]`.\n",
    "\n",
    "  * Then it processes the 3 constituents of the grammar rule:\n",
    "    * First, call `variable()`, which removes and returns `'X'`.\n",
    "    * Second, call `pop('=')`, which removes `'='` from `tokens`, and discard it.\n",
    "    * Third, call `expression()`, which returns a representation of `X + 1`; let's write that as `Opcall('X', '+', 1.0)`.\n",
    "\n",
    "  * Finally, `statement` assembles the pieces and returns `Stmt(num=20, typ='LET', args=['X', Opcall('X', '+', 1.0)])`.\n",
    "* If anything goes wrong, call `fail(\"`*error message*`\")`, which raises an error.\n",
    "\n",
    "Here is the definition of `statement`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3ad7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def statement():\n",
    "    \"Parse a BASIC statement from `tokens`.\"\n",
    "    num  = linenumber()\n",
    "    typ  = pop(is_stmt_type) or fail('unknown statement type')\n",
    "    args = []\n",
    "    for c in grammar[typ]: # For each constituent of rule, call if callable or match if literal string\n",
    "        if callable(c):\n",
    "            args.append(c())\n",
    "        else:\n",
    "            pop(c) or fail('expected ' + repr(c))\n",
    "    return Stmt(num, typ, args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8cc02d7",
   "metadata": {},
   "source": [
    "Some of the grammatical categories, like `expression`, are complex. But many of the categories are easy one-liners:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4b6fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linenumber():    return (int(pop()) if peek().isnumeric() else fail('missing line number'))\n",
    "def number():        return (-1 if pop('-') else +1) * float(pop()) # Optional minus sign before number\n",
    "def step():          return (expression() if pop('STEP') else 1)    # 1 is the default step\n",
    "def relational():    return pop(is_relational) or fail('expected a relational operator')\n",
    "def varname():       return pop(is_varname)    or fail('expected a variable name')\n",
    "def funcname():      return pop(is_funcname)   or fail('expected a function name')\n",
    "def anycharacters(): tokens.clear() # The tokens in a REM statement don't matter, so just clear them"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089b3949",
   "metadata": {},
   "source": [
    "Here are the predicates that distinguish different types of tokens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c17d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_stmt_type(x):  return isinstance(x, str) and x in grammar # LET, READ, ...\n",
    "def is_funcname(x):   return isinstance(x, str) and len(x) == 3 and x.isalpha()  # SIN, COS, FNA, FNB, ...\n",
    "def is_varname(x):    return isinstance(x, str) and len(x) in (1, 2) and x[0].isalpha() # A, A1, A2, B, ...\n",
    "def is_label(x):      return isinstance(x, str) and x.startswith('\"') # \"HELLO WORLD\", ...\n",
    "def is_relational(x): return isinstance(x, str) and x in ('<', '=', '>', '<=', '<>', '>=')\n",
    "def is_number(x):     return isinstance(x, str) and x and x[0] in '.0123456789' # '3', '.14', ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0ef025",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(program): execute(parse(program))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b130c3a",
   "metadata": {},
   "source": [
    "The function `execute(stmts)` first calls `preprocess(stmts)` to handle *declarations*: `DATA` and `DEF` statements that are processed one time only, before the program runs, regardless of their line numbers. (`DIM` statements are also declarations, but I decided that all lists/tables can have any number of elements, so I can ignore `DIM` declarations.)\n",
    "`execute` keeps track of the state of the program, partially in three globals:\n",
    "\n",
    "* `variables`: A mapping of the values of all BASIC variables (both subscripted and unsubscripted). <br>For example, `{'P1': 3.14, ('M', (1, 1)): 42.0}` says that the value of `P1` is `3.14` and `M(1, 1)` is `42.0`.\n",
    "* `functions`: A mapping of the values of all BASIC functions (both built-in and user-defined). <br>For example, `{'FNC': Function('X', Opcall('X', '^', 3)), 'SIN': math.sin}` \n",
    "* `column`: The column that `PRINT` will print in next.\n",
    "\n",
    "And also with these local variables:\n",
    "\n",
    "* `data`: a queue of all the numbers in `DATA` statements.\n",
    "* `pc`: program counter; the index into the list of statements.\n",
    "* `ret`: the index where a `RETURN` statement will return to.\n",
    "* `fors`: a map of `{varname: ForState(...)}` which gives the state of each `FOR` loop variable.\n",
    "* `goto`: a mapping of `{linenumber: index}`, for example `{10: 0, 20: 1}` for a program with two line numbers, 10 and 20.\n",
    "\n",
    "\n",
    "Running the program means executing the statement that the program counter (`pc`) is currently pointing at, repeatedly, until we hit an `END` or `STOP` statement (or a `READ` statement when there is no more data). \n",
    "The variable `pc` is initialized to `0` (the index of the first statement in the program) and is then incremented by `1` each cycle to go to the following statement; but a branching statement (`GOTO`, `IF`, `GOSUB`, or `RETURN`) can change the `pc` to something other than the following statement. Note that branching statements refer to line numbers, but the `pc` refers to the *index* number within the list of statements. The variable `goto` maps from line numbers to index numbers. In BASIC there is no notion of a *stack*, neither for variables nor return addresses. If I do a `GOSUB` to a subroutine that itself does a `GOSUB`, then the original return address is lost, because BASIC has only one return address register (which we call `ret`).\n",
    "\n",
    "The main body of `execute` checks the statement type, and takes appropriate action. All the statement types are straightforward, except for `FOR` and `NEXT`, which are explained a bit later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4902bb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute(stmts): \n",
    "    \"Parse and execute the BASIC program.\"\n",
    "    global variables, functions, column\n",
    "    functions, data = preprocess(stmts) # {name: function,...}, deque[number,...]\n",
    "    variables = defaultdict(float) # mapping of {variable: value}, default 0.0\n",
    "    column    = 0                  # column to PRINT in next\n",
    "    pc        = 0                  # program counter\n",
    "    ret       = 0                  # index (pc) that a GOSUB returns to\n",
    "    fors      = {}                 # runtime map of {varname: ForState(...)}\n",
    "    goto      = {stmt.num: i       # map of {linenumber: index}\n",
    "                 for (i, stmt) in enumerate(stmts)}\n",
    "    while pc < len(stmts):\n",
    "        (_, typ, args) = stmts[pc] # Fetch and decode the instruction\n",
    "        pc += 1                    # Increment the program counter\n",
    "        if typ in ('END', 'STOP') or (typ == 'READ' and not data): \n",
    "            return\n",
    "        elif typ == 'LET':\n",
    "            V, exp = args\n",
    "            let(V, evalu(exp))\n",
    "        elif typ == 'READ':\n",
    "            for V in args[0]:\n",
    "                let(V, data.popleft())\n",
    "        elif typ == 'PRINT':\n",
    "            basic_print(args[0])\n",
    "        elif typ == 'GOTO':\n",
    "            pc = goto[args[0]]\n",
    "        elif typ == 'IF':\n",
    "            lhs, relational, rhs, dest = args\n",
    "            if functions[relational](evalu(lhs), evalu(rhs)):\n",
    "                pc = goto[dest]\n",
    "        elif typ == 'FOR':\n",
    "            V, start, end, step = args\n",
    "            variables[V] = evalu(start)\n",
    "            fors[V] = ForState(pc, evalu(end), evalu(step))\n",
    "        elif typ == 'NEXT':\n",
    "            V = args[0]\n",
    "            continu, end, step = fors[V]\n",
    "            if ((step >= 0 and variables[V] + step <= end) or\n",
    "                (step <  0 and variables[V] + step >= end)):\n",
    "                variables[V] += step\n",
    "                pc = continu\n",
    "        elif typ == 'GOSUB':\n",
    "            ret = pc\n",
    "            pc  = goto[args[0]]\n",
    "        elif typ == 'RETURN':\n",
    "            pc = ret"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf5c618",
   "metadata": {},
   "source": [
    "Here are the functions referenced by `execute`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12ae46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import operator as op\n",
    "\n",
    "def preprocess(stmts):\n",
    "    \"\"\"Go through stmts and return two values extracted from the declarations: \n",
    "    functions: a mapping of {name: function}, for both built-in and user-defined functions,\n",
    "    data:      a queue of all the numbers in DATA statements.\"\"\"\n",
    "    functions = {  # A mapping of {name: function}; first the built-ins:\n",
    "        'SIN': math.sin, 'COS': math.cos, 'TAN': math.tan, 'ATN': math.atan, \n",
    "        'ABS': abs, 'EXP': math.exp, 'LOG': math.log, 'SQR': math.sqrt, 'INT': int,\n",
    "        '>': op.gt, '<': op.lt, '=': op.eq, '>=': op.ge, '<=': op.le, '<>': op.ne, \n",
    "        '^': pow, '+': op.add, '-': op.sub, '*': op.mul, '/': op.truediv, \n",
    "        'RND': lambda _: random.random(), 'NEG': op.neg}\n",
    "    data = deque() # A queue of numbers that READ can read from\n",
    "    for (_, typ, args) in stmts:\n",
    "        if typ == 'DEF':\n",
    "            name, parm, body = args\n",
    "            functions[name] = Function(parm, body)\n",
    "        elif typ == 'DATA':\n",
    "            data.extend(args[0])\n",
    "    return functions, data\n",
    "\n",
    "def evalu(exp):\n",
    "    \"Evaluate an expression, returning a number.\"\n",
    "    if isinstance(exp, Opcall):\n",
    "        return functions[exp.op](evalu(exp.x), evalu(exp.y))\n",
    "    elif isinstance(exp, Funcall):\n",
    "        return functions[exp.f](evalu(exp.x))\n",
    "    elif isinstance(exp, Subscript):\n",
    "        return variables[exp.var, tuple(evalu(x) for x in  exp.indexes)]\n",
    "    elif is_varname(exp):\n",
    "        return variables[exp]\n",
    "    else: # number constant\n",
    "        return exp\n",
    "    \n",
    "def let(V, value):\n",
    "    \"Assign value to the variable name or Subscripted variable.\"\n",
    "    if isinstance(V, Subscript): # A subsscripted variable\n",
    "        variables[V.var, tuple(evalu(x) for x in V.indexes)] = value \n",
    "    else:                        # An unsubscripted variable\n",
    "        variables[V] = value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f165d73",
   "metadata": {},
   "source": [
    "# Execution: `FOR/NEXT` Statements\n",
    "\n",
    "I have to admit I don't completely understand `FOR` loops. My questions include:\n",
    "\n",
    "* Are the `END` and `STEP` expressions evaluated once when we first enter the `FOR` loop, or each time through the loop?\n",
    "* After executing `\"FOR V = 1 TO 10\"`, is the value of `V` equal to 10 or 11? (Answer: the manual says 10.)\n",
    "* Does `\"FOR V = 0 TO -2\"` execute zero times? Or do all loops execute at least once, with the termination test done by the `NEXT`?\n",
    "* What if control branches into the middle of a loop and hits the `NEXT` statement, without ever executing the corresponding `FOR` statement? \n",
    "* What if control branches into the middle of a loop and hits the `NEXT` statement, without ever executing the corresponding `FOR` statement, but we have previously\n",
    "executed a `FOR` statement of a *different* loop that happens to use the same variable name?\n",
    "\n",
    "I chose a solution that is easy to implement, and correctly runs all the examples in the manual, but I'm not certain that my solution is true to the original intent. Consider this program:\n",
    "\n",
    "    10 PRINT \"TABLE OF SQUARES\"\n",
    "    20 LET N = 10\n",
    "    30 FOR V = 1 to N STEP N/5\n",
    "    40   PRINT V, V * V\n",
    "    50 NEXT V\n",
    "    60 END\n",
    "  \n",
    "    \n",
    "* When control hits the `\"FOR V\"` statement in line 30, I assign:\n",
    "<br>`variables['V'] = 1`\n",
    "<br>`    fors['V'] = ForState(continu=3, end=10, step=2)`\n",
    "<br>where `3` is the index of line 40 (the line right after the `FOR` statement); `10` is the value of `N`; and `2` is the value of `N/5`.\n",
    "* When control hits the `\"NEXT V\"` statement in line 50, I do the following:\n",
    "<br>Examine `fors['V']` to check if `V` incremented by the step value, `2`, is within the bounds defined by the end, `10`. \n",
    "<br>If it is, increment `V` and assign `pc` to be `3`, the `continu` value. \n",
    "<br>If not, continue on to the following statement, `60`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ac7ed4",
   "metadata": {},
   "source": [
    "# Execution: Printing\n",
    "\n",
    "We showed how to parse a `PRINT` statement with `labels_and_expressions()`; now it is time to execute a `PRINT` statement, printing each of the labels and expressions, and keeping track of what column to print at next, using the global variable `column`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615381e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_print(items): \n",
    "    \"Print the items (',' / ';' / label / expression) in appropriate columns.\"\n",
    "    for item in items:\n",
    "        if item == ',':      pad(15)\n",
    "        elif item == ';':    pad(3)\n",
    "        elif is_label(item): print_string(item.replace('\"', ''))\n",
    "        else:                print_string(\"{:g} \".format(evalu(item)))\n",
    "    if (not items) or items[-1] not in (',', ';'):\n",
    "        newline()\n",
    "        \n",
    "def print_string(s): \n",
    "    \"Print a string, keeping track of column, and advancing to newline if at or beyond column 75.\"\n",
    "    global column\n",
    "    print(s, end='')\n",
    "    column += len(s)\n",
    "    if column >= 75: newline()\n",
    "        \n",
    "def pad(width): \n",
    "    \"Pad out to the column that is the next multiple of width.\"\n",
    "    while column % width != 0: \n",
    "        print_string(' ')\n",
    "\n",
    "def newline(): global column; print(); column = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c036a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenize('10 GO TO 99')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6861dd81",
   "metadata": {},
   "source": [
    "My first thought was to remove all white space from the input. That would work for this example, but it would change the token `\"HELLO WORLD\"` to `\"HELLOWORLD\"`, which is wrong.  To remove spaces everywhere *except* between  double quotes, I can tokenize the line and join the tokens back together. Then I can re-tokenize to get the final list of tokens; I do that in my new function below called `tokenizer`. \n",
    "\n",
    "Once I have a list of tokens, I access them through this interface:\n",
    "* `peek()`: returns the next token in `tokens` (without changing `tokens`), or `None` if there are no more tokens.\n",
    "* `pop()`: removes and returns the next token. \n",
    "* `pop(`*string*`)`: removes and returns the next token if it is equal to the string; else return `None` and leave `tokens` unchanged.\n",
    "* `pop(`*predicate*`)`: removes and returns the next token if *predicate*(*token*) is true; else return `None` and leave `tokens` unchanged."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
