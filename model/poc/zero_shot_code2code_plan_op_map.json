{
    "4.2. Joining": [
        "def movie_rating_by_genre(ratings, movies, genres):\n    joined_df = ratings.merge(movies, left_on='item_id', right_on='movie_id', how='left')\n    return {genre: joined_df['rating'].mul(joined_df[genre]).sum() / joined_df[genre].sum() for genre in genres}",
        "ratings.merge(movies, left_on='item_id', right_on='movie_id', how='left')",
        "def movie_rating_by_genre(ratings, movies, genres):\n    joined_df = ratings.merge(movies, left_on='item_id', right_on='movie_id', how='left')\n    mp = {}\n    for genre in genres:\n        genre_df = joined_df.loc[joined_df[genre] == 1]\n        mp[genre] = genre_df['rating'].mean()\n    return mp",
        "ratings.merge(movies, left_on='item_id', right_on='movie_id', how='left')",
        "ratings.merge(movies[genres], how='outer', left_on='item_id', right_on='movie_id')",
        "ratings['item_id'].isin(movie_by_genre.index)",
        "ratings.join(req_movies, on='item_id', how='left', lsuffix='_mov', rsuffix='_rat')",
        "def movie_rating_distribution(movies, ratings, starting_year=1990):\n    movies_ratings = movies.merge(ratings, left_on='movie_id', right_on='item_id', how='inner')\n    movies_ratings['release_year'] = movies_ratings['release_date'].str[-4:].astype('Int64')\n    x = movies_ratings[movies_ratings['release_year'].notna()]\n    return x[x['release_year'] >= 1990][['release_year', 'rating']]",
        "movies.merge(ratings, left_on='movie_id', right_on='item_id', how='inner')",
        "movies_modified.merge(ratings, left_on='movie_id', right_on='item_id', how='inner')",
        "ratings.merge(movies_copy, left_on='item_id', right_on='movie_id', how='left')",
        "def movie_rating_distribution(movies, ratings, starting_year=1990):\n    df_movie_rating = ratings.merge(movies, left_on='item_id', right_on='movie_id', how='inner')\n    df_movie_rating = df_movie_rating.dropna(subset=['release_date'])\n    df_movie_rating['release_year'] = df_movie_rating['release_date'].str.slice(-4).astype(int)\n    df_movie_rating = df_movie_rating[df_movie_rating['release_year'] >= starting_year]\n    df_movie_rating = df_movie_rating[['release_year', 'rating']]\n    return df_movie_rating",
        "ratings.merge(movies, left_on='item_id', right_on='movie_id', how='inner')",
        "ratings.merge(year_concated, left_on='item_id', right_on='movie_id', how='left')",
        "def low_rank_matrix_factorization(X_sparse, k, niters=5, lam=10.0, seed=0):\n    np.random.seed(seed)\n    pass",
        "def low_rank_matrix_factorization(X_sparse, k, niters=5, lam=10.0, seed=0):\n    np.random.seed(seed)\n    pass",
        "def low_rank_matrix_factorization(X_sparse, k, niters=5, lam=10.0, seed=0):\n    np.random.seed(seed)\n    pass",
        "def low_rank_matrix_factorization(X_sparse, k, niters=5, lam=10.0, seed=0):\n    pass",
        "def low_rank_matrix_factorization(X_sparse, k, niters=5, lam=10.0, seed=0):\n    np.random.seed(seed)\n    pass",
        "def low_rank_matrix_factorization(X_sparse, k, niters=5, lam=10.0, seed=0):\n    np.random.seed(seed)\n    pass"
    ],
    "standard numerical operations": [
        "joined_df['rating'].mul(joined_df[genre])",
        "def movie_rating_by_genre(ratings, movies, genres):\n    rating_dic = {}\n    for genre in genres:\n        cur_genre = movies.loc[movies[genre] == 1]\n        id_ls = cur_genre.index.tolist()\n        cur_genre_rating = ratings[ratings['item_id'].isin(id_ls)]\n        rating_dic[genre] = cur_genre_rating['rating'].mean()\n    return rating_dic",
        "cur_genre_rating['rating'].mean()",
        "def movie_rating_by_genre(ratings, movies, genres):\n    result = {}\n    for genre in genres:\n        rslt_df = movies[movies[genre] == 1]\n        rate = rslt_df.set_index('movie_id').join(ratings.set_index('item_id'))['rating'].mean()\n        result[genre] = rate\n    return result",
        "genre_df['rating'].mean()",
        "def movie_rating_by_genre(ratings, movies, genres):\n    Dict = {}\n    for key in genres:\n        movie_ids = movies[movies[key] == 1].index\n        Dict[key] = ratings[ratings['item_id'].isin(movie_ids)]['rating'].mean()\n    return Dict\n    pass",
        "def find_rating_scores(group, ratings, genre):\n    avg_rating = 0\n    if group[genre].iloc[0] == 1:\n        avg_rating = ratings.loc[group[genre].index].sum()['rating'] / len(ratings.loc[group[genre].index])\n    return avg_rating",
        "ratings.loc[group[genre].index].sum()",
        "new_ratings[new_ratings[i] == 1].rating.mean()",
        "def movie_rating_by_genre(ratings, movies, genres):\n    d = {}\n    for i in genres:\n        m = movies[movies[i] == 1].index.values\n        d[i] = ratings[ratings['item_id'].isin(m)]['rating'].mean()\n    return d",
        "ratings['item_id'].isin(m)",
        "genres_rating_cnt.sum()",
        "def movie_count_by_genre(movies, genres):\n    movie_count_by_genre = {genre: {} for genre in genres}\n    for (_, movie) in movies.iterrows():\n        try:\n            year = int(movie['release_date'][-4:])\n        except (ValueError, TypeError):\n            continue\n        for genre in genres:\n            if movie[genre]:\n                if year in movie_count_by_genre[genre]:\n                    movie_count_by_genre[genre][year] += 1\n                else:\n                    movie_count_by_genre[genre][year] = 1\n    return movie_count_by_genre",
        "for (_, movie) in movies.iterrows():\n    try:\n        year = int(movie['release_date'][-4:])\n    except (ValueError, TypeError):\n        continue\n    for genre in genres:\n        if movie[genre]:\n            if year in movie_count_by_genre[genre]:\n                movie_count_by_genre[genre][year] += 1\n            else:\n                movie_count_by_genre[genre][year] = 1",
        "for genre in genres:\n    if movie[genre]:\n        if year in movie_count_by_genre[genre]:\n            movie_count_by_genre[genre][year] += 1\n        else:\n            movie_count_by_genre[genre][year] = 1",
        "if movie[genre]:\n    if year in movie_count_by_genre[genre]:\n        movie_count_by_genre[genre][year] += 1\n    else:\n        movie_count_by_genre[genre][year] = 1",
        "if year in movie_count_by_genre[genre]:\n    movie_count_by_genre[genre][year] += 1\nelse:\n    movie_count_by_genre[genre][year] = 1",
        "movies.copy()",
        "for (year, count) in ans.iteritems():\n    year = int(year)\n    res[genre][year] = count",
        "def movie_count_by_genre(movies, genres):\n    movie_count_by_genre = {genre: {} for genre in genres}\n    for (_, movie) in movies.iterrows():\n        try:\n            year = int(movie['release_date'][-4:])\n        except (ValueError, TypeError):\n            continue\n        for genre in genres:\n            if movie[genre]:\n                if year in movie_count_by_genre[genre]:\n                    movie_count_by_genre[genre][year] += 1\n                else:\n                    movie_count_by_genre[genre][year] = 1\n    return movie_count_by_genre",
        "for (_, movie) in movies.iterrows():\n    try:\n        year = int(movie['release_date'][-4:])\n    except (ValueError, TypeError):\n        continue\n    for genre in genres:\n        if movie[genre]:\n            if year in movie_count_by_genre[genre]:\n                movie_count_by_genre[genre][year] += 1\n            else:\n                movie_count_by_genre[genre][year] = 1",
        "for genre in genres:\n    if movie[genre]:\n        if year in movie_count_by_genre[genre]:\n            movie_count_by_genre[genre][year] += 1\n        else:\n            movie_count_by_genre[genre][year] = 1",
        "if movie[genre]:\n    if year in movie_count_by_genre[genre]:\n        movie_count_by_genre[genre][year] += 1\n    else:\n        movie_count_by_genre[genre][year] = 1",
        "if year in movie_count_by_genre[genre]:\n    movie_count_by_genre[genre][year] += 1\nelse:\n    movie_count_by_genre[genre][year] = 1",
        "def movie_count_by_genre(movies, genres):\n    out = {}\n    new_movies = movies\n    new_movies['Year'] = new_movies['release_date'].str[-4:].dropna().astype(int)\n    for g in genres:\n        k = new_movies.loc[new_movies[g] == 1]\n        out[g] = k.groupby('Year').count()[g].to_dict()\n    return out\n    pass",
        "def movie_count_by_genre(movies, genres):\n    movie_count_by_genre_year = {}\n    movies = movies[movies['release_date'].notna()]\n    for genre in genres:\n        grouped_date_genre = movies.groupby('release_date')[genre].sum()\n        movie_count_by_genre_year[genre] = defaultdict(int)\n        for (full_year, movie_count) in grouped_date_genre.items():\n            movie_count_by_genre_year[genre][int(full_year[-4:])] += movie_count\n    return movie_count_by_genre_year",
        "movie_count_by_genre_year = {}",
        "for (full_year, movie_count) in grouped_date_genre.items():\n    movie_count_by_genre_year[genre][int(full_year[-4:])] += movie_count",
        "def movie_count_by_genre(movies, genres):\n    movies_long = movies.melt(id_vars=['release_date'], value_vars=genres, var_name='genre', value_name='is_genre')\n    movies_long = movies_long[movies_long.is_genre == 1]\n    movies_long['year'] = movies_long['release_date'].apply(lambda x: int(x[-4:]))\n    return {k: f.groupby('year').agg(cnt=('is_genre', 'count')).to_dict()['cnt'] for (k, f) in movies_long.groupby('genre')}",
        "movies['release_date'].astype(str)",
        "movies_year['release_year'].astype('int64')",
        "movies.copy()",
        "mov_ratings['release_year'].astype('int64')",
        "movies['release_date'].apply(get_year)",
        "for (_, row) in ratings.iterrows():\n    item_id = row['item_id']\n    rating = row['rating']\n    if item_id in id_to_rating:\n        id_to_rating[item_id][0] += rating\n        id_to_rating[item_id][1] += 1\n    else:\n        id_to_rating[item_id] = [rating, 1]",
        "yearwise_ratings['release_year'].astype(int)",
        "yearwise_ratings['rating'].astype(int)",
        "movies.copy()",
        "ratings_movies_merged['release_year'].astype('int')",
        "movies.copy()",
        "ret['release_year'].astype(int)",
        "def movies_reviewed_by_month(ratings, year):\n    datetime_series = pd.to_datetime(ratings['timestamp'], unit='s')\n    yeartime_series = datetime_series.dt.year\n    monthtime_series = datetime_series.dt.month[yeartime_series >= year]\n    month_count = monthtime_series.value_counts()\n    month_count.sort_index(ascending=True, inplace=True)\n    df = pd.DataFrame({'month': list(month_count.index), 'rating_count': month_count})\n    return df",
        "def movies_reviewed_by_month(ratings, year):\n    ratings = ratings.copy()\n    ratings['timestamp'] = pd.to_datetime(ratings['timestamp'], unit='s')\n    ratings = ratings[ratings['timestamp'].dt.year == year]\n    ratings['month'] = ratings['timestamp'].dt.month\n    ratings = ratings.groupby('month').size().reset_index(name='rating_count')\n    return ratings",
        "def movies_reviewed_by_month(ratings, year):\n    ratings['month'] = pd.to_datetime(ratings['timestamp'], unit='s').dt.month\n    ratings['year'] = pd.to_datetime(ratings['timestamp'], unit='s').dt.year\n    return ratings[ratings['year'] == year].groupby('month')[['rating']].agg(rating_count=('rating', 'count')).reset_index()",
        "def movies_reviewed_by_month(ratings, year):\n    work_df = ratings.copy()\n    work_df['date'] = pd.to_datetime(work_df['timestamp'], unit='s')\n    work_df['year'] = work_df.date.dt.year\n    work_df['month'] = work_df.date.dt.month\n    result = work_df[work_df.year == year].groupby(['month'], as_index=False)['rating'].count()\n    result.columns = ['month', 'rating_count']\n    return result\n    pass",
        "ratings_copy['item_id'].isin(movies_list)",
        "np.mean(nonzero_ratings_i)",
        "np.zeros(num_users)",
        "for (_, row) in ratings.iterrows():\n    user_id = row['user_id'] - 1\n    movie_id = row['item_id'] - 1\n    rating = row['rating']\n    X[user_id, movie_id] = max(X[user_id, movie_id], rating)",
        "range(num_users)",
        "range(num_movies)",
        "np.zeros(num_movies)",
        "np.mean(nonzero_ratings_j)",
        "tmp_mat.mean(axis=1)",
        "tmp_mat.mean(axis=0)",
        "range(m)",
        "X.mean(axis=0)",
        "X.mean(axis=1, where=X != 0)",
        "X.mean(axis=0, where=X != 0)",
        "tempx.mean(axis=1)",
        "tempx.mean(axis=0)",
        "print(user_means)",
        "print(movie_means)",
        "np.zeros(sorted_userids.size)",
        "X.getnnz(axis=1)",
        "enumerate(unique_users)",
        "ratings['rating'].to_numpy()",
        "X.getnnz(axis=0)",
        "enumerate(unique_movies)",
        "len(unique_users)",
        "len(unique_movies)",
        "np.linalg.norm(X, axis=1)",
        "np.linalg.norm(X, axis=1)",
        "np.linalg.norm(X, axis=1)",
        "la.norm(X, axis=1)",
        "def mean_rating_diff(X_true, X_pred):\n    mse_num = ((X_true - X_pred) ** 2)[X_true != 0].sum()\n    mse_den = (X_true != 0).sum()\n    return mse_num / mse_den",
        "(X_true != 0).sum()",
        "def mean_rating_diff(X_true, X_pred):\n    return 0.0",
        "def mean_rating_diff(X_true, X_pred):\n    pass\n    X_bool = (X_true != 0).astype(int)\n    return np.sum(X_bool * (X_true - X_pred) ** 2) / np.sum(X_bool)",
        "np.sum(X_bool)",
        "range(niters)",
        "range(m)",
        "range(niters)",
        "range(niters)",
        "range(num_users)",
        "range(num_movies)",
        "range(niters)"
    ],
    "data filtering": [
        "for genre in genres:\n    cur_genre = movies.loc[movies[genre] == 1]\n    id_ls = cur_genre.index.tolist()\n    cur_genre_rating = ratings[ratings['item_id'].isin(id_ls)]\n    rating_dic[genre] = cur_genre_rating['rating'].mean()",
        "cur_genre = movies.loc[movies[genre] == 1]",
        "for genre in genres:\n    rslt_df = movies[movies[genre] == 1]\n    rate = rslt_df.set_index('movie_id').join(ratings.set_index('item_id'))['rating'].mean()\n    result[genre] = rate",
        "rslt_df = movies[movies[genre] == 1]",
        "result[genre] = rate",
        "for genre in genres:\n    genre_df = joined_df.loc[joined_df[genre] == 1]\n    mp[genre] = genre_df['rating'].mean()",
        "genre_df = joined_df.loc[joined_df[genre] == 1]",
        "for key in genres:\n    movie_ids = movies[movies[key] == 1].index\n    Dict[key] = ratings[ratings['item_id'].isin(movie_ids)]['rating'].mean()",
        "movie_ids = movies[movies[key] == 1].index",
        "if group[genre].iloc[0] == 1:\n    avg_rating = ratings.loc[group[genre].index].sum()['rating'] / len(ratings.loc[group[genre].index])",
        "for i in genres:\n    m = movies[movies[i] == 1].index.values\n    d[i] = ratings[ratings['item_id'].isin(m)]['rating'].mean()",
        "m = movies[movies[i] == 1].index.values",
        "for genre in genres:\n    movie_by_genre = movies[movies[genre] == 1]\n    avg = ratings[ratings['item_id'].isin(movie_by_genre.index)]['rating'].mean()\n    movie_rating_by_genre_dict[genre] = avg",
        "movie_rating_by_genre_dict[genre] = avg",
        "movie_by_genre = movies[movies[genre] == 1]",
        "movie_count_by_genre[genre][year] = 1",
        "df = df[df['value'] == 1]",
        "for genre in genres:\n    res[genre] = {}\n    movie_genres = movies.loc[movies[genre] == 1]\n    ans = movie_genres['release_year'].value_counts(dropna=True)\n    for (year, count) in ans.iteritems():\n        year = int(year)\n        res[genre][year] = count",
        "res[genre][year] = count",
        "res[genre] = {}",
        "movie_genres = movies.loc[movies[genre] == 1]",
        "movie_count_by_genre[genre][year] = 1",
        "for g in genres:\n    k = new_movies.loc[new_movies[g] == 1]\n    out[g] = k.groupby('Year').count()[g].to_dict()",
        "new_movies = movies",
        "k = new_movies.loc[new_movies[g] == 1]",
        "movies_long = movies_long[movies_long.is_genre == 1]",
        "for genre in genres:\n    genre_df = movies.loc[movies[genre] == 1]\n    count_df = genre_df.groupby('year').count()\n    filt = count_df['movie_title'] > 0\n    count_df = count_df[filt]\n    year_mp = count_df['movie_title'].to_dict()\n    result[genre] = year_mp",
        "result[genre] = year_mp",
        "genre_df = movies.loc[movies[genre] == 1]",
        "filt = count_df['movie_title'] > 0",
        "count_df = count_df[filt]",
        "req_movies = movies_year[movies_year['release_year'] >= starting_year]",
        "set(year_series[year_series >= starting_year].index)",
        "for (movie_id, release_date) in zip(movies.index, movies['release_date']):\n    if pd.isnull(release_date):\n        continue\n    release_year = int(release_date[-4:])\n    if release_year < starting_year:\n        continue\n    if movie_id in unique_ratings:\n        movie_ratings = ratings.loc[ratings['item_id'] == movie_id, 'rating']\n        result_list.extend(({'release_year': release_year, 'rating': int(rating)} for rating in movie_ratings))",
        "if movie_id in unique_ratings:\n    movie_ratings = ratings.loc[ratings['item_id'] == movie_id, 'rating']\n    result_list.extend(({'release_year': release_year, 'rating': int(rating)} for rating in movie_ratings))",
        "result_list = []",
        "if pd.isnull(release_date):\n    continue",
        "movie_ratings = ratings.loc[ratings['item_id'] == movie_id, 'rating']",
        "if release_year < starting_year:\n    continue",
        "if item_id in id_to_rating:\n    id_to_rating[item_id][0] += rating\n    id_to_rating[item_id][1] += 1\nelse:\n    id_to_rating[item_id] = [rating, 1]",
        "id_to_rating[item_id] = [rating, 1]",
        "ans = ratings_with_year.loc[ratings_with_year['release_year'] >= 1990, :].loc[:, ['release_year', 'rating']]",
        "yearwise_ratings = yearwise_ratings[yearwise_ratings['release_year'] >= starting_year]",
        "ratings_movies_merged = ratings_movies_merged[ratings_movies_merged['release_year'] >= starting_year]",
        "df_movie_rating = df_movie_rating[df_movie_rating['release_year'] >= starting_year]",
        "ret = ratings_year_cleaned[ratings_year_cleaned['release_year'] >= 1990][['release_year', 'rating']]",
        "yeartime_series = datetime_series.dt.year",
        "monthtime_series = datetime_series.dt.month[yeartime_series >= year]",
        "df[df['year'] == year].dropna()",
        "df['year'] = df['month'].dt.year",
        "df['month'] = df['month'].dt.month",
        "ratings['month'] = ratings['timestamp'].dt.month",
        "ratings = ratings[ratings['timestamp'].dt.year == year]",
        "month_integrated_year = month_integrated[month_integrated['year'] == year]",
        "ratings[ratings['year'] == year].groupby('month')",
        "work_df[work_df.year == year].groupby(['month'], as_index=False)",
        "work_df['year'] = work_df.date.dt.year",
        "work_df['month'] = work_df.date.dt.month",
        "worst = [s[0] for s in sorted_avg[:10]]",
        "if len(mr_dict[m]) > 50:\n    avg = sum(mr_dict[m]) / len(mr_dict[m])\n    mr_avg[m] = avg",
        "mr_dict[m].append(r)",
        "mr_dict[m] = []",
        "mr_avg[m] = avg",
        "best = [s[0] for s in sorted_avg[-10:]][::-1]",
        "all_ratings = all_ratings.loc[all_ratings['rating', 'count'] > threshold]",
        "df2_robust = df2_robust[df2_robust['count'] > threshold]",
        "ratings_copy = ratings_copy[filt]",
        "df = df[df['counts'] > threshold]",
        "mean_ratings = mean_ratings[mean_ratings.item_id > threshold]",
        "ratings_count_avg = ratings_count_avg[ratings_count_avg['count'] > threshold]",
        "df = df[df['rating_count'] >= 50]",
        "user_id = row['user_id'] - 1",
        "for j in range(num_movies):\n    ratings_j = X[:, j]\n    nonzero_ratings_j = ratings_j[ratings_j != 0]\n    movie_means[j] = np.mean(nonzero_ratings_j)",
        "ratings_j = X[:, j]",
        "ratings_i = X[i, :]",
        "nonzero_ratings_j = ratings_j[ratings_j != 0]",
        "nonzero_ratings_i = ratings_i[ratings_i != 0]",
        "movie_id = row['item_id'] - 1",
        "X[rating_user_indices, rating_movie_indices] = ratings['rating']",
        "v = ratings[ratings['user_id'] == sorted_userids[i]]",
        "rating_matrix[i] = w",
        "((X_true - X_pred) ** 2)[X_true != 0].sum()",
        "L = L1 + L2",
        "for i in range(U.shape[0]):\n    c_indices = [c for (r, c) in zip(X_csr.nonzero()[0], X_csr.nonzero()[1]) if r == i]\n    if k == 1:\n        U[i, :] = (V[:, c_indices] @ V[:, c_indices].T) ** (-1) @ (V[:, c_indices] @ X_csc[i, c_indices])\n    else:\n        U[i:i + 1, :] = (np.linalg.inv(lam * np.eye(k) + V[:, c_indices] @ V[:, c_indices].T) @ (V[:, c_indices] @ X_csc[i, c_indices].T)).T",
        "U[1] = u2",
        "U[0] = u1",
        "mask = _x_row_i != 0",
        "mask = _x_col_j != 0",
        "V_masked = V * mask",
        "U_masked = U * mask",
        "indicator = X != 0",
        "indicator = X != 0",
        "indicator = X != 0",
        "indicator = X != 0",
        "indicator = X != 0",
        "indicator = X != 0"
    ],
    "extract unique values": [
        "ratings['item_id'].isin(id_ls)",
        "ratings['item_id'].isin(movie_ids)",
        "def movie_rating_by_genre(ratings, movies, genres):\n    movie_rating_by_genre_dict = dict()\n    for genre in genres:\n        movie_by_genre = movies[movies[genre] == 1]\n        avg = ratings[ratings['item_id'].isin(movie_by_genre.index)]['rating'].mean()\n        movie_rating_by_genre_dict[genre] = avg\n    return movie_rating_by_genre_dict",
        "movie_rating_by_genre_dict = dict()",
        "df['release_date'].notna()",
        "grouped_date_genre.items()",
        "count_df['movie_title'].to_dict()",
        "def movie_rating_distribution(movies, ratings, starting_year=1990):\n    movies_year = movies.copy()\n    movies_year['release_year'] = movies_year['release_date'].str[-4:]\n    movies_year['release_year'] = pd.to_numeric(movies_year['release_year'])\n    movies_year = movies_year.dropna(subset=['release_year'])\n    movies_year['release_year'] = movies_year['release_year'].astype('int64')\n    req_movies = movies_year[movies_year['release_year'] >= starting_year]\n    mov_ratings = ratings.join(req_movies, on='item_id', how='left', lsuffix='_mov', rsuffix='_rat').dropna(subset=['release_year'])\n    mov_ratings['release_year'] = mov_ratings['release_year'].astype('int64')\n    return mov_ratings[['release_year', 'rating']]\n    pass",
        "def movie_rating_distribution(movies, ratings, starting_year=1990):\n    year_series = movies['release_date'].apply(get_year)\n    non_nan_idx = year_series.notnull()\n    year_series = year_series[non_nan_idx].astype(dtype=np.int32)\n    movie_ids_after = set(year_series[year_series >= starting_year].index)\n    filtered_ratings = ratings[ratings['item_id'].isin(movie_ids_after)].reset_index(drop=True)\n    filtered_ratings['release_year'] = year_series[filtered_ratings['item_id']].reset_index(drop=True)\n    return filtered_ratings[['release_year', 'rating']]",
        "ratings['item_id'].isin(movie_ids_after)",
        "movies_ratings['release_year'].notna()",
        "def movie_rating_distribution(movies, ratings, starting_year=1990):\n    result_list = []\n    id_to_rating = {}\n    for (_, row) in ratings.iterrows():\n        item_id = row['item_id']\n        rating = row['rating']\n        if item_id in id_to_rating:\n            id_to_rating[item_id][0] += rating\n            id_to_rating[item_id][1] += 1\n        else:\n            id_to_rating[item_id] = [rating, 1]\n    unique_ratings = set(ratings['item_id'].unique())\n    for (movie_id, release_date) in zip(movies.index, movies['release_date']):\n        if pd.isnull(release_date):\n            continue\n        release_year = int(release_date[-4:])\n        if release_year < starting_year:\n            continue\n        if movie_id in unique_ratings:\n            movie_ratings = ratings.loc[ratings['item_id'] == movie_id, 'rating']\n            result_list.extend(({'release_year': release_year, 'rating': int(rating)} for rating in movie_ratings))\n    return pd.DataFrame(result_list, columns=['release_year', 'rating'], dtype='int')",
        "ratings['item_id'].unique()",
        "def movie_rating_distribution(movies, ratings, starting_year=1990):\n    movies_modified = movies.copy()\n    movies_modified['release_year'] = pd.to_datetime(movies_modified['release_date']).dt.year\n    yearwise_ratings = movies_modified.merge(ratings, left_on='movie_id', right_on='item_id', how='inner')[['release_year', 'rating']]\n    yearwise_ratings = yearwise_ratings[yearwise_ratings['release_year'] >= starting_year]\n    yearwise_ratings['release_year'] = yearwise_ratings['release_year'].astype(int)\n    yearwise_ratings['rating'] = yearwise_ratings['rating'].astype(int)\n    return yearwise_ratings",
        "df1['item_id'].isin(filter_movies)",
        "def matrix_data(ratings):\n    num_users = ratings['user_id'].nunique()\n    num_movies = ratings['item_id'].nunique()\n    X = np.zeros((num_users, num_movies), dtype=int)\n    for (_, row) in ratings.iterrows():\n        user_id = row['user_id'] - 1\n        movie_id = row['item_id'] - 1\n        rating = row['rating']\n        X[user_id, movie_id] = max(X[user_id, movie_id], rating)\n    user_means = np.zeros(num_users)\n    for i in range(num_users):\n        ratings_i = X[i, :]\n        nonzero_ratings_i = ratings_i[ratings_i != 0]\n        user_means[i] = np.mean(nonzero_ratings_i)\n    movie_means = np.zeros(num_movies)\n    for j in range(num_movies):\n        ratings_j = X[:, j]\n        nonzero_ratings_j = ratings_j[ratings_j != 0]\n        movie_means[j] = np.mean(nonzero_ratings_j)\n    return (X, user_means, movie_means)",
        "ratings['user_id'].nunique()",
        "ratings['item_id'].nunique()",
        "np.unique(ratings['user_id'])",
        "np.unique(ratings['item_id'])",
        "ratings['user_id'].unique()",
        "ratings['user_id'].rank(method='dense')",
        "ratings['item_id'].unique()",
        "ratings['item_id'].rank(method='dense')",
        "tempx.to_numpy()",
        "ratings['user_id'].nunique()",
        "ratings['item_id'].nunique()",
        "temp_ratings['user_id'].nunique()",
        "temp_ratings['item_id'].nunique()",
        "ratings.user_id.unique()",
        "ratings.item_id.unique()",
        "def matrix_data(ratings):\n    unique_users = ratings['user_id'].unique()\n    M = len(unique_users)\n    unique_movies = ratings['item_id'].unique()\n    N = len(unique_movies)\n    unique_users.sort()\n    unique_movies.sort()\n    user_id_to_index = {user_id: i for (i, user_id) in enumerate(unique_users)}\n    movie_id_to_index = {movie_id: i for (i, movie_id) in enumerate(unique_movies)}\n    np_row_indices = np.array([user_id_to_index[user_id] for user_id in ratings['user_id']])\n    np_col_indices = np.array([movie_id_to_index[movie_id] for movie_id in ratings['item_id']])\n    np_ratings = ratings['rating'].to_numpy()\n    X = coo_matrix((np_ratings, (np_row_indices, np_col_indices)), shape=(M, N)).tocsr()\n    user_means = np.asarray(X.sum(axis=1) / X.getnnz(axis=1).reshape((-1, 1))).reshape(-1)\n    movie_means = np.asarray(X.sum(axis=0) / X.getnnz(axis=0).reshape((1, -1))).reshape(-1)\n    return (X.toarray(), user_means, movie_means)",
        "ratings['user_id'].unique()",
        "ratings['item_id'].unique()",
        "X_csr.nonzero()"
    ],
    ".A converts the sparse matrix to its dense representation (of type np.ndarray)": [
        "rating_dic = {}",
        "result = {}",
        "mp = {}",
        "Dict = {}",
        "d = {}",
        "d = {}",
        "result = {}",
        "res = {}",
        "out = {}",
        "result = {}",
        "id_to_rating = {}",
        "mr_dict = {}",
        "mr_avg = {}",
        "mask = mask.A"
    ],
    "sort index/values (not in primer)": [
        "cur_genre.index.tolist()",
        "df.groupby(['genre', 'release_year'])",
        "movies.dropna(subset=['release_date'])",
        "pd.to_numeric(movies_year['release_year'])",
        "movies_year.dropna(subset=['release_year'])",
        "pd.to_datetime(movies_modified['release_date'])",
        "df_movie_rating.dropna(subset=['release_date'])",
        "pd.to_datetime(movies['release_date'])",
        "ratings_year.dropna(subset=['release_year'])",
        "pd.to_datetime(ratings['timestamp'], unit='s')",
        "list(month_count.index)",
        "month_count.sort_index(ascending=True, inplace=True)",
        "pd.to_datetime(ratings['timestamp'], unit='s')",
        "df.groupby(['month'])",
        "pd.to_datetime(ratings['timestamp'], unit='s')",
        "pd.to_datetime(ratings['timestamp'], unit='s')",
        "pd.to_datetime(ratings['timestamp'], unit='s')",
        "pd.to_datetime(work_df['timestamp'], unit='s')",
        "result.columns = ['month', 'rating_count']",
        "mr_avg.items()",
        "def best_worst_movies(ratings, threshold=50, size=10):\n    all_ratings = ratings.groupby('item_id').agg({'rating': ['mean', 'count']})\n    all_ratings = all_ratings.loc[all_ratings['rating', 'count'] > threshold]\n    all_ratings.sort_values(by=[('rating', 'mean')], ascending=False, inplace=True)\n    return (list(all_ratings.index[:10]), list(all_ratings.index[::-1][:10]))",
        "all_ratings.sort_values(by=[('rating', 'mean')], ascending=False, inplace=True)",
        "def best_worst_movies(ratings, threshold=50, size=10):\n    df1 = ratings[['item_id', 'rating']]\n    df2_robust = df1.groupby(['item_id']).count()\n    df2_robust = df2_robust.rename({'rating': 'count'}, axis=1)\n    df2_robust = df2_robust[df2_robust['count'] > threshold]\n    filter_movies = df2_robust.to_dict()['count']\n    df2 = df1[df1['item_id'].isin(filter_movies)]\n    result = df2.groupby(['item_id']).mean().sort_values(by=['rating'])\n    result = result.reset_index()\n    worst_movie_ids = result['item_id'].head(size).values.tolist()\n    result = result.sort_values(by=['rating'], ascending=False)\n    best_movie_ids = result['item_id'].head(size).values.tolist()\n    return (best_movie_ids, worst_movie_ids)",
        "result.sort_values(by=['rating'], ascending=False)",
        "df2.groupby(['item_id'])",
        "df1.groupby(['item_id'])",
        "df2.sort_values(by=['rating'])",
        "ratings_copy.groupby(['item_id'])",
        "df2.sort_values(by=['rating'], ascending=False)",
        "def best_worst_movies(ratings, threshold=50, size=10):\n    mean_ratings = ratings.groupby('item_id').agg({'item_id': 'count', 'rating': 'mean'})\n    mean_ratings = mean_ratings[mean_ratings.item_id > threshold]\n    sorted_ratings = mean_ratings.sort_values('rating')\n    best_movie_ids = sorted_ratings.index[::-1][:size].to_list()\n    worst_movie_ids = sorted_ratings.index[:size].to_list()\n    return (best_movie_ids, worst_movie_ids)",
        "sorted_ratings.index[:size].to_list()",
        "sorted_ratings.index[::-1][:size].to_list()",
        "mean_ratings.sort_values('rating')",
        "def best_worst_movies(ratings, threshold=50, size=10):\n    ratings_count = ratings.groupby('item_id').size()\n    avg_ratings = ratings.groupby('item_id')['rating'].mean()\n    ratings_count_avg = pd.concat([ratings_count, avg_ratings], axis=1)\n    ratings_count_avg.columns = ['count', 'avg_rating']\n    ratings_count_avg = ratings_count_avg[ratings_count_avg['count'] > threshold]\n    ratings_count_avg = ratings_count_avg.sort_values('avg_rating', ascending=False)\n    best_movie_ids = ratings_count_avg.index[:size].tolist()\n    worst_movie_ids = ratings_count_avg.index[-size:].tolist()\n    worst_movie_ids.reverse()\n    return (best_movie_ids, worst_movie_ids)",
        "worst_movie_ids.reverse()",
        "ratings_count_avg.index[-size:].tolist()",
        "ratings_count_avg.sort_values('avg_rating', ascending=False)",
        "ratings_count_avg.index[:size].tolist()",
        "ratings_count_avg.columns = ['count', 'avg_rating']",
        "def best_worst_movies(ratings, threshold=50, size=10):\n    temp = ratings[['item_id', 'rating']]\n    temp = temp.pivot_table(index='item_id', values='rating', aggfunc=('count', 'mean'))\n    temp = temp[temp['count'] > threshold].sort_values('mean', ascending=False)\n    best = list(temp.index[0:size])\n    worst = list(temp.index[-size:])[::-1]\n    return (best, worst)",
        "list(temp.index[-size:])",
        "temp[temp['count'] > threshold].sort_values('mean', ascending=False)",
        "list(temp.index[0:size])",
        "def best_worst_movies(ratings, threshold=50, size=10):\n    df = ratings.groupby('item_id').agg(rating_count=('rating', 'count'), avg_rating=('rating', 'mean')).reset_index()\n    df = df[df['rating_count'] >= 50]\n    best_movie_ids = df.sort_values(by='avg_rating', ascending=False)['item_id'].values.tolist()[:size]\n    worst_movie_ids = df.sort_values(by='avg_rating', ascending=True)['item_id'].values.tolist()[:size]\n    return (best_movie_ids, worst_movie_ids)",
        "df.sort_values(by='avg_rating', ascending=True)",
        "df.sort_values(by='avg_rating', ascending=False)",
        "ratings.groupby('user_id', as_index=False)",
        "ratings.groupby('item_id', as_index=False)",
        "X.toarray()",
        "temp.sort_values(['user_id', 'item_id'], ascending=[True, True])",
        "temp.sort_values('rating')",
        "ratings[['user_id', 'item_id', 'rating']].sort_values(by=['user_id', 'item_id'])",
        "ratings[['user_id', 'item_id', 'rating']].sort_values(by=['user_id', 'item_id'])",
        "np.isin(sorted_userids, v.index)",
        "np.isin(sorted_itemids, v.index)",
        "unique_users.sort()",
        "unique_movies.sort()",
        "X.toarray()",
        "Y.tocsr()",
        "X.tocsr()",
        "X_sparse.tocsr()",
        "X_sparse.toarray()",
        "X_sparse.tocsr()"
    ],
    "reset dataframe index (not in primer)": [
        "rslt_df.set_index('movie_id')",
        "new_ratings.head()",
        "df.reset_index()",
        "movie_genres['release_year'].value_counts(dropna=True)",
        "year_series[filtered_ratings['item_id']].reset_index(drop=True)",
        "pd.DataFrame()",
        "df.reset_index()",
        "by_month.reset_index(inplace=True)",
        "result.reset_index()",
        "df2.reset_index()",
        "tmp_mat.fillna(0, inplace=True)"
    ],
    "Sum of every column in the dataframe": [
        "avg_rating = 0",
        "np.count_nonzero(X, axis=0)",
        "np.count_nonzero(X, axis=0)",
        "np.abs(W)",
        "np.abs(W)",
        "np.abs(W)",
        "np.abs(W)",
        "np.abs(W)",
        "np.abs(W)"
    ],
    "4.1. Concatenation": [
        "def movie_rating_by_genre(ratings, movies, genres):\n    new_ratings = ratings.merge(movies[genres], how='outer', left_on='item_id', right_on='movie_id')\n    new_ratings.head()\n    d = {}\n    for i in genres:\n        d[i] = new_ratings[new_ratings[i] == 1].rating.mean()\n    return d",
        "def movie_rating_by_genre(ratings, movies, genres):\n    ratings_group = ratings.groupby('item_id').agg(rating_cnt=('rating', 'count'), rating_sum=('rating', 'sum'))\n    genres_rating_sum = movies[genres].multiply(ratings_group['rating_sum'], axis='index')\n    genres_rating_cnt = movies[genres].multiply(ratings_group['rating_cnt'], axis='index')\n    ans = (genres_rating_sum.sum() / genres_rating_cnt.sum()).to_dict()\n    return ans",
        "movies[genres].multiply(ratings_group['rating_sum'], axis='index')",
        "movies[genres].multiply(ratings_group['rating_cnt'], axis='index')",
        "def movie_rating_distribution(movies, ratings, starting_year=1990):\n    movies['release_year'] = movies['release_date'].str[-4:].astype('Int64')\n    ratings_with_year = ratings.merge(movies[['release_year']], left_on='item_id', right_index=True, how='left')\n    ans = ratings_with_year.loc[ratings_with_year['release_year'] >= 1990, :].loc[:, ['release_year', 'rating']]\n    return ans",
        "result.insert(1, 'rating', ratings_movies_merged['rating'])",
        "def movie_rating_distribution(movies, ratings, starting_year=1990):\n    year = pd.to_datetime(movies['release_date']).dt.year\n    year = pd.DataFrame(year).rename(columns={'release_date': 'release_year'})\n    year_concated = pd.concat([movies, year], axis=1)\n    ratings_year = ratings.merge(year_concated, left_on='item_id', right_on='movie_id', how='left')\n    ratings_year_cleaned = ratings_year.dropna(subset=['release_year'])\n    ret = ratings_year_cleaned[ratings_year_cleaned['release_year'] >= 1990][['release_year', 'rating']]\n    ret['release_year'] = ret['release_year'].astype(int)\n    return ret",
        "pd.concat([movies, year], axis=1)",
        "pd.concat([ratings, mon, yr], axis=1)",
        "pd.concat([ratings_count, avg_ratings], axis=1)",
        "max(X[user_id, movie_id], rating)",
        "csr_matrix((ratings['rating'], (user_index, item_index)), shape=(m, n))",
        "ratings.drop(['timestamp'], axis=1)",
        "np.maximum(temp_arr[:, 2], X[temp_arr[:, 0] - 1, temp_arr[:, 1] - 1])",
        "np.maximum(temp_ratings['value'], X[temp_ratings['user_id'] - 1, temp_ratings['item_id'] - 1])",
        "np.multiply(M[:, None], U)"
    ],
    "1.4. Dealing with SettingWithCopyWarning": [
        "for i in genres:\n    d[i] = new_ratings[new_ratings[i] == 1].rating.mean()",
        "for genre in genres:\n    grouped_date_genre = movies.groupby('release_date')[genre].sum()\n    movie_count_by_genre_year[genre] = defaultdict(int)\n    for (full_year, movie_count) in grouped_date_genre.items():\n        movie_count_by_genre_year[genre][int(full_year[-4:])] += movie_count"
    ],
    "3.2 Groupby: split-apply-combine": [
        "ratings.groupby('item_id')",
        "k.groupby('Year')",
        "movies.groupby('release_date')",
        "f.groupby('year')",
        "genre_df.groupby('year')",
        "ratings.groupby('month')",
        "month_integrated_year.groupby('mon')",
        "ratings.groupby('item_id')",
        "ratings.groupby('item_id').agg({'item_id': 'count', 'rating': 'mean'})",
        "ratings.groupby('item_id')",
        "ratings.groupby('item_id')",
        "ratings.groupby('item_id').agg(rating_count=('rating', 'count'), avg_rating=('rating', 'mean'))",
        "ratings.groupby('item_id')",
        "def matrix_data(ratings):\n    user_mean = ratings.groupby('user_id', as_index=False).agg({'rating': 'mean'})\n    movie_mean = ratings.groupby('item_id', as_index=False).agg({'rating': 'mean'})\n    m = user_mean.shape[0]\n    n = movie_mean.shape[0]\n    user_unq = np.unique(ratings['user_id'])\n    movie_unq = np.unique(ratings['item_id'])\n    user_mapper = dict(zip(user_unq, list(range(m))))\n    movie_mapper = dict(zip(movie_unq, list(range(n))))\n    user_index = [user_mapper[i] for i in ratings['user_id']]\n    item_index = [movie_mapper[i] for i in ratings['item_id']]\n    X = csr_matrix((ratings['rating'], (user_index, item_index)), shape=(m, n))\n    return (X.toarray(), user_mean['rating'].values, movie_mean['rating'].values)",
        "v.groupby('item_id')",
        "ratings.groupby('user_id')",
        "ratings.groupby('item_id')"
    ],
    "1.3. Data Access": [
        "int(movie['release_date'][-4:])",
        "for genre in genres:\n    result[genre] = df.loc[genre, :].to_dict()['count']",
        "df.loc[genre, :].to_dict()",
        "df['release_date'].str[-4:].astype(int)",
        "def movie_count_by_genre(movies, genres):\n    movies['release_year'] = movies['release_date'].str[-4:]\n    res = {}\n    for genre in genres:\n        res[genre] = {}\n        movie_genres = movies.loc[movies[genre] == 1]\n        ans = movie_genres['release_year'].value_counts(dropna=True)\n        for (year, count) in ans.iteritems():\n            year = int(year)\n            res[genre][year] = count\n    return res",
        "movies['release_year'] = movies['release_date'].str[-4:]",
        "int(movie['release_date'][-4:])",
        "movies['year'] = df_new",
        "movies_year['release_year'] = movies_year['release_date'].str[-4:]",
        "zip(movies.index, movies['release_date'])",
        "rating = row['rating']",
        "item_id = row['item_id']",
        "df_movie_rating = df_movie_rating[['release_year', 'rating']]",
        "result = result[['month', 'rating_count']]",
        "df['rating'] = ratings['rating']",
        "for (m, r) in zip(ratings['item_id'], ratings['rating']):\n    if m not in mr_dict:\n        mr_dict[m] = []\n    mr_dict[m].append(r)",
        "zip(ratings['item_id'], ratings['rating'])",
        "len(mr_dict[m])",
        "if m not in mr_dict:\n    mr_dict[m] = []",
        "list(all_ratings.index[::-1][:10])",
        "result['item_id'].head(size)",
        "df1 = ratings[['item_id', 'rating']]",
        "movies_list = df['item_id']",
        "temp = ratings[['item_id', 'rating']]",
        "rating = row['rating']",
        "user_index = [user_mapper[i] for i in ratings['user_id']]",
        "item_index = [movie_mapper[i] for i in ratings['item_id']]",
        "np.array([user_id_to_index[user_id] for user_id in ratings['user_id']])",
        "np.array([movie_id_to_index[movie_id] for movie_id in ratings['item_id']])",
        "V[:, 1] = v2"
    ],
    "dataframe iteration": [
        "movies.iterrows()",
        "movie_count_by_genre = {genre: {} for genre in genres}",
        "ans.iteritems()",
        "movies.iterrows()",
        "movie_count_by_genre = {genre: {} for genre in genres}",
        "ratings.iterrows()",
        "ratings.iterrows()",
        "for i in range(num_users):\n    _x_row_i = X_row.getrow(i)\n    mask = _x_row_i != 0\n    mask = mask.A\n    V_masked = V * mask\n    _left = V_masked @ V_masked.T\n    _left += lam * np.eye(_left.shape[0])\n    _left = np.linalg.inv(_left)\n    _right = V_masked @ _x_row_i.A.T\n    _result = _left @ _right\n    U[i, :] = _result.squeeze()"
    ],
    "remove NAN values": [
        "def movie_count_by_genre(movies, genres):\n    df = movies.copy()\n    df = df[df['release_date'].notna()]\n    df['release_year'] = df['release_date'].str[-4:].astype(int)\n    df = df.reset_index().drop_duplicates(['movie_id', 'release_year'])\n    df = df[['release_year'] + genres].melt(id_vars=['release_year'], value_vars=genres, var_name='genre', value_name='value')\n    df = df[df['value'] == 1]\n    df = df.groupby(['genre', 'release_year']).agg(count=('value', 'count'))\n    result = {}\n    for genre in genres:\n        result[genre] = df.loc[genre, :].to_dict()['count']\n    return result",
        "movies['release_date'].notna()",
        "def movie_count_by_genre(movies, genres):\n    movies = movies.dropna(subset=['release_date'])\n    movies['release_date'] = movies['release_date'].astype(str)\n    df_new = movies['release_date'].str.slice(-4)\n    movies['year'] = df_new\n    movies['year'] = movies['year'].astype(int)\n    result = {}\n    for genre in genres:\n        genre_df = movies.loc[movies[genre] == 1]\n        count_df = genre_df.groupby('year').count()\n        filt = count_df['movie_title'] > 0\n        count_df = count_df[filt]\n        year_mp = count_df['movie_title'].to_dict()\n        result[genre] = year_mp\n    return result",
        "year_series.notnull()",
        "pd.isnull(release_date)",
        "def movie_rating_distribution(movies, ratings, starting_year=1990):\n    movies_copy = movies.copy()\n    movies_copy['release_year'] = movies_copy['release_date'].str.split('-').str[-1].dropna().astype('int')\n    ratings_movies_merged = ratings.merge(movies_copy, left_on='item_id', right_on='movie_id', how='left')\n    ratings_movies_merged = ratings_movies_merged[ratings_movies_merged['release_year'] >= starting_year]\n    result = pd.DataFrame()\n    result.insert(0, 'release_year', ratings_movies_merged['release_year'].astype('int'))\n    result.insert(1, 'rating', ratings_movies_merged['rating'])\n    return result",
        "pd.DataFrame(df)",
        "tempx.fillna(0)",
        "tempx.astype('int64')",
        "ui.ravel()",
        "len(X.data)",
        "_result.squeeze()"
    ],
    "convert from wide to long": [
        "df[['release_year'] + genres].melt(id_vars=['release_year'], value_vars=genres, var_name='genre', value_name='value')",
        "movies.melt(id_vars=['release_date'], value_vars=genres, var_name='genre', value_name='is_genre')",
        "ratings.merge(movies[['release_year']], left_on='item_id', right_index=True, how='left')"
    ],
    "Data types": [
        "int(year)",
        "defaultdict(int)",
        "movies['year'].astype(int)",
        "year_series[non_nan_idx].astype(dtype=np.int32)",
        "int(rating)",
        "np.zeros((num_users, num_movies), dtype=int)",
        "tmp_mat.values.astype(np.int64)",
        "np.zeros(sorted_itemids.size, np.int64)",
        "np.zeros((sorted_userids.size, sorted_itemids.size), np.int64)",
        "np.nan_to_num(X)",
        "(X_true != 0).astype(int)",
        "def compute_col_V(j, X, U, lam, k):\n    data2 = np.ones(len(X.data))\n    Y = sp.coo_matrix((data2, (X.row, X.col)), shape=X.shape)\n    Y = Y.tocsc()\n    M = Y.getcol(j).A.ravel()\n    U_masked = np.multiply(M[:, None], U)\n    L2 = U_masked.T @ U_masked\n    L1 = np.eye(k) * lam\n    L = L1 + L2\n    R = U.T @ X.tocsc().getcol(j)\n    vj = la.solve(L, R)\n    return list(vj.ravel())",
        "def compute_row_U(i, X, V, lam, k):\n    data2 = np.ones(len(X.data))\n    Y = sp.coo_matrix((data2, (X.row, X.col)), shape=X.shape)\n    Y = Y.tocsr()\n    M = Y.getrow(i).A.ravel()\n    V_masked = np.multiply(M, V)\n    L2 = V_masked @ V_masked.T\n    L1 = np.eye(k) * lam\n    L = L1 + L2\n    R = V @ X.tocsr().getrow(i).A.ravel()\n    ui = la.solve(L, R)\n    return list(ui.ravel())",
        "(X != 0).astype(int)"
    ],
    "lowercase strings and replace": [
        "new_movies['release_date'].str[-4:].dropna()",
        "movies_ratings['release_date'].str[-4:].astype('Int64')",
        "movies['release_date'].str[-4:].astype('Int64')",
        "movies_copy['release_date'].str.split('-')"
    ],
    "Slicing": [
        "int(full_year[-4:])",
        "int(x[-4:])",
        "int(release_date[-4:])",
        "V[:, 2] = v3",
        "V[:, 0] = v1"
    ],
    "1.1 Arrays": [
        "movies.head(3)",
        "np.random.normal(loc=0.0, scale=0.1, size=(m, k))",
        "np.random.normal(loc=0.0, scale=0.1, size=(k, n))",
        "np.eye(k)",
        "np.random.normal(loc=0, scale=0.1, size=(k, X_sparse.shape[1]))",
        "np.random.normal(loc=0, scale=0.1, size=(X_sparse.shape[0], k))",
        "np.eye(k)",
        "np.eye(k)",
        "np.random.normal(loc=0, scale=0.1, size=(num_users, k))",
        "np.random.normal(loc=0, scale=0.1, size=(k, num_movies))",
        "np.random.normal(0, 0.1, size=(num_users, k))",
        "np.random.normal(0, 0.1, size=(k, num_movies))",
        "np.linalg.inv(_left)",
        "np.eye(_left.shape[0])"
    ],
    "get string length": [
        "movies['release_date'].str.slice(-4)",
        "df_movie_rating['release_date'].str.slice(-4)"
    ],
    "wide format dataframe": [
        "pd.DataFrame(result_list, columns=['release_year', 'rating'], dtype='int')",
        "def movies_reviewed_by_month(ratings, year):\n    df = pd.to_datetime(ratings['timestamp'], unit='s')\n    df = pd.DataFrame(df)\n    df = df.rename({'timestamp': 'month'}, axis=1)\n    df['rating'] = ratings['rating']\n    df['year'] = df['month'].dt.year\n    df['month'] = df['month'].dt.month\n    df = df[df['year'] == year].dropna()\n    df = df.groupby(['month']).count().dropna()\n    df = df.rename({'rating': 'rating_count'}, axis=1)\n    result = df.reset_index()\n    result = result[['month', 'rating_count']]\n    return result",
        "def movies_reviewed_by_month(ratings, year):\n    mon = pd.DataFrame(pd.to_datetime(ratings['timestamp'], unit='s').dt.month)\n    yr = pd.DataFrame(pd.to_datetime(ratings['timestamp'], unit='s').dt.year)\n    mon = mon.rename(columns={'timestamp': 'mon'})\n    yr = yr.rename(columns={'timestamp': 'year'})\n    month_integrated = pd.concat([ratings, mon, yr], axis=1)\n    month_integrated_year = month_integrated[month_integrated['year'] == year]\n    by_month = pd.DataFrame(month_integrated_year.groupby('mon').count()['rating'])\n    by_month.reset_index(inplace=True)\n    by_month = by_month.rename(columns={'mon': 'month', 'rating': 'rating_count'})\n    return by_month",
        "def matrix_data(ratings: pd.DataFrame):\n    user_num = len(ratings['user_id'].unique())\n    movie_num = len(ratings['item_id'].unique())\n    X = np.zeros((user_num, movie_num)).astype(int)\n    rating_user_indices = ratings['user_id'].rank(method='dense').astype('int') - 1\n    rating_movie_indices = ratings['item_id'].rank(method='dense').astype('int') - 1\n    X[rating_user_indices, rating_movie_indices] = ratings['rating']\n    user_means = X.mean(axis=1, where=X != 0)\n    movie_means = X.mean(axis=0, where=X != 0)\n    return (X, user_means, movie_means)",
        "def matrix_data(ratings):\n    temp_ratings = ratings[['user_id', 'item_id', 'rating']].sort_values(by=['user_id', 'item_id']).melt(id_vars=['user_id', 'item_id'], value_vars=['rating'], var_name='attribute', value_name='value')\n    X = np.zeros((temp_ratings['user_id'].nunique(), temp_ratings['item_id'].nunique()), dtype=np.int64)\n    user_means = np.zeros((temp_ratings['user_id'].nunique(),))\n    movie_means = np.zeros((temp_ratings['item_id'].nunique(),))\n    X[temp_ratings['user_id'] - 1, temp_ratings['item_id'] - 1] = np.maximum(temp_ratings['value'], X[temp_ratings['user_id'] - 1, temp_ratings['item_id'] - 1])\n    user_means = X.sum(axis=1) / np.count_nonzero(X, axis=1)\n    movie_means = X.sum(axis=0) / np.count_nonzero(X, axis=0)\n    return (X, user_means, movie_means)"
    ],
    "convert NumPy matrix to Pandas dataframe": [
        "pd.DataFrame(year)",
        "np.random.seed(seed)",
        "np.random.seed(seed)",
        "np.random.seed(seed)",
        "np.random.seed(seed)",
        "np.random.seed(seed)",
        "np.random.seed(seed)",
        "np.random.seed(seed)",
        "np.random.seed(seed)",
        "np.random.seed(seed)"
    ],
    "frequency count for each unique value": [
        "monthtime_series.value_counts()",
        "df2_robust.to_dict()"
    ],
    "convert from long to wide": [
        "df.rename({'timestamp': 'month'}, axis=1)",
        "df.rename({'rating': 'rating_count'}, axis=1)",
        "yr.rename(columns={'timestamp': 'year'})",
        "mon.rename(columns={'timestamp': 'mon'})",
        "by_month.rename(columns={'mon': 'month', 'rating': 'rating_count'})",
        "df2_robust.rename({'rating': 'count'}, axis=1)",
        "temp.pivot_table(index='item_id', values='rating', aggfunc=('count', 'mean'))",
        "ratings.pivot_table(index='user_id', columns='item_id', aggfunc='max', values='rating')",
        "ratings.pivot_table(index='user_id', columns='item_id', values='rating', fill_value=0)",
        "temp.pivot_table(index='user_id', columns='item_id', values='rating')"
    ],
    "convert Pandas dataframe to Numpy matrix": [
        "ratings.copy()",
        "ratings.copy()",
        "ratings.copy()"
    ],
    "1.1. Series": [
        "def best_worst_movies(ratings, threshold=50, size=10):\n    mr_dict = {}\n    for (m, r) in zip(ratings['item_id'], ratings['rating']):\n        if m not in mr_dict:\n            mr_dict[m] = []\n        mr_dict[m].append(r)\n    mr_avg = {}\n    for m in mr_dict:\n        if len(mr_dict[m]) > 50:\n            avg = sum(mr_dict[m]) / len(mr_dict[m])\n            mr_avg[m] = avg\n    sorted_avg = sorted(mr_avg.items(), key=lambda x: x[1])\n    worst = [s[0] for s in sorted_avg[:10]]\n    best = [s[0] for s in sorted_avg[-10:]][::-1]\n    return (best, worst)",
        "def best_worst_movies(ratings, threshold=50, size=10):\n    ratings_copy = ratings.copy()\n    df = ratings_copy.groupby(['item_id']).size().reset_index(name='counts')\n    df = df[df['counts'] > threshold]\n    movies_list = df['item_id']\n    filt = ratings_copy['item_id'].isin(movies_list)\n    ratings_copy = ratings_copy[filt]\n    df2 = ratings_copy.groupby(['item_id']).mean()\n    df2 = df2.reset_index()\n    worst = df2.sort_values(by=['rating'])['item_id'].iloc[:10].tolist()\n    best = df2.sort_values(by=['rating'], ascending=False)['item_id'].iloc[:10].tolist()\n    return (best, worst)\n    pass"
    ],
    "2.2. Internal representation": [
        "for m in mr_dict:\n    if len(mr_dict[m]) > 50:\n        avg = sum(mr_dict[m]) / len(mr_dict[m])\n        mr_avg[m] = avg",
        "for i in range(num_users):\n    ratings_i = X[i, :]\n    nonzero_ratings_i = ratings_i[ratings_i != 0]\n    user_means[i] = np.mean(nonzero_ratings_i)",
        "def matrix_data(ratings):\n    tmp_mat = ratings.pivot_table(index='user_id', columns='item_id', aggfunc='max', values='rating')\n    user_means = tmp_mat.mean(axis=1)\n    movies_means = tmp_mat.mean(axis=0)\n    tmp_mat.fillna(0, inplace=True)\n    tmp_mat = tmp_mat.values.astype(np.int64)\n    return (tmp_mat, user_means.values, movies_means.values)",
        "def matrix_data(ratings):\n    X = ratings.pivot_table(index='user_id', columns='item_id', values='rating', fill_value=0)\n    return (X.to_numpy(dtype=int), X.mean(axis=1), X.mean(axis=0))",
        "def matrix_data(ratings):\n    temp_arr = np.array(ratings[['user_id', 'item_id', 'rating']].sort_values(by=['user_id', 'item_id']))\n    X = np.zeros((ratings['user_id'].nunique(), ratings['item_id'].nunique()), dtype=np.int64)\n    user_means = np.zeros((ratings['user_id'].nunique(),))\n    movie_means = np.zeros((ratings['item_id'].nunique(),))\n    X[temp_arr[:, 0] - 1, temp_arr[:, 1] - 1] = np.maximum(temp_arr[:, 2], X[temp_arr[:, 0] - 1, temp_arr[:, 1] - 1])\n    print(X.shape)\n    user_means = X.sum(axis=1) / np.count_nonzero(X, axis=1)\n    movie_means = X.sum(axis=0) / np.count_nonzero(X, axis=0)\n    return (X, user_means, movie_means)",
        "def matrix_data(ratings):\n    sorted_userids = np.sort(ratings.user_id.unique())\n    sorted_itemids = np.sort(ratings.item_id.unique())\n    rating_matrix = np.zeros((sorted_userids.size, sorted_itemids.size), np.int64)\n    for i in range(sorted_userids.size):\n        w = np.zeros(sorted_itemids.size, np.int64)\n        v = ratings[ratings['user_id'] == sorted_userids[i]]\n        v = v.groupby('item_id').agg(max_rating=('rating', 'max'))\n        np.put(w, np.where(np.isin(sorted_itemids, v.index)), v.max_rating)\n        rating_matrix[i] = w\n    user_means = np.zeros(sorted_userids.size)\n    v = ratings.groupby('user_id').agg(mean_rating=('rating', 'mean'))\n    np.put(user_means, np.where(np.isin(sorted_userids, v.index)), v.mean_rating)\n    movie_means = np.zeros(sorted_itemids.size)\n    v = ratings.groupby('item_id').agg(mean_rating=('rating', 'mean'))\n    np.put(movie_means, np.where(np.isin(sorted_itemids, v.index)), v.mean_rating)\n    return (rating_matrix, user_means, movie_means)",
        "for i in range(sorted_userids.size):\n    w = np.zeros(sorted_itemids.size, np.int64)\n    v = ratings[ratings['user_id'] == sorted_userids[i]]\n    v = v.groupby('item_id').agg(max_rating=('rating', 'max'))\n    np.put(w, np.where(np.isin(sorted_itemids, v.index)), v.max_rating)\n    rating_matrix[i] = w",
        "def cosine_similarity(X):\n    norm = np.linalg.norm(X, axis=1)\n    denom = np.outer(norm, norm)\n    num = np.dot(X, X.T)\n    return num / denom\n    pass",
        "def cosine_similarity(X):\n    normed = np.linalg.norm(X, axis=1)\n    normed = normed.reshape((normed.shape[0], 1))\n    denom = np.matmul(normed, normed.T)\n    numer = np.matmul(X, X.T)\n    return numer / denom",
        "def cosine_similarity(X):\n    X = np.nan_to_num(X)\n    norm = np.linalg.norm(X, axis=1)\n    W = X @ X.T / np.outer(norm, norm)\n    return W",
        "def cosine_similarity(X):\n    X_pairwise_dot = np.einsum('ij,kj->ik', X, X)\n    X_row_norm = np.sqrt(np.einsum('ij,ij->i', X, X))\n    return X_pairwise_dot / np.einsum('i,j->ij', X_row_norm, X_row_norm)",
        "def cosine_similarity(X):\n    nume = X @ X.T\n    deno1 = np.sqrt(np.sum(np.square(X), axis=1))\n    deno = np.outer(deno1, deno1.T)\n    final_output = nume / deno\n    return final_output\n    pass",
        "def cosine_similarity(X):\n    matrix_1 = np.dot(X, X.T)\n    l2_norm = np.sqrt(np.sum(X * X, axis=1))\n    norm_matrix = np.outer(l2_norm, l2_norm)\n    cosine = matrix_1 / norm_matrix\n    return cosine",
        "def cosine_similarity(X):\n    raw_prod = X @ X.T\n    norm = la.norm(X, axis=1)\n    return np.divide(np.divide(raw_prod, norm).T, norm).T",
        "for w in range(niters):\n    for i in range(V.shape[1]):\n        r_indices = [r for (r, c) in zip(X_csr.nonzero()[0], X_csr.nonzero()[1]) if c == i]\n        if k == 1:\n            V[:, i] = ((U[r_indices].T @ U[r_indices]) ** (-1) @ (U[r_indices].T @ X_csr[r_indices, i]).reshape(-1, 1)).T\n        else:\n            V[:, i] = (np.linalg.inv(lam * np.eye(k) + U[r_indices].T @ U[r_indices]) @ (U[r_indices].T @ X_csr[r_indices, i]).reshape(-1, 1)).T\n    for i in range(U.shape[0]):\n        c_indices = [c for (r, c) in zip(X_csr.nonzero()[0], X_csr.nonzero()[1]) if r == i]\n        if k == 1:\n            U[i, :] = (V[:, c_indices] @ V[:, c_indices].T) ** (-1) @ (V[:, c_indices] @ X_csc[i, c_indices])\n        else:\n            U[i:i + 1, :] = (np.linalg.inv(lam * np.eye(k) + V[:, c_indices] @ V[:, c_indices].T) @ (V[:, c_indices] @ X_csc[i, c_indices].T)).T",
        "for _ in range(niters):\n    v1 = la.inv(lam * np.eye(k) + U[indicator_matrix[:, 0] != 0].T @ U[indicator_matrix[:, 0] != 0]) @ np.dot(X[:, 0][indicator_matrix[:, 0] != 0], U[indicator_matrix[:, 0] != 0])\n    v2 = la.inv(lam * np.eye(k) + U[indicator_matrix[:, 1] != 0].T @ U[indicator_matrix[:, 1] != 0]) @ np.dot(X[:, 1][indicator_matrix[:, 1] != 0], U[indicator_matrix[:, 1] != 0])\n    v3 = la.inv(lam * np.eye(k) + U[indicator_matrix[:, 2] != 0].T @ U[indicator_matrix[:, 2] != 0]) @ np.dot(X[:, 2][indicator_matrix[:, 2] != 0], U[indicator_matrix[:, 2] != 0])\n    V[:, 0] = v1\n    V[:, 1] = v2\n    V[:, 2] = v3\n    V = np.vstack((v1, v2, v3))\n    u1 = la.inv(lam * np.eye(k) + V[indicator_matrix[0, :] != 0].T @ V[indicator_matrix[0, :] != 0]) @ np.dot(X[0, :][indicator_matrix[0, :] != 0], V[indicator_matrix[0, :] != 0])\n    u2 = la.inv(lam * np.eye(k) + V[indicator_matrix[1, :] != 0].T @ V[indicator_matrix[1, :] != 0]) @ np.dot(X[1, :][indicator_matrix[1, :] != 0], V[indicator_matrix[1, :] != 0])\n    U[0] = u1\n    U[1] = u2",
        "for iter in range(niters):\n    for j in range(num_movies):\n        _x_col_j = X_col.getcol(j)\n        mask = _x_col_j != 0\n        mask = mask.A\n        U_masked = U * mask\n        _left = U_masked.T @ U_masked\n        _left += lam * np.eye(_left.shape[0])\n        _left = np.linalg.inv(_left)\n        _right = U_masked.T @ _x_col_j.A\n        _result = _left @ _right\n        V[:, j] = _result.squeeze()\n    for i in range(num_users):\n        _x_row_i = X_row.getrow(i)\n        mask = _x_row_i != 0\n        mask = mask.A\n        V_masked = V * mask\n        _left = V_masked @ V_masked.T\n        _left += lam * np.eye(_left.shape[0])\n        _left = np.linalg.inv(_left)\n        _right = V_masked @ _x_row_i.A.T\n        _result = _left @ _right\n        U[i, :] = _result.squeeze()",
        "for j in range(num_movies):\n    _x_col_j = X_col.getcol(j)\n    mask = _x_col_j != 0\n    mask = mask.A\n    U_masked = U * mask\n    _left = U_masked.T @ U_masked\n    _left += lam * np.eye(_left.shape[0])\n    _left = np.linalg.inv(_left)\n    _right = U_masked.T @ _x_col_j.A\n    _result = _left @ _right\n    V[:, j] = _result.squeeze()"
    ],
    "Array math": [
        "range(n)",
        "np.zeros((user_num, movie_num))",
        "print(tempx)",
        "coo_matrix((np_ratings, (np_row_indices, np_col_indices)), shape=(M, N))",
        "np.dot(X, X.T)",
        "np.outer(norm, norm)",
        "def cosine_similarity(X):\n    pass",
        "def cosine_similarity(X):\n    pass",
        "np.outer(norm, norm)",
        "np.einsum('ij,ij->i', X, X)",
        "np.einsum('ij,kj->ik', X, X)",
        "np.einsum('i,j->ij', X_row_norm, X_row_norm)",
        "nume = X @ X.T",
        "np.square(X)",
        "np.outer(deno1, deno1.T)",
        "np.outer(l2_norm, l2_norm)",
        "np.dot(X, X.T)",
        "def cosine_similarity(X):\n    pass",
        "raw_prod = X @ X.T",
        "np.divide(raw_prod, norm)",
        "def mean_rating_diff(X_true, X_pred):\n    pass",
        "def mean_rating_diff(X_true, X_pred):\n    pass",
        "def mean_rating_diff(X_true, X_pred):\n    pass",
        "def mean_rating_diff(X_true, X_pred):\n    pass",
        "def mean_rating_diff(X_true, X_pred):\n    pass",
        "def mean_rating_diff(X_true, X_pred):\n    pass",
        "def mean_rating_diff(X_true, X_pred):\n    pass",
        "la.solve(L, R)",
        "sp.coo_matrix((data2, (X.row, X.col)), shape=X.shape)",
        "range(n)",
        "np.multiply(M, V)",
        "L2 = V_masked @ V_masked.T",
        "L2 = U_masked.T @ U_masked",
        "np.vstack((v1, v2, v3))",
        "_right = V_masked @ _x_row_i.A.T",
        "_right = U_masked.T @ _x_col_j.A",
        "_result = _left @ _right",
        "_left = V_masked @ V_masked.T",
        "_left = U_masked.T @ U_masked",
        "((X - item_means[None, :]) * indicator).dot(W)",
        "((X - item_means[None, :]) * indicator).dot(W)",
        "((X - item_means[None, :]) * indicator).dot(W)",
        "((X - item_means[None, :]) * indicator).dot(W)",
        "((X - item_means[None, :]) * indicator).dot(W)",
        "((X - item_means[None, :]) * indicator).dot(W)"
    ],
    "Caution about array shapes": [
        "n = movie_mean.shape[0]",
        "m = user_mean.shape[0]",
        "print(X.shape)",
        "range(sorted_userids.size)",
        "np.zeros(sorted_itemids.size)",
        "np.matmul(X, X.T)",
        "np.matmul(normed, normed.T)",
        "normed.reshape((normed.shape[0], 1))",
        "(m, n) = X_sparse.shape",
        "for i in range(V.shape[1]):\n    r_indices = [r for (r, c) in zip(X_csr.nonzero()[0], X_csr.nonzero()[1]) if c == i]\n    if k == 1:\n        V[:, i] = ((U[r_indices].T @ U[r_indices]) ** (-1) @ (U[r_indices].T @ X_csr[r_indices, i]).reshape(-1, 1)).T\n    else:\n        V[:, i] = (np.linalg.inv(lam * np.eye(k) + U[r_indices].T @ U[r_indices]) @ (U[r_indices].T @ X_csr[r_indices, i]).reshape(-1, 1)).T",
        "range(V.shape[1])",
        "range(U.shape[0])",
        "U[i, :] = (V[:, c_indices] @ V[:, c_indices].T) ** (-1) @ (V[:, c_indices] @ X_csc[i, c_indices])",
        "(num_users, num_movies) = X_sparse.shape",
        "(num_users, num_movies) = X_sparse.shape"
    ],
    "array element access": [
        "print(X[0])"
    ],
    "Sum of every row in the dataframe": [
        "np.count_nonzero(X, axis=1)",
        "np.count_nonzero(X, axis=1)",
        "np.sum(X * X, axis=1)"
    ],
    "elementwise operation between multiple series": [
        "final_output = nume / deno",
        "cosine = matrix_1 / norm_matrix"
    ],
    "convert returned row (2D sparse matrix) to dense vector": [
        "vj.ravel()",
        "Y.getrow(i)",
        "X_row.getrow(i)"
    ],
    "Boolean array indexing": [
        "def low_rank_matrix_factorization(X_sparse, k, niters=5, lam=10.0, seed=0):\n    np.random.seed(seed)\n    (m, n) = X_sparse.shape\n    U = np.random.normal(loc=0.0, scale=0.1, size=(m, k))\n    V = np.random.normal(loc=0.0, scale=0.1, size=(k, n))\n    for i in range(niters):\n        V = np.array([compute_col_V(j, X_sparse, U, lam, k) for j in range(n)]).T\n        U = np.array([compute_row_U(i, X_sparse, V, lam, k) for i in range(m)])\n    return (U, V)",
        "def low_rank_matrix_factorization(X_sparse, k, niters=5, lam=10.0, seed=0):\n    np.random.seed(seed)\n    U = np.random.normal(loc=0, scale=0.1, size=(X_sparse.shape[0], k))\n    V = np.random.normal(loc=0, scale=0.1, size=(k, X_sparse.shape[1]))\n    X_csr = X_sparse.tocsr()\n    X_csc = X_sparse.tocsc()\n    for w in range(niters):\n        for i in range(V.shape[1]):\n            r_indices = [r for (r, c) in zip(X_csr.nonzero()[0], X_csr.nonzero()[1]) if c == i]\n            if k == 1:\n                V[:, i] = ((U[r_indices].T @ U[r_indices]) ** (-1) @ (U[r_indices].T @ X_csr[r_indices, i]).reshape(-1, 1)).T\n            else:\n                V[:, i] = (np.linalg.inv(lam * np.eye(k) + U[r_indices].T @ U[r_indices]) @ (U[r_indices].T @ X_csr[r_indices, i]).reshape(-1, 1)).T\n        for i in range(U.shape[0]):\n            c_indices = [c for (r, c) in zip(X_csr.nonzero()[0], X_csr.nonzero()[1]) if r == i]\n            if k == 1:\n                U[i, :] = (V[:, c_indices] @ V[:, c_indices].T) ** (-1) @ (V[:, c_indices] @ X_csc[i, c_indices])\n            else:\n                U[i:i + 1, :] = (np.linalg.inv(lam * np.eye(k) + V[:, c_indices] @ V[:, c_indices].T) @ (V[:, c_indices] @ X_csc[i, c_indices].T)).T\n    return (U, V)\n    pass",
        "def low_rank_matrix_factorization(X_sparse, k, niters=5, lam=10.0, seed=0):\n    np.random.seed(seed)\n    X = X_sparse.toarray()\n    (num_users, num_movies) = X_sparse.shape\n    U = np.random.normal(loc=0, scale=0.1, size=(num_users, k))\n    V = np.random.normal(loc=0, scale=0.1, size=(k, num_movies))\n    indicator_matrix = (X != 0).astype(int)\n    for _ in range(niters):\n        v1 = la.inv(lam * np.eye(k) + U[indicator_matrix[:, 0] != 0].T @ U[indicator_matrix[:, 0] != 0]) @ np.dot(X[:, 0][indicator_matrix[:, 0] != 0], U[indicator_matrix[:, 0] != 0])\n        v2 = la.inv(lam * np.eye(k) + U[indicator_matrix[:, 1] != 0].T @ U[indicator_matrix[:, 1] != 0]) @ np.dot(X[:, 1][indicator_matrix[:, 1] != 0], U[indicator_matrix[:, 1] != 0])\n        v3 = la.inv(lam * np.eye(k) + U[indicator_matrix[:, 2] != 0].T @ U[indicator_matrix[:, 2] != 0]) @ np.dot(X[:, 2][indicator_matrix[:, 2] != 0], U[indicator_matrix[:, 2] != 0])\n        V[:, 0] = v1\n        V[:, 1] = v2\n        V[:, 2] = v3\n        V = np.vstack((v1, v2, v3))\n        u1 = la.inv(lam * np.eye(k) + V[indicator_matrix[0, :] != 0].T @ V[indicator_matrix[0, :] != 0]) @ np.dot(X[0, :][indicator_matrix[0, :] != 0], V[indicator_matrix[0, :] != 0])\n        u2 = la.inv(lam * np.eye(k) + V[indicator_matrix[1, :] != 0].T @ V[indicator_matrix[1, :] != 0]) @ np.dot(X[1, :][indicator_matrix[1, :] != 0], V[indicator_matrix[1, :] != 0])\n        U[0] = u1\n        U[1] = u2\n    return (U, V.T)\n    pass",
        "def low_rank_matrix_factorization(X_sparse, k, niters=5, lam=10.0, seed=0):\n    np.random.seed(seed)\n    (num_users, num_movies) = X_sparse.shape\n    U = np.random.normal(0, 0.1, size=(num_users, k))\n    V = np.random.normal(0, 0.1, size=(k, num_movies))\n    X_col = X_sparse.tocsc()\n    X_row = X_sparse.tocsr()\n    for iter in range(niters):\n        for j in range(num_movies):\n            _x_col_j = X_col.getcol(j)\n            mask = _x_col_j != 0\n            mask = mask.A\n            U_masked = U * mask\n            _left = U_masked.T @ U_masked\n            _left += lam * np.eye(_left.shape[0])\n            _left = np.linalg.inv(_left)\n            _right = U_masked.T @ _x_col_j.A\n            _result = _left @ _right\n            V[:, j] = _result.squeeze()\n        for i in range(num_users):\n            _x_row_i = X_row.getrow(i)\n            mask = _x_row_i != 0\n            mask = mask.A\n            V_masked = V * mask\n            _left = V_masked @ V_masked.T\n            _left += lam * np.eye(_left.shape[0])\n            _left = np.linalg.inv(_left)\n            _right = V_masked @ _x_row_i.A.T\n            _result = _left @ _right\n            U[i, :] = _result.squeeze()\n    return (U, V)",
        "def predict_item_item(X, W, item_means, eps=1e-12):\n    indicator = X != 0\n    fenmu = ((X - item_means[None, :]) * indicator).dot(W)\n    fenzi = indicator.dot(np.abs(W)) + eps\n    return fenmu / fenzi + item_means[None, :]\n    pass",
        "def predict_item_item(X, W, item_means, eps=1e-12):\n    indicator = X != 0\n    fenmu = ((X - item_means[None, :]) * indicator).dot(W)\n    fenzi = indicator.dot(np.abs(W)) + eps\n    return fenmu / fenzi + item_means[None, :]\n    pass",
        "def predict_item_item(X, W, item_means, eps=1e-12):\n    indicator = X != 0\n    fenmu = ((X - item_means[None, :]) * indicator).dot(W)\n    fenzi = indicator.dot(np.abs(W)) + eps\n    return fenmu / fenzi + item_means[None, :]\n    pass",
        "def predict_item_item(X, W, item_means, eps=1e-12):\n    indicator = X != 0\n    fenmu = ((X - item_means[None, :]) * indicator).dot(W)\n    fenzi = indicator.dot(np.abs(W)) + eps\n    return fenmu / fenzi + item_means[None, :]\n    pass",
        "def predict_item_item(X, W, item_means, eps=1e-12):\n    indicator = X != 0\n    fenmu = ((X - item_means[None, :]) * indicator).dot(W)\n    fenzi = indicator.dot(np.abs(W)) + eps\n    return fenmu / fenzi + item_means[None, :]\n    pass",
        "def predict_item_item(X, W, item_means, eps=1e-12):\n    indicator = X != 0\n    fenmu = ((X - item_means[None, :]) * indicator).dot(W)\n    fenzi = indicator.dot(np.abs(W)) + eps\n    return fenmu / fenzi + item_means[None, :]\n    pass"
    ],
    "3.1 Creating sparse matrix": [
        "for i in range(niters):\n    V = np.array([compute_col_V(j, X_sparse, U, lam, k) for j in range(n)]).T\n    U = np.array([compute_row_U(i, X_sparse, V, lam, k) for i in range(m)])",
        "if k == 1:\n    U[i, :] = (V[:, c_indices] @ V[:, c_indices].T) ** (-1) @ (V[:, c_indices] @ X_csc[i, c_indices])\nelse:\n    U[i:i + 1, :] = (np.linalg.inv(lam * np.eye(k) + V[:, c_indices] @ V[:, c_indices].T) @ (V[:, c_indices] @ X_csc[i, c_indices].T)).T",
        "if k == 1:\n    V[:, i] = ((U[r_indices].T @ U[r_indices]) ** (-1) @ (U[r_indices].T @ X_csr[r_indices, i]).reshape(-1, 1)).T\nelse:\n    V[:, i] = (np.linalg.inv(lam * np.eye(k) + U[r_indices].T @ U[r_indices]) @ (U[r_indices].T @ X_csr[r_indices, i]).reshape(-1, 1)).T"
    ],
    "data overview": [
        "Y.tocsc()",
        "X.tocsc()",
        "X_sparse.tocsc()",
        "X_sparse.tocsc()"
    ],
    "convert returned column (2D sparse matrix) to dense vector": [
        "Y.getcol(j)",
        "X_col.getcol(j)"
    ],
    "Broadcasting": [
        "(U[r_indices].T @ X_csr[r_indices, i]).reshape(-1, 1)"
    ]
}