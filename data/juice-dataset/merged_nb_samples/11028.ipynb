{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d86557f",
   "metadata": {},
   "source": [
    "# Analysis of NSF Abstracts\n",
    "\n",
    "Here we show some practical Text Analysis with emphasis on Feature Engineering on the collection of NSF Award abstracts. Abstracts are generously available at **UCI Machine Learning Dataset** collection by **Michael J. Pazzani** (hope my citation is right!).\n",
    "\n",
    "Each document consists of a research abstract along with metadata including the name of NSF department to which the abstract belongs. Here is an example of how these documents look like:\n",
    "\n",
    "\n",
    "<img src=\"doc_ex.png\" width=\"800\">\n",
    "\n",
    "As seen above, the funded research is on Mathematics and the department is Devision of Mathematical Science with tag **DMS**.\n",
    "\n",
    "For sake of practicing, we exclude all meta data and only use abstract text to predict the department."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7ea516",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "import os\n",
    "import itertools\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import pickle \n",
    "import time\n",
    "import string\n",
    "from collections import Counter\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import warnings\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa90b68",
   "metadata": {},
   "source": [
    "# Reading Raw Files\n",
    "\n",
    "For sake of simplicity I used I processed data beforehand and here will just upload it but the process of reading files is in the **read_data** function for those who want to check.\n",
    "\n",
    "In this showcase we use only a fraction of text documents. The complete dataset is from 1990 to 2003 with almost 129000 documents. \n",
    "\n",
    "**PS:** *Later I decided to limit the scope of analysis to only 3 tags (classes) to ease running the notebook for everyone. You may skip this limitation and explore a broader analysis.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43728557",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(nsf_data_dir, pfile=False, wrt=False):\n",
    "    if pfile == True:\n",
    "        data = pickle.load( open( \"data.p\", \"rb\" ) )\n",
    "        return data\n",
    "    d = {}\n",
    "\n",
    "    for root, dirs, files in os.walk(nsf_data_dir):\n",
    "        print(root)\n",
    "        for f in files:\n",
    "            if 'txt' in f:\n",
    "                d[f] = []\n",
    "                fle = open(os.path.join(root, f), \"r\")\n",
    "                content = ' '.join([ii.strip() for ii in fle.readlines()])\n",
    "                d[f].append(re.search(r'NSF Org(.*?)Latest', content).group(1).strip(': '))\n",
    "                d[f].append(content.split('Abstract')[1].strip(':  '))\n",
    "                fle.close()\n",
    "\n",
    "    \n",
    "    data = pd.DataFrame.from_dict(d, orient='index')\n",
    "    data.columns = ['Tag','Text']\n",
    "    data['Text'] = data['Text'].str.replace('\\n',' ').str.lower() # Removing new lines / Upper-Case to Lower-Case\n",
    "    data['Text'] = data['Text'].str.replace('\\t',' ') # Removing tabs\n",
    "    data['Text'] = data['Text'].str.replace('_',' ') \n",
    "    data['Text'] = data['Text'].str.replace('[^\\w\\s]',' ') # Removing punctuations\n",
    "    data['Text'] = data['Text'].apply(lambda x: x.translate(str.maketrans(' ',' ',string.digits))) # Removing numbers\n",
    "    if wrt:\n",
    "        pickle.dump( data, open( \"data_1995_2003.p\", \"wb\" ) )\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23250cc2",
   "metadata": {},
   "source": [
    "Indices are the file names and two columns Text and Tag represent the research abstract and the department respectively. As you see bellow a part of abstracts are not available! The description of data shows even more duplicate texts.\n",
    "\n",
    "Let's go through them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507d01ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I initially choose only 3 tags to ease and lighten the whole tutorial. \n",
    "# You can start (and even finish!) with larger fraction of data.\n",
    "data = read_data('NSF',pfile=True)\n",
    "data = data[data['Tag'].isin(['OCE','DMS','CHE'])]\n",
    "\n",
    "# Have a look at how data is organized\n",
    "display(data.head())\n",
    "\n",
    "# Get a summary of data\n",
    "display(data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07264ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search duplicates and keep only one from each\n",
    "for text,count in Counter(data['Text']).items():\n",
    "    if count>1:\n",
    "        data.drop(list(data.index[data['Text']==text])[1::],axis=0,inplace=True)\n",
    "\n",
    "# Get a summary of data again\n",
    "display(data.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3784064",
   "metadata": {},
   "source": [
    "So the problem of duplicates is solved (in a blind way!) but is every abstract informative?\n",
    "\n",
    "Let's explore short abstracts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813d7653",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search short (probably not informative) abstracts\n",
    "c = Counter(data['Text'])\n",
    "for text, count in c.items():\n",
    "    if len(text) < 150: # try with 1000 as well and see how it affects\n",
    "        data.drop(data.index[data['Text']==text],axis=0,inplace=True)\n",
    "        \n",
    "# Get a summary of data again\n",
    "display(data.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff26a4f",
   "metadata": {},
   "source": [
    "Before starting anything, we need to know how classes (here *Tags*) are distributed as a general aspect of data. Histograms are the right way to do this but here I would like to show more detailed information so I simply sort the class populations and plot it.\n",
    "\n",
    "**PS:** *It makes much more sense in the presence of whole dataset. Now we are limited to only 3 classes. Please remove this limitation and run the code again to get a better insight about what imbalance class distribution means.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d03afb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Class population in ascending order:\\n',sorted(list(Counter(data['Tag'].tolist()).values())))\n",
    "# plt.figure(figsize=(15,5))\n",
    "# plt.plot(sorted(list(Counter(data['Tag'].tolist()).values())),'-*')\n",
    "# plt.ylabel('Population of Classes')\n",
    "# plt.xlabel('Class Index')\n",
    "# plt.show()\n",
    "\n",
    "### Now we can also check the histogram but we choose bins to put close class populations together.\n",
    "\n",
    "print('Class populations\\n',Counter(data['Tag'].tolist()).items())#('First 20 largest classes:\\n',Counter(data['Tag'].tolist()).most_common(20))\n",
    "# plt.figure(figsize=(15,5))\n",
    "# plt.hist(list(Counter(data['Tag'].tolist()).values()),bins=40)\n",
    "# plt.ylabel('# of Classes')\n",
    "# plt.xlabel('Class Population')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41d9209",
   "metadata": {},
   "source": [
    "Let's reduce problem to some classes with almost similar number of samples according to the histogram above (**1000** to **2000**)\n",
    "\n",
    "**PS:** *This does not make sense on the reduced version of problem. Try it on the whole dataset.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535423c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = ['OCE','DMS','CHE'] \n",
    "# We already chose these tags at the beginning. It was supposed to happen here. \n",
    "# Since now on the original task equals the reduced version.\n",
    "\n",
    "# To start our journey, we first need to tokenize the data\n",
    "data = data[data.Tag.isin(tags)]\n",
    "data['Tokens'] = data.apply(lambda row: nltk.word_tokenize(row['Text'].strip()), axis=1)\n",
    "print(len(data),'samples from',len(tags),'classes')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7067e6f4",
   "metadata": {},
   "source": [
    "Let's check the abstract length (in words and characters) as well. It is a pretty naive feature but let's explore it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f857a609",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lengths of documents in character all together\n",
    "lens = [len(ii) for ii in data.Text]\n",
    "print('minimum text length (in char) is:',np.min(lens))\n",
    "print('maximum text length (in char) is:',np.max(lens))\n",
    "print('mean and median text lengths (in char) are:',np.mean(lens),np.median(lens))\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.hist(lens,bins=80)\n",
    "plt.xlabel('Text Length (in char)')\n",
    "plt.ylabel('# of Documents')\n",
    "plt.title('Lengths of documents in character all together')\n",
    "plt.show()\n",
    "\n",
    "# Lengths of documents in character separately\n",
    "lens = {tag:[len(ii) for ii in data.loc[data['Tag']==tag].Text] for tag in tags}\n",
    "plt.figure(figsize=(20,10))\n",
    "for tag in tags:\n",
    "    plt.hist(lens[tag],bins=80,alpha=.5,label=tag)\n",
    "    plt.xlabel('Text Length (in char)')\n",
    "    plt.ylabel('# of Documents')\n",
    "    plt.title('Lengths of documents in character separately')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Lengths of documents in token all together\n",
    "lens = [len(ii) for ii in data.Tokens]\n",
    "print('minimum text length (in token) is:',np.min(lens))\n",
    "print('maximum text length (in token) is:',np.max(lens))\n",
    "print('mean and median text lengths (in token) are:',np.mean(lens),np.median(lens))\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.hist(lens,bins=80)\n",
    "plt.xlabel('Text Length (in token)')\n",
    "plt.ylabel('# of Documents')\n",
    "plt.title('Lengths of documents in token all together')\n",
    "plt.show()\n",
    "\n",
    "# Lengths of documents in token separately\n",
    "lens = {tag:[len(ii) for ii in data.loc[data['Tag']==tag].Tokens] for tag in tags}\n",
    "plt.figure(figsize=(20,10))\n",
    "for tag in tags:\n",
    "    plt.hist(lens[tag],bins=80,alpha=.5,label=tag)\n",
    "    plt.xlabel('Text Length (in token)')\n",
    "    plt.ylabel('# of Documents')\n",
    "    plt.title('Lengths of documents in token separately')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fbc25ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def len_of_tag_char(tag):\n",
    "    return [len(ii) for ii in data[data.Tag == tag]['Text']]\n",
    "def len_of_tag_tok(tag):\n",
    "    return [len(ii) for ii in data[data.Tag == tag]['Tokens']]\n",
    "\n",
    "lengths = [len_of_tag_char(tag) for tag in tags]\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.boxplot(lengths)\n",
    "plt.ylabel('Text Length (character)')\n",
    "plt.xticks([ii for ii in range(1,len(tags)+1)], tags)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "lengths = [len_of_tag_tok(tag) for tag in tags]\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.boxplot(lengths)\n",
    "plt.ylabel('Text Length (token)')\n",
    "plt.xticks([ii for ii in range(1,len(tags)+1)], tags)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90fc5be9",
   "metadata": {},
   "source": [
    "Let's continue with finding StopWords and important words. StopWords are non-informative words inside the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba983af",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_total = Counter()\n",
    "for ind in data.index:\n",
    "    c_total.update(Counter(data.loc[ind].Tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de440d89",
   "metadata": {},
   "source": [
    "In this container, we saved the number of occurances of **each word** in **all documents**. Let's have a look at it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15467fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(c_total.most_common(50))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaeb5064",
   "metadata": {},
   "source": [
    "Now we check the number of times each word appeared in **different documents (Document Frequency)** i.e. if a word appeard several times within a document, we count only one.\n",
    "\n",
    "This reveals a part of our **curpos-based StopWord** list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c17c036",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_unique = Counter()\n",
    "for ind in data.index:\n",
    "    c_unique.update(Counter(set(data.loc[ind].Tokens)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5325e6d1",
   "metadata": {},
   "source": [
    "Let's have a look at them. Are they really StopWords??!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30e789b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('First 15 common words:\\n')\n",
    "for word in c_unique.most_common(15):\n",
    "    print(word[0],'-->', 'appeared in',word[1],'documents out of 10953 documents i.e.',np.round(100*word[1]/len(data),2),'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a357b629",
   "metadata": {},
   "source": [
    "and what about the total number of words?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5efbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('There are',len(c_unique),'unique words i.e. the complete size of our vocab.\\\n",
    " This is the intrinsic dimension of any BoW representation.')\n",
    "\n",
    "print(np.sum(list(c_total.values())), 'words in total (with repeatations) i.e. sum of BoW matrix elements.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efeb740a",
   "metadata": {},
   "source": [
    "Let's check the class-based specification of each word:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5087db10",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_dict = {tag:Counter() for tag in data.Tag.unique()}\n",
    "for ind in data.index:\n",
    "    tag = data.loc[ind]['Tag']\n",
    "    tag_dict[tag].update(Counter(set(data.loc[ind].Tokens)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "076d3c30",
   "metadata": {},
   "source": [
    "Now a fun starts with a basic example. Let's see how words are assigned to tags and what we can infer from this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42189e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_specific_words = pd.DataFrame(columns=['OCE_Words','OCE_%','CHE_Words','CHE_%','DMS_Words','DMS_%'])\n",
    "for tag in ['OCE','CHE', 'DMS']:\n",
    "    len_tag = len(data[data['Tag']==tag])\n",
    "    words = []\n",
    "    percent = []\n",
    "    for word in tag_dict[tag].most_common(15):\n",
    "        words.append(word[0])\n",
    "        percent.append(np.round(100*word[1]/len_tag,2))\n",
    "    tag_specific_words[tag+'_Words'] = words\n",
    "    tag_specific_words[tag+'_%'] = percent\n",
    "display(tag_specific_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a852bf66",
   "metadata": {},
   "source": [
    "Now I repeat the same but this time let's remove some of the very frequent StopWords. It means that we are going from least specific word-tag relation to most specific one. Recall the concept of underfitting-overfitting. (Please note that we did not find all StopWords yet)\n",
    "\n",
    "So let's go this way; first we find most frequent words of each tag ignoring first 50 most common words we found. Then we do it with ignoring first 500 common words and then 5000 and see the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f029d8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n_stop_words in [50,500,5000]:\n",
    "    tag_specific_words = pd.DataFrame(columns=['OCE_Words','OCE_%','CHE_Words','CHE_%','DMS_Words','DMS_%'])\n",
    "    print('Ignoring first',n_stop_words,'stop-words ##############')\n",
    "    StopWords = [ii[0] for ii in c_unique.most_common(n_stop_words)]\n",
    "    for tag in ['OCE','CHE', 'DMS']:\n",
    "        len_tag = len(data[data['Tag']==tag])\n",
    "        jj = 0\n",
    "        words = []\n",
    "        percent = []\n",
    "        for word in tag_dict[tag].most_common(2*n_stop_words):\n",
    "            if word[0] not in StopWords:\n",
    "                words.append(word[0])\n",
    "                percent.append(np.round(100*word[1]/len_tag,2))\n",
    "                jj += 1\n",
    "            if jj == 20:\n",
    "                break\n",
    "        tag_specific_words[tag+'_Words'] = words\n",
    "        tag_specific_words[tag+'_%'] = percent\n",
    "    display(tag_specific_words)\n",
    "    print('\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60fb5664",
   "metadata": {},
   "source": [
    "Interesting ...! We are clearly seeing what *Feature* means in terms of *Text Data*.\n",
    "\n",
    "Let's go on by doing the same but this time with calculating some information theoretic score for each word to be selected as a feature (feature importance, ranking, selection, blahblah). Later we can compare the performance of our methods on these words with the performance of the same models on other feature sets like BoW variations.\n",
    "\n",
    "The score is calculated based on the intuitive idea bellow\n",
    "\n",
    "### How class-informative is a word? i.e. how confident you can predict the class of a text if you see this word in it?\n",
    "\n",
    "To do this we calculate an information-theoretic inspired score as follows:\n",
    "\n",
    "$$\\large S(w_{i}) = \\frac{1}{N_{c}-1}\\times\\frac{N_{c}-N_{w_{i},c}}{N_{w_{i},c}} $$\n",
    "\n",
    "where $N_{w,c}$ is the number of classes in which the word $w_{i}$ appeard, and $N_{c}$ is the total number of classes. This score is bounded between $0$ and $1$ (I confess that I complicated a simple concept too much but it became beatiful at least :P ).\n",
    "\n",
    "## Advantage\n",
    "* Captures the most distingushable words.\n",
    "* Does not need normalization by class sizes as it looks at word appearence in a binary way.\n",
    "\n",
    "## Disadvantage\n",
    "* Pretty naive idea! Of course the total number of appearences in classes is more informative than *if the word $w$ ever appeared in class $c$ or not*.\n",
    " * Just assume the case that a word appears in $N_{c}-1$ classes only once and in one class $10k$ times.\n",
    " \n",
    " \n",
    "* Danger zone! The features captured here are pretty special such that do not capture an unseen document in general (overfitting problem).\n",
    " * **Solution**: randomly add not-so-special words to this dictionary to improve generalization (doesn't looks like Regularization?!).\n",
    "* It **CAN NOT** consider all classes i.e. the score **DOES NOT** tell to which class a word belongs!\n",
    " * A slight modification on the formulation can solve this problem. In this case we calculate the top $n$ best words for each class and concatenate them to construct feature vector **(It will become a supervised version of what we know as TF-IDF :) )**"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
