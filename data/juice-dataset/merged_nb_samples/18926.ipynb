{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f621a7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_arrays(nb_rows, img_size):\n",
    "  if nb_rows:\n",
    "    dataset = np.ndarray((nb_rows, img_size, img_size), dtype=np.float32)\n",
    "    labels = np.ndarray(nb_rows, dtype=np.int32)\n",
    "  else:\n",
    "    dataset, labels = None, None\n",
    "  return dataset, labels\n",
    "\n",
    "def merge_datasets(pickle_files, train_size, valid_size=0):\n",
    "  num_classes = len(pickle_files)\n",
    "  valid_dataset, valid_labels = make_arrays(valid_size, image_size)\n",
    "  train_dataset, train_labels = make_arrays(train_size, image_size)\n",
    "  vsize_per_class = valid_size // num_classes\n",
    "  tsize_per_class = train_size // num_classes\n",
    "    \n",
    "  start_v, start_t = 0, 0\n",
    "  end_v, end_t = vsize_per_class, tsize_per_class\n",
    "  end_l = vsize_per_class+tsize_per_class\n",
    "  for label, pickle_file in enumerate(pickle_files):       \n",
    "    try:\n",
    "      with open(pickle_file, 'rb') as f:\n",
    "        letter_set = pickle.load(f)\n",
    "        # let's shuffle the letters to have random validation and training set\n",
    "        np.random.shuffle(letter_set)\n",
    "        if valid_dataset is not None:\n",
    "          valid_letter = letter_set[:vsize_per_class, :, :]\n",
    "          valid_dataset[start_v:end_v, :, :] = valid_letter\n",
    "          valid_labels[start_v:end_v] = label\n",
    "          start_v += vsize_per_class\n",
    "          end_v += vsize_per_class\n",
    "                    \n",
    "        train_letter = letter_set[vsize_per_class:end_l, :, :]\n",
    "        train_dataset[start_t:end_t, :, :] = train_letter\n",
    "        train_labels[start_t:end_t] = label\n",
    "        start_t += tsize_per_class\n",
    "        end_t += tsize_per_class\n",
    "    except Exception as e:\n",
    "      print('Unable to process data from', pickle_file, ':', e)\n",
    "      raise\n",
    "    \n",
    "  return valid_dataset, valid_labels, train_dataset, train_labels\n",
    "            \n",
    "            \n",
    "train_size = 200000\n",
    "valid_size = 10000\n",
    "test_size = 10000\n",
    "\n",
    "valid_dataset, valid_labels, train_dataset, train_labels = merge_datasets(\n",
    "  train_datasets, train_size, valid_size)\n",
    "_, _, test_dataset, test_labels = merge_datasets(test_datasets, test_size)\n",
    "\n",
    "print('Training:', train_dataset.shape, train_labels.shape)\n",
    "print('Validation:', valid_dataset.shape, valid_labels.shape)\n",
    "print('Testing:', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104a5af2",
   "metadata": {},
   "source": [
    "Next, we'll randomize the data. It's important to have the labels well shuffled for the training and test distributions to match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28efb5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomize(dataset, labels):\n",
    "  permutation = np.random.permutation(labels.shape[0])\n",
    "  shuffled_dataset = dataset[permutation,:,:]\n",
    "  shuffled_labels = labels[permutation]\n",
    "  return shuffled_dataset, shuffled_labels\n",
    "train_dataset, train_labels = randomize(train_dataset, train_labels)\n",
    "test_dataset, test_labels = randomize(test_dataset, test_labels)\n",
    "valid_dataset, valid_labels = randomize(valid_dataset, valid_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73ec645",
   "metadata": {},
   "source": [
    "---\n",
    "Problem 4\n",
    "---------\n",
    "Convince yourself that the data is still good after shuffling!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559ed199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's print 12 random samples for the dataset and check they correspond to their labels.\n",
    "def check_consistency(samples,labels,title):\n",
    "    if len(samples) != len(labels):\n",
    "        print (\"Samples and labels should have same length.\")\n",
    "        return\n",
    "    letters = 'ABCDEFGHIJ'\n",
    "    indexes = np.random.randint(len(samples),size=12)\n",
    "    fig = plt.figure(figsize=(12, 3), dpi=80)\n",
    "    fig.suptitle(title,fontsize=14)\n",
    "    for i,index in enumerate(indexes):\n",
    "        plt.subplot(1,12,i+1)\n",
    "        plt.title(letters[labels[index]])\n",
    "        plt.imshow(samples[index],interpolation='nearest',cmap='Greys')\n",
    "    plt.tight_layout()\n",
    "\n",
    "check_consistency(train_dataset,train_labels,\"Training set\")\n",
    "check_consistency(valid_dataset,valid_labels,\"Validation set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831126c5",
   "metadata": {},
   "source": [
    "Finally, let's save the data for later reuse:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1604963b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_file = os.path.join(data_folder,'notMNIST.pickle')\n",
    "\n",
    "try:\n",
    "  f = open(pickle_file, 'wb')\n",
    "  save = {\n",
    "    'train_dataset': train_dataset,\n",
    "    'train_labels': train_labels,\n",
    "    'valid_dataset': valid_dataset,\n",
    "    'valid_labels': valid_labels,\n",
    "    'test_dataset': test_dataset,\n",
    "    'test_labels': test_labels,\n",
    "    }\n",
    "  pickle.dump(save, f, pickle.HIGHEST_PROTOCOL)\n",
    "  f.close()\n",
    "except Exception as e:\n",
    "  print('Unable to save data to', pickle_file, ':', e)\n",
    "  raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69119ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "statinfo = os.stat(pickle_file)\n",
    "print('Compressed pickle size:', statinfo.st_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2270a8bd",
   "metadata": {},
   "source": [
    "---\n",
    "Problem 5\n",
    "---------\n",
    "\n",
    "By construction, this dataset might contain a lot of overlapping samples, including training data that's also contained in the validation and test set! Overlap between training and test can skew the results if you expect to use your model in an environment where there is never an overlap, but are actually ok if you expect to see training samples recur when you use it.\n",
    "Measure how much overlap there is between training, validation and test samples.\n",
    "\n",
    "Optional questions:\n",
    "- What about near duplicates between datasets? (images that are almost identical)\n",
    "- Create a sanitized validation and test set, and compare your accuracy on those in subsequent assignments.\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4e42c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import hashlib\n",
    "def clean_overlap(train_set,test_set,test_labels,valid_set,valid_labels):\n",
    "    t1 = time.time()\n",
    "    #create arrays with hashes for each image\n",
    "    train_hashes = [hashlib.sha1(x).digest() for x in train_set]\n",
    "    valid_hashes = [hashlib.sha1(x).digest() for x in valid_set]\n",
    "    test_hashes  = [hashlib.sha1(x).digest() for x in test_set]\n",
    "\n",
    "    #Create arrays containing True values for indexes in common\n",
    "    valid_in_train = np.in1d(valid_hashes, train_hashes)\n",
    "    test_in_train  = np.in1d(test_hashes,  train_hashes)\n",
    "    test_in_valid  = np.in1d(test_hashes,  valid_hashes)\n",
    "\n",
    "    #Create arrays containing indexes (as True values) of elements to keep in test and validation sets\n",
    "    valid_keep = ~valid_in_train\n",
    "    test_keep  = ~(test_in_train | test_in_valid)\n",
    "\n",
    "    #Create clean sets\n",
    "    valid_dataset_clean = valid_dataset[valid_keep]\n",
    "    valid_labels_clean  = valid_labels [valid_keep]\n",
    "\n",
    "    test_dataset_clean = test_dataset[test_keep]\n",
    "    test_labels_clean  = test_labels [test_keep]\n",
    "    t2 = time.time()\n",
    "    print(\"Time: %0.2fs\" % (t2 - t1))\n",
    "    print(\"valid -> train overlap: %d samples\" % valid_in_train.sum())\n",
    "    print(\"test  -> train overlap: %d samples\" % test_in_train.sum())\n",
    "    print(\"test  -> valid overlap: %d samples\" % test_in_valid.sum())\n",
    "    print('Clean validation set:', valid_dataset_clean.shape, valid_labels_clean.shape)\n",
    "    print('Clean test set:', test_dataset_clean.shape, test_labels_clean.shape)\n",
    "\n",
    "    return valid_dataset_clean,valid_labels_clean,test_dataset_clean,test_labels_clean\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39717dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_clean_data, valid_clean_labels, test_clean_data, test_clean_labels = clean_overlap(train_dataset,test_dataset,test_labels,valid_dataset,valid_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32cff200",
   "metadata": {},
   "source": [
    "To find near duplicates, a cheap and fast way would be to round numbers to, say, one decimal, so similar images will end up the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d2f2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rounded_train = [np.round(x,1) for x in train_dataset]\n",
    "rounded_test = [np.round(x,1) for x in test_dataset]\n",
    "rounded_valid = [np.round(x,1) for x in valid_dataset]\n",
    "valid_clean_rounded, valid_clean_rounded_labels, test_clean_rounded, test_clean_rounded_labels = clean_overlap(rounded_train,rounded_test,test_labels,rounded_valid,valid_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5580403",
   "metadata": {},
   "source": [
    "---\n",
    "Problem 6\n",
    "---------\n",
    "\n",
    "Let's get an idea of what an off-the-shelf classifier can give you on this data. It's always good to check that there is something to learn, and that it's a problem that is not so trivial that a canned solution solves it.\n",
    "\n",
    "Train a simple model on this data using 50, 100, 1000 and 5000 training samples. Hint: you can use the LogisticRegression model from sklearn.linear_model.\n",
    "\n",
    "Optional question: train an off-the-shelf model on all the data!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca7e2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "def trainLR(train_data,train_labels,test_data,test_labels):\n",
    "    t1 = time.time()\n",
    "    train_data_r = train_data.reshape((len(train_data),28*28))\n",
    "    test_data_r = test_data.reshape((len(test_data),28*28))\n",
    "    clf = linear_model.LogisticRegression()\n",
    "    clf.fit(train_data_r,train_labels)\n",
    "    score = clf.score(test_data_r,test_labels)\n",
    "    t2 = time.time()\n",
    "    return score,(t2-t1)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b4768e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Training and validating on the original dataset\")\n",
    "s50,t50 = trainLR(train_dataset[0:50],train_labels[0:50],valid_dataset,valid_labels)\n",
    "print (s50,t50)\n",
    "s100,t100 = trainLR(train_dataset[0:100],train_labels[0:100],valid_dataset,valid_labels)\n",
    "print (s100,t100)\n",
    "s1000,t1000 = trainLR(train_dataset[0:1000],train_labels[0:1000],valid_dataset,valid_labels)\n",
    "print (s1000,t1000)\n",
    "s5000,t5000 = trainLR(train_dataset[0:5000],train_labels[0:5000],valid_dataset,valid_labels)\n",
    "print (s5000,t5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c2050c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Training and validating on the set\")\n",
    "s50,t50 = trainLR(train_dataset[0:50],train_labels[0:50],valid_clean_data,valid_clean_labels)\n",
    "print (s50,t50)\n",
    "s100,t100 = trainLR(train_dataset[0:100],train_labels[0:100],valid_clean_data,valid_clean_labels)\n",
    "print (s100,t100)\n",
    "s1000,t1000 = trainLR(train_dataset[0:1000],train_labels[0:1000],valid_clean_data,valid_clean_labels)\n",
    "print (s1000,t1000)\n",
    "s5000,t5000 = trainLR(train_dataset[0:5000],train_labels[0:5000],valid_clean_data,valid_clean_labels)\n",
    "print (s5000,t5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0adc2e67",
   "metadata": {},
   "source": [
    "We observe that the score is lower when removing the overlap, which makes sense: samples from the training set also present in the validation set will increase the accuracy of the predictions"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
