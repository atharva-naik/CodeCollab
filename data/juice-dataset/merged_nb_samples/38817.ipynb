{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1402d072",
   "metadata": {},
   "source": [
    "# ISLR-Python: Ch7-Applied 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5872e275",
   "metadata": {},
   "source": [
    "- [Generate Data](#Generate-Data)\n",
    "- [Perform a Single Backfit](#Perform-a-Single-Backfit)\n",
    "- [Backfit Algorithm](#Backfit-Algorithm)\n",
    "- [Compare to Multiple Linear Regression Fit](#Compare-to-Multiple-Linear-Regression-Fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543352ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5dcb961",
   "metadata": {},
   "source": [
    "## Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1285119a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will make a 2 predictor model Y= 4 + 0.3*X1 + 0.07*X2 where X2 = X1**2\n",
    "# predictors\n",
    "X1 = np.linspace(1,20,1000).reshape(-1,1)\n",
    "X2 = (X1-2)**2\n",
    "\n",
    "# model data\n",
    "beta = [4, -0.3, .007]\n",
    "X = np.concatenate((X1,X2), axis=1)\n",
    "Y = (beta[0] + np.dot(X, beta[1:]) + .3*np.random.randn(1,len(X))).reshape(-1,1)\n",
    "\n",
    "# Take a look at the data\n",
    "fig,ax = plt.subplots(1,1, figsize=(8,6))\n",
    "ax.scatter(X1,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a070cbb1",
   "metadata": {},
   "source": [
    "## Perform a Single Backfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7443bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize starting beta estimate\n",
    "init_beta = [1,1,1]\n",
    "\n",
    "# hold beta1 fixed and fit the model Y-beta1*X1 = Beta0 + Beta2*X2 + eps. Extract Beta2_hat\n",
    "beta2_hat = LinearRegression().fit(X2,Y-init_beta[1]*X1).coef_[0]\n",
    "\n",
    "# Do the same to get the beta1 estimate using the new beta2_hat estimate\n",
    "beta1_hat = LinearRegression().fit(X1, Y-beta2_hat*X2).coef_[0]\n",
    "\n",
    "print('beta1 est=', beta1_hat,'\\n','beta2 est=', beta2_hat, sep='')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3c0854",
   "metadata": {},
   "source": [
    "## Backfit Algortihm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a0afde",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta1=np.empty([1000,1])\n",
    "beta2=np.empty([1000,1])\n",
    "\n",
    "# initial beta values\n",
    "beta1[0]= 1\n",
    "beta2[0] = LinearRegression().fit(X2,Y-beta1[0]*X1).coef_[0]\n",
    "\n",
    "iterations = np.arange(1,1000)\n",
    "for iteration in np.arange(1,1000):\n",
    "    \n",
    "    # use the last beta1 to estimate the new beta2\n",
    "    beta2[iteration] = LinearRegression().fit(X2,Y-beta1[iteration-1]*X1).coef_[0]\n",
    "    # use the updated beta2 to estimate a new beta1\n",
    "    beta1[iteration] = LinearRegression().fit(X1,Y-beta2[iteration]*X2).coef_[0]\n",
    "    \n",
    "    # print every 50th iteration\n",
    "    if iteration%100==0:\n",
    "        print(beta1[iteration],beta2[iteration])\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(10,6));\n",
    "ax.plot(iterations, beta1[1:], color='b', label=r'$\\beta_1$');\n",
    "ax.plot(iterations, beta2[1:], color='g', label=r'$\\beta_2$');\n",
    "ax.legend(loc='best', prop={'size':20});"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d8ae16",
   "metadata": {},
   "source": [
    "So within the first 50 iterations, we are seeing convergence. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31d59e8",
   "metadata": {},
   "source": [
    "## Compare to Multiple Linear Regression Fit"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
