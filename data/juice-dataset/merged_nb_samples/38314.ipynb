{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0292900",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "import cv2\n",
    "import numpy as np\n",
    "import logging\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7191ec",
   "metadata": {},
   "source": [
    "# Debugging and Display Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca97b581",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_frame(cap, index):\n",
    "    ''' Display a frame from a video capture stream. '''\n",
    "    frame = get_frame(cap, index)\n",
    "    display_image(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d0c649",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_image(image):\n",
    "    ''' Show an image in a matplotlib figure. '''\n",
    "    # If colored, swap color order to RGB\n",
    "    if len(image.shape) > 2:\n",
    "        image = image[:,:,[2,1,0]]\n",
    "        imshow(image)\n",
    "    else:\n",
    "        imshow(image, cmap=cm.Greys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1c83b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_image_matrix(images, imgsize=(8, 5)):\n",
    "    ''' Show matrix of images of variable size. '''\n",
    "    if len(images) == 0 or len(images[0]) == 0:\n",
    "        return\n",
    "    rows = len(images)\n",
    "    cols = len(images[0])\n",
    "    w, h = imgsize\n",
    "    figure(figsize=(w * cols, h * rows))\n",
    "    for r, row in enumerate(images):\n",
    "        for c, img in enumerate(row):\n",
    "            spn = r * cols + c + 1\n",
    "            subplot(rows, cols, spn)\n",
    "            display_image(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7073fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_rectangle(image, rect):\n",
    "    ''' Draw a rectangle on an image. '''\n",
    "    l, t, w, h = rect\n",
    "    cv2.rectangle(image, \n",
    "        (l, t),\n",
    "        (l + w, t + h), \n",
    "        (0, 255, 0), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3f8ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Helpers for fetching specific frames. '''\n",
    "get_findex = lambda : int(cap.get(cv2.cv.CV_CAP_PROP_POS_FRAMES))\n",
    "set_findex = lambda f : cap.set(cv2.cv.CV_CAP_PROP_POS_FRAMES, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11d7661",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frame(cap, index):\n",
    "    ''' Modified from code on SO question, \"How to process images of a video, frame \n",
    "        by frame in video streaming using Opencv python \"'''\n",
    "    \n",
    "    set_findex(index)    \n",
    "    logging.debug(\"Fetching frame %d\", index)\n",
    "\n",
    "    while True:\n",
    "        flag, frame = cap.read()    \n",
    "        if flag:\n",
    "            logging.debug(\"Got frame %d\", index)\n",
    "            return frame\n",
    "            break\n",
    "        else:\n",
    "            logging.debug(\"Frame %d not ready, trying again\", index)\n",
    "            # The frame number increments after a read attempt.\n",
    "            # Furthermore, to try to read frame i, we set frame number to i + 1.\n",
    "            # I don't know why, but this is just how the API works.\n",
    "            index = get_findex()\n",
    "            set_findex(index)\n",
    "            cv2.waitKey(500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0ded5b",
   "metadata": {},
   "source": [
    "# Main Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de858b45",
   "metadata": {},
   "source": [
    "###Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72373df",
   "metadata": {},
   "source": [
    "Load up stream "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a71470",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('./video.mp4')  # Initialize the video stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463ffe27",
   "metadata": {},
   "outputs": [],
   "source": [
    "fps = cap.get(cv2.cv.CV_CAP_PROP_FPS)\n",
    "frame_at_time = lambda s: int(math.ceil(s * fps))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618d871f",
   "metadata": {},
   "source": [
    "Show that we can display frames of video by index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a904a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure(figsize=(20, 50))\n",
    "subplot(1, 3, 1)\n",
    "display_frame(cap, 570)\n",
    "subplot(1, 3, 2)\n",
    "display_frame(cap, 600)\n",
    "subplot(1, 3, 3)\n",
    "display_frame(cap, 5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db0a575",
   "metadata": {},
   "source": [
    "Show that we can display frames of video at times, indexed by second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9bd5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure(figsize=(20, 50))\n",
    "subplot(1, 3, 1)\n",
    "display_frame(cap, frame_at_time(1))\n",
    "subplot(1, 3, 2)\n",
    "display_frame(cap, frame_at_time(2))\n",
    "subplot(1, 3, 3)\n",
    "display_frame(cap, frame_at_time(200))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98eb7218",
   "metadata": {},
   "source": [
    "### Fetch frames of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481c5c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each event is a tuple of (time_before, time_after)\n",
    "events = [\n",
    "    [22.5, 23],   # open file menu\n",
    "    [27, 27.5],   # open New Android Application dialog\n",
    "    [99.8, 100.2],  # open context menu for folder\n",
    "    [100.5, 101], # highlight \"New\" label in context menu\n",
    "]\n",
    "frames = []\n",
    "for e in events:\n",
    "    findexes = [frame_at_time(t) for t in e]\n",
    "    frames.append([get_frame(cap, f) for f in findexes])\n",
    "\n",
    "display_image_matrix(frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d85247",
   "metadata": {},
   "source": [
    "### Compute differences between pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3cb130b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_smooth_diff(fend, frames_before=10):\n",
    "    ''' Get a smooth difference up to a frame by adding up the differences from\n",
    "        a sequence of earlier frames and normalizing based on the largest difference\n",
    "        found.  Has an effect of canceling out some noise.  '''\n",
    "    \n",
    "    frame_shape = get_frame(cap, fend).shape\n",
    "    diff = np.zeros(frame_shape, dtype='uint32')\n",
    "    for f in range(fend - frames_before, fend + 1):\n",
    "        f1 = get_frame(cap, f)\n",
    "        f2 = get_frame(cap, f + 1)\n",
    "        diff += (f2 - f1)\n",
    "    \n",
    "    diff_norm = diff * (255.0 / np.max(diff))\n",
    "    diff_norm = diff_norm.astype('uint8')\n",
    "    diff_norm = cv2.cvtColor(diff_norm, cv2.COLOR_RGB2GRAY)\n",
    "    return diff_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebe04c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames_with_diffs = []\n",
    "\n",
    "for e in events:\n",
    "    \n",
    "    findexes = [frame_at_time(t) for t in e]\n",
    "    fp = [get_frame(cap, f) for f in findexes] \n",
    "    diff = np.abs(fp[1] - fp[0])\n",
    "    \n",
    "    diff_grey = cv2.cvtColor(diff, cv2.COLOR_RGB2GRAY)\n",
    "    diff_threshold = diff_grey > 200\n",
    "    smooth_diff = get_smooth_diff(findexes[1])\n",
    "    \n",
    "    fp_with_diffs = fp + [diff, diff_grey, diff_threshold, smooth_diff]\n",
    "    frames_with_diffs.append(fp_with_diffs)\n",
    "\n",
    "display_image_matrix(frames_with_diffs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8034b16d",
   "metadata": {},
   "source": [
    "### Extract regions of change for menus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395fdefd",
   "metadata": {},
   "source": [
    "Display the frame differences for our menu events"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
