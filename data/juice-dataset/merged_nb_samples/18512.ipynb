{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b64b61cf",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b86ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv('epi_r.csv')\n",
    "z = {0.0: 0, 1.25: 1, 1.875: 2, 2.5: 3, 3.125: 4, 3.75: 5, 4.375: 6, 5.0: 7}\n",
    "z_inv = {v: k for k, v in z.items()}\n",
    "raw_data[\"rating_cat\"] = raw_data.rating.map(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115ee986",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First lets look at the ratings.\n",
    "raw_data.rating.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30300680",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data[\"rating_cat\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8c4ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.diff(np.array([0.0, 1.25, 1.875, 2.5, 3.125, 3.75, 4.375, 5.0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ffe2125",
   "metadata": {},
   "source": [
    "Since the ratings are actually discrete, a classifier makes more sense. Note that the rating levels are not uniformly distributed. \n",
    "\n",
    "First lets add a binary feature to indicate if the recipe lists calories that are in the top 75% of all ratings, as well as some group some highly correlated features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "998f3385",
   "metadata": {},
   "source": [
    "# Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba08f75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = raw_data.dropna().drop(['rating', 'title', 'rating_cat'], axis = 1)\n",
    "X_test, X_train, y_test, y_train = train_test_split(X, raw_data.dropna().rating, test_size=0.70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63882c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets see what features are extrmely correlated\n",
    "cm = X_train.corr()\n",
    "s = cm.unstack()\n",
    "so = s[s!=1.0].sort_values(kind=\"quicksort\", ascending=False)\n",
    "so[so>=0.7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d87ed97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine calories, fat and sodium\n",
    "X_train[\"source\"] = X_train[['fat', 'calories', 'sodium']].sum(axis=1)\n",
    "X_test[\"source\"] = X_test[['fat', 'calories', 'sodium']].sum(axis=1)\n",
    "# features to combine* (binary interaction)\n",
    "features1 = ['calories', 'calories', 'sodium', 'peanut free', \n",
    "             'pescatarian', 'drink', 'peanut free', 'portland', \n",
    "             'soy free', 'sodium', 'vegetarian', 'snack week', \n",
    "             'pescatarian', 'kosher', 'peanut free', 'peanut free', \n",
    "             'soy free', 'calories', 'brunch', 'kentucky', 'denver', \n",
    "             'louisiana', 'new orleans', 'lasagna']\n",
    "\n",
    "features2 = ['sodium', 'fat', 'fat', 'soy free', 'kosher', 'alcoholic', \n",
    "             'tree nut free', 'oregon', 'tree nut free', 'protein', \n",
    "             'pescatarian', 'snack', 'soy free', 'vegetarian', \n",
    "             'pescatarian', 'kosher', 'kosher', 'protein', 'breakfast', \n",
    "             'louisville', 'omelet', 'kitchen olympics', 'louisiana', 'epi loves the microwave']\n",
    "\n",
    "for a,b in zip(features1, features2):\n",
    "    X_train[a + \"_\" + b] = X_train[a] * X_train[b]\n",
    "    X_test[a + \"_\" + b] = X_test[a] * X_test[b]\n",
    "    \n",
    "for b in ['fat', 'calories', 'sodium']:\n",
    "    X_train['protein_' + b] = X_train['protein'] * X_train[b]\n",
    "    X_test['protein_' + b] = X_test['protein'] * X_test[b]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2792da7",
   "metadata": {},
   "source": [
    "# Feature Selection  \n",
    "\n",
    "We will first predict how likely the recipe is a high (>=2.5 rating) or low (<2.5), and given this predicted probability we can feed the data to a further model (2 layer)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daed37b0",
   "metadata": {},
   "source": [
    "**High or Low rating?** (<= 2.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392480e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_dummy = pd.get_dummies(X_train)\n",
    "# convert all columns to int's and make source_pc binary\n",
    "X_train_dummy = X_train_dummy.astype(int)\n",
    "\n",
    "# Features & Target\n",
    "y_low = y_train <= 2.5\n",
    "\n",
    "#Pipeline Construction.\n",
    "anova_low = SelectKBest(f_classif, k=30)\n",
    "svc_low = SVC(kernel='linear')\n",
    "anova_svc = make_pipeline(anova_low, svc_low)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55f5369",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fitting & Cross-Validation.\n",
    "anova_svc.fit(X_train_dummy,y_low)\n",
    "scores_low = cross_val_score(anova_svc, X_train_dummy, y_low, cv=5)\n",
    "\n",
    "#De-Masking Selected Features.\n",
    "features_low = anova_low.get_support(indices=True)\n",
    "selected_features_low = list(X_train_dummy.columns[features_low])\n",
    "\n",
    "#Printing Outcomes.\n",
    "print('Cross-Validation Scores: {}'.format(scores_low))\n",
    "print('Cross-Validation Score Averaged Across Folds: {:.2%}.\\n'.format(scores_low.mean()))\n",
    "print('Selected Features: {}\\n'.format(selected_features_low))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd91331",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_1ow = SVC()\n",
    "X_low = X_train[selected_features_low]\n",
    "svc_1ow.fit(X_low,y_low)\n",
    "\n",
    "scores_low = cross_val_score(svc_1ow, X_train[selected_features_low], y_low, cv=5)\n",
    "print('Cross-Validation Scores: {}'.format(scores_low))\n",
    "print('Cross-Validation Score Averaged Across Folds: {:.2%}.\\n'.format(scores_low.mean()))\n",
    "y_pred_train = svc_1ow.predict(X_train[selected_features_low]).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8611ebf8",
   "metadata": {},
   "source": [
    "This model simply predicts if the given recipe will be rated high or low. Let's see how it performs on the test set.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637cd9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clasification report\n",
    "results_train = metrics.classification_report(y_true=(y_train<=2.5).astype(int), y_pred=y_pred_train)\n",
    "print(results_train)\n",
    "metrics.accuracy_score(y_true=(y_train<=2.5).astype(int), y_pred=y_pred_train)\n",
    "#metrics.auc() HOW TO USE THIS?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6324f0aa",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894eeaaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = svc_1ow.predict(X_test[selected_features_low])\n",
    "#Clasification report\n",
    "results_test = metrics.classification_report(y_true=(y_test<=2.5).astype(int), y_pred=y_pred_test)\n",
    "print(results_test)\n",
    "metrics.accuracy_score(y_true=(y_test<=2.5).astype(int), y_pred=y_pred_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cafe902",
   "metadata": {},
   "source": [
    "This classification task seems quite limited (not practical), so let's open it up to predict each rating level.\n",
    "\n",
    "Let's use LASSO regression to identify features.  \n",
    "\n",
    "## LASSO Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29cdfae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "#solvers = ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
    "lassoregr = LogisticRegression(penalty ='l1', solver='saga', multi_class='multinomial')\n",
    "lassoregr.fit(X_train, y_train.map(z))\n",
    "\n",
    "coeffs = pd.DataFrame(lassoregr.coef_.transpose())\n",
    "coeffs.index = X_train.columns\n",
    "coeffs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737a8682",
   "metadata": {},
   "source": [
    "It would be easier to visualize if we first converted the above matrix into rankings (along each column). Say we wanted to optimize the model to perform on those recipes with a 3.125 rating, then we take the top k features for the 5th column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2728ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_features = coeffs.iloc[:,4].sort_values().index[:29]\n",
    "print(new_features)\n",
    "\n",
    "svc_new = SVC(probability=True)\n",
    "svc_new.fit(X_train[new_features], y_train.map(z))\n",
    "\n",
    "scores_new = cross_val_score(svc_new, X_train[new_features], y_train.map(z), cv=5)\n",
    "print('Cross-Validation Scores: {}'.format(scores_new))\n",
    "print('Cross-Validation Score Averaged Across Folds: {:.2%}.\\n'.format(scores_new.mean()))\n",
    "\n",
    "p_pred_new = svc_new.predict_proba(X_test[new_features])\n",
    "\n",
    "y_pred_new = p_pred_new.argmax(axis=1)\n",
    "#Clasification report\n",
    "results_new = metrics.classification_report(y_true=y_test.map(z), y_pred=y_pred_new)\n",
    "print(results_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8c7393",
   "metadata": {},
   "source": [
    "Whoa this set of features appears to improve on all classes! Let's see if we can get better model performance from using a random forest to select the same number of features.\n",
    "\n",
    "## Random Forest  "
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
