{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1fe7a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class Distribution\n",
    "target_names_list = [\"Spruce/Fir\", \"Lodgepole Pine\", \"Ponderosa Pine\", \n",
    "                \"Cottonwood/Willow\", \"Aspen\", \"Douglas-fir\", \"Krummholz\"]\n",
    "target_names_dict = {1:\"Spruce/Fir\",2:\"Lodgepole Pine\",3:\"Ponderosa Pine\", \n",
    "                4:\"Cottonwood/Willow\",5:\"Aspen\", 6:\"Douglas-fir\", 7:\"Krummholz\"}\n",
    "\n",
    "counts = target.value_counts(sort=False)\n",
    "total = sum(counts)\n",
    "print \"Class Distribution in Target Var: \"\n",
    "print \"\\tClass                    |  Number of Examples\"\n",
    "for c in np.unique(target):\n",
    "    print \"\\t%i, %-17s     |   %i (%0.2f%%)\" %(c, target_names_dict[c] ,counts[c], (counts[c]/float(total))*100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a25cdf",
   "metadata": {},
   "source": [
    "### Correlation matrix on continuous variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7606d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = train_df[continuous].corr()\n",
    "# Generate a mask for the upper triangle\n",
    "mask = np.zeros_like(corr, dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(11, 9))\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "sns.heatmap(corr, mask=mask, vmax=.3, center=0,\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})\n",
    "\n",
    "corr_columns = list(corr.columns)\n",
    "corr_comparison_list = []\n",
    "corr_value_list = []\n",
    "for column in corr:\n",
    "    temp_corr_columns = corr_columns   \n",
    "    temp_corr_columns.remove(column)\n",
    "    for index in corr.loc[temp_corr_columns, column].index:\n",
    "        corr_comparison_list.append(str(column) + '_vs_' + str(index))\n",
    "        corr_value_list.append(corr.loc[index, column])\n",
    "        \n",
    "corr_df = pd.DataFrame({\n",
    "    \"corr_comparison\" : corr_comparison_list,\n",
    "    \"corr_value\" : corr_value_list \n",
    "})\n",
    "\n",
    "corr_df = corr_df.iloc[corr_df.corr_value.abs().argsort()][::-1].reset_index()\n",
    "corr_df = corr_df.loc[:, ~corr_df.columns.str.contains('index')]\n",
    "print corr_df.loc[:10,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cef8176",
   "metadata": {},
   "source": [
    "Looking at the above correlation matrix, we see combination of variables that may cause collinearity issues in the analysis.\n",
    "\n",
    "For example Hillshade_3pm is correlated heavily with Hillshade_9am (corr ~ -0.77).\n",
    "\n",
    "The above dataframe output shows the top 10 (absolute value) correlation values between continuous variables, so we will need to be knowledgeable about having both of the features in the analysis in the top 10 list. The duplicated information may overfit the data and reduce the generalizability of the final analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff9003e",
   "metadata": {},
   "source": [
    "### Visualize continuous variables mapped to 2D plane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e92783",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20, 120))\n",
    "gs = gridspec.GridSpec(23, 2) \n",
    "df_column_list = list(train_df[continuous].columns)\n",
    "itr = 0\n",
    "cmap = mpl.colors.ListedColormap(['black','red', 'green', 'blue', 'cyan', 'violet', 'yellow'])\n",
    "black_patch = mpatches.Patch(color='black', label='1')\n",
    "red_patch = mpatches.Patch(color='red', label='2')\n",
    "green_patch = mpatches.Patch(color='green', label='3')\n",
    "blue_patch = mpatches.Patch(color='blue', label='4')\n",
    "cyan_patch = mpatches.Patch(color='cyan', label='5')\n",
    "violet_patch = mpatches.Patch(color='violet', label='6')\n",
    "yellow_patch = mpatches.Patch(color='yellow', label='7')\n",
    "\n",
    "\n",
    "for feature in corr:    \n",
    "    temp_columns = df_column_list\n",
    "    index_value = temp_columns.index(feature) + 1\n",
    "    \n",
    "    for sub_feature in temp_columns[index_value:]:\n",
    "        ax = plt.subplot(gs[itr])\n",
    "        ax.scatter(train_df.loc[:, feature], train_df.loc[:, sub_feature], \n",
    "                   c=target, alpha=0.3, cmap=cmap)\n",
    "        ax.set_xlabel(feature)\n",
    "        ax.set_ylabel(sub_feature)\n",
    "        ax.set_title('{} vs {}'.format(feature, sub_feature, fontsize=12))\n",
    "        ax.legend(handles=[black_patch, red_patch, green_patch, blue_patch, cyan_patch, violet_patch, yellow_patch])\n",
    "        itr += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269e837a",
   "metadata": {},
   "source": [
    "### Replace missing/bad data in Hillshade 3pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592316ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_parameter_grid = {'n_estimators': [300, 500, 600, 700, 800]}\n",
    "\n",
    "\n",
    "rf_3pm_fix_df = train_df[continuous]\n",
    "rf_3pm_fix_df = rf_3pm_fix_df.loc[rf_3pm_fix_df['Hillshade_3pm'] != 0.0]\n",
    "rf_3pm_fix_df_target = rf_3pm_fix_df['Hillshade_3pm']\n",
    "rf_3pm_fix_df = rf_3pm_fix_df[['Elevation',\n",
    " 'Aspect',\n",
    " 'Slope',\n",
    " 'Horizontal_Distance_To_Hydrology',\n",
    " 'Vertical_Distance_To_Hydrology',\n",
    " 'Horizontal_Distance_To_Roadways',\n",
    " 'Hillshade_9am',\n",
    " 'Hillshade_Noon',\n",
    " 'Horizontal_Distance_To_Fire_Points']]\n",
    "\n",
    "param_searcher = GridSearchCV(RandomForestRegressor(), RF_parameter_grid, cv=5)\n",
    "X_train_3pm, X_dev_3pm, y_train_3pm, y_dev_3pm = train_test_split(rf_3pm_fix_df, rf_3pm_fix_df_target)\n",
    "param_searcher.fit(X_train_3pm, y_train_3pm)\n",
    "\n",
    "model_best_3pm = RandomForestRegressor(**param_searcher.best_params_)\n",
    "model_best_3pm.fit(X_train_3pm, y_train_3pm)\n",
    "pred_3pm = model_best_3pm.predict(X_dev_3pm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eae71d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "difference_3pm_percentage = (pred_3pm/y_dev_3pm - 1)*100\n",
    "difference_3pm_percentage.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64b9808",
   "metadata": {},
   "source": [
    "Very good fit, average difference is 0.04% off with the majority of data (1 and 3rd quartile) in between ~ +/- 0.35 % difference between predicted Hillshade at 3pm and Actual Hillshade at 3pm. Will move forward and replace zero values with this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd24e362",
   "metadata": {},
   "outputs": [],
   "source": [
    "itr = 0\n",
    "while itr < len(train_df):\n",
    "    if train_df.loc[itr, 'Hillshade_3pm'] == 0:\n",
    "        train_df.loc[itr, 'Hillshade_3pm'] = model_best_3pm.predict(train_df.loc[itr, ['Elevation', 'Aspect', 'Slope', \n",
    "                        'Horizontal_Distance_To_Hydrology', 'Vertical_Distance_To_Hydrology',\n",
    "                       'Horizontal_Distance_To_Roadways', 'Hillshade_9am', 'Hillshade_Noon',\n",
    "                       'Horizontal_Distance_To_Fire_Points']].reshape(1,9))\n",
    "        \n",
    "    itr += 1\n",
    "print train_df.Hillshade_3pm.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f60c4ee",
   "metadata": {},
   "source": [
    "No more zero values for HillShade at 3pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3c2e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "GB_parameter_grid = {\n",
    "    'n_estimators': [300, 400, 500, 600, 700]\n",
    "}\n",
    "\n",
    "GB_model_score, GB_df_param, GB_df_confusion, GB_model = model_optimize(GradientBoostingClassifier, X_train, y_train, X_dev, y_dev, GB_parameter_grid, True)\n",
    "GB_model_score_custom, GB_df_param_custom, GB_df_confusion_custom = model_optimize(GradientBoostingClassifier, X_train_cust, y_train_cust, X_dev_cust, y_dev_cust, GB_parameter_grid)\n",
    "GB_model_score_custom_filt, GB_df_param_custom_filt, GB_df_confusion_custom_filt = model_optimize(GradientBoostingClassifier, X_train_cust_filt, y_train_cust_filt, X_dev_cust_filt, y_dev_cust_filt, GB_parameter_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7aa32a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print GB_model_score\n",
    "print GB_model_score_custom\n",
    "print GB_model_score_custom_filt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee93adb9",
   "metadata": {},
   "source": [
    "###  Support Vector Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8cd8852",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_svm = {'C': [1500, 2000, 2500], \n",
    "              'gamma': [0.5, 1.0, 1.5], \n",
    "              'kernel': ['rbf']}\n",
    "\n",
    "SVM_model_score, SVM_df_param, SVM_df_confusion = model_optimize(SVC, X_train, y_train, X_dev, y_dev, param_grid_svm)\n",
    "SVM_model_score_custom, SVM_df_param_custom, SVM_df_confusion_custom = model_optimize(SVC, X_train_cust, y_train_cust, X_dev_cust, y_dev_cust, param_grid_svm)\n",
    "SVM_model_score_custom_filt, SVM_df_param_custom_filt, SVM_df_confusion_custom_filt = model_optimize(SVC, X_train_cust_filt, y_train_cust_filt, X_dev_cust_filt, y_dev_cust_filt, param_grid_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01745962",
   "metadata": {},
   "outputs": [],
   "source": [
    "print SVM_model_score\n",
    "print SVM_model_score_custom\n",
    "print SVM_model_score_custom_filt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c29afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "XRF_parameter_grid = {'criterion': ['entropy'],\n",
    "                     'n_estimators': [300, 500, 600, 700, 800], \n",
    "                     'min_samples_split': [2,10,20,50], \n",
    "                     'min_samples_leaf': [1,10,20,30,40,50]}\n",
    "\n",
    "# 'min_samples_split': np.linspace(2,400,10), \n",
    "# 'min_samples_leaf': np.linspace(1,50,5)\n",
    "\n",
    "\n",
    "XRF_model_score, XRF_df_param, XRF_df_confusion, XRF_model = model_optimize(ExtraTreesClassifier, X_train, y_train, X_dev, y_dev, RF_parameter_grid, True)\n",
    "XRF_model_score_custom, XRF_df_param_custom, XRF_df_confusion_custom, XRF_custom_model = model_optimize(ExtraTreesClassifier, X_train_cust, y_train_cust, X_dev_cust, y_dev_cust, RF_parameter_grid, True)\n",
    "XRF_model_score_custom_filt, XRF_df_param_custom_filt, XRF_df_confusion_custom_filt, XRF_custom_filt_model = model_optimize(ExtraTreesClassifier, X_train_cust_filt, y_train_cust_filt, X_dev_cust_filt, y_dev_cust_filt, RF_parameter_grid, True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46b3a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# min_impurity_decrease, min_samples_leaf, min_samples_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0f3b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "print XRF_model_score\n",
    "print XRF_model_score_custom\n",
    "print XRF_model_score_custom_filt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a575059a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary Bar Plot\n",
    "group_names = ('kNN', 'Naive Bayes','Decision Tree','Random Forest','ADA Boost',\n",
    "               'Gradient Boost', 'Support Vector', 'ExtraTreesClassifier') #  Model Families\n",
    "n_groups = len(group_names)\n",
    "\n",
    "\n",
    "standard_df_scores = (kNN_model_score, NB_model_score, DT_model_score, RF_model_score,\n",
    "                     AB_model_score, GB_model_score, SVM_model_score, XRF_model_score)\n",
    "filtered_df_scores = (kNN_model_score_custom, NB_model_score_custom, DT_model_score_custom, RF_model_score_custom,\n",
    "                   AB_model_score_custom, GB_model_score_custom, SVM_model_score_custom, XRF_model_score_custom)\n",
    "custom_filtered_df_scores = (kNN_model_score_custom_filt, NB_model_score_custom_filt, DT_model_score_custom_filt, RF_model_score_custom_filt,\n",
    "                            AB_model_score_custom_filt, GB_model_score_custom_filt, SVM_model_score_custom_filt, XRF_model_score_custom_filt)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "index = np.arange(n_groups)\n",
    "bar_width = 0.20\n",
    "\n",
    "opacity = 0.7\n",
    "\n",
    "rects1 = plt.bar(index, standard_df_scores, bar_width,\n",
    "                  alpha=opacity, color='b', label='Standard')\n",
    "\n",
    "rects2 = plt.bar(index + bar_width, filtered_df_scores, bar_width,\n",
    "                  alpha=opacity, color='r', label='Custom')\n",
    "\n",
    "rects3 = plt.bar(index + bar_width*2, filtered_df_scores, bar_width,\n",
    "                  alpha=opacity, color='g', label='Custom Filtered')\n",
    "\n",
    "plt.xlabel('Model Type')\n",
    "plt.ylabel('Model Scores')\n",
    "plt.title('Scores by Model Type and Data Preparation')\n",
    "plt.xticks(index + bar_width / 2, group_names, rotation = 30)\n",
    "plt.ylim(0,1)\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a1031a",
   "metadata": {},
   "source": [
    "## Export Model Predictions on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b50c4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose Model to Run\n",
    "test_preds = ADA_custom_filt_model.predict(custom_transformation_test_filtered)\n",
    "\n",
    "submission_df = pd.DataFrame(data= {'Id': test_df['Id'], 'Cover_Type': test_preds})\n",
    "submission_df.to_csv(file_path + '/submission.csv', index = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b850ce61",
   "metadata": {},
   "source": [
    "## PCA Aanlysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0e2acf",
   "metadata": {},
   "source": [
    "### Boxplots of continuous variables by Cover_Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655faafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot_df_cont = train_df[:]\n",
    "boxplot_df_cont['Cover_Type'] = target\n",
    "fig, axes = plt.subplots(nrows=4, ncols=3, figsize=(20, 20))\n",
    "\n",
    "itr_1 = 0\n",
    "itr_2 = 0\n",
    "for feature in continuous:\n",
    "    if itr_2 == 3:\n",
    "        itr_2 = 0\n",
    "        itr_1 += 1\n",
    "    if itr_1 == 3:\n",
    "        itr_2 = 1\n",
    "    temp_list = []\n",
    "    temp_list.append(feature)\n",
    "    temp_list.append(u'Cover_Type')\n",
    "    boxplot_df_cont[temp_list].boxplot(by='Cover_Type', ax=axes[itr_1, itr_2])\n",
    "    itr_2 += 1\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c137227b",
   "metadata": {},
   "source": [
    "Looking at the above boxplots by forest cover type, the elevation shows very distinct values per category. Elevation is looking like it is a very important feature in determining the target value of the problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a77a6f",
   "metadata": {},
   "source": [
    "### Binary variable exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e630420",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_binary = train_df[binary]\n",
    "df_binary['Cover_Type'] = target\n",
    "fig, axes = plt.subplots(nrows=21, ncols=2, figsize=(20, 60))\n",
    "\n",
    "df_binary_columns = []\n",
    "df_dict = {}\n",
    "itr = 0\n",
    "master_df = pd.DataFrame()\n",
    "pic_itr1 = 0\n",
    "pic_itr2 = 0\n",
    "for feature in df_binary:\n",
    "    if 'Cover_Type' not in feature:\n",
    "        df_binary_columns.append(feature)\n",
    "        temp_list = []\n",
    "        temp_list.append(feature)\n",
    "        temp_list.append(u'Cover_Type')\n",
    "        \n",
    "        if pic_itr2 == 2:\n",
    "            pic_itr2 = 0\n",
    "            pic_itr1 += 1\n",
    "        \n",
    "        itr = 1\n",
    "        for name, group in df_binary.loc[:, temp_list].groupby('Cover_Type'):\n",
    "            if itr == 1:\n",
    "                df_out = group[feature].value_counts()\n",
    "                df_out.name = 'type_{}'.format(itr)\n",
    "            else:\n",
    "                df_temp = group[feature].value_counts()\n",
    "                df_temp.name = 'type_{}'.format(itr)\n",
    "                df_out = pd.concat([df_out, df_temp], axis = 1)\n",
    "            itr += 1\n",
    "            \n",
    "        \n",
    "        print df_out.plot(kind='bar', title =feature, \n",
    "                          color=['black','red', 'green', 'blue', 'cyan', 'violet', 'yellow'],\n",
    "                          ax=axes[pic_itr1, pic_itr2])\n",
    "        master_df = master_df.append(df_out.rename({0: feature + '_0', 1: feature + '_1'}))\n",
    "        \n",
    "        pic_itr2 += 1\n",
    "        \n",
    "# print master_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2627e81",
   "metadata": {},
   "source": [
    "It appears that a lot of the soil type information is very similar with not a lot of added information to the data analysis. This information along with the continuous data information will help make engineering feature elimination decisions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb31927c",
   "metadata": {},
   "source": [
    "### Regularization study on variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915d1810",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNetCV\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.linear_model import RidgeCV\n",
    "\n",
    "linreg = LinearRegression()\n",
    "linreg.fit(train_df[predictors], target)\n",
    "\n",
    "ridge = RidgeCV(alphas= np.linspace(5, 50, 100))\n",
    "ridge.fit(train_df[predictors], target)\n",
    "\n",
    "lasso = LassoCV(alphas= 2. ** np.arange(-10, 10))\n",
    "lasso.fit(train_df[predictors], target)\n",
    "\n",
    "en = ElasticNetCV(l1_ratio=np.linspace(.05, .95, 20), alphas= 2. ** np.arange(-10, 10))\n",
    "en.fit(train_df[predictors], target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9993d621",
   "metadata": {},
   "outputs": [],
   "source": [
    "print 'Train R-squared: {:.3}'.format(linreg.score(train_df[predictors], target))\n",
    "print 'Ridge Train R-squared: {:.3}'.format(ridge.score(train_df[predictors], target))\n",
    "print 'Lasso Train R-squared: {:.3}'.format(lasso.score(train_df[predictors], target))\n",
    "print 'EN Train R-squared: {:.3}'.format(en.score(train_df[predictors], target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3476cb76",
   "metadata": {},
   "outputs": [],
   "source": [
    "coeffs = pd.DataFrame({\n",
    "        'variable': predictors,\n",
    "        'OLS': linreg.coef_,\n",
    "        'Ridge': ridge.coef_,\n",
    "        'Lasso': lasso.coef_,\n",
    "        'ElasticNet': en.coef_\n",
    "    })\n",
    "\n",
    "coeffs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ce23f0",
   "metadata": {},
   "source": [
    "Looking at the above regression equations, we see that they are not good for fit prediction. However, we also see that some variables are poor added information for prediction:\n",
    "\n",
    "Soil_Type1\n",
    "Soil_Type8\n",
    "Soil_Type9\n",
    "Soil_Type11\n",
    "Soil_Type25\n",
    "Soil_Type27\n",
    "Soil_Type28\n",
    "Soil_Type34"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e074448",
   "metadata": {},
   "source": [
    "### Split train/dev sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01ef152",
   "metadata": {},
   "outputs": [],
   "source": [
    "print ADA_model_score_custom_filt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ba8a30",
   "metadata": {},
   "source": [
    "### Gradient Boost"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
