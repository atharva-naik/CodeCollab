{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "207b9f8c",
   "metadata": {},
   "source": [
    "# Data Retreival\n",
    "\n",
    "I am working with several datasets in this project. Several are publicly available as flat files, while others I have had to construct myself from scraped sites. This notebook walks through all the data retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfdf7d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.io.common import get_filepath_or_buffer\n",
    "import geopandas as gpd\n",
    "import json\n",
    "import re\n",
    "from datetime import datetime\n",
    "from requests_futures.sessions import FuturesSession\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import dill\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba38aaa",
   "metadata": {},
   "source": [
    "### Turnstile and Fare Card Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e889b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dated_links(url, select):\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.text, \"lxml\")\n",
    "    tags = soup.select(select)\n",
    "            \n",
    "    links = [(tag.attrs['href'], datetime.strptime(tag.contents[0], '%A, %B %d, %Y').date()) for tag in tags]\n",
    "    return links\n",
    "\n",
    "def filter_by_date(links, cutoff=datetime(2016,1,1).date()):\n",
    "    return list(filter(lambda x: x[1] >= cutoff, links))\n",
    "\n",
    "def dl_MTA_data(url,links,out):\n",
    "    basePage = re.match(r'(.+?/)\\w+.html', url).group(1)\n",
    "    pages = [basePage + link[0] for link in links]\n",
    "\n",
    "    session = FuturesSession(max_workers=3)\n",
    "    futures = [(session.get(page), page) for page in pages]\n",
    "\n",
    "    s = re.compile(r'.+/(\\w+\\.\\w{3})')\n",
    "    for future in tqdm_notebook(futures):\n",
    "        with open('../data/' + s.search(future[1]).group(1), 'w') as f:\n",
    "            f.write(future[0].result().text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3dba5a8",
   "metadata": {},
   "source": [
    "You might have to inspect the HTML of the pages to make sure the correct files are getting retrieved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060219fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# turnstile data\n",
    "url = 'http://web.mta.info/developers/turnstile.html'\n",
    "\n",
    "links = filter_by_date(get_dated_links(url, 'div.span-84 a'))\n",
    "dl_MTA_data(url, links, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1badf418",
   "metadata": {},
   "outputs": [],
   "source": [
    "# farecard data\n",
    "url = 'http://web.mta.info/developers/fare.html'\n",
    "\n",
    "links = filter_by_date(get_dated_links(url, 'div.span-19 a'))\n",
    "dl_MTA_data(url, links, out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100a2874",
   "metadata": {},
   "source": [
    "### Census Data\n",
    "\n",
    "Unfortunately the API for American Community Survey is not well documented and I've had a hard time getting it to give me the data I want. I ultimately went to https://factfinder.census.gov/faces/nav/jsf/pages/download_center.xhtml and requested the 'DISABILITY CHARACTERISTICS' table from the 2015 ACS 5-year survey at the block level for New York, Bronx, Kings, and Queens counties. I've joined these 4 tables into one, which I'll be using in the other notebooks, and which I've included in the `data` directory in this repo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5183f56",
   "metadata": {},
   "source": [
    "### Station Geo Data"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
