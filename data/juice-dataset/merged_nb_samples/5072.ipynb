{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a40db10c",
   "metadata": {},
   "source": [
    "# Introduction about the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238cc41b",
   "metadata": {},
   "source": [
    "*The dataset has information collected from a company which faces issue with employees leaving the company. The database has information collected from different employees who have left or still staying in the company. The company wants to use your expertise in identifying which is the major contributor for employees leaving the company.* \n",
    "\n",
    "1. Satisfaction Level - ranges between 0 & 1 - gives the satisfaction level of the employee\n",
    "2. last_evaluation - ranges between 0 & 1 - defines the normalised employee's rating in the last appraisal\n",
    "3. number_project - numeric - No of projects the employee has worked on so far\n",
    "4. average_monthly_hours - Average amount of hours employee spends in the office per month\n",
    "5. time_spend_company - Time employee has spent in the company (in months)\n",
    "6. Work_accident - categorical - If the employee has encountered any accident in the work environment\n",
    "7. Department - Categorical - Department in which the employee is working/ has worked\n",
    "8. Salary - Categorical - Divided into low,medium & high "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5a82f0",
   "metadata": {},
   "source": [
    "### Read the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fdbaaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "hr = pd.read_csv(\"hr-analytics.csv\")\n",
    "hr.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ab6a40",
   "metadata": {},
   "source": [
    "### Observe the shape and the type of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f8ab20",
   "metadata": {},
   "outputs": [],
   "source": [
    "hr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b493090",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(hr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dadbc59",
   "metadata": {},
   "source": [
    "### Use summary statistics to check if missing values,outlier  treament is necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e391f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "hr.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f092c863",
   "metadata": {},
   "source": [
    "### Data Preprocessing -  Missing values Treatment \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f293e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(hr2, diag_kind='kde')\n",
    "# categorical variables show similar spread of satisfaction levels across categories\n",
    "# low correlations between independent variables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15dac8a",
   "metadata": {},
   "source": [
    "### Standardization of Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257f8635",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "std_scale = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410d462b",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = hr2['left']\n",
    "features = hr2.drop(['left'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50079a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(features,target, test_size = 0.3, random_state = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a07b880",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.reshape(len(y_train),1)\n",
    "y_test = y_test.reshape(len(y_test),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666e7887",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = std_scale.fit_transform(X_train)\n",
    "X_test_scaled = std_scale.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7c3f22",
   "metadata": {},
   "source": [
    "### Use Naive Bayes Modelling and find out the accuracy of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9bf3ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "model = GaussianNB()\n",
    "model.fit(X_train_scaled, y_train)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2595fb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "# make predictions\n",
    "\n",
    "predicted = model.predict(X_test_scaled)\n",
    "predicted_tr = model.predict(X_train_scaled)\n",
    "\n",
    "print( \"Accuracy for Test:\\n\",metrics.classification_report(y_test, predicted),\n",
    "       \"Accuracy for Training:\\n\",metrics.classification_report(y_train, predicted_tr))\n",
    "print(\"Confusion Matrix:\\n\",metrics.confusion_matrix(y_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8223843",
   "metadata": {},
   "source": [
    "### Use SVM and find out the accuracy & print the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c79ad6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "# Building a Support Vector Machine on train data\n",
    "svc = SVC(C=6, kernel='linear')\n",
    "svc.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63194ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "prediction = svc.predict(X_test_scaled)\n",
    "print('Accuracy for test: ', svc.score(X_test_scaled, y_test), \"\\n\",\n",
    "      'Accuracy for training: ',svc.score(X_train_scaled, y_train))\n",
    "\n",
    "print(\"Confusion Matrix:\\n\",metrics.confusion_matrix(prediction,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6f8cac",
   "metadata": {},
   "source": [
    "### Find out cross - validation scores with 10-fold for both the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e866ae50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import cross_val_score, cross_val_predict\n",
    "c,r = y_test.shape\n",
    "y_test = y_test.reshape(c,)\n",
    "scores = cross_val_score(svc, X_test_scaled, y_test, cv=10)\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1035766a",
   "metadata": {},
   "source": [
    "### Find the Optimal parameters of the SVM model by tuning hyperparameters: Use c Values: (6,7) & Kernels (rbf, linear) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9761018",
   "metadata": {},
   "outputs": [],
   "source": [
    "def svcm(x,y):\n",
    "    svc = SVC(C=x, kernel=y)\n",
    "    svc.fit(X_train_scaled, y_train)\n",
    "    return print(\"For c = \",x,\" and kernel = \", y, \"\\n\",\n",
    "                 \"Accuracy on training set: \", svc.score(X_train_scaled, y_train), \"\\n\",\n",
    "                 \"Accuracy on test set: \", svc.score(X_test_scaled, y_test))\n",
    "svcm(6,'rbf')\n",
    "svcm(7,'rbf')\n",
    "svcm(6,'linear')\n",
    "svcm(7,'linear')\n",
    "    \n",
    "# best hyperparameters are with rbf = kernel and c=6 or 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c92f19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC(C=6, kernel='rbf')\n",
    "svc.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8c53a0",
   "metadata": {},
   "source": [
    "### Considering the best hyperparameters and performing CrossValidation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e31773",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(svc, X_test_scaled, y_test, cv=10)\n",
    "scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5752e5fc",
   "metadata": {},
   "source": [
    "### Use Decision Tree and find out the feature importances scores and accuracy of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e97ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "hr.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef032aeb",
   "metadata": {},
   "source": [
    "### Dealing with Outliers - Find IQR and remove the row if there are any outlier\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d636cc",
   "metadata": {},
   "source": [
    "### Use Histogram to Check distribution of dependent variable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df846d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.hist(hr2['left'], ec='black')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61458dbd",
   "metadata": {},
   "source": [
    "### Use correlation & scatter matrix to observe the dependency between variables (Drop the dependent variable if the abs(correlation) with dependent variable is <0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b692e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check correlation between continuous variables\n",
    "hr2.corr()\n",
    "#none of the continuous variables have correlation <0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d12cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset data for continuous variables\n",
    "hr_ct = hr[['satisfaction_level','last_evaluation','number_project','average_montly_hours','time_spend_company']]\n",
    "q1 = hr_ct.quantile(0.25)\n",
    "q3 = hr_ct.quantile(0.75)\n",
    "iqr = q3-q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea110e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove outliers basis 1.5IQR\n",
    "hr2 = hr[~((hr_ct<(q1-1.5*iqr))|(hr_ct>(q3+1.5*iqr))).any(axis=1)]\n",
    "hr2.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a3e9ca",
   "metadata": {},
   "source": [
    "### Dealing with Categorical Values - Use LabelEncoder from skilearn to encode categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0de2810",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encode department and salary\n",
    "labelencoder = LabelEncoder()\n",
    "hr2['Department'] = labelencoder.fit_transform(hr2.Department)\n",
    "hr2['salary'] = labelencoder.fit_transform(hr2.salary)\n",
    "hr2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798fc69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt_model = DecisionTreeClassifier(criterion = 'entropy' )\n",
    "dt_model.fit(X_train, y_train)\n",
    "dt_model.score(X_test , y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b574e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (pd.DataFrame(dt_model.feature_importances_, columns = [\"Imp\"], index = X_train.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394d896f",
   "metadata": {},
   "source": [
    "### Find out cross-validation scores with 10-fold for the above model"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
