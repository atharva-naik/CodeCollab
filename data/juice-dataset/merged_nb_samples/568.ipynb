{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb465ddf",
   "metadata": {},
   "source": [
    "# Classifying Text Features by Class Within Each Axis\n",
    "This approach attempts to classify the text features by training four separate binary classifiers; one for each axis. This was effective for reducing the noise in the data by allowing SGDClassifier to focus on only two hypothetically polar aspects of the data at a time, and also increased the support for each sample size by decreasing the number of classes it was split into from 16 down to 2 at a time. By checking the distribution of the classification probabilities, we can observe how confident the classifier is in its classifications. Ideally we would want to see a bimodal distribution, showing that the classifier is confident in its classifications. This would suggest that the idea of 4 axis to describe personality is supported by the features of the text being analyzed.\n",
    "## Import data set and clear out null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b7f2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#read in data\n",
    "df = pd.read_csv('mbti_cleaned_unsplit2.csv', encoding = \"'ISO-8859-1\")\n",
    "df = df.drop('Unnamed: 0', axis=1)\n",
    "\n",
    "#select only entries with no null values\n",
    "df = df[pd.notnull(df['clean_posts'])]\n",
    "df = df[pd.notnull(df['posts'])]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94f766d",
   "metadata": {},
   "source": [
    "## Prepare corpus/labels and split 30% away for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432ef230",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#set up and split train and test data\n",
    "corpus = np.array(df.clean_posts)\n",
    "labels = np.array(df.type)\n",
    "\n",
    "train_corpus, test_corpus, train_labels, test_labels  = train_test_split(corpus, labels, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98679230",
   "metadata": {},
   "source": [
    "## Seperate labels into individual class labels per axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa31a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split training data labels into new labels for each axis\n",
    "train_labels_IE = [entry[0] for entry in train_labels]\n",
    "train_labels_NS = [entry[1] for entry in train_labels]\n",
    "train_labels_TF = [entry[2] for entry in train_labels]\n",
    "train_labels_JP = [entry[3] for entry in train_labels]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e51e87",
   "metadata": {},
   "source": [
    "This step requires to split each four-letter label into each of its letters, creating 4 categories of binary labels. The categories are I/E, N/S, T/F, and J/P. \n",
    "## Feature-extract the training corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff1606b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "\n",
    "#vectorize and weight train corpus\n",
    "count_vect = CountVectorizer()\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "\n",
    "train_counts = count_vect.fit_transform(train_corpus) #vectorizes text features\n",
    "train_transform = tfidf_transformer.fit_transform(train_counts) #inverse frequency weighting "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88034cda",
   "metadata": {},
   "source": [
    "## Initiate a classifier object for each axis\n",
    "Since not all classes are represented equally, trade precision for recall to balance weights of the classes by passing 'balanced' to `class_weight`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba77815",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "#train a separate classifier for each axis, enable loss='log' and class_weight='balanced'\n",
    "sgdc1 = SGDClassifier(loss='log', l1_ratio=0.3, penalty='l1', class_weight='balanced')\n",
    "sgdc2 = SGDClassifier(loss='log', l1_ratio=0.3, penalty='l1', class_weight='balanced')\n",
    "sgdc3 = SGDClassifier(loss='log', l1_ratio=0.3, penalty='l1', class_weight='balanced')\n",
    "sgdc4 = SGDClassifier(loss='log', l1_ratio=0.3, penalty='l1', class_weight='balanced')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e086935",
   "metadata": {},
   "source": [
    "## Fit a classifier for each axis with test corpus and corresponding labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fde215e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit each classifier with the data and respective train labels\n",
    "IE = sgdc1.fit(train_transform, train_labels_IE)\n",
    "NS = sgdc2.fit(train_transform, train_labels_NS)\n",
    "TF = sgdc3.fit(train_transform, train_labels_TF)\n",
    "JP = sgdc4.fit(train_transform, train_labels_JP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7c1371",
   "metadata": {},
   "source": [
    "## Feature-extract test corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac462d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorize and weight test data\n",
    "test_counts = count_vect.transform(test_corpus)\n",
    "test_transform = tfidf_transformer.transform(test_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd3e345",
   "metadata": {},
   "source": [
    "## Seperate test labels into individual class labels per axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef28a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split test labels into new labels for each axis\n",
    "test_IE = [entry[0] for entry in test_labels]\n",
    "test_NS = [entry[1] for entry in test_labels]\n",
    "test_TF = [entry[2] for entry in test_labels]\n",
    "test_JP = [entry[3] for entry in test_labels]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95809dea",
   "metadata": {},
   "source": [
    "## Print classifier score on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c189e460",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print the score for each classifier on respective test data\n",
    "IE_score = sgdc1.score(test_transform, test_IE)\n",
    "NS_score = sgdc2.score(test_transform, test_NS)\n",
    "TS_score = sgdc3.score(test_transform, test_TF)\n",
    "JP_score = sgdc4.score(test_transform, test_JP)\n",
    "\n",
    "print('IE score: {}'.format(IE_score) + '\\n'\n",
    "     + 'NS score: {}'.format(NS_score) + '\\n'\n",
    "     + 'TF score: {}'.format(TS_score) + '\\n'\n",
    "     + 'JP score: {}'.format(JP_score))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2110c56",
   "metadata": {},
   "source": [
    "This looks pretty promising; these results are much better than looking at classification of the text from 16 seperate classes.\n",
    "## Gather the probabilities of each classification per axis\n",
    "The probability of class A is proportional to the probability of class B in a binary classification problem; 75% probability for class A is proportional to 25% probability for class B). This means that when graphed along one axis, the certainty of the classifiers predictions can be observed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c0edc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#return probabilities for each prediction on test data\n",
    "probs_IE = IE.predict_proba(test_transform)\n",
    "probs_NS = NS.predict_proba(test_transform)\n",
    "probs_TF = TF.predict_proba(test_transform)\n",
    "probs_JP = JP.predict_proba(test_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0afe1264",
   "metadata": {},
   "source": [
    "This function should give a little more insight into what is happening within each axis being classified.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f37734",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "def display_confusion_matrix(true_labels, predicted_labels, classes=[1,0]):\n",
    "    'returns a dataframe of the confusion matrix with true labels compared to predicted labels'\n",
    "    total_classes = len(classes)\n",
    "    level_labels = [total_classes*[0], list(range(total_classes))]\n",
    "\n",
    "    cm = metrics.confusion_matrix(y_true=true_labels, y_pred=predicted_labels, \n",
    "                                  labels=classes)\n",
    "    cm_frame = pd.DataFrame(data=cm, \n",
    "                            columns=pd.MultiIndex(levels=[['Predicted:'], classes], \n",
    "                                                  labels=level_labels), \n",
    "                            index=pd.MultiIndex(levels=[['Actual:'], classes], \n",
    "                                                labels=level_labels)) \n",
    "    return (cm_frame) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d09ebd8",
   "metadata": {},
   "source": [
    "## Plot the distributions of probabilities per axis\n",
    "### I - E Axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1f7679",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the distribution of the first probability element\n",
    "pd.DataFrame(probs_IE[:,0]).hist()\n",
    "plt.xlabel('I - E')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Probability distribution of I to E')\n",
    "plt.show()\n",
    "\n",
    "#show metrics of the classification\n",
    "IE_pred = sgdc1.predict(test_transform)\n",
    "\n",
    "print(metrics.classification_report(test_IE, IE_pred, sgdc1.classes_))\n",
    "print(display_confusion_matrix(test_IE, IE_pred, sgdc1.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6355601d",
   "metadata": {},
   "source": [
    "### S - N Axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90976ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame((probs_NS[:,0])).hist()\n",
    "plt.xlabel('S - N')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Probability distribution of S to N')\n",
    "plt.show()\n",
    "\n",
    "NS_pred = sgdc2.predict(test_transform)\n",
    "\n",
    "print(metrics.classification_report(test_NS, NS_pred, sgdc2.classes_))\n",
    "print(display_confusion_matrix(test_NS, NS_pred, sgdc2.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9c7a4f",
   "metadata": {},
   "source": [
    "### T - F Axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6de6a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame((probs_TF[:,0])).hist()\n",
    "plt.xlabel('T - F')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Probability distribution of T to F')\n",
    "plt.show()\n",
    "\n",
    "TF_pred = sgdc3.predict(test_transform)\n",
    "\n",
    "print(metrics.classification_report(test_TF, TF_pred, sgdc3.classes_))\n",
    "print(display_confusion_matrix(test_TF, TF_pred, sgdc3.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae14101",
   "metadata": {},
   "source": [
    "### P - J Axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9c6560",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame((probs_JP[:,0])).hist()\n",
    "plt.xlabel('P - J')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Probability distribution of P to J')\n",
    "plt.show()\n",
    "\n",
    "JP_pred = sgdc4.predict(test_transform)\n",
    "\n",
    "print(metrics.classification_report(test_JP, JP_pred, sgdc4.classes_))\n",
    "print(display_confusion_matrix(test_JP, JP_pred, sgdc4.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9690525f",
   "metadata": {},
   "source": [
    "The lack of support in certain classes was affecting its ability to predict them, but with the balanced weighting there was a reasonable bimodal distribution along each axis. Pertaining to the cleaned posts, the results seemed to suggest support for MBTI as a construct of personality from a text based perspective. Looking at each graph, the classifiers were very certain in their classifications and had less probabilities distributed around the center, which was the original problem with the actual MBTI personality test. However, this success needs to be viewed in context to Sample 3 (recall that Sample 3 had all mentions of any of the 16 classes removed). Lets test the classifier on Sample 3 (the clean posts with all references to personality types, like \"ENFJ\" for example, removed).\n",
    "## Prepare second set of test data with `no_ref` as corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac27bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#declare corpus and labels \n",
    "corpus_no_ref = np.array(df.no_ref)\n",
    "labels_no_ref = np.array(df.type)\n",
    "\n",
    "#split data labels into new labels for each axis\n",
    "labels_IE = [entry[0] for entry in labels_no_ref]\n",
    "labels_NS = [entry[1] for entry in labels_no_ref]\n",
    "labels_TF = [entry[2] for entry in labels_no_ref]\n",
    "labels_JP = [entry[3] for entry in labels_no_ref]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96afe488",
   "metadata": {},
   "source": [
    "## Feature-extract and weight "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd5d6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_nr_counts = count_vect.transform(corpus_no_ref)\n",
    "X_nr = tfidf_transformer.transform(X_nr_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346fb866",
   "metadata": {},
   "source": [
    "## Print scores of each classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3768cdfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "IE_score_nr = sgdc1.score(X_nr_counts, labels_IE)\n",
    "NS_score_nr = sgdc2.score(X_nr_counts, labels_NS)\n",
    "TS_score_nr = sgdc3.score(X_nr_counts, labels_TF)\n",
    "JP_score_nr = sgdc4.score(X_nr_counts, labels_JP)\n",
    "\n",
    "print('IE score: {}'.format(IE_score_nr) + '\\n'\n",
    "     + 'NS score: {}'.format(NS_score_nr) + '\\n'\n",
    "     + 'TF score: {}'.format(TS_score_nr) + '\\n'\n",
    "     + 'JP score: {}'.format(JP_score_nr))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9468308",
   "metadata": {},
   "source": [
    "As we can see the accuracy too a big hit with the remove of the class names as a text feature. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc4946b",
   "metadata": {},
   "source": [
    "# Predict probabilities of classifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80d8289",
   "metadata": {},
   "outputs": [],
   "source": [
    "probs_IE_nr = IE.predict_proba(X_nr)\n",
    "probs_NS_nr = NS.predict_proba(X_nr)\n",
    "probs_TF_nr = TF.predict_proba(X_nr)\n",
    "probs_JP_nr = JP.predict_proba(X_nr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7091d452",
   "metadata": {},
   "source": [
    "## Plot distribution of classification probabilities"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
