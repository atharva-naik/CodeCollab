{
    "Machine Learning::C": {
        "Artificial Intelligence::C::influenced by": {
            "Learning Symbolic Representations of Concepts::T::has goal(s)": null,
            "Machine Learning as a Search Problem::C::has part(s)": null,
            "Learning as Improving Problem Solving::C::has part(s)": null,
            "Using Prior Knowledge with Data to Guide Learning::C::has goal(s)": null
        },
        "Bayesian Methods::C::influenced by": {
            "Bayes' Theorem for Calculating Probabilities of Hypotheses::C": null,
            "Naive Bayes Classifier::M": null,
            "Algorithms for Estimating Values of Unobserved Variables::M": null
        },
        "Computational Complexity Theory::C::influenced by": {
            "Theoretical Bounds on Complexity of Learning Tasks::B::has goal(s)": {
                "Computational Effort::C::has part(s)": null,
                "Number of Training Examples::C::has part(s)": null,
                "Number of Mistakes::C::has part(s)": null
            }
        },
        "Control Theory::C::influenced by": {
            "Objectives to Predict Next State of Process::T::has part(s)": null,
            "Optimization Procedures to Learn to Control Process::M::has part(s)": null
        },
        "Information Theory::C::influenced by": {
            "Measures of Entropy and Information Content::C::has part(s)": null,
            "Minimum Description Length Approach to Learning::C::has goal(s)": null,
            "Optimal Codes::C::has part(s)": null,
            "Relation of Optimal Codes to Optimal Training Sequences for Encoding Hypothesis::C::has goal(s)": null
        },
        "Philosophy::C::influenced by": {
            "Occam's Razor::C::has part(s)": {
                "DESC": "principle suggesting the simplest hypothesis is the best"
            },
            "Analysis of Generalization beyond Observed Data::A::has goal(s)": null
        },
        "Psychology and Neurobiology::C::influenced by": {
            "Power Law of Practice::C::has part(s)": {
                "DESC": "It states that over a very broad range of learning problems, people's response time improves with practice according to a power law"
            },
            "Neurobiological Motivation for Artificial Neural Networks::C::has part(s)": null
        },
        "Statistics::C::influenced by": {
            "Characterization of Errors::C::has part(s)": {
                "Bias::S::uses": null,
                "Variance::S::uses": null
            },
            "Estimating Accuracy of Hypothesis based on Limited Data Sample::E::has part(s)": null,
            "Confidence Intervals::S::has part(s)": null,
            "Statistical Tests::S::has part(s)": null
        }
    },
    "Well Posed Learning Problems::T": {
        "STEPS": [
            "define task T",
            "learn from experience E",
            "measure performance P on T"
        ],
        "Task T::T::has goal(s)": {
            "Playing Checkers::T::superclass of": null,
            "Recognizing and Classifying Handwritten Words in Images::T::superclass of": null,
            "Driving on Public Highways using Vision Sensors::T::superclass of": null
        },
        "Performance Measure P::E::evaluated by": {
            "Percent of Games Won Against Opponents::E::superclass of": null,
            "Percent of Words Correctly Classified::E::superclass of": null,
            "Average Distance Traveled before Error::E::superclass of": null
        },
        "Training Experience E::D::uses": {
            "Self Play::D::superclass of": null,
            "Database of Handwritten Words and Given Classifications::D::superclass of": null,
            "Sequence of Images and Steering Commands Recorded while Observing Human Driver::D::superclass of": null
        },
        "Learning to Recognize Spoken Words::T::has instance": {
            "Sphinx System::M::modeled by": {
                "DESC": "learns speaker-specific strategies for recognizing the primitive sounds (phonemes) and words from the observed speech signal"
            },
            "Neural Networks::M::modeled by": {
                "DESC": "effective for automatically customizing to, individual speakers, vocabularies, microphone characteristics, background noise, etc."
            },
            "Hidden Markov Models::M::modeled by": {
                "DESC": "effective for automatically customizing to, individual speakers, vocabularies, microphone characteristics, background noise, etc."
            }
        },
        "Learning to Drive an Autonomous Vehicle::T::has instance": {
            "ALVINN System::M::modeled by": {
                "DESC": "learned strategies to drive unassisted at 70 to 90 mph unassisted on public highways"
            }
        },
        "Learning to Classify new Astronomical Structures::T::has instance": {
            "Decision Tree Learning Algorithms::M::modeled by": {
                "DESC": "classify celestial objects in observatory data"
            }
        },
        "Learning to play Backgammon::T::has instance": {
            "TD-Gammon::M::modeled by": {
                "DESC": "computer program for backgammon that learns through self play"
            }
        },
        "Checkers Learning Problem::T::has instance": {
            "Playing Checkers::T::has goal(s)": null,
            "Percent of Games Won Against Opponents::E::evaluated by": null,
            "Self Play::D::uses": null
        },
        "Handwriting Recognition Learning Problem::T::has instance": {
            "Recognizing and Classifying Handwritten Words in Images::T::has goal(s)": null,
            "Percent of Words Correctly Classified::E::evaluated by": null,
            "Database of Handwritten Words and Given Classifications::D::uses": null
        },
        "Robot Driving Learning Problem::T::has instance": {
            "Driving on Public Highways using Vision Sensors::T::has goal(s)": null,
            "Average Distance Traveled before Error::E::evaluated by": null,
            "Sequence of Images and Steering Commands Recorded while Observing Human Driver::D::uses": null
        }
    },
    "Designing a Learning System::C": {
        "STEPS": [
            "fix the task T",
            "fix performance measure P",
            "fix training experience E",
            "choose exact type of knowledge to be learned",
            "choose representation for target knowledge",
            "choose learning mechanism"
        ],
        "Choosing the Training Experience::C::has part(s)": {
            "Feedback::C::has part(s)": {
                "Direct Feedback::C::superclass of": {
                    "Checker Board States and Correct Moves::D::has instance": null,
                    "Indirect Feedback::C::better than": null
                },
                "Indirect Feedback::C::superclass of": {
                    "Move Sequences and Final Outcomes::D::has instance": null,
                    "Credit Assignment::C::has part(s)": "determining the degree to which each move in the sequence deserves credit or blame for the final outcome"
                }
            },
            "Sequence of Training Examples::C::has part(s)": {
                "Teacher Controlled Sequence of Training Examples::C::superclass of": null,
                "Learner Controlled Sequence of Training Examples::C::superclass of": {
                    "Student Teacher Learning::C::superclass of": {
                        "DESC": "learner proposes confusing examples and asks teacher for correct prediction"
                    },
                    "Self Play::C::superclass of": {
                        "DESC": "learner has complete control over example selection and prediction",
                        "Exploration::T": null,
                        "Exploitation::T": null
                    }
                },
                "Random Sequence of Training Examples::C::superclass of": null
            },
            "Distribution of Training Examples": {
                "DESC": "how representative is the distribution of training examples to the distribution of examples over which the final system performance P must be measured"
            }
        },
        "Choosing the Target Function::C::has part(s)": {
            "choose exact type of knowledge to be learned::s::has part(s)": null
        },
        "Choosing a Representation for the Target Function::C::has part(s)": null,
        "Choosing a Function Approximation Algorithm::C::has part(s)": {
            "Estimating Training Values::C::has part(s)": null,
            "Adjusting the Weights::C::has part(s)": {
                "LMS Weight Update Rule::C::has instance": null
            }
        },
        "Final Design::C::has goal(s)": {
            "Performance System::M::has part(s)": null,
            "Critic::M::has part(s)": null,
            "Generalizer::M::has part(s)": null,
            "Experiment Generator::M::has part(s)": null
        }
    },
    "Issues in Machine Learning::C": {
        "Learning Algorithm::M": {
            "Generalizability of Algorithms::C": null,
            "Convergence of Algorithms::C": null,
            "Finding Best Algorithm for Problem Type and Representation::T": null
        },
        "Data::D": {
            "Sufficient Data::C": null,
            "Confidence Bounds with Training Experience::B": null,
            "Character of Hypothesis Space::F": null
        },
        "Prior Knowledge::C": {
            "Guiding Generalization::C": null,
            "Usefulness if Approximately Correct::C": null
        }
    },
    "Concept Learning::M": {
        "Concept Learning Task::T": {
            "Inductive Learning Hypothesis::C": null
        },
        "Concept Learning as Search::C": {
            "General-to-Specifc Ordering of Hypotheses::C": null
        },
        "Finding a Maximally Specific Hypothesis::T": null,
        "Version Spaces and Candidate Elimination Algorithm::C": {
            "Representation::F": null,
            "List then Eliminate Algorithm::M": null,
            "More Compact Representation of Version Spaces::F": null,
            "Candidate Elimination Learning Algorithm::M": null
        },
        "Version Spaces and Candidate Elimination::C": {
            "Convergence to Correct Hypothesis for Candidate Elimination Algorithm::C": null,
            "Deciding Next Training Example for Learner::C": null,
            "Using Partially Learned Concepts::C": null
        },
        "Inductive Bias::C": {
            "Biased Hypothesis Space::F": null,
            "Unbiased Learner::M": null,
            "Futility of Bias-Free Learning::C": null
        }
    },
    "Decision Tree Learning::M": {
        "Decision Tree Representation::F": null,
        "Problems for Decision Tree Learning::C": null,
        "Basic Decision Tree Learning Algorithm::M": {
            "Best Classifier Attribute::C": null
        },
        "Hypothesis Space Search in Decision Tree Learning::M": null,
        "Inductive Bias in Decision Tree Learning::C": {
            "Restriction Biases and Preference Biases::C": null,
            "Preference of Short Hypotheses::C": null
        },
        "Issues in Decision Tree Learning::C": {
            "Avoiding Overfitting::C": null,
            "Incorporating Continuous Valued Attributes::C": null,
            "Alternative Measures for Selecting Attributes::C": null,
            "Handling Training Examples wuth Missing Attribute Values::C": null,
            "Handling Attributes with Differing Costs::C": null
        }
    },
    "Artificial Neural Networks::M": {
        "Biological Motivation::C": null,
        "Neural Network Representations::F": null,
        "Appropriate Problems for Neural Network Learning::T": null,
        "Perceptrons::M": {
            "Representational Power of Perceptrons::C": null,
            "Perceptron Training Rule::C": null,
            "Gradient Descent and Delta Rule::C": null
        },
        "Multilayer Networks and Backpropagation Algorithm::C": {
            "Differentiable Threshold Unit::C": null,
            "Backpropagation Algorithm::M": {
                "Convergence and Local Minima::C": null,
                "Representational Power of Feedforward Networks::C": null,
                "Hypothesis Space Search and Inductive Bias::C": null,
                "Hidden Layer Representations::F": null,
                "Generalization, Overfitting, and Stopping Criterion::C": null
            },
            "Derivation of Backpropagation Rule::C": null
        },
        "Face Recognition::T": {
            "Task Description::C": null,
            "Design Choices::C": null,
            "Learned Hidden Representations::F": null
        },
        "Advanced Topics in Artificial Neural Networks::C": {
            "Alternative Error Functions::T": null,
            "Alternative Error Minimization Procedures::M": null,
            "Recurrent Networks::M": null,
            "Dynamically Modifying Network Structure::C": null
        }
    },
    "Evaluating Hypotheses::C": {
        "Estimating Hypothesis Accuracy::C": {
            "Sample Error and True Error::E": null,
            "Confidence Intervals for Discrete Valued Hypothesis::E": null
        },
        "Sampling Theory::C": {
            "Error Estimation and Estimating Binomial Proportions::C": null,
            "Binomial Distribution::S": null,
            "Mean and Variance::S": null,
            "Estimators, Bias and Variance::S": null,
            "Confidence Intervals::S": null,
            "Two Sided and One Sided Bounds::B": null
        },
        "Deriving Confidence Intervals::S": {
            "Central Limit Theorem::S": null
        },
        "Difference in Error of Hypotheses::E": {
            "Hypothesis Testing::S": null
        },
        "Comparing Learning Algorithms::C": {
            "Paired t Tests::S": null
        }
    },
    "Bayesian Learning::T": {
        "Bayes Theorem::C": null,
        "Bayes Theorem and Concept Learning::C": {
            "Brute Force Bayes Concept Learning::M": null,
            "MAP Hypotheses and Consistent Learners::C": null
        },
        "Maximum Likelihood and Least Squared Error Hypotheses::C": null,
        "Maximum Likelihood Hypotheses for Predicting Probabilities::C": {
            "Gradient Search to Maximize Likelihood in a Neural Net::M": null
        },
        "Minimum Description Length Principle::C": null,
        "Bayes Optimal Classifier::M": null,
        "Gibbs Algorithm::M": null,
        "Naive Bayes Classifier::M": null,
        "Text Classification::T": null,
        "Bayesian Belief Networks::M": {
            "Conditional Independence::S": null,
            "Representation::F": null,
            "Inference::C": null,
            "Learning Bayesian Belief Networks::T": null,
            "Gradient Ascent Training of Bayesian Networks::M": null,
            "Learning Structure of Bayesian Networks::T": null
        },
        "EM Algorithm::M": {
            "Estimating Means of k Gaussians::S": null,
            "Derivation of k Means Algorithm::M": null
        }
    },
    "Computational Learning Theory::C": {
        "PAC Hypothesis Learning::M": {
            "Problem Setting::T": null,
            "Error of Hypothesis::E": null,
            "PAC Learnability::C": null
        },
        "Sample Complexity for Finite Hypothesis Spaces::C": {
            "Agnostic Learning and Inconsistent Hypotheses::C": null,
            "Conjunctions of Boolean Literals are PAC Learnable::C": null,
            "PAC Learnability of Concept Classes::C": null
        },
        "Sample Complexity for Infinite Hypothesis Spaces::C": {
            "Shattering a Set of Instances::C": null,
            "VC Dimension::C": null,
            "Sample Complexity and VC Dimension::C": null,
            "VC Dimension for Neural Networks::C": null
        },
        "Mistake Bound Model of Learning::M": {
            "Mistake Bound for Find-S Algorithm::B": null,
            "Mistake Bound for Halving Algorithm::B": null,
            "Optimal Mistake Bounds::B": null,
            "Weighted Majority Algorithm::M": null
        }
    },
    "Instance Based Learning::T": {
        "k Nearest Neighbor Learning::M": {
            "Distance Weighted Nearest Neighbor Algorithm::M": null
        },
        "Locally Weighted Regression::M": {
            "Locally Weighted Linear Regression::M": null
        },
        "Radial Basis Functions::C": null,
        "Case Based Reasoning::M": null,
        "Lazy and Eager Learning::M": null
    },
    "Genetic Algorithms::M": {
        "Representing Hypotheses::F": null,
        "Genetic Operators::C": null,
        "Fitness Function and Selection::C": null,
        "Hypothesis Space Search::M": {
            "Population Evolution and the Schema Theorem::C": null
        },
        "Genetic Programming::C": {
            "Representing Programs::F": null
        },
        "Models of Evolution and Learning::M": {
            "Lamarckian Evolution::C": null,
            "Baldwin Effect::C": null
        },
        "Parallelizing Genetic Algorithms::C": null
    },
    "Learning Sets of Rules::T": {
        "Sequential Covering Algorithms::M": {
            "General to Specific Beam Search::M": null,
            "Variations::C": null
        },
        "Learning Rule Sets::T": null,
        "Learning First Order Rules::T": {
            "First-Order Horn Clauses::C": null
        },
        "Learning Sets of First Order Rules FOIL::T": {
            "Generating Candidate Specializations in FOIL::T": null,
            "Guiding the Search in FOIL::C": null,
            "Learning Recursive Rule Sets::T": null
        },
        "Induction as Inverted Deduction::C": null,
        "Inverting Resolution::C": {
            "First Order Resoultion::C": null,
            "Inverting Resolution First Order Case::C": null,
            "Generalization, \u03b8-Subsumption, and Entailment::C": null,
            "PROGOL::C": null
        }
    },
    "Analytical Learning::T": {
        "Inductive and Analytical Learning Problems::T": null,
        "Learning with Perfect Domain Theories: PROLOG-EBG::C": {
            "Illustrative Trace::D": null
        },
        "Explanation Based Learning::T": {
            "Discovering New Features::F": null,
            "Deductive Learning::C": null,
            "Inductive Bias in Explanation Based Learning::C": null,
            "Knowledge Level Learning::T": null
        },
        "Explanation Based Learning of Search Control Knowledge::T": null
    },
    "Combining Inductive and Analytical Learning::T": {
        "Inductive Analytical Approaches to Learning::C": {
            "Learning Problem::T": null,
            "Hypothesis Space Search::M": null
        },
        "Using Prior Knowledge to Initialize the Hypothesis::C": {
            "KBANN Algorithm::M": null
        },
        "Using Prior Knowledge to Alter the Search Objective::C": {
            "TangentProp Algorithm::M": null,
            "EBNN Algorithm::M": null
        },
        "Using Prior Knowledge to Augment Search::C": {
            "FOCL Algorithm::M": null
        }
    },
    "Reinforcement Learning::T": {
        "Learning Task::T": null,
        "Q Learning::M": {
            "Q Function::C": null,
            "Algorithm for Q Learning::M": null,
            "Convergence::C": null,
            "Experimentation Strategies::C": null,
            "Updating Sequence::C": null
        },
        "Nondeterministic Rewards and Actions::C": null,
        "Temporal Difference Learning::T": null,
        "Generalizing from Examples::C": null,
        "Relationship to Dynamic Programming::C": null
    }
}