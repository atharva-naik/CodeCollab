{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b7b93b4",
   "metadata": {},
   "source": [
    "# Stock Price Prediction #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453f099f",
   "metadata": {},
   "source": [
    "## Load Packages ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97218f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "np.random.seed(0)\n",
    "import tensorflow as tf\n",
    "tf.set_random_seed(0)\n",
    "\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, BatchNormalization, Dropout, Activation\n",
    "from keras.layers import LSTM, GRU\n",
    "from keras.optimizers import Adam, SGD, RMSprop\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33d63e1",
   "metadata": {},
   "source": [
    "## Load Data ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2ebfd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/home/lee/Documents/Datasets for GitHub/us_stocks_etfs_price_volume/\"\n",
    "\n",
    "symbols = ['SKX']\n",
    "\n",
    "# symbols = ['skx', 'twou', 'nbix', 'abmd', 'bofi']\n",
    "\n",
    "df = pd.DataFrame()\n",
    "for symbol in symbols:\n",
    "    single_stock = pd.read_csv(data_dir + \"Stocks/\" + symbol.lower() + '.us.txt', header=0)\n",
    "    single_stock['symbol'] = symbol\n",
    "    df = pd.concat([df, single_stock], ignore_index=True)\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "df.drop('OpenInt', axis=1, inplace=True)\n",
    "df.set_index(['symbol', 'Date'], inplace=True, drop=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f943140a",
   "metadata": {},
   "source": [
    "## Inspect Data ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9012e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def look_at_dataset(df):\n",
    "\n",
    "    print(\"dataframe shape: {}\".format(df.shape))\n",
    "    print(\"\\n\")\n",
    "\n",
    "    print(\"preview data: \\n\")\n",
    "    for i in list(range(0, len(df.columns), 8)):\n",
    "        print(df.iloc[0:5, i:i+8])\n",
    "    print(\"\\n\")\n",
    "\n",
    "    print(\"summarize data: \\n\")\n",
    "    for i in list(range(0, len(df.columns), 8)):\n",
    "        print(df.iloc[:, i:i+8].describe())\n",
    "\n",
    "look_at_dataset(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4441d4",
   "metadata": {},
   "source": [
    "### Check Missing ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb27aa25",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of records with missing value in each column: \\n{}\".format(df.isnull().sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d0b58c",
   "metadata": {},
   "source": [
    "### Visualize ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06af4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_price(code, point):\n",
    "\n",
    "    plt.figure(figsize = (16, 8))\n",
    "    sns.lineplot(x=\"Date\", y=point, data=df.loc[code, :])\n",
    "    plt.grid(True)\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Price')\n",
    "    plt.title(code + \" \" + point.lower() + \" prices\")\n",
    "    plt.show()\n",
    "for i in symbols:\n",
    "    plot_price(i, \"Close\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd8b708",
   "metadata": {},
   "source": [
    "## Prepare Data for Modeling ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5e7158",
   "metadata": {},
   "source": [
    "The below looks at one single stock. Next step is to automate this process so that it will take a ticker as argument and then output predictions. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7fcd9e5",
   "metadata": {},
   "source": [
    "### Scale Prices ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6882734a",
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks_df = df.loc[symbols, :]\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "stocks = scaler.fit_transform(stocks_df['Close'].to_frame())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ffdc8f6",
   "metadata": {},
   "source": [
    "### Split Train and Test ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a4bb97",
   "metadata": {},
   "source": [
    "Use the first 80% of data for training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc0aae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_time_cutoff = int(len(stocks) * 0.80)\n",
    "train = stocks[0:train_time_cutoff]\n",
    "test = stocks[train_time_cutoff:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367ff58f",
   "metadata": {},
   "source": [
    "### Reshape Data ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dffd1875",
   "metadata": {},
   "source": [
    "How many historical prices do we use to predict the next day's price? Let's start with 2 for computation simplicity. Later we may optimize this value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ff7076",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(data, n_historical_records):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(data)-n_historical_records-1):\n",
    "        window = data[i:(i+n_historical_records), 0]\n",
    "        dataX.append(window)\n",
    "        dataY.append(data[i + n_historical_records, 0])\n",
    "    return np.array(dataX), np.array(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144a716d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_historical_records = 2\n",
    "\n",
    "trainX, trainY = process_data(train, n_historical_records)\n",
    "testX, testY = process_data(test, n_historical_records)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019dab63",
   "metadata": {},
   "source": [
    "This model requires a 3-D input. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc574d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = trainX.reshape(trainX.shape[0], 1, trainX.shape[1])\n",
    "testX = testX.reshape(testX.shape[0], 1, testX.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6376183d",
   "metadata": {},
   "source": [
    "## Modeling ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c6f630",
   "metadata": {},
   "source": [
    "### Define Model ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcfa6d47",
   "metadata": {},
   "source": [
    "During training we are interested in optimizing learning rate and batch size. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0632c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(GRU(256, input_shape = (1, n_historical_records), return_sequences=True))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(LSTM(256))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(64,  activation = 'relu'))\n",
    "model.add(Dense(1))\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a602e9",
   "metadata": {},
   "source": [
    "### Define Optimizer ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b90c43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error', optimizer=Adam(lr = 0.0005), \\\n",
    "              metrics = ['mean_squared_error'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de78d4a8",
   "metadata": {},
   "source": [
    "### Define Early Stopping Callback ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ba528a",
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystop = EarlyStopping(monitor='val_acc', min_delta=0.0001, patience=5, \\\n",
    "                          verbose=1, mode='auto')\n",
    "callbacks_list = [earlystop]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a2cc56",
   "metadata": {},
   "source": [
    "### Train Model ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6772d37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For faster iteration, during training we try 20-50-100 epochs. Use early stopping if needed. \n",
    "# history = model.fit(trainX, trainY, epochs=100, batch_size=128, \\\n",
    "#                     verbose=0, callbacks=callbacks_list, validation_data=(testX,testY))\n",
    "history = model.fit(trainX, trainY, epochs=100, batch_size=128, \\\n",
    "                    verbose=0, validation_data=(testX,testY))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b68c81d",
   "metadata": {},
   "source": [
    "### Plot Training History ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac73f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['mean_squared_error'])\n",
    "plt.plot(history.history['val_mean_squared_error'])\n",
    "plt.title('model mean squared error')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='best')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d835f617",
   "metadata": {},
   "source": [
    "### Make Predictions ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50dea018",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(testX)\n",
    "pred = np.around(scaler.inverse_transform(pred), decimals=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2353121",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the prices back\n",
    "testY = testY.reshape(testY.shape[0], 1)\n",
    "testY = scaler.inverse_transform(testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b904c7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_vs_test = pd.concat([pd.Series(stocks_df.iloc[train_time_cutoff:, :]['Date'].tolist()), \\\n",
    "                          pd.Series(testY.flatten()), pd.Series(pred.flatten())], axis=1, \\\n",
    "                         ignore_index=True)\n",
    "pred_vs_test.rename(columns={0: \"date\", 1: \"actual\", 2: \"prediction\"}, inplace=True)\n",
    "pred_vs_test_long = pd.melt(pred_vs_test, id_vars=['date'], value_vars=[\"actual\", 'prediction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c607db21",
   "metadata": {},
   "outputs": [],
   "source": [
    "del pred, testY, pred_vs_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b46959",
   "metadata": {},
   "source": [
    "### Plot Predictions ###"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
