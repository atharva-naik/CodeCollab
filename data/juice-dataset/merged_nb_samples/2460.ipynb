{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b302b81",
   "metadata": {},
   "source": [
    "# BEHAVIORAL CLONING PROJECT\n",
    "\n",
    "The aim of this project is to design a system that can drive a car autonomously in a simulated environment.\n",
    "\n",
    "Our process is splitted into the following several steps:\n",
    "1. **Data Collecting**\n",
    "    * The sample data is used to train the designed model. It's worth to mention that my previous code and strategy for collecting data from simulator can also work here.\n",
    "    \n",
    "2. **Data Cleaning and Tidying**\n",
    "    * We check distribution of the data and remove outliers in this step\n",
    "    \n",
    "3. **Data Exploration and Augmentation.**\n",
    "    * One observation from the last step is that the data is unblanced, which will cause a skewed result. So data augmentation is necessary. In this model, we use all images from center, left, and right cameras. Random flip, shift, brightness and shadow skill are used to augmentation. \n",
    "         \n",
    "4. **Data Preprocessing**\n",
    "    * Since the NVIDIA model (as a base) is going to be used in our method, some necessary preprocess steps, such as, resizing, convert the image from RGB format to YUV are should be done beforehands. We also take a cropping step so that the image only contain necessary information for predict a steering angle.\n",
    "\n",
    "5. **Modeling and Deep Learning**\n",
    "    * A lambda layer is used to normalize the preprocessed data. Then we throw them into the NVIDIA model, followed with a dropout (dropout rate is 0.5) layer and a flatten layer. As a last step, four full connected layers (->100->50->10->1) are used to obtain a final result. \n",
    "    * One interesting thing is, if the sample data is not properly augmented then the above model will result in both high training loss and validation loss. \n",
    "\n",
    "6. **Training and Saving**\n",
    "    * We used Adam as the optimizer in this step. It is worth to mention that the default learning rate 0.001 is still too large to improve the validation loss.\n",
    "    * The MSE is used to measure the loss.\n",
    "    * Thanks to my reviewer, the ModelCheckpoint from Keras is used this time to save the best model.\n",
    "    * The EPOCHS is set to 10. I tried other higher numbers, and found 10 should be enough. Even though the best validation loss arrives at epoch 7, but the models from epochs 3 are good enough to survive in the test track. \n",
    "    * The training and validation loss for each epoch are plot\n",
    "    * PS. the data tidying step here is not enough and still allow some space to improve. If I remove this step, the obtained model works even better.\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "Links: \n",
    "* Simulators: [macOS](https://d17h27t6h515a5.cloudfront.net/topher/2016/November/5831f290_simulator-macos/simulator-macos.zip), [Windows 64-bit](https://d17h27t6h515a5.cloudfront.net/topher/2016/November/5831f3a4_simulator-windows-64/simulator-windows-64.zip), [Linux](https://d17h27t6h515a5.cloudfront.net/topher/2016/November/5831f0f7_simulator-linux/simulator-linux.zip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decb3ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3f8bb2",
   "metadata": {},
   "source": [
    "## DATA COLLECTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98af935a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = './data'\n",
    "driving_log = pd.read_csv(os.path.join(data_dir, 'driving_log.csv'))\n",
    "\n",
    "X = driving_log[['center', 'left', 'right']].values\n",
    "y = driving_log['steering'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d71bd1",
   "metadata": {},
   "source": [
    "## DATA VISUALIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dee7ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "driving_log.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06305160",
   "metadata": {},
   "source": [
    "### data distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a9ce61",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,3))\n",
    "plt.subplot(1,2,1)\n",
    "plt.hist(y, bins=30)\n",
    "plt.title(\"Data distribution\")\n",
    "plt.subplot(1,2,2)\n",
    "plt.hist(y, bins=30)\n",
    "plt.title(\"Truncated data distribution\")\n",
    "plt.ylim(0,40)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac25dd5",
   "metadata": {},
   "source": [
    "I didn't go deeper of the data and show the outliers in the range [-1, -0.4) and (0.4, 1]. Because after the data augmentation its proportion becomes low. If the model is trained properly, those effect hopefully can be ignored.\n",
    "\n",
    "## TIDYING DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00251b3b",
   "metadata": {},
   "source": [
    "### remove the outliers in the range (0.5, 1] and [-1, -0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58f2615",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_set = []\n",
    "for i in range(len(y)):\n",
    "    if abs(y[i]) > 0.5:\n",
    "        check_set.append([i, y[i]])\n",
    "\n",
    "print(\"In total, there are {} samples whose steering angles are in the range [-1, -0.5) or (0.5, 1].\".format(len(check_set)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9685ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,24))\n",
    "for i in range(len(check_set)):\n",
    "    plt.subplot(11,4,i+1)\n",
    "    row = i % 4\n",
    "    image = mpimg.imread(os.path.join(data_dir, X[check_set[i][0]][0].strip()))\n",
    "    plt.imshow(image)\n",
    "    if row == 0:\n",
    "        plt.title(\"row {}: {}\".format(i//4 + 1, check_set[i][1]))\n",
    "    else:\n",
    "        plt.title(check_set[i][1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929df940",
   "metadata": {},
   "source": [
    "It is not hard to find all images in row 5 and the first image of row 6 are outliers. We decide to remove them. The following formula is used to calculate their indexes.\n",
    "\n",
    "(Row i, Col j) corresponding to the index (i - 1)* 4 + (j - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64418fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_pre = [16, 17, 18, 19, 20]\n",
    "remove_indexes = []\n",
    "for i in range(len(remove_pre)):\n",
    "    remove_indexes.append(check_set[remove_pre[i]][0])\n",
    "print(\"The indexes of images that we are going to remove are: {}\".format(remove_indexes))\n",
    "\n",
    "# Remove outliers\n",
    "X = np.delete(X, remove_indexes, 0)\n",
    "y = np.delete(y, remove_indexes, 0)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e8dc6c4e",
   "metadata": {},
   "source": [
    "#### Double check\n",
    "\n",
    "print(type(X_new), type(y_new))\n",
    "check_set2 = []\n",
    "\n",
    "for i in range(len(y_new)):\n",
    "    if abs(y_new[i]) > 0.5:\n",
    "        check_set2.append([i, y_new[i]])\n",
    "\n",
    "print(len(check_set2))\n",
    "print(check_set2[0:3])\n",
    "\n",
    "plt.figure(figsize=(12,20))\n",
    "for i in range(len(check_set2)):\n",
    "    plt.subplot(10,4,i+1)\n",
    "    row = i % 4\n",
    "    image = mpimg.imread(os.path.join(data_dir, X_new[check_set2[i][0]][0].strip()))\n",
    "    plt.imshow(image)\n",
    "    if row == 0:\n",
    "        plt.title(\"row {}: {}\".format(i//4 + 1, check_set2[i][1]))\n",
    "    else:\n",
    "        plt.title(check_set2[i][1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd6e183",
   "metadata": {},
   "outputs": [],
   "source": [
    "stable_indexes = []\n",
    "for i in range(len(y)):\n",
    "    if abs(y[i]) < 0.05:\n",
    "        stable_indexes.append(i)\n",
    "print(\"There are {} samples in total whose steering angles are loacted in (-0.05, 0.05).\".format(len(stable_indexes)))\n",
    "\n",
    "remove_indexes = np.random.choice(stable_indexes, len(stable_indexes)*2//3)\n",
    "#print(remove_indexes[0:10], len(remove_indexes))\n",
    "X = np.delete(X, remove_indexes, 0)\n",
    "y = np.delete(y, remove_indexes, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659dce60",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(y))\n",
    "plt.figure(figsize=(12,3))\n",
    "plt.subplot(1,2,1)\n",
    "plt.hist(y, bins=30)\n",
    "plt.title(\"Data distribution\")\n",
    "plt.subplot(1,2,2)\n",
    "plt.hist(y, bins=30)\n",
    "plt.title(\"Truncated data distribution\")\n",
    "plt.ylim(0,40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d9c32f",
   "metadata": {},
   "source": [
    "## DATA AUGMENTATION \n",
    "### use all images obtained from center, left and right cameras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db29541",
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_image(data_dir, center, left, right, steering_angle):\n",
    "    trigger = np.random.choice(3)\n",
    "    if trigger == 0:\n",
    "        return mpimg.imread(os.path.join(data_dir, left.strip())), steering_angle + 0.2\n",
    "    elif trigger == 1:\n",
    "        return mpimg.imread(os.path.join(data_dir, right.strip())), steering_angle - 0.2\n",
    "    return mpimg.imread(os.path.join(data_dir, center.strip())), steering_angle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a0e20b",
   "metadata": {},
   "source": [
    "### random flip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6113eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_flip(image, steering_angle):\n",
    "    if np.random.choice(2):\n",
    "        image = cv2.flip(image, 1)\n",
    "        steering_angle = -steering_angle\n",
    "    return image, steering_angle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459ac0e4",
   "metadata": {},
   "source": [
    "### random shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a361aba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_translate(image, steering_angle, range_x, range_y):\n",
    "    \"\"\"\n",
    "    Randomly shift the image virtically and horizontally\n",
    "    \"\"\"\n",
    "    trans_x = range_x * (np.random.rand() - 0.5)\n",
    "    trans_y = range_y * (np.random.rand() - 0.5)\n",
    "    steering_angle += trans_x * 0.002\n",
    "    trans_m = np.float32([[1,0,trans_x], [0,1,trans_y]])\n",
    "    height, width = image.shape[:2]\n",
    "    image = cv2.warpAffine(image, trans_m, (width, height))\n",
    "    return image, steering_angle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2116d989",
   "metadata": {},
   "source": [
    "### random shadow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf8e32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_shadow(image):\n",
    "    \"\"\"\n",
    "    Generates and adds random shadow\n",
    "    \"\"\"\n",
    "    # (x1, y1) and (x2, y2) forms a line\n",
    "    # xm, ym gives all the locations of the image\n",
    "    x1, y1 = IMAGE_WIDTH * np.random.rand(), 0\n",
    "    x2, y2 = IMAGE_WIDTH * np.random.rand(), IMAGE_HEIGHT\n",
    "    xm, ym = np.mgrid[0:IMAGE_HEIGHT, 0:IMAGE_WIDTH]\n",
    "    \n",
    "    mask = np.zeros_like(image[:, :, 1])\n",
    "    mask[(ym - y1) * (x2 - x1) - (y2 - y1) * (xm - x1) > 0] = 1\n",
    "\n",
    "    # choose which side should have shadow and adjust saturation\n",
    "    cond = mask == np.random.randint(2)\n",
    "    s_ratio = np.random.uniform(low=0.2, high=0.5)\n",
    "\n",
    "    # adjust Saturation in HLS(Hue, Light, Saturation)\n",
    "    hls = cv2.cvtColor(image, cv2.COLOR_RGB2HLS)\n",
    "    hls[:, :, 1][cond] = hls[:, :, 1][cond] * s_ratio\n",
    "    return cv2.cvtColor(hls, cv2.COLOR_HLS2RGB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8037d4",
   "metadata": {},
   "source": [
    "### random brightness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6de024",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_brightness(image):\n",
    "    image_hsv = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "    ratio = 1.0 + 0.4 * (np.random.rand() - 0.5)\n",
    "    image_hsv[:,:,2] = image_hsv[:,:,2] * ratio\n",
    "    return cv2.cvtColor(image_hsv, cv2.COLOR_HSV2RGB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a01a3b",
   "metadata": {},
   "source": [
    "### data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180a6707",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augument(data_dir, center, left, right, steering_angle, range_x=100, range_y=10):\n",
    "    \"\"\"\n",
    "    Generate an augumented image and adjust steering angle.\n",
    "    \"\"\"\n",
    "    image, steering_angle = choose_image(data_dir, center, left, right, steering_angle)\n",
    "    image, steering_angle = random_flip(image, steering_angle)\n",
    "    image, steering_angle = random_translate(image, steering_angle, range_x, range_y)\n",
    "    image = random_shadow(image)\n",
    "    image = random_brightness(image)\n",
    "    return image, steering_angle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba55e11c",
   "metadata": {},
   "source": [
    "## DATA PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56dc87f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop(image):\n",
    "    \"\"\"\n",
    "    Remove the unrelevant content from image\n",
    "    \"\"\"\n",
    "    return image[60:140,:,:]\n",
    "\n",
    "def resize(image):\n",
    "    \"\"\"\n",
    "    In order to fit the input shape of NVIDIA model\n",
    "    \"\"\"\n",
    "    return cv2.resize(image, (IMAGE_WIDTH, IMAGE_HEIGHT), cv2.INTER_AREA)\n",
    "\n",
    "def rgb2yuv(image):\n",
    "    \"\"\"\n",
    "    Will be used in the NVIDIA model\n",
    "    \"\"\"\n",
    "    return cv2.cvtColor(image, cv2.COLOR_RGB2YUV)\n",
    "\n",
    "def preprocess(image):\n",
    "    image = crop(image)\n",
    "    image = resize(image)\n",
    "    image = rgb2yuv(image)\n",
    "    return image\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33eb98f1",
   "metadata": {},
   "source": [
    "## CREATE DATA PARTITION"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
