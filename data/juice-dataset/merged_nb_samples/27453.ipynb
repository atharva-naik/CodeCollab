{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9e442b7",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4903f3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Image loading, binarization, inversion and display\n",
    "def load_image(path):\n",
    "    return cv2.cvtColor(cv2.imread(path), cv2.COLOR_BGR2RGB)\n",
    "def image_gray(image):\n",
    "    return cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "def image_bin_otsu(image_gs):\n",
    "    ret,image_bin = cv2.threshold(image_gs, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "    return image_bin\n",
    "def invert(image):\n",
    "    return 255-image\n",
    "def display_image(image, color= False):\n",
    "    plt.figure()\n",
    "    if color:\n",
    "        plt.imshow(image)\n",
    "    else:\n",
    "        plt.imshow(image, 'gray')\n",
    "    plt.show()\n",
    "    \n",
    "# Image morphological operations\n",
    "def dilate(image, kernel, iterations = 1):\n",
    "    return cv2.dilate(image, kernel, iterations)\n",
    "def erode(image, kernel, iterations = 1):\n",
    "    return cv2.erode(image, kernel, iterations)\n",
    "def open_image(image, kernel = None):\n",
    "    if kernel is None:\n",
    "        kernel = np.ones((1, 100))\n",
    "    return dilate(erode(image, kernel), kernel)\n",
    "\n",
    "# Horizontal projection\n",
    "def horizontal_projection(image):\n",
    "    hor_proj = []\n",
    "    for i in range(len(image)):\n",
    "        row_sum = 0\n",
    "        for j in range(len(image[i])):\n",
    "            row_sum += image[i][j] == 255\n",
    "        hor_proj.append([255] * row_sum + [0] * (len(image[0]) - row_sum))\n",
    "\n",
    "    return hor_proj\n",
    "\n",
    "# Image crop\n",
    "def crop_image(image, crop_start = None, crop_width = None):\n",
    "    if crop_width is None:\n",
    "        crop_width = len(image[0]) // 10\n",
    "        \n",
    "    if crop_start is None:\n",
    "        end = 0\n",
    "        for row in image:\n",
    "            s = sum(row) / 255\n",
    "            if s > end:\n",
    "                end = s\n",
    "\n",
    "        crop_start = end - crop_width\n",
    "        \n",
    "    cutoff = image[:]\n",
    "    \n",
    "    for i in range(len(cutoff)):\n",
    "        cutoff[i] = cutoff[i][crop_start : crop_start + crop_width] \n",
    "\n",
    "    cutoff = np.array(cutoff, dtype = np.uint8)\n",
    "    return cutoff\n",
    "\n",
    "# Find Y coordinates of white pixels\n",
    "def find_y(image):\n",
    "    y = []\n",
    "    for i in range(len(image)):\n",
    "        for j in range(len(image[i])):\n",
    "            if (image[i][j] == 255) and (i not in y):\n",
    "                y.append(i)\n",
    "    return sorted(y)\n",
    "\n",
    "# Intersect two lists\n",
    "def intersect_lists(first, second):\n",
    "    ret_val = []\n",
    "    for val in first:\n",
    "        if val in second:\n",
    "            ret_val += [val]\n",
    "    return ret_val\n",
    "\n",
    "# Group points and get distances\n",
    "def label_y(y_list):\n",
    "    labels = [[]]\n",
    "    line_distances = []\n",
    "    prev_y = None\n",
    "    for y in y_list:\n",
    "        if prev_y is not None:\n",
    "            if y - prev_y > 1:\n",
    "                labels.append([])\n",
    "                line_distances += [y - prev_y]\n",
    "        labels[-1] += [y]\n",
    "        prev_y = y\n",
    "    return labels, line_distances\n",
    "\n",
    "# Find lines\n",
    "def find_lines(image):\n",
    "    first = find_y(crop_image(horizontal_projection(image)))\n",
    "    second = find_y(open_image(image))\n",
    "    \n",
    "    \n",
    "    lines, distances = label_y(intersect_lists(first, second))\n",
    "    staff_spacings = [distances[i] for i in range(len(distances)) if (i+1) % 5 != 0 ]\n",
    "    staff_spacing = sum(staff_spacings) * 1./len(staff_spacings)\n",
    "    return lines, distances, staff_spacing\n",
    "\n",
    "# Remove lines\n",
    "def remove_lines(org_image, tolerance = 0, lines = None, topBotPixelRemoval = True, widthBasedRemoval = True):\n",
    "    image = org_image.copy()\n",
    "    \n",
    "    if lines == None:\n",
    "        lines, distances, staff_spacing = find_lines(org_image)\n",
    "    \n",
    "    if topBotPixelRemoval:\n",
    "        for line in lines:\n",
    "            top = line[0]\n",
    "            bot = line[-1]\n",
    "            for j in range(len(image[top])):\n",
    "                remove = True\n",
    "                is_line = False\n",
    "                for row in image[top:bot+1]:\n",
    "                    if row[j] == 255:\n",
    "                        is_line = True\n",
    "                        break\n",
    "                if not is_line:\n",
    "                    continue\n",
    "                # check 2 pixels above and below\n",
    "                diff = 2\n",
    "                for row in image[top - diff : top]:\n",
    "                    if row[j] == 255:\n",
    "                        remove = False\n",
    "                        break\n",
    "                if remove:\n",
    "                    for row in image[bot + 1: bot + diff + 1]:\n",
    "                        if row[j] == 255:\n",
    "                            remove = False\n",
    "                            break\n",
    "                if remove:\n",
    "                    for row in image[top:bot+1]:\n",
    "                        row[j] = 0\n",
    "    \n",
    "    if widthBasedRemoval:\n",
    "        avg_thickness = lines[:]\n",
    "        for i, line in enumerate(avg_thickness):\n",
    "            avg_thickness[i] = len(line)\n",
    "        avg_thickness = sum(avg_thickness) * 1./len(avg_thickness)\n",
    "\n",
    "        for j in range(len(image[0])):\n",
    "            white = False\n",
    "            for i in range(len(image)):\n",
    "                if image[i][j] == 255:\n",
    "                    if not white:\n",
    "                        start = i\n",
    "                    white = True\n",
    "                else:\n",
    "                    if white:\n",
    "                        thickness = i - start\n",
    "                        if thickness <= (avg_thickness + tolerance):\n",
    "                            for row in image[start : i]:\n",
    "                                row[j] = 0\n",
    "                    white = False\n",
    "    return image\n",
    "\n",
    "def add_region(image, row, col, regions):\n",
    "    append = True\n",
    "    coords = [(row, col)]\n",
    "    idx = 0\n",
    "    while (idx < len(coords)):\n",
    "        row, col = coords[idx]\n",
    "        for dr in range(-1,2):\n",
    "            for dc in range(-1,2):\n",
    "                r = row + dr\n",
    "                c = col + dc\n",
    "                if r >= 0 and c >= 0 and r < len(image) and c < len(image[r]):\n",
    "                    if image[r][c] == 255 and ((r,c) not in coords):\n",
    "                        skip = False\n",
    "                        for region in regions:\n",
    "                            if (r,c) in region:\n",
    "                                skip = True\n",
    "                                append = False\n",
    "                                for coord in coords:\n",
    "                                    region.append((r,c))\n",
    "                        if not skip:\n",
    "                            coords += [(r,c)]\n",
    "        idx += 1\n",
    "    if append:\n",
    "        regions.append(coords)\n",
    "\n",
    "def find_vertical_lines(image):\n",
    "    # Find lines, distances\n",
    "    lines, distances, staff_spacing = find_lines(image)\n",
    "\n",
    "    # Find vertical objects\n",
    "    img_open = open_image(remove_lines(image), np.ones((1.5 * staff_spacing, 1)))\n",
    "    return img_open\n",
    "\n",
    "def find_regions(org_image, ref_image = None):\n",
    "    if ref_image is None:\n",
    "        ref_image = org_image\n",
    "    # Label regions of interest\n",
    "    regions = []\n",
    "    for row in range(len(ref_image)):\n",
    "        for col in range(len(ref_image[row])):\n",
    "            if ref_image[row][col] == 255:\n",
    "                isFound = False\n",
    "                for region in regions:\n",
    "                    if (row,col) in region:\n",
    "                        isFound = True\n",
    "                        break\n",
    "                if not isFound:\n",
    "                    add_region(org_image, row, col, regions)\n",
    "    \n",
    "    img_regions = org_image.copy()\n",
    "    for row in range(len(img_regions)):\n",
    "        for col in range(len(img_regions[row])):\n",
    "            img_regions[row][col] = 0\n",
    "\n",
    "    for region in regions:\n",
    "        for row, col in region:\n",
    "            img_regions[row, col] = 255\n",
    "            \n",
    "    return img_regions, regions\n",
    "\n",
    "def find_vertical_objects(image, image_vert_lines):\n",
    "    return find_regions(image, image_vert_lines)\n",
    "\n",
    "def split_image(image, regions):\n",
    "    split_images = []\n",
    "    for region in regions:\n",
    "        minr = min([r for r,c in region])\n",
    "        maxr = max([r for r,c in region])\n",
    "        minc = min([c for r,c in region])\n",
    "        maxc = max([c for r,c in region])\n",
    "        sub_image = []\n",
    "        for row in range(minr,maxr+1):\n",
    "            sub_image.append([])\n",
    "            for col in range(minc,maxc+1):\n",
    "                sub_image[-1] += [image[row][col]]\n",
    "        sub_image = np.array(sub_image)\n",
    "        sub_image = np.uint8(sub_image)\n",
    "        split_images.append(sub_image)\n",
    "    return split_images\n",
    "\n",
    "def resize_image(tmp_img, new_width, new_height):\n",
    "    return cv2.resize(tmp_img, (int(round(new_width)), int(round(new_height))), interpolation = cv2.INTER_CUBIC)\n",
    "\n",
    "def match_clef(obj, clef_templates):\n",
    "    obj_height, obj_width = obj.shape[:2]\n",
    "    best_match = (None, 0)\n",
    "    for template in clef_templates:\n",
    "        template_name = template\n",
    "        # Template Image Processing\n",
    "        template = load_image(template)\n",
    "        template = resize_image(template,obj_width,obj_height)\n",
    "        template = image_gray(template)\n",
    "        template = image_bin_otsu(template)\n",
    "        template = invert(template)\n",
    "        match = 0\n",
    "        for row in range(len(template)):\n",
    "            for col in range(len(template[row])):\n",
    "                match += 1 if obj[row][col] == template[row][col] else 0\n",
    "\n",
    "\n",
    "        # Normalize\n",
    "        match *= 1./(obj_width * obj_height)\n",
    "        if match > best_match[1]:\n",
    "            best_match = (template_name, match)\n",
    "    print(\"Best match: %d%%\" % (best_match[1]*100))\n",
    "    print(\"Template name: %s\" % best_match[0])\n",
    "    return best_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc47db23",
   "metadata": {},
   "outputs": [],
   "source": [
    "org_image = load_image(\"test_images/staff-with-notes.jpg\")\n",
    "img_gray = image_gray(org_image)\n",
    "img_otsu = image_bin_otsu(img_gray)\n",
    "inv_img = invert(img_otsu)\n",
    "img_wo_lines = remove_lines(inv_img)\n",
    "display_image(img_wo_lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc574cee",
   "metadata": {},
   "source": [
    "We find the vertical objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0febf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_vert_lines = find_vertical_lines(inv_img)\n",
    "display_image(img_vert_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c6d82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_vert_objects, regions = find_vertical_objects(img_wo_lines, img_vert_lines)\n",
    "display_image(img_vert_objects)\n",
    "print(\"Number of recognized objects: %s\" % len(regions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96acd1b6",
   "metadata": {},
   "source": [
    "Let's find and remove the G-clef."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078675ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.clock()\n",
    "for note in objects:\n",
    "    match_object(note, templates)\n",
    "end = time.clock()\n",
    "print(\"Elapsed time: %ss\" % (end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b084392",
   "metadata": {},
   "source": [
    "Once again, this example is limited to finding only one note head. It won't work if the segmented object represents two eighth notes connected or a chord with noteheads on top of each other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d61c5d3",
   "metadata": {},
   "source": [
    "### Method B: Stemless noteheads"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dff9ffb",
   "metadata": {},
   "source": [
    "Another way is to remove the stems, and concentrate only on note heads.\n",
    "\n",
    "This way templates can be resized to fit the segmented note heads. However, this would still be a problem if there are more than one note head on top of the other, and instead of recognizing each of them, we would recognize them as one.\n",
    "\n",
    "So, we will remove the stems, but must improve the algorithm to recognize multiple note heads. But let's do it one step at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11376590",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_stemless = img_vert_objects.copy()\n",
    "for row in range(len(img_stemless)):\n",
    "    for col in range(len(img_stemless[row])):\n",
    "        if img_vert_lines[row,col] == 255:\n",
    "            img_stemless[row,col] = 0\n",
    "display_image(img_stemless)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06f74e8",
   "metadata": {},
   "source": [
    "Now we find the regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea1a9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "img, regions = find_regions(img_stemless)\n",
    "display_image(img)\n",
    "print(\"Number of recognized regions: %s\" % len(regions))\n",
    "print(\"False regions:\")\n",
    "for region in regions:\n",
    "    if len(region) < 10:\n",
    "        print region"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a2d44b",
   "metadata": {},
   "source": [
    "Since there are more regions than we need, because of the tiny spots and freckles, we will morphologically open the image to remove them. And we'll do that with a circle (ellipse, diamond) shaped kernel, with a size of 1/4 staff spacing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1cc72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(staff_spacing / 4.)\n",
    "y,x = np.ogrid[-n : n +1, -n : n+1]\n",
    "mask = x*x+y*y <= n*n\n",
    "kernel = np.zeros((len(mask), len(mask)))\n",
    "kernel[mask] = 1\n",
    "kernel = np.uint8(kernel)\n",
    "img_stemless = open_image(img_stemless, kernel)\n",
    "img, regions = find_regions(img_stemless)\n",
    "display_image(img)\n",
    "print(\"Number of recognized regions: %s\" % len(regions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97835c36",
   "metadata": {},
   "source": [
    "We split the image into smaller images that contain only the heads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db4fbfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "objects = split_image(img_stemless, regions)\n",
    "print(\"First note head\")\n",
    "display_image(objects[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b4c422",
   "metadata": {},
   "source": [
    "And perform the template matching for each note head."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6575508",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.clock()\n",
    "for note in objects:\n",
    "    match_object(note, templates)\n",
    "end = time.clock()\n",
    "print(\"Elapsed time: %ss\" % (end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1dae7d",
   "metadata": {},
   "source": [
    "We got slightly better results and we got them much faster.\n",
    "\n",
    "However the algorithm still recognizes only one note head in segmented image, so we'll have to improve the algorithm. This can be done by segmenting regions on and between staff lines."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ea4d3c",
   "metadata": {},
   "source": [
    "### Method C: Line-by-line Segmentation\n",
    "We'll take the stemless image and split it into several sub images. Each sub-image will contain regions on each staff line or in each staff spacing, if there are any. We'll even take small parts above the highest staff line and below the lowest one."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd55cf6",
   "metadata": {},
   "source": [
    "First, we find the highest and the lowest regions of stemless image. We won't use this now, but it's good to mention it here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b587a420",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxy = 0\n",
    "miny = len(img_stemless)\n",
    "lowest_region = None\n",
    "highest_region = None\n",
    "for region in regions:\n",
    "    for r,c in region:\n",
    "        if r > maxy:\n",
    "            maxy = r\n",
    "            lowest_region = region\n",
    "        if r < miny:\n",
    "            miny = r\n",
    "            highest_region = region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247ef5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if any([ r == lines[0][0] or r > lines[0][0] for r,c in highest_region]):\n",
    "    print(\"Highest region is either around the highest staff line or under it!\")\n",
    "else:\n",
    "    print(\"Highest region is above the highest staff line!\")\n",
    "if any([ r == lines[-1][-1] or r < lines[-1][-1] for r,c in lowest_region]):\n",
    "    print(\"Lowest region is either around the lowest staff line or above it!\")\n",
    "else:\n",
    "    print(\"Highest region is below the lowest staff line!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9951a9b8",
   "metadata": {},
   "source": [
    "Now we split the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412046f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "two_thirds_spacing = round(staff_spacing * 2. / 3)\n",
    "from collections import OrderedDict\n",
    "sub_images = OrderedDict()\n",
    "for i in range(len(lines)):\n",
    "    if i == 0:\n",
    "        sub_images[\"Above Line %s\" % (i + 1)] = img_stemless[lines[i][0] - int(staff_spacing) - len(lines[i]) : lines[i][-1]]\n",
    "    sub_images[\"On Line %s\" % (i + 1)] = img_stemless[lines[i][0] -  int (two_thirds_spacing) : lines[i][-1] + int(two_thirds_spacing)]\n",
    "    if i + 1 < len(lines):\n",
    "        sub_images[\"Below Line %s\" % (i + 1)] = img_stemless[lines[i][0] : lines[i + 1][-1]]\n",
    "    else:\n",
    "        sub_images[\"Below Line %s\" % (i + 1)] = img_stemless[lines[i][0] : lines[i][-1] + int(staff_spacing) + len(lines[i])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e3e302",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, image in sub_images.items():\n",
    "    print(key)\n",
    "    display_image(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acdf6b80",
   "metadata": {},
   "source": [
    "And now we can template match each sub image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c815c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.clock()\n",
    "for key, sub_image in sub_images.items():\n",
    "    print(key)\n",
    "    match_object(sub_image, templates)\n",
    "end = time.clock()\n",
    "print(\"Elapsed time: %ss\" % (end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da34e1f",
   "metadata": {},
   "source": [
    "In previous example we used sliding windows through each sub-image. However, using techniques from Method B, we can further split the images and reduce the time needed to find the notes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ea9d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.clock()\n",
    "for key, sub_image in sub_images.items():\n",
    "    print(key)\n",
    "    img, regions = find_regions(sub_image)\n",
    "    objects = split_image(img, regions)\n",
    "    for obj in objects:\n",
    "        match_object(obj, templates)\n",
    "end = time.clock()\n",
    "print(\"Elapsed time: %ss\" % (end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce30b4a6",
   "metadata": {},
   "source": [
    "There you go! We significantly reduced time needed and found every note head."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4068f62",
   "metadata": {},
   "source": [
    "### Half node heads\n",
    "Now we can focus on empty note heads, such as half notes and whole notes. Though, we will focus only on half notes, as they are vertical objects (because of their stems), while whole notes aren't."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84203b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "org_image = load_image(\"test_images/noteheads.jpg\")\n",
    "img_gray = image_gray(org_image)\n",
    "img_otsu = image_bin_otsu(img_gray)\n",
    "inv_img = invert(img_otsu)\n",
    "img_wo_lines = remove_lines(inv_img, topBotPixelRemoval = True, widthBasedRemoval = False)\n",
    "display_image(img_wo_lines)\n",
    "lines, distances, staff_spacing = find_lines(inv_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb284418",
   "metadata": {},
   "source": [
    "Note that I used only Method A for staff lines removal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97d2b0d",
   "metadata": {},
   "source": [
    "Now, we can't morphologically open the image with same kernel as previous time, because it will break the half note head."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a63a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "two_thirds_spacing = round(staff_spacing * 2. / 3)\n",
    "from collections import OrderedDict\n",
    "sub_images = OrderedDict()\n",
    "for i in range(len(lines)):\n",
    "    if i == 0:\n",
    "        sub_images[\"Above Line %s\" % (i + 1)] = img_stemless[lines[i][0] - int(staff_spacing) - len(lines[i]) : lines[i][-1]]\n",
    "    sub_images[\"On Line %s\" % (i + 1)] = img_stemless[lines[i][0] -  int (two_thirds_spacing) : lines[i][-1] + int(two_thirds_spacing)]\n",
    "    if i + 1 < len(lines):\n",
    "        sub_images[\"Below Line %s\" % (i + 1)] = img_stemless[lines[i][0] : lines[i + 1][-1]]\n",
    "    else:\n",
    "        sub_images[\"Below Line %s\" % (i + 1)] = img_stemless[lines[i][0] : lines[i][-1] + int(staff_spacing) + len(lines[i])]\n",
    "for key, image in sub_images.items():\n",
    "    print(key)\n",
    "    display_image(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994cfd63",
   "metadata": {},
   "outputs": [],
   "source": [
    "note_heads_templates = search_for_templates(\"note_heads\")\n",
    "templates = {}\n",
    "for templateName in note_heads_templates:\n",
    "    template = load_image(templateName)\n",
    "    template = resize_image(template,staff_spacing,staff_spacing)\n",
    "    template = image_gray(template)\n",
    "    template = image_bin_otsu(template)\n",
    "    template = invert(template)\n",
    "    templates[templateName] = template"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd65785",
   "metadata": {},
   "source": [
    "We'll check only \"On Line 4\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61feb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"On Line 4\")\n",
    "img, regions = find_regions(sub_images[\"On Line 4\"])\n",
    "objects = split_image(img, regions)\n",
    "for obj in objects:\n",
    "    display_image(obj)\n",
    "    match_object(obj, templates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70de18b4",
   "metadata": {},
   "source": [
    "As you can see, it's a bit harder to recognize empty note head, than filled note head. However, even if you don't recognize it this way, you can template match it with the note AND stem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759ca9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isdir\n",
    "g_clef_templates = []\n",
    "\n",
    "vertFile = \"clefs/g_clef\"\n",
    "split = vertFile.split('/')\n",
    "for listedFile in listdir(\"templates\"):\n",
    "    if listedFile == split[0]:\n",
    "        for innerFile in listdir(\"templates/%s\" % listedFile):\n",
    "            if len(split) == 1 or innerFile.startswith(split[1]):\n",
    "                g_clef_templates += [\"templates/%s/%s\" % (listedFile, innerFile)]\n",
    "\n",
    "print(g_clef_templates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41835b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "objects = split_image(img_vert_objects, regions)\n",
    "        \n",
    "best_obj = (None, (None, 0))\n",
    "best_index = None\n",
    "for i in range(len(objects)):\n",
    "    obj = objects[i]\n",
    "    match = match_clef(obj, g_clef_templates)\n",
    "    if match[1] > best_obj[1][1]:\n",
    "        best_obj = (obj, match)\n",
    "        best_index = i\n",
    "display_image(best_obj[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43dd0d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "for r,c in regions[best_index]:\n",
    "    img_vert_objects[r][c] = 0\n",
    "display_image(img_vert_objects)\n",
    "regions.remove(regions[best_index])\n",
    "objects.remove(objects[best_index])\n",
    "print(len(regions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e55ef5",
   "metadata": {},
   "source": [
    "## Note heads\n",
    "In this section we will try to recognize note heads.\n",
    "\n",
    "### Filled note heads\n",
    "While researching and experimenting with this part of the project I found out several different methods, each representing an improvement of the previous one."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf2a7f8",
   "metadata": {},
   "source": [
    "First, let's load the templates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8b3820",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_for_templates(vertFile):\n",
    "    templates = []\n",
    "    split = vertFile.split('/')\n",
    "    for listedFile in listdir(\"templates\"):\n",
    "        if listedFile == split[0]:\n",
    "            for innerFile in listdir(\"templates/%s\" % listedFile):\n",
    "                if len(split) == 1 or innerFile.startswith(split[1]):\n",
    "                    templates += [\"templates/%s/%s\" % (listedFile, innerFile)]\n",
    "    return templates\n",
    "\n",
    "filled_head_templates = search_for_templates(\"note_heads/filled\")\n",
    "print(filled_head_templates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe73365",
   "metadata": {},
   "source": [
    "Load template images and resize them so they fit the staff spacing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d10250",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines, distances, staff_spacing = find_lines(inv_img)\n",
    "print(staff_spacing)\n",
    "templates = {}\n",
    "for templateName in filled_head_templates:\n",
    "    template = load_image(templateName)\n",
    "    template = resize_image(template,staff_spacing,staff_spacing)\n",
    "    template = image_gray(template)\n",
    "    template = image_bin_otsu(template)\n",
    "    template = invert(template)\n",
    "    templates[templateName] = template"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b6a20d",
   "metadata": {},
   "source": [
    "### Method A: Search through whole regions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a518cd98",
   "metadata": {},
   "source": [
    "Using this method, we take each segmented object (region) and search through it to find the note head(s). This is dones using the sliding window technique. Example is given below, used only on first segmented object and searching for only one candidate for filled note head."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c620cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "note = objects[0]\n",
    "object_height, object_width = note.shape[:2]\n",
    "best_match = (None,(0,0),0)\n",
    "for templateName, template in templates.items():\n",
    "    print(\"Template matching: %s\" % templateName)\n",
    "    match_matrix = []\n",
    "    for row in range(object_height - len(template)):\n",
    "        match_matrix.append([])\n",
    "        for col in range(object_width - len(template[0])):\n",
    "            match = 0\n",
    "            for r in range(len(template)):\n",
    "                for c in range(len(template[r])):\n",
    "                    match += 1 if note[row + r ][col + c] == template[r][c] else 0\n",
    "            match *= 1./(len(template) * len(template[0]))\n",
    "            \n",
    "            match_matrix[-1] += [match]\n",
    "            if match > best_match[2]:\n",
    "                best_match = (templateName,(row,col),match)\n",
    "                \n",
    "# Normalize\n",
    "print(\"best match: %d%%\" % (best_match[2]*100))\n",
    "print(\"templateName: %s\" % best_match[0])\n",
    "print(\"rows: %s - %s\" % (best_match[1][0], best_match[1][0] + len(templates[best_match[0]])))\n",
    "print(\"cols: %s - %s\" % (best_match[1][1], best_match[1][1] + len(templates[best_match[0]][0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bcd19e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = templates[best_match[0]]\n",
    "print(\"Segmented object:\")\n",
    "display_image(note)\n",
    "recognized_part = note[best_match[1][0]:][best_match[1][1]:best_match[1][1] + len(templates[best_match[0]][0])]\n",
    "print(\"Note head of segmented object:\")\n",
    "display_image(recognized_part)\n",
    "print(\"height of segment: %s, width of segment: %s\" % (len(recognized_part), len(recognized_part[0])))\n",
    "print(\"\")\n",
    "print(\"Best match template:\")\n",
    "display_image(template)\n",
    "print(\"height of template: %s, width of template: %s\" % (len(template), len(template[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8ebaba",
   "metadata": {},
   "source": [
    "We will try to match all the other segmented notes as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d41105",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_object(note, templates):\n",
    "    object_height, object_width = note.shape[:2]\n",
    "    best_match = (None,(0,0),0)\n",
    "    for templateName, template in templates.items():\n",
    "        match_matrix = []\n",
    "        for row in range(object_height - len(template) + 1):\n",
    "            match_matrix.append([])\n",
    "            for col in range(object_width - len(template[0]) + 1):\n",
    "                match = 0\n",
    "                for r in range(len(template)):\n",
    "                    for c in range(len(template[r])):\n",
    "                        match += 1 if note[row + r ][col + c] == template[r][c] else 0\n",
    "                match *= 1./(len(template) * len(template[0]))\n",
    "\n",
    "                match_matrix[-1] += [match]\n",
    "                if match > best_match[2]:\n",
    "                    best_match = (templateName,(row,col),match)\n",
    "\n",
    "    if best_match[0] is None:\n",
    "        print(\"NO MATCH!\")\n",
    "    else:\n",
    "        print(\"best match: %d%%\" % (best_match[2]*100))\n",
    "        print(\"templateName: %s\" % best_match[0])\n",
    "        print(\"rows: %s - %s\" % (best_match[1][0], best_match[1][0] + len(templates[best_match[0]])))\n",
    "        print(\"cols: %s - %s\" % (best_match[1][1], best_match[1][1] + len(templates[best_match[0]][0])))"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
