{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68668015",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,4))\n",
    "sns.kdeplot(train_df['NumberOfDependents'])\n",
    "plt.title('Plot of Number of Dependents')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xlabel('Number of Dependents')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f7fbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_dep = train_df[train_df['NumberOfDependents'] == 20]\n",
    "train_df.drop(outlier_dep.index, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7a77f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Mean: ', train_df['NumberOfDependents'].mean())\n",
    "print ('Median: ', train_df['NumberOfDependents'].median())\n",
    "print ('Std Dev: ', np.std(train_df['NumberOfDependents']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171fc1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check age vs number of dependepnts\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.boxplot(x='NumberOfDependents', y='age', data=train_df)\n",
    "plt.title('Plot of No. Of Dependents vs Age')\n",
    "\n",
    "# sns.jointplot(x='NumberOfDependents', y='age', data=train_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed3fe23",
   "metadata": {},
   "source": [
    "We can infer that as a customer age, the number of dependents would increase."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff540c15",
   "metadata": {},
   "source": [
    "### Monthly Income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19185a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['MonthlyIncome'].plot(kind='box')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45bc0096",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df.drop(['age_band', 'MonthlyIncome'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6d046a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e988a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# looking at the distribution of the monthly income of sample before removing outliers\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "sns.kdeplot(train_df['MonthlyIncome_1'])\n",
    "plt.title('Plot of Monthly Income Before Outliers Removal')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xlabel('Monthly Income')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad69381",
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Mean: ', train_df['MonthlyIncome_1'].mean())\n",
    "print ('Median: ', train_df['MonthlyIncome_1'].median())\n",
    "print ('Std Dev: ', np.std(train_df['MonthlyIncome_1']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a07f34",
   "metadata": {},
   "source": [
    "We will remove those rows that have more than 3 std dev from the median."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29c6e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_up = RandomForestClassifier()\n",
    "\n",
    "param = {'criterion':['gini'],\n",
    "              'n_estimators': [30, 40, 50, 100, 150],\n",
    "             'max_depth':[10, 15]}\n",
    "\n",
    "   \n",
    "#fit gridsearch with model, param_grid, cv_itr\n",
    "grid_rfc_up = GridSearchCV(rfc_up, param, verbose=2, cv=10)\n",
    "\n",
    "# fit model\n",
    "grid_rfc_up.fit(Xs_train_up, y_train_up)\n",
    "\n",
    "grid_rfc_up.best_params_\n",
    "model_rfc_gs_up = grid_rfc_up.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ca674f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# score model\n",
    "score_rfc_gs_up = model_rfc_gs_up.score(Xs_test_up, y_test)\n",
    "\n",
    "print ('Score: {}' .format(score_rfc_gs_up), '\\n')\n",
    "\n",
    "\n",
    "pred_rfc_gs_up = model_rfc_gs_up.predict(Xs_test_up)\n",
    "\n",
    "print (classification_print, '\\n')\n",
    "print ('Classification report: \\n', classification_report(y_test, pred_rfc_gs_up), '\\n')\n",
    "print (cm_print, '\\n')\n",
    "\n",
    "cm_rfc_gs_up = confusion_matrix(y_test, pred_rfc_gs_up)\n",
    "\n",
    "plot_confusion_matrix(cm_rfc_gs_up, classes)\n",
    "\n",
    "\n",
    "# Plotting AUC Curve\n",
    "\n",
    "model_performance(model_rfc_gs_up, Xs_test_up, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0ba020",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking for features\n",
    "\n",
    "feat = []\n",
    "for feature in zip(X_train.columns.values, model_rfc_gs_up.feature_importances_):\n",
    "    feat.append(feature)\n",
    "    \n",
    "feat_df_rfc_up = pd.DataFrame(feat, columns=['Feature', 'Value'])\n",
    "feat_df_rfc_up.sort_values('Value', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2bf76c",
   "metadata": {},
   "source": [
    "#### RFC Downsampled GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c0c6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_ds = RandomForestClassifier()\n",
    "\n",
    "param = {'criterion':['gini'],\n",
    "              'n_estimators': [30, 40, 50, 100, 150],\n",
    "             'max_depth':[10, 15]\n",
    "        }\n",
    "\n",
    "    \n",
    "#fit gridsearch with model, param_grid, cv_itr\n",
    "grid_rfc_ds = GridSearchCV(rfc_ds, param, verbose=2, cv=10)\n",
    "\n",
    "# fit model\n",
    "grid_rfc_ds.fit(Xs_train_ds, y_train_ds)\n",
    "\n",
    "grid_rfc_ds.best_params_\n",
    "model_rfc_gs_ds = grid_rfc_ds.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3f4ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# score model\n",
    "score_rfc_gs_ds = model_rfc_gs_ds.score(Xs_test_ds, y_test)\n",
    "\n",
    "print ('Score: {}' .format(score_rfc_gs_ds), '\\n')\n",
    "\n",
    "\n",
    "pred_rfc_gs_ds = model_rfc_gs_ds.predict(Xs_test_ds)\n",
    "\n",
    "print (classification_print, '\\n')\n",
    "print ('Classification report: \\n', classification_report(y_test, pred_rfc_gs_ds), '\\n')\n",
    "print (cm_print, '\\n')\n",
    "\n",
    "cm_rfc_gs_ds = confusion_matrix(y_test, pred_rfc_gs_ds)\n",
    "\n",
    "plot_confusion_matrix(cm_rfc_gs_ds, classes)\n",
    "\n",
    "\n",
    "# Plotting AUC Curve\n",
    "\n",
    "model_performance(model_rfc_gs_ds, Xs_test_ds, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2289645d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking for features\n",
    "\n",
    "feat = []\n",
    "for feature in zip(X_train.columns.values, model_rfc_gs_ds.feature_importances_):\n",
    "    feat.append(feature)\n",
    "    \n",
    "feat_df_rfc_ds = pd.DataFrame(feat, columns=['Feature', 'Value'])\n",
    "feat_df_rfc_ds.sort_values('Value', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5ac8cb",
   "metadata": {},
   "source": [
    "### MLP Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7feffdf9",
   "metadata": {},
   "source": [
    "#### MLP Classifier Upsampled GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14733d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining model and params\n",
    "\n",
    "mlpc = MLPClassifier(hidden_layer_sizes=(50, 50, 50), activation='relu')\n",
    "# mlpc.fit(Xs_train_up, y_train_up)\n",
    "\n",
    "\n",
    "# param_grid_lr_gs = {'penalty':['l1', 'l2'],\n",
    "#                     'C': [0.0001, 0.001, 0.01, 0.1, 1, 10]\n",
    "#                    }\n",
    "\n",
    "param = {'alpha':[0.0001, 0.001, 0.01, 1],\n",
    "         'solver': ['lbfgs', 'adam']\n",
    "        }\n",
    "    \n",
    "# fit gridsearch with model, param_grid, cv_tir\n",
    "grid_mlpc_gs = GridSearchCV(mlpc, param, verbose=2, cv=5)\n",
    "\n",
    "#fit model\n",
    "grid_mlpc_gs.fit(Xs_train_up, y_train_up)\n",
    "\n",
    "# get best param\n",
    "grid_mlpc_gs.best_params_\n",
    "model_mlpc_gs = grid_mlpc_gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db9d2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# score model\n",
    "score_mlpc_gs_up = model_mlpc_gs.score(Xs_test_up, y_test)\n",
    "\n",
    "print ('Score: {}' .format(score_mlpc_gs_up), '\\n')\n",
    "\n",
    "\n",
    "pred_mlpc_gs_up = model_mlpc_gs.predict(Xs_test_up)\n",
    "\n",
    "print (classification_print, '\\n')\n",
    "print ('Classification report: \\n', classification_report(y_test, pred_mlpc_gs_up), '\\n')\n",
    "print (cm_print, '\\n')\n",
    "\n",
    "cm_mlpc_gs_up = confusion_matrix(y_test, pred_mlpc_gs_up)\n",
    "\n",
    "plot_confusion_matrix(cm_mlpc_gs_up, classes)\n",
    "\n",
    "\n",
    "# Plotting AUC Curve\n",
    "\n",
    "model_performance(model_mlpc_gs, Xs_test_up, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2809ee27",
   "metadata": {},
   "source": [
    "#### MLP Classifier Downsampled GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d878e078",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_dev = 3\n",
    "lower_limit = train_df['MonthlyIncome_1'].median() - (std_dev * np.std(train_df['MonthlyIncome_1']))\n",
    "upper_limit = train_df['MonthlyIncome_1'].median() + (std_dev * np.std(train_df['MonthlyIncome_1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e480b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing outliers based on Monthly Income.\n",
    "\n",
    "outlier_income = train_df[train_df['MonthlyIncome_1'] > upper_limit]\n",
    "train_df.drop(outlier_income.index, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01dad2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# looking at the distribution of the monthly income of sample after removing outliers\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "sns.kdeplot(train_df['MonthlyIncome_1'])\n",
    "plt.title('Plot of Monthly Income After Outliers Removal')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xlabel('Monthly Income')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dfc54d7",
   "metadata": {},
   "source": [
    "We observe that the distribution of income is slightly skewed to the right. We will further investigate the Monthly Income of customers against Number of Dependents. <br>In theory, the higher the number of dependents, the more income a customer would require."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13e2088",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,6))\n",
    "sns.violinplot(x='NumberOfDependents', y='MonthlyIncome_1', hue='SeriousDlqin2yrs', data=train_df)\n",
    "plt.title('Plot of Monthly Income vs No. of Dependents')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748c1c67",
   "metadata": {},
   "source": [
    "Based on the plot above, we observe that a customers who are prone to deliquent in 2 years generally have lesser monthly income compared to their counterparts in the same no. of dependents spectrum. <br>\n",
    "We also observe that generally, the higher the number of dependents, the higher the income of the person by looking at the violin plot above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df407dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (y_test.value_counts())\n",
    "print ('0: ', y_test.value_counts()[0] / len(train_df))\n",
    "print ('1: ', y_test.value_counts()[1] / len(train_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a01240e",
   "metadata": {},
   "source": [
    "### Upsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa071c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = pd.concat([X_train, y_train], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b93de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "# Separate majority and minority classes\n",
    "df_majority = temp_df[temp_df['SeriousDlqin2yrs'] == 0]\n",
    "df_minority = temp_df[temp_df['SeriousDlqin2yrs'] == 1]\n",
    " \n",
    "# Upsample minority class\n",
    "df_minority_upsampled = resample(df_minority, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=y_train.value_counts()[0],    # to match majority class\n",
    "                                 random_state=123) # reproducible results\n",
    " \n",
    "# Combine majority class with upsampled minority class\n",
    "temp_upsampled = pd.concat([df_majority, df_minority_upsampled])\n",
    " \n",
    "# Display new class counts\n",
    "temp_upsampled.SeriousDlqin2yrs.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1f038f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_up = temp_upsampled.drop('SeriousDlqin2yrs', axis=1)\n",
    "y_train_up = temp_upsampled['SeriousDlqin2yrs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d9d194",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss_up = StandardScaler()\n",
    "\n",
    "# standard scaling for X_train and X_test\n",
    "ss_up.fit(X_train_up)\n",
    "Xs_train_up = ss_up.transform(X_train_up)\n",
    "\n",
    "Xs_test_up = ss_up.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4baa9e7",
   "metadata": {},
   "source": [
    "### Downsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26f43a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate majority and minority classes\n",
    "df_majority_ds = temp_df[temp_df['SeriousDlqin2yrs'] == 0]  # for ref\n",
    "df_minority_ds = temp_df[temp_df['SeriousDlqin2yrs'] == 1]  # for ref\n",
    " \n",
    "# Downsample majority class\n",
    "df_majority_downsampled = resample(df_majority_ds, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=y_train.value_counts()[1],    # to match majority class\n",
    "                                 random_state=123) # reproducible results\n",
    " \n",
    "# Combine majority class with upsampled minority class\n",
    "temp_downsampled = pd.concat([df_minority_ds, df_majority_downsampled])\n",
    " \n",
    "# Display new class counts\n",
    "temp_downsampled.SeriousDlqin2yrs.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b781e565",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ds = temp_downsampled.drop('SeriousDlqin2yrs', axis=1)\n",
    "y_train_ds = temp_downsampled['SeriousDlqin2yrs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076de78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss_ds = StandardScaler()\n",
    "\n",
    "# standard scaling for X_train and X_test\n",
    "ss_ds.fit(X_train_ds)\n",
    "Xs_train_ds = ss_ds.transform(X_train_ds)\n",
    "\n",
    "Xs_test_ds = ss_ds.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2e14d9",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4b17c6",
   "metadata": {},
   "source": [
    "### Functions for modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2baeec4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_print = ('-'* 20 + 'Classification Report' + '-'*20)\n",
    "cm_print = ('-'* 20 + 'Confusion Matrix' + '-'*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b7219a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUC Plot Function\n",
    "\n",
    "# write function to get model performance\n",
    "def model_performance(model, X_test, y_test):\n",
    "#     model.fit(X_train_q2, y_train_q2)\n",
    "    Y_pp = pd.DataFrame(model.predict_proba(X_test), columns=['class_0_pp','class_1_pp'])\n",
    "    # roc, auc for model for common performance measurement\n",
    "    \n",
    "    # For class 1, find the area under the curve.\n",
    "    fpr, tpr, _ = roc_curve(y_test, Y_pp.class_1_pp)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    # Plot of a ROC curve.\n",
    "    plt.figure(figsize=[4,4])\n",
    "    plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc, linewidth=4)\n",
    "    plt.plot([0, 1], [0, 1], 'k--', linewidth=4)\n",
    "    plt.xlim([-0.05, 1.0])\n",
    "    plt.ylim([-0.05, 1.05])\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.title('Receiver operating characteristic for Model', fontsize=18)\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "    print ('Auc:',roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ccaf87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix Function\n",
    "\n",
    "classes = set(y_train)\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be115415",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1bedae6",
   "metadata": {},
   "source": [
    "#### Bernoulli Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e038fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(class_weight='balanced')\n",
    "\n",
    "\n",
    "bnb = BernoulliNB()\n",
    "\n",
    "\n",
    "# 10-Fold Cross validation\n",
    "print ('Cross-Val Score: ', np.mean(cross_val_score(bnb, Xs_train, y_train, cv=10)))\n",
    "\n",
    "\n",
    "\n",
    "# fitting the model\n",
    "bnb.fit(Xs_train, y_train)    \n",
    "score_model = bnb.score(Xs_test, y_test)\n",
    "\n",
    "\n",
    "# print score of model\n",
    "print ('Score: {}' .format(score_model), '\\n')\n",
    "\n",
    "\n",
    "# predicting model\n",
    "predict_model = bnb.predict(Xs_test)\n",
    "\n",
    "\n",
    "print (classification_print, '\\n')\n",
    "print ('Classification report: \\n', classification_report(y_test, predict_model), '\\n')\n",
    "print (cm_print, '\\n')\n",
    "\n",
    "cm_model = confusion_matrix(y_test, predict_model)\n",
    "\n",
    "\n",
    "plot_confusion_matrix(cm_model, classes)\n",
    "\n",
    "# plotting AUC Curve\n",
    "model_performance(bnb, Xs_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0190def3",
   "metadata": {},
   "source": [
    "#### NB - Upsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60f27bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "bnb_gs_up = BernoulliNB()\n",
    "\n",
    "param = {'alpha':[0.001, 0.01, 1, 10]}\n",
    " \n",
    "grid_gs_bnb_up = GridSearchCV(bnb_gs_up, param, verbose=2, cv=10)\n",
    "\n",
    "# fit model\n",
    "grid_gs_bnb_up.fit(Xs_train_up, y_train_up)\n",
    "\n",
    "grid_gs_bnb_up.best_params_\n",
    "model_gs_bnb_up = grid_gs_bnb_up.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb349cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# score model\n",
    "score_gs_bnb_up = model_gs_bnb_up.score(Xs_test_up, y_test)\n",
    "\n",
    "print ('Score: {}' .format(score_gs_bnb_up), '\\n')\n",
    "\n",
    "\n",
    "pred_gs_bnb_up = model_gs_bnb_up.predict(Xs_test_up)\n",
    "\n",
    "print (classification_print, '\\n')\n",
    "print ('Classification report: \\n', classification_report(y_test, pred_gs_bnb_up), '\\n')\n",
    "print (cm_print, '\\n')\n",
    "\n",
    "cm_gs_bnb_up = confusion_matrix(y_test, pred_gs_bnb_up)\n",
    "\n",
    "plot_confusion_matrix(cm_gs_bnb_up, classes)\n",
    "\n",
    "\n",
    "# Plotting AUC Curve\n",
    "model_performance(model_gs_bnb_up, Xs_test_up, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e727ae7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the features\n",
    "\n",
    "gs_bnb_coef = [item for sublist in model_gs_bnb_up.coef_ for item in sublist]\n",
    "feat = []\n",
    "for feature in zip(list(X_train.columns.values), gs_bnb_coef):\n",
    "    feat.append(feature)\n",
    "    \n",
    "feat_df_bnb = pd.DataFrame(feat, columns=['Feature', 'Coef'])\n",
    "feat_df_bnb.sort_values('Coef', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f04fcf",
   "metadata": {},
   "source": [
    "#### NB Downsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40999047",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For GridSearch Downsampling\n",
    "\n",
    "bnb_gs_ds = BernoulliNB()\n",
    "\n",
    "param = {'alpha':[0.001, 0.01, 1, 10]}\n",
    " \n",
    "\n",
    "grid_bnb_ds = GridSearchCV(bnb_gs_ds, param, verbose=1, cv=10)\n",
    "\n",
    "# fit model\n",
    "grid_bnb_ds.fit(Xs_train_ds, y_train_ds)\n",
    "\n",
    "grid_bnb_ds.best_params_\n",
    "model_bnb_gs_ds = grid_bnb_ds.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23187850",
   "metadata": {},
   "outputs": [],
   "source": [
    "# score model\n",
    "score_gs_bnb_ds = model_bnb_gs_ds.score(Xs_test_ds, y_test)\n",
    "\n",
    "print ('Score: {}' .format(score_gs_bnb_ds), '\\n')\n",
    "\n",
    "\n",
    "pred_bnb_gs_ds = model_bnb_gs_ds.predict(Xs_test_ds)\n",
    "\n",
    "print (classification_print, '\\n')\n",
    "print ('Classification report: \\n', classification_report(y_test, pred_bnb_gs_ds), '\\n')\n",
    "print (cm_print, '\\n')\n",
    "\n",
    "cm_bnb_gs_ds = confusion_matrix(y_test, pred_bnb_gs_ds)\n",
    "\n",
    "plot_confusion_matrix(cm_bnb_gs_ds, classes)\n",
    "\n",
    "\n",
    "# Plotting AUC Curve\n",
    "\n",
    "model_performance(model_bnb_gs_ds, Xs_test_ds, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e0357e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the features\n",
    "\n",
    "gs_bnb_ds_coef = [item for sublist in model_bnb_gs_ds.coef_ for item in sublist]\n",
    "feat = []\n",
    "for feature in zip(list(X_train.columns.values), gs_bnb_ds_coef):\n",
    "    feat.append(feature)\n",
    "    \n",
    "feat_df_bnb_ds = pd.DataFrame(feat, columns=['Feature', 'Coef'])\n",
    "feat_df_bnb_ds.sort_values('Coef', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936b4621",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd07715d",
   "metadata": {},
   "source": [
    "#### Logistic Regression CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dfb7628",
   "metadata": {},
   "outputs": [],
   "source": [
    "lrcv = LogisticRegressionCV(class_weight='balanced', cv=10, penalty='l2', solver='liblinear') #liblinear\n",
    "\n",
    "#fit model\n",
    "lrcv.fit(Xs_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810806de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# score model\n",
    "score_lrcv = lrcv.score(Xs_test, y_test)\n",
    "\n",
    "print ('Accuracy Score: {}' .format(score_lrcv), '\\n')\n",
    "\n",
    "# predict\n",
    "pred_lrcv = lrcv.predict(Xs_test)\n",
    "\n",
    "cm_lrcv = confusion_matrix(y_test, pred_lrcv)\n",
    "\n",
    "print (classification_print, '\\n')\n",
    "\n",
    "print ('Classification report: \\n', classification_report(y_test, pred_lrcv), '\\n')\n",
    "\n",
    "print (cm_print, '\\n')\n",
    "\n",
    "plot_confusion_matrix(cm_lrcv, classes)\n",
    "\n",
    "\n",
    "# Plotting AUC Curve\n",
    "model_performance(lrcv, Xs_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f64c583",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the features\n",
    "\n",
    "lrcv_coef = [item for sublist in lrcv.coef_ for item in sublist]\n",
    "feat = []\n",
    "for feature in zip(list(X_train.columns.values), lrcv_coef):\n",
    "    feat.append(feature)\n",
    "    \n",
    "feat_df_rfc = pd.DataFrame(feat, columns=['Feature', 'Coef'])\n",
    "feat_df_rfc.sort_values('Coef', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba429a29",
   "metadata": {},
   "source": [
    "#### Logistic Regression GridSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba701775",
   "metadata": {},
   "source": [
    "### Target Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e3a21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# understanding the target variable\n",
    "\n",
    "train_df['SeriousDlqin2yrs'].value_counts()\n",
    "\n",
    "print ('0: ', train_df['SeriousDlqin2yrs'].value_counts()[0] / len(train_df)*100)\n",
    "print ('1: ', train_df['SeriousDlqin2yrs'].value_counts()[1] / len(train_df)*100)\n",
    "\n",
    "sns.countplot(train_df['SeriousDlqin2yrs'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bec203d",
   "metadata": {},
   "source": [
    "We see that there is an imbalance class in our target variable. We will need to handle this imbalance class issue by either upsampling, downsampling or selecting class_weight: balance (Logistic Regression and Random Forest)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e4b1cd",
   "metadata": {},
   "source": [
    "### Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2e3cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking for any abnormality in age\n",
    "\n",
    "train_df.age.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fbb6320",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[train_df['age'] == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b67c39",
   "metadata": {},
   "source": [
    "We will be removing row index 65695 as the age could have been inputted with error at age: 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d333edb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping row as it could be entered in error\n",
    "\n",
    "train_df.drop(65695, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395f310d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['age'].plot(kind='box')\n",
    "plt.title('Boxplot of Age of customers')\n",
    "plt.ylabel('Count')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47969dd3",
   "metadata": {},
   "source": [
    "We can see that there are a handful of outliers in the box plot above. These outliers will not be removed now, till we further explore our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20766fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "age_band_order = ['21 to 30', '31 to 40', '41 to 50', '51 to 60', '61 to 70', '71 to 80', '81 to 90',\n",
    "                 '91 to 100', '100 to 110']\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.stripplot(x='age_band_1', y='NumberRealEstateLoansOrLines', data=train_df, order=age_band_order)\n",
    "plt.title('Plot of No. of Real Estate Loans or Lines vs Age Band')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba23b9e",
   "metadata": {},
   "source": [
    "From the above, we see that generally an older person will have more Real Estate Loans or Lines. However, the number of Real Estate Loans or Lines tend to decrease after the age of 60. A possibility could be that the mortgage is fully paid or tenure of loan is completed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928273ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[train_df['NumberRealEstateLoansOrLines']>30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2dbd6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping the outlier based on the chart above, since it's only 2 customers\n",
    "\n",
    "train_df.drop(train_df[train_df['NumberRealEstateLoansOrLines'] > 30].index, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4839b2b",
   "metadata": {},
   "source": [
    "### NumberOfDependents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8a706e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Median Number of Dependents: ', train_df['NumberOfDependents'].median())\n",
    "print ('Mean Number of Dependents: ', train_df['NumberOfDependents'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e81f341",
   "metadata": {},
   "source": [
    "NA would generally mean not applicable, hence it would make sense to input 0 value for NumberOfDependents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a95ef6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filling up Number of Dependents with 0\n",
    "\n",
    "train_df['NumberOfDependents'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1b5b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['NumberOfDependents'].value_counts().plot(kind='bar')\n",
    "plt.title('Plot of Number of Dependents')\n",
    "plt.xlabel('Number of Dependents')\n",
    "plt.ylabel('Count')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea9913e",
   "metadata": {},
   "source": [
    "Most of the customers in our dataset have 0 dependents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7dbd837",
   "metadata": {},
   "outputs": [],
   "source": [
    "# score model\n",
    "score_lr_gs = model_lr_gs.score(Xs_test, y_test)\n",
    "\n",
    "print ('Accuracy Score: {}' .format(score_lr_gs), '\\n')\n",
    "\n",
    "pred_lr_gs = model_lr_gs.predict(Xs_test)\n",
    "\n",
    "cm_lr_gs = confusion_matrix(y_test, pred_lr_gs)\n",
    "\n",
    "print (classification_print, '\\n')\n",
    "\n",
    "print ('Classification report: \\n', classification_report(y_test, pred_lr_gs), '\\n')\n",
    "\n",
    "print (cm_print, '\\n')\n",
    "\n",
    "plot_confusion_matrix(cm_lr_gs, classes)\n",
    "\n",
    "\n",
    "# Plotting AUC Curve\n",
    "model_performance(model_lr_gs, Xs_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8bdb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the features\n",
    "\n",
    "lrcv_coef = [item for sublist in model_lr_gs.coef_ for item in sublist]\n",
    "feat = []\n",
    "for feature in zip(list(X_train.columns.values), lrcv_coef):\n",
    "    feat.append(feature)\n",
    "    \n",
    "feat_df_rfc = pd.DataFrame(feat, columns=['Feature', 'Coef'])\n",
    "feat_df_rfc.sort_values('Coef', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7a52fb",
   "metadata": {},
   "source": [
    "#### Logistic Regression GridSearch Upsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7babc9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# param = {'penalty':['l1', 'l2'],\n",
    "#          'C': [0.0001, 0.001, 0.01, 0.1, 1, 10]\n",
    "#         }\n",
    "\n",
    "lr_up = LogisticRegression()\n",
    "\n",
    "param = {'solver':['liblinear', 'lbfgs', 'newton-cg'],\n",
    "         'C': [0.0001, 0.001, 0.01, 0.1, 1, 10]\n",
    "        }\n",
    " \n",
    "grid_gs_lr_up = GridSearchCV(lr_up, param, verbose=2, cv=5)\n",
    "\n",
    "# fit model\n",
    "grid_gs_lr_up.fit(Xs_train_up, y_train_up)\n",
    "\n",
    "grid_gs_lr_up.best_params_\n",
    "model_gs_lr_up = grid_gs_lr_up.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dced001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# score model\n",
    "score_gs_lr_up = model_gs_lr_up.score(Xs_test_up, y_test)\n",
    "\n",
    "print ('Score: {}' .format(score_gs_lr_up), '\\n')\n",
    "\n",
    "\n",
    "pred_gs_lr_up = model_gs_lr_up.predict(Xs_test_up)\n",
    "\n",
    "print (classification_print, '\\n')\n",
    "print ('Classification report: \\n', classification_report(y_test, pred_gs_lr_up), '\\n')\n",
    "print (cm_print, '\\n')\n",
    "\n",
    "cm_gs_lr_up = confusion_matrix(y_test, pred_gs_lr_up)\n",
    "\n",
    "plot_confusion_matrix(cm_gs_lr_up, classes)\n",
    "\n",
    "\n",
    "# Plotting AUC Curve\n",
    "model_performance(model_gs_lr_up, Xs_test_up, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27648687",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the features\n",
    "\n",
    "lrcv_coef = [item for sublist in model_gs_lr_up.coef_ for item in sublist]\n",
    "feat = []\n",
    "for feature in zip(list(X_train.columns.values), lrcv_coef):\n",
    "    feat.append(feature)\n",
    "    \n",
    "feat_df_rfc = pd.DataFrame(feat, columns=['Feature', 'Coef'])\n",
    "feat_df_rfc.sort_values('Coef', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1429a739",
   "metadata": {},
   "source": [
    "#### Logistic Regression GridSearch Downsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c363b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'solver':['liblinear', 'lbfgs', 'newton-cg'],\n",
    "         'C': [0.0001, 0.001, 0.01, 0.1, 1, 10]\n",
    "        }\n",
    "\n",
    "lr_ds = LogisticRegression()\n",
    "\n",
    "\n",
    "# For GridSearch Downsampling\n",
    "    \n",
    "#fit gridsearch with model, param_grid, cv_itr\n",
    "grid_lr_ds = GridSearchCV(lr_ds, param, verbose=1, cv=10)\n",
    "\n",
    "# fit model\n",
    "grid_lr_ds.fit(Xs_train_ds, y_train_ds)\n",
    "\n",
    "grid_lr_ds.best_params_\n",
    "model_lr_gs_ds = grid_lr_ds.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b8fb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# score model\n",
    "score_gs_lr_ds = model_lr_gs_ds.score(Xs_test_ds, y_test)\n",
    "\n",
    "print ('Score: {}' .format(score_gs_lr_ds), '\\n')\n",
    "\n",
    "\n",
    "pred_lr_gs_ds = model_lr_gs_ds.predict(Xs_test_ds)\n",
    "\n",
    "print (classification_print, '\\n')\n",
    "print ('Classification report: \\n', classification_report(y_test, pred_lr_gs_ds), '\\n')\n",
    "print (cm_print, '\\n')\n",
    "\n",
    "cm_lr_gs_ds = confusion_matrix(y_test, pred_lr_gs_ds)\n",
    "\n",
    "plot_confusion_matrix(cm_lr_gs_ds, classes)\n",
    "\n",
    "\n",
    "# Plotting AUC Curve\n",
    "\n",
    "model_performance(model_lr_gs_ds, Xs_test_ds, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d35b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the features\n",
    "\n",
    "lrcv_coef = [item for sublist in model_lr_gs_ds.coef_ for item in sublist]\n",
    "feat = []\n",
    "for feature in zip(list(X_train.columns.values), lrcv_coef):\n",
    "    feat.append(feature)\n",
    "    \n",
    "feat_df_rfc = pd.DataFrame(feat, columns=['Feature', 'Coef'])\n",
    "feat_df_rfc.sort_values('Coef', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a26585",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65019172",
   "metadata": {},
   "source": [
    "#### Random Forest GridSearch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72dd5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(class_weight='balanced')\n",
    "\n",
    "# 10-Fold Cross validation\n",
    "print ('Cross-Val Score: ', np.mean(cross_val_score(rfc, Xs_train, y_train, cv=10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ffecb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'criterion':['gini'],\n",
    "              'n_estimators': [30, 40, 50, 100, 150],\n",
    "             'max_depth':[10, 15]}\n",
    "   \n",
    "# fit gridsearch with model, param_grid, cv_tir\n",
    "grid_rfc_gs = GridSearchCV(rfc, param_grid, cv=10)\n",
    "\n",
    "#fit model\n",
    "grid_rfc_gs.fit(Xs_train, y_train)\n",
    "\n",
    "# get best param\n",
    "grid_rfc_gs.best_params_\n",
    "model_rfc_gs = grid_rfc_gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310183c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# score model\n",
    "score_rfc_gs = model_rfc_gs.score(Xs_test, y_test)\n",
    "\n",
    "print ('Accuracy Score: {}' .format(score_rfc_gs), '\\n')\n",
    "\n",
    "pred_rfc_gs = model_rfc_gs.predict(Xs_test)\n",
    "\n",
    "cm_rfc_gs = confusion_matrix(y_test, pred_rfc_gs)\n",
    "\n",
    "print (classification_print, '\\n')\n",
    "\n",
    "print ('Classification report: \\n', classification_report(y_test, pred_rfc_gs), '\\n')\n",
    "\n",
    "print (cm_rfc_gs, '\\n')\n",
    "\n",
    "plot_confusion_matrix(cm_rfc_gs, classes)\n",
    "\n",
    "\n",
    "# Plotting AUC Curve\n",
    "model_performance(model_rfc_gs, Xs_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b31bb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking for features\n",
    "\n",
    "feat = []\n",
    "for feature in zip(X_train.columns.values, model_rfc_gs.feature_importances_):\n",
    "    feat.append(feature)\n",
    "    \n",
    "feat_df_rfc = pd.DataFrame(feat, columns=['Feature', 'Value'])\n",
    "feat_df_rfc.sort_values('Value', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0aa349",
   "metadata": {},
   "source": [
    "#### RFC Upsampled GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15b2448",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "sns.heatmap(train_df.corr(), annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4fc8e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filling up null values\n",
    "\n",
    "# filling up Number of Dependents with 0\n",
    "\n",
    "train_df['NumberOfDependents'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4d7f5d",
   "metadata": {},
   "source": [
    "We will fill up the NA values for Monthly Income based on the age band median monthly income."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4db1cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filling up Monthly Income null values\n",
    "\n",
    "# we will be categorizing the age columns based on age band of 10 years, ie. 1-10, 11-20, etc.\n",
    "\n",
    "train_df['age_band'] = train_df['age'].apply(lambda x: '1 to 10' if 1<=x<10 else\n",
    "                                            ('11 to 20' if 11<=x<=20 else\n",
    "                                            ('21 to 30' if 21<=x<=30 else\n",
    "                                            ('31 to 40' if 31<=x<=40 else\n",
    "                                            ('41 to 50' if 41<=x<=50 else\n",
    "                                            ('51 to 60' if 51<=x<=60 else\n",
    "                                            ('61 to 70' if 61<=x<=70 else\n",
    "                                            ('71 to 80' if 71<=x<=80 else\n",
    "                                            ('81 to 90' if 81<=x<=90 else\n",
    "                                            ('91 to 100' if 91<=x<=100 else\n",
    "                                            ('100 to 110' if 100<=x<=110 else x\n",
    "                                            )))))))))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43f0817",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting median MonthlyIncome based on age_band\n",
    "age_band = train_df.groupby('age_band')['MonthlyIncome'].median()\n",
    "age_band_df = age_band.to_frame().reset_index()\n",
    "\n",
    "\n",
    "# resetting index after dropping 1 row earlier to prepare for the next step\n",
    "train_df.reset_index(inplace=True)\n",
    "train_df.drop('index', axis=1, inplace=True)\n",
    "\n",
    "\n",
    "# filling in NA values with median values based on age_band.\n",
    "tempp_df = train_df.set_index('age_band').MonthlyIncome.fillna(age_band_df.set_index('age_band').MonthlyIncome).reset_index()\n",
    "tempp_df.columns = ['age_band_1', 'MonthlyIncome_1']\n",
    "train_df = pd.concat([train_df, tempp_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44089666",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining model and params\n",
    "\n",
    "lr_gs = LogisticRegression(class_weight='balanced')\n",
    "\n",
    "# param_grid_lr_gs = {'penalty':['l1', 'l2'],\n",
    "#                     'C': [0.0001, 0.001, 0.01, 0.1, 1, 10]\n",
    "#                    }\n",
    "\n",
    "param = {'solver':['liblinear', 'lbfgs', 'newton-cg'],\n",
    "         'C': [0.0001, 0.001, 0.01, 0.1, 1, 10]\n",
    "        }\n",
    "    \n",
    "# fit gridsearch with model, param_grid, cv_tir\n",
    "grid_lr_gs = GridSearchCV(lr_gs, param, verbose=2, cv=10)\n",
    "\n",
    "#fit model\n",
    "grid_lr_gs.fit(Xs_train, y_train)\n",
    "\n",
    "# get best param\n",
    "grid_lr_gs.best_params_\n",
    "model_lr_gs = grid_lr_gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1403be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a high Percentage of customers face serious deliquency if they have been in deliquency between 30 -59 days\n",
    "print ('Percentage of Person facing Serious Deliq in 30 - 59 days: ', float(train_df[(train_df['NumberOfTime30-59DaysPastDueNotWorse'] > 80) & (train_df['SeriousDlqin2yrs'] == 1)].shape[0]) / train_df[train_df['NumberOfTime30-59DaysPastDueNotWorse'] >80].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6091093",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "sns.lmplot(x='NumberOfTime60-89DaysPastDueNotWorse', y='DebtRatio', data=train_df,  hue='SeriousDlqin2yrs')\n",
    "plt.title('No. of Time 60-89 Days Late vs Debt Ratio')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17361e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Percentage of Deliquency if late for 60 - 89 days: ',float(train_df[(train_df['NumberOfTime60-89DaysPastDueNotWorse']>80) & (train_df['SeriousDlqin2yrs'] ==1)].shape[0]) / float(train_df[train_df['NumberOfTime60-89DaysPastDueNotWorse']>80].shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d4ba82",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "sns.lmplot(x='NumberOfTimes90DaysLate', y='DebtRatio', data=train_df, hue='SeriousDlqin2yrs')\n",
    "plt.title('No. of Time 90 Days Late vs Debt Ratio')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ce1e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Percentage of Deliquency if late for 90 days or more: ',float(train_df[(train_df['NumberOfTimes90DaysLate']>80) & (train_df['SeriousDlqin2yrs'] ==1)].shape[0]) / float(train_df[train_df['NumberOfTimes90DaysLate']>80].shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa892c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['NumberOfTime60-89DaysPastDueNotWorse'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc1032d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['NumberOfTime30-59DaysPastDueNotWorse'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2aa10d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['NumberOfTimes90DaysLate'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233411ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot('NumberOfTimes90DaysLate', 'NumberOfTime60-89DaysPastDueNotWorse', train_df, hue='SeriousDlqin2yrs')\n",
    "plt.title('No. of Times 90 Days Late vs No. of Times 60-89 Days Late')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e799c531",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot('NumberOfTimes90DaysLate', 'NumberOfTime30-59DaysPastDueNotWorse', train_df,  hue='SeriousDlqin2yrs')\n",
    "plt.title('No. of Times 90 Days Late vs No. of Times 30-59 Days Late')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129c0b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot('NumberOfTime60-89DaysPastDueNotWorse', 'NumberOfTime30-59DaysPastDueNotWorse', train_df,  hue='SeriousDlqin2yrs')\n",
    "plt.title('No. of Times 60-89 Days Late vs No. of Times 30-59 Days Late')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85cea00a",
   "metadata": {},
   "source": [
    "### Preparing X and y variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb2ed2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing ML modules\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier, LogisticRegressionCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.cross_validation import cross_val_predict, cross_val_score\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB, GaussianNB\n",
    "from sklearn.metrics import classification_report, confusion_matrix, r2_score, roc_curve, auc\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0156745",
   "metadata": {},
   "source": [
    "## Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59fef192",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = './cs-training.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d63d77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a44a0ae",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1563283e",
   "metadata": {},
   "source": [
    "<b> Data Dictionary </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759d9024",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124ef78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4187f826",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.drop('Unnamed: 0', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d351c2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418e833c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5ad135",
   "metadata": {},
   "source": [
    "### Start of EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729eed6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,10))\n",
    "sns.stripplot(x='age_band_1', y='MonthlyIncome_1', data=train_df, order=age_band_order, hue='SeriousDlqin2yrs')\n",
    "plt.title('Plot of Age Band vs Monthly Income')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f504a3b7",
   "metadata": {},
   "source": [
    "We can see that generally monthly income increases as you grow older and have more working experience, untill the after 70 years old (approx retirement age), where monthly income reduces. We observe there are more delinquencies below the ageband of 61 to 70."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d39719",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(train_df, hue='SeriousDlqin2yrs')"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
