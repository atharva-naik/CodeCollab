{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ed50521",
   "metadata": {},
   "source": [
    "Implement **`one-vs-all logistic regression and neural networks to recognize handwritten digit`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137adbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy  as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import scipy\n",
    "import scipy.optimize as opt\n",
    "import scipy.io as sio\n",
    "from scipy.io import loadmat\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f5243b",
   "metadata": {},
   "source": [
    "# Multi-Class Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66386d9b",
   "metadata": {},
   "source": [
    "Extend your previous implementation of logistic regression and apply it to **`one-vs-all classification`**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01021e7d",
   "metadata": {},
   "source": [
    "###### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21cbdd5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"dataset/ex3data1.mat\"\n",
    "ori_data = sio.loadmat(path)\n",
    "X_ori = ori_data.get('X')\n",
    "y_ori = ori_data.get('y').reshape((-1,))\n",
    "m = y_ori.shape[0]\n",
    "print(\">> X_ori.shape :\", X_ori.shape)\n",
    "print(\"   y_ori.shape :\", y_ori.shape)\n",
    "print(\"   Samples :\", m)\n",
    "print(\"   y classes :\", np.unique(y_ori))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ce02e2",
   "metadata": {},
   "source": [
    "## Visualizing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61384fae",
   "metadata": {},
   "source": [
    "There are 5000 training examples in `ex4data1.mat`, where each training example is `a 20 pixel by 20 pixel grayscale image of the digit`. Each pixel is represented by a floating point number indicating the grayscale intensity at that location. The 20 by 20 grid of pixels is “unrolled” into a 400-dimensional vector. Each of these training examples becomes a single row in our data matrix $X$. This gives us a 5000 by 400 matrix $X$ where every row is a training example for a handwritten digit image.\n",
    "\n",
    "$$ X = \\begin{bmatrix} - \\left(x^{(1)} \\right)^T - \\\\\n",
    "- \\left(x^{(2)} \\right)^T - \\\\\n",
    "\\vdots \\\\\n",
    "- \\left(x^{(m)} \\right)^T - \\\\\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1455cb43",
   "metadata": {},
   "source": [
    "###### form data for visualize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e103f8",
   "metadata": {},
   "source": [
    "###### visualize one image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d487d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_one_image(image, method=0):\n",
    "    fig, ax = plt.subplots(figsize=(1, 1))\n",
    "    if method == 0:\n",
    "        ax.matshow(image.reshape((20, 20)), cmap=mpl.cm.binary)\n",
    "    elif method == 1:\n",
    "        plt.imshow(image.reshape((20, 20)), cmap=mpl.cm.binary)\n",
    "    plt.xticks(np.array([]))  # just get rid of ticks\n",
    "    plt.yticks(np.array([]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca44c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pick_one = np.random.choice(5000, 1)\n",
    "pick_one = np.random.randint(0, 5000)\n",
    "visualize_one_image(X_img[pick_one, :])\n",
    "print('this should be {}'.format(y_img[pick_one]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435b6d3b",
   "metadata": {},
   "source": [
    "###### visualize all classes data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a5277d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_one_class = y_ori.copy()\n",
    "y_one_class[y_one_class == 10] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea86bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = np.arange(0, 10)\n",
    "num_classes = len(classes)\n",
    "sample_each_class = 1\n",
    "\n",
    "for y, cla in enumerate(classes):\n",
    "    idxs = np.array(np.where(y_one_class == y)).reshape((-1,))\n",
    "    idxs = np.random.choice(idxs, sample_each_class, replace=False)\n",
    "\n",
    "    for i, idx in enumerate(idxs):\n",
    "        plt_idx = i * num_classes + y + 1\n",
    "        plt.subplot(sample_each_class, num_classes, plt_idx)\n",
    "        plt.imshow(X_img[idx].reshape((20, 20)), cmap=mpl.cm.binary)\n",
    "        plt.axis('off')\n",
    "        if i == 0:\n",
    "            plt.title(cla)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96dc2f59",
   "metadata": {},
   "source": [
    "##### form training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fdf698e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def form_train_data(X_ori, y_ori):\n",
    "    X_train = np.insert(X_ori, 0, 1, axis=1)\n",
    "    \n",
    "    # transform vector-y to one-hot\n",
    "    y_matrix = []\n",
    "    for k in range(1,11):\n",
    "        y_matrix.append((y_ori == k).astype(int))\n",
    "        # y_matrix.append([1 if label == k else 0 for label in y])\n",
    "    y_matrix = [y_matrix[-1]] + y_matrix[:-1]\n",
    "    y_train = np.array(y_matrix)\n",
    "    \n",
    "    print(\"X_train.shape :\", X_train.shape)\n",
    "    print(\"y_train.shape :\", y_train.shape)\n",
    "    \n",
    "    return X_train, y_train\n",
    "\n",
    "X_train, y_train = form_train_data(X_ori, y_ori)\n",
    "theta_init_zero = np.zeros((X_train.shape[1],))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1db2312",
   "metadata": {},
   "source": [
    "## Vetor regularization logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2cf2f7",
   "metadata": {},
   "source": [
    "**`Using multiple one-vs-all logistic regression models to build a multi-class classifier`**.\n",
    "\n",
    "`Since there are 10 classes, you will need to train 10 separate logistic regression classifiers`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74701f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_choose_lamd = y_ori.copy()\n",
    "sk_X_train, sk_X_test, sk_y_train, sk_y_test = train_test_split(\n",
    "    X_train, y_choose_lamd, test_size=0.3, random_state=0\n",
    ")\n",
    "sk_X_img, sk_y_img = form_data_for_visualize(sk_X_train[:,1:], sk_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f551565f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lamdas = np.linspace(0.01, 1000, 5)\n",
    "\n",
    "acu_train = np.empty(len(lamdas))\n",
    "acu_cv = np.empty(len(lamdas))\n",
    "\n",
    "for i, lamda in enumerate(lamdas):\n",
    "    model = LogisticRegression(penalty='l2', C=lamda, fit_intercept=False, multi_class='ovr')\n",
    "    model.fit(X_train, y_ori)\n",
    "    \n",
    "    # calc accuracy - method-01\n",
    "    hyp_prd_train = hypothesis(model.coef_.T, sk_X_train)\n",
    "    y_prd_train   = np.argmax(hyp_prd_train, axis=1) + 1\n",
    "    y_answer_train = sk_y_train.copy()\n",
    "    corret_train = [1 if a == b else 0 for (a,b) in zip (y_answer_train, y_prd_train)]\n",
    "    acu_train[i]   = np.mean(corret_train)\n",
    "    \n",
    "    hyp_prd_cv = hypothesis(model.coef_.T, sk_X_test)\n",
    "    y_prd_cv   = np.argmax(hyp_prd_cv, axis=1) + 1\n",
    "    y_answer_cv = sk_y_test.copy()\n",
    "    corret_cv = [1 if a == b else 0 for (a,b) in zip (y_answer_cv, y_prd_cv)]\n",
    "    acu_cv[i]   = np.mean(corret_cv)\n",
    "\n",
    "    # calc accuracy - method-02\n",
    "    # acu_train[i] = model.score(sk_X_train, sk_y_train)\n",
    "    # acu_cv[i] = model.score(sk_X_test, sk_y_test)\n",
    "\n",
    "    print('>>>  Lamd = %f' % (1 / lamda))\n",
    "    print('     train acu = %.3f%%' % (acu_train[i] * 100))\n",
    "    print('     cv acu    = %.3f%%' % (acu_cv[i] * 100))\n",
    "    print()\n",
    "    \n",
    "    # plot digit-0\n",
    "    digit_show = 9\n",
    "    ind = np.where(sk_y_train == digit_show)\n",
    "    visualize_one_image(sk_X_img[ind][0])\n",
    "    axes = plt.gca()\n",
    "    axes.set_title('digit - %d' % (digit_show))\n",
    "    \n",
    "    # plot error predict digit\n",
    "    inct_ind = np.where(y_answer_train != y_prd_train)\n",
    "    visualize_one_image(sk_X_img[inct_ind][0])\n",
    "    axes = plt.gca()\n",
    "    axes.set_title('predict as %d, ori - %d' % (y_prd_train[inct_ind][0] , y_answer_train[inct_ind][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7237dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(lamdas, acu_train, lamdas, acu_cv)\n",
    "ind = np.where(acu_cv == np.amax(acu_cv))\n",
    "print(ind[0][0])\n",
    "optLambda = lamdas[ind[0][0]]\n",
    "plt.scatter(optLambda, acu_cv[ind[0][0]], label=\"best lamd - {%f - %0.4f}\" % (optLambda, acu_cv[ind[0][0]]))\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b66e452",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5984a062",
   "metadata": {},
   "source": [
    "    However, logistic regression can't form more complex hypothesis as it is only a linear classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd890891",
   "metadata": {},
   "source": [
    "<img style=\"float: left;\" src=\"dataset/nn_model.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2adb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_weight(path):\n",
    "    weights = sio.loadmat(path)\n",
    "    print('weight.keys()', weights.keys())\n",
    "    print('weights[\\'Theta1\\'].shape', weights['Theta1'].shape)\n",
    "    print('weights[\\'Theta2\\'].shape', weights['Theta2'].shape)\n",
    "    \n",
    "    return weights['Theta1'], weights['Theta2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ee673e",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_path = \"dataset/ex3weights.mat\"\n",
    "theta1, theta2 = load_weight(weights_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491acae1",
   "metadata": {},
   "source": [
    "theta - (out, in)\n",
    "z - (m, n)\n",
    "Z - (m, out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afaae5e1",
   "metadata": {},
   "source": [
    "## layer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7940faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "J_history = []\n",
    "theta_init_zero = np.zeros((X_train.shape[1],))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea63662",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(Z):\n",
    "    return scipy.special.expit(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91cfc8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hypothesis(theta, X):\n",
    "    return sigmoid(X @ theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c26af5b",
   "metadata": {},
   "source": [
    "+ Normal : $ J\\left( \\theta  \\right)=-\\frac{1}{m}\\sum\\limits_{i=1}^{m}{[{{y}^{(i)}}\\log \\left( {{h}_{\\theta }}\\left( {{x}^{(i)}} \\right) \\right)+\\left( 1-{{y}^{(i)}} \\right)\\log \\left( 1-{{h}_{\\theta }}\\left( {{x}^{(i)}} \\right) \\right)]} + \\frac{\\lambda }{2m}\\sum\\limits_{j=1}^{n}{{\\theta }_{j}^{2}} $\n",
    "+ Vector : $ J(\\theta) = -\\frac{1}{m}\\big((\\,log\\,(g(X\\theta))^Ty+(\\,log\\,(1-g(X\\theta))^T(1-y)\\big) + \\frac{\\lambda }{2m}\\sum\\limits_{j=1}^{n}{{\\theta }_{j}^{2}} $\n",
    "> + theta - (n+1, )\n",
    "> + X - (m, n+1)\n",
    "> + y - (m, )\n",
    "> + scalars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d833815b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_zeros(data):\n",
    "    if np.count_nonzero(data):\n",
    "        min_nonzero = np.min(data[np.nonzero(data)])\n",
    "    else:\n",
    "        min_nonzero = 0.000000000001\n",
    "    data[data == 0] = min_nonzero\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "def cost_function(theta, X, y, lamd=0):\n",
    "    global J_history\n",
    "    \n",
    "    hyp = hypothesis(theta, X)\n",
    "    y_1 = np.log(replace_zeros(hyp)).T @ y\n",
    "    y_0 = np.log(replace_zeros(1-hyp)).T @ (1-y)\n",
    "    cost = -(y_1 + y_0) / y.size\n",
    "    \n",
    "    reg_item = lamd * np.mean(np.power(theta[1:], 2)) / (2 * y.size)\n",
    "    cost_reg = cost + reg_item\n",
    "    \n",
    "    \"\"\"\n",
    "        if np.isnan(cost_reg):\n",
    "            cost_reg = np.inf\n",
    "    \"\"\"\n",
    "\n",
    "    J_history.append(cost_reg)\n",
    "    \n",
    "    return cost_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2ece35",
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_function(theta_init_zero, X_train, y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6834c0f2",
   "metadata": {},
   "source": [
    "+ Vector : $$ \\frac{\\delta J(\\theta)}{\\delta\\theta_{j}} = \\frac{1}{m} X^T(g(X\\theta)-y) + \\frac{\\lambda}{m}\\theta_{j}$$ \n",
    "##### $$\\text{Note: intercept parameter } \\theta_{0} \\text{ is not to be regularized}$$\n",
    "> + theta - (n+1, )\n",
    "> + X - (m, n+1)\n",
    "> + y - (m, )\n",
    "> + (n+1, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8557b317",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient(theta, X, y, lamd=0):\n",
    "    err = hypothesis(theta, X) - y\n",
    "    grad = X.T @ err / y.size\n",
    "    \n",
    "    reg_theta = lamd * theta[1:] / y.size\n",
    "    reg_item = np.r_[[0], reg_theta]\n",
    "    \n",
    "    grad_reg = grad + reg_item\n",
    "    \n",
    "    return grad_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13e02fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scipy_opt_minimize(theta, X, y, Method, lamd=0):\n",
    "    global J_history\n",
    "    J_history = []\n",
    "    res = opt.minimize(\n",
    "        fun    = cost_function,\n",
    "        x0     = theta,\n",
    "        args   = (X, y, lamd),\n",
    "        jac    = gradient,\n",
    "        method = Method\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        \"result\"  : res,\n",
    "        \"theta\"   : res.x,\n",
    "        \"success\" : res.success,\n",
    "        \"cost_history\" : J_history.copy(),\n",
    "        \"name\" : Method,\n",
    "        \"lamd\" : lamd\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0856c9",
   "metadata": {},
   "source": [
    "## Training One Class Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a0e279",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyp_prd = hypothesis(theta_scipy_opt.T, X_train)\n",
    "y_prd   = np.argmax(hyp_prd, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1fce8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_answer = y_ori.copy()\n",
    "y_answer[y_answer == 10] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370a7d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_answer, y_prd))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d951320",
   "metadata": {},
   "source": [
    "#### np.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28bb56a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "corret = [1 if a == b else 0 for (a,b) in zip (y_answer, y_prd)]\n",
    "accu   = sum(map(int, corret)) / float(len(corret))\n",
    "print('Accuracy = {0}%'.format(accu * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6bbdf0",
   "metadata": {},
   "source": [
    "#### model.score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb8f3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f033de",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(penalty='l2', C=1.0, fit_intercept=False, multi_class='ovr')\n",
    "model.fit(X_train, y_ori)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbaa92c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.coef_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb47c93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(X_train, y_ori)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ffa6ee",
   "metadata": {},
   "source": [
    "### choose best lamd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0180659",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_matrix = []\n",
    "y_matrix.append([1 if label == 10 else 0 for label in y_ori])\n",
    "y_vector_for_accuary_digit_0 = np.array(y_matrix).reshape((-1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1dbead1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_vector_for_accuary_digit_0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6f27d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyp_digit_0 = hypothesis(res_digit_0[\"theta\"], X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568c3769",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_vector_for_accuary_digit_0, hyp_digit_0.round().astype(int)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5982f8",
   "metadata": {},
   "source": [
    "## Training all Class Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "245f9673",
   "metadata": {},
   "source": [
    "    Since there are 10 classes, you will need to train 10 separate logistic regression classifiers, one for each of the K classes in our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fed2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6c2fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022db898",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_scipy_opt = []\n",
    "for i in range(10):\n",
    "    res = scipy_opt_minimize(theta_init_zero, X_train, y_train[i], \"BFGS\", lamd=1)\n",
    "    theta_scipy_opt.append(res[\"theta\"])\n",
    "\n",
    "theta_scipy_opt = np.array(theta_scipy_opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5f1e96",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0909ba",
   "metadata": {},
   "source": [
    "#### classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba0b943",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_scipy_opt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec65c48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def form_data_for_visualize(X, y):\n",
    "    # for this dataset, you need a transpose to get the orientation right\n",
    "    X_img = np.array([im.reshape((20, 20)).T for im in X])\n",
    "    # and I flat the image again to preserve the vector presentation\n",
    "    X_img = np.array([im.reshape(400) for im in X_img])\n",
    "    y_img = y\n",
    "    \n",
    "    return X_img, y_img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37604f4",
   "metadata": {},
   "source": [
    "###### visualize all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c384dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_data(X, y):\n",
    "    img_size = int(np.sqrt(X.shape[1]))\n",
    "    \n",
    "    sample_idx = np.sort(np.random.choice(5000, 100))\n",
    "    sample_img = X[sample_idx, :]\n",
    "    \n",
    "    fig, ax_array = plt.subplots(nrows=10, ncols=10, sharey=True, sharex=True, figsize=(8, 8))\n",
    "    for r in range(10):\n",
    "        for c in range(10):\n",
    "            ax_array[r, c].matshow(sample_img[10 * r + c].reshape((img_size, img_size)),\n",
    "                                   cmap=mpl.cm.binary) # Greys_r\n",
    "            plt.xticks(np.array([]))\n",
    "            plt.yticks(np.array([]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f45f997",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_img, y_img = form_data_for_visualize(X_ori, y_ori)\n",
    "visualize_data(X_img, y_img)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
