{
    "faiss_index": "./dense_indices/CoNaLa_CSN_CodeBERT_CodeSearch2_CosSim/codebert_plan_ops_cos_sim.index",
    "nb_assgns": [
        [
            {
                "code": "%matplotlib inline\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.mlab as mlab\nimport math",
                "true_label": "imports",
                "top5_preds": [
                    "timing, numpy, plotting",
                    "plot using matplotlib",
                    "line plot with a dataframe",
                    "trend lines in pyplot",
                    "matplotlib"
                ]
            },
            {
                "code": "donations = pd.DataFrame.from_csv('opendata_donations.csv', index_col=None).ix[:,0:23]\ndonations = donations.rename(columns=lambda x: x.strip()) # removing whitespaces from columns\ndonations = donations[(donations.donor_zip!='SC')&(donations.donor_zip!='NY')&(donations.donor_zip!='NJ')&(donations.donor_zip!='TX')]\ndonations.head(5)",
                "true_label": "creating dataframes & basic manipulations",
                "top5_preds": [
                    "importing data with pandas",
                    "formatting datetimes as strings",
                    "load table in pandas",
                    "loading a csv into a dataframe",
                    "relationships between dataframes"
                ]
            },
            {
                "code": "projects = pd.DataFrame.from_csv('opendata_projects.csv', index_col=None)\nprojects.head(5)",
                "true_label": "loading a csv into a dataframe",
                "top5_preds": [
                    "loading a csv into a dataframe",
                    "load table in pandas",
                    "from dictionary to dataframe",
                    "importing data with pandas",
                    "line plot with a dataframe"
                ]
            },
            {
                "code": "# Join donations and projects data\nprojects_donations = projects.merge(donations, on='_projectid',how='inner')\nprojects_donations.head(5)",
                "true_label": "merging data frames",
                "top5_preds": [
                    "relationships between dataframes",
                    "join two dataframes along rows",
                    "from dictionary to dataframe",
                    "join two dataframes along columns",
                    "create a dataframe by joining series by column"
                ]
            },
            {
                "code": "len(projects_donations)",
                "true_label": "length of dataframe",
                "top5_preds": [
                    "formatting datetimes as strings",
                    "sum all the numbers in a list",
                    "convert date to datetime format",
                    "get a positive integer from a user",
                    "get the names of all the tables in the database"
                ]
            },
            {
                "code": "#1) Proportions of state wise donations against state wise projects \n# Creating a n*n empty data frame for each state\nstates = projects_donations.school_state.drop_duplicates()\ndf = pd.DataFrame(columns = states)\nfor state in states:\n    df.loc[state] = states\n\n# Filling the data frame\np_g = projects_donations.groupby('school_state')\nfor state_p,group_p in p_g:\n    #print state_p,'--',group_p.donation_total.sum()\n    d_g = group_p.groupby('donor_state')\n    for state_d,group_d in d_g:\n        #print state_d, group_d.donation_total.sum()\n        df.loc[state_p,state_d] = 100*(group_d.donation_total.sum())/(group_p.donation_total.sum())",
                "true_label": "create dataframe with given values",
                "top5_preds": [
                    "from dictionary to dataframe",
                    "relationships between dataframes",
                    "create dataframe with given values",
                    "create a one column dataframe with the values of a series",
                    "import polynomial features from sklearn"
                ]
            },
            {
                "code": "df.fillna(0).head(5)",
                "true_label": "fill all the nas",
                "top5_preds": [
                    "line plot with a dataframe",
                    "create dataframe with given values",
                    "create a one column dataframe with the values of a series",
                    "create a dataframe by joining series by column",
                    "create a dataframe"
                ]
            },
            {
                "code": "## Randomly picked few states - for data story sake\ndf.fillna(0)#.head(5)\ndf.loc[(df.index == 'NY')|(df.index == 'CA')|(df.index == 'DC')|(df.index == 'IA')|(df.index == 'NV')|(df.index == 'SC') ,(df.columns == 'NY')|(df.columns == 'CA')|(df.columns == 'DC')|(df.columns == 'IA')|(df.columns == 'NV')|(df.columns == 'SC')]",
                "true_label": "fill all the nas",
                "top5_preds": [
                    "create dataframe with given values",
                    "create a dataframe",
                    "create a one column dataframe with the values of a series",
                    "load table in pandas",
                    "dataframe methods"
                ]
            },
            {
                "code": "df[df.index == 'IA'].sum().sort_values(ascending=False).head(5)",
                "true_label": "sorting data",
                "top5_preds": [
                    "create a one column dataframe with the values of a series",
                    "line plot with a dataframe",
                    "create a dataframe by joining series by column",
                    "line plots show the trend of a numerical variable over time",
                    "predicting a categorical response"
                ]
            },
            {
                "code": "# Identify donations that came from the teacher who created the project\n# and assigning donor category\npds = projects_donations\npds.loc[:, 'donor_category'] = 'donor_other'\npds.loc[pds._teacher_acctid == pds._donor_acctid, 'donor_category'] = 'donor_teacher_project'\npds.loc[(pds._teacher_acctid != pds._donor_acctid) & (pds.is_teacher_acct == 't'), 'donor_category'] = 'donor_teacher_other'",
                "true_label": "locate rows and columns in dataframe",
                "top5_preds": [
                    "from dictionary to dataframe",
                    "relationships between dataframes",
                    "import polynomial features from sklearn",
                    "find all by term in field in case insensitive way",
                    "create a dataframe by joining series by column"
                ]
            },
            {
                "code": "pds_g = pds.groupby(by='donor_category')\npds_g = pds_g['donation_total'].mean()\npds_gx = pds_g.plot(kind='bar')\npds_gx.set_ylabel(\"Average Donation Amount\")\npds_gx.set_title('Plot between donor category and Average donation amount', fontsize=14)",
                "true_label": "use pandas to make a bar chart",
                "top5_preds": [
                    "line plot with a dataframe",
                    "pandas plotting",
                    "pandas plotting documentation",
                    "use pandas to make a bar chart",
                    "ploting out data with box plots"
                ]
            },
            {
                "code": "subjects = pds.primary_focus_subject.drop_duplicates()\ndf = pd.DataFrame(columns = ['Subjects','donor_teacher_project','donor_teacher_other','donor_other'])\ndf['Subjects'] = subjects\ndf = df.set_index('Subjects')\n\n# Filling the data frame\npds1 = pds.groupby('primary_focus_subject')\nfor sub,group_s in pds1:\n    pds2 = group_s.groupby('donor_category')\n    for dc,group_dc in pds2:\n        df.loc[sub,dc] = 100*(group_dc.donation_total.sum())/(group_s.donation_total.sum())\ndf.head(10)",
                "true_label": "create dataframe with given values",
                "top5_preds": [
                    "from dictionary to dataframe",
                    "create dataframe with given values",
                    "dataframe methods",
                    "create a one column dataframe with the values of a series",
                    "relationships between dataframes"
                ]
            },
            {
                "code": "a = pds[pds.donor_category == 'donor_teacher_project']\n#a = a[(100 * a.donation_total / a.total_donations) > 33]\nax = a.groupby(by='primary_focus_subject')['donation_total'].mean().plot(kind='bar',figsize=(20,5))\nax.set_ylabel('Average Donation Amount')\nax.set_title('Plot between Subject and Donation amount for a teacher contributing to own project', fontsize=14)",
                "true_label": "use pandas to make a bar chart",
                "top5_preds": [
                    "line plot with a dataframe",
                    "predicting a categorical response",
                    "ploting out data with box plots",
                    "relationships between dataframes",
                    "pandas plotting"
                ]
            },
            {
                "code": "b = pds[pds.donor_category == 'donor_teacher_other']\n#a = a[(100 * a.donation_total / a.total_donations) > 33]\nbx = b.groupby(by='primary_focus_subject')['donation_total'].mean().plot(kind='bar',figsize=(20,5))\nbx.set_ylabel('Average Donation Amount')\nbx.set_title('Plot between Subject and Donation amount for a teacher contributing to other project', fontsize=14)",
                "true_label": "use pandas to make a bar chart",
                "top5_preds": [
                    "predicting a categorical response",
                    "line plot with a dataframe",
                    "ploting out data with box plots",
                    "relationships between dataframes",
                    "dataframe methods"
                ]
            },
            {
                "code": "c = pds[pds.donor_category == 'donor_other']\n#a = a[(100 * a.donation_total / a.total_donations) > 33]\ncx = c.groupby(by='primary_focus_subject')['donation_total'].mean().plot(kind='bar',figsize=(20,5))\ncx.set_ylabel('Average Donation Amount')\ncx.set_title('Plot between Subject and Donation amount for a non-teacher', fontsize=14)",
                "true_label": "use pandas to make a bar chart",
                "top5_preds": [
                    "predicting a categorical response",
                    "line plot with a dataframe",
                    "ploting out data with box plots",
                    "relationships between dataframes",
                    "dataframe methods"
                ]
            },
            {
                "code": "p = pds[pds.funding_status != 'live'] # Considering only completed projects\np.loc[:,'date_completed'] = pd.to_datetime(p['date_completed'])\np.loc[:,'date_posted'] = pd.to_datetime(p['date_posted'])\np.loc[:,'date_expiration'] = pd.to_datetime(p['date_expiration'])\np1 = p.groupby(by='donor_category')\np2 = p[p.funding_status == 'completed']\np2.loc[:,'project_duration'] = p2['date_completed'] - p2['date_posted']\np2.loc[:,'project_expire_duration'] = p2['date_expiration'] - p2['date_posted']\np2.loc[:,'project_duration_days'] = p2['project_duration'].astype('timedelta64[D]')\np2.loc[:,'project_expire_duration_days'] = p2['project_expire_duration'].astype('timedelta64[D]')\np2 = p2[(p2.project_duration_days < p2.project_expire_duration_days) & (p2.project_duration_days < 200)]\np3 = p2.groupby(by='donor_category')\na = 100*p3.size()/p1.size()\nb = p3['project_duration_days'].mean()",
                "true_label": "",
                "top5_preds": [
                    "formatting datetimes as strings",
                    "relationships between dataframes",
                    "integrating datetime tools with pandas for time series",
                    "convert date to datetime format",
                    "from dictionary to dataframe"
                ]
            },
            {
                "code": "#a.plot(kind='bar')\nax = a.plot(kind='bar',figsize=(7,5),ylim=(50,100))\nax.set_ylabel(\"Project Completion Percent\")",
                "true_label": "",
                "top5_preds": [
                    "use pandas to make a bar chart",
                    "line plot with a dataframe",
                    "pandas plotting",
                    "trend lines in pyplot",
                    "pandas plotting documentation"
                ]
            },
            {
                "code": "bx = b.plot(kind='bar',figsize=(7,5))\nbx.set_ylabel(\"Project Duration\")",
                "true_label": "",
                "top5_preds": [
                    "use pandas to make a bar chart",
                    "plotting time series with pandas",
                    "create a bar chart",
                    "formatting datetimes as strings",
                    "line plots show the trend of a numerical variable over time"
                ]
            }
        ],
        [
            {
                "code": "!cat ~/.keras/keras.json",
                "true_label": "cat file",
                "top5_preds": [
                    "loading json in python",
                    "running a local postgres database",
                    "postgres sql lab",
                    "calculating the mean of a vector with nans",
                    "import polynomial features from sklearn"
                ]
            },
            {
                "code": "from gpu import share\n\nsimultaneous_users_count = 2\nshare(simultaneous_users_count)",
                "true_label": "cpu vs gpu",
                "top5_preds": [
                    "get a positive integer from a user",
                    "cpu vs gpu",
                    "sum all the numbers in a list",
                    "test whether a number is positive",
                    "detect the number of local variables declared in a function"
                ]
            },
            {
                "code": "from keras.models import Sequential\nfrom keras.layers import BatchNormalization, Dense, Dropout, ELU, Flatten\n\nclasses_count = len(classes)\ntop_model = Sequential([\n        Flatten(input_shape=training_intermediate_output.shape[1:]),\n        ELU(),\n        Dense(512),\n        Dropout(0.5),\n        Dense(classes_count, activation='softmax', name='predictions')\n    ])\n\ntop_model.compile(optimizer='adam', # NOTE: several optimizers to choose from besides regular gradient descent\n                  loss='categorical_crossentropy', # NOTE: several error metrics to choose from (e.g., MSE for regression)\n                  metrics=['accuracy'])",
                "true_label": "keras sequential model",
                "top5_preds": [
                    "tensorflow + keras",
                    "logistic regression using tensorflow",
                    "keras sequential model",
                    "what is scikit learn?",
                    "import polynomial features from sklearn"
                ]
            },
            {
                "code": "from keras.utils.np_utils import to_categorical\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n\nmax_epochs = 8\n\nearly_stopping = EarlyStopping(patience=2, verbose=1)\n\n!rm {current_data_path}/*.hdf5\ncheckpoint = ModelCheckpoint(filepath=current_data_path+\"/weights.{epoch:02d}-{val_loss:.5f}.hdf5\", \n                             verbose=1, \n                             save_best_only=True, \n                             save_weights_only=True)\nlearning_rate_reducer = ReduceLROnPlateau(patience=1, verbose=1)\n\ntop_model.fit(training_intermediate_output, to_categorical(bottleneck_training_labels),\n              batch_size=batch_size,\n              nb_epoch=max_epochs, \n              callbacks=[checkpoint, learning_rate_reducer, early_stopping],\n              validation_data=(validation_intermediate_output, to_categorical(bottleneck_validation_labels))\n              )",
                "true_label": "early stopping",
                "top5_preds": [
                    "optimal value of k for dataset",
                    "what is scikit learn?",
                    "logistic regression using tensorflow",
                    "tensorflow + keras",
                    "polynomial regression with sklearn"
                ]
            },
            {
                "code": "best_model_weights_filename = 'weights.07-0.63838.hdf5'\ntop_model.load_weights(current_data_path + '/' + best_model_weights_filename)\n\nvalidation_prediction_probabilities = top_model.predict_proba(validation_intermediate_output, batch_size=batch_size)",
                "true_label": "using the model for prediction",
                "top5_preds": [
                    "using the model for prediction",
                    "tensorflow + keras",
                    "test the model for accuracy",
                    "build a vector of prediction from the trained model",
                    "import polynomial features from sklearn"
                ]
            },
            {
                "code": "errors = validation_prediction_probabilities[:, 1] - bottleneck_validation_labels\ntop_count = 4\nworst_dog_prediction_indices = np.argsort(errors)[:top_count]\nworst_cat_prediction_indices = np.argsort(errors)[::-1][:top_count]",
                "true_label": "predicting a categorical response",
                "top5_preds": [
                    "predicting a categorical response",
                    "predicting a continuous response using linear regression",
                    "using k nearest neighbor for imputing missing data",
                    "numpy",
                    "predicting on sample validation data"
                ]
            },
            {
                "code": "validation_prediction_probabilities",
                "true_label": "predict on validation",
                "top5_preds": [
                    "predicting a categorical response",
                    "predicting on sample validation data",
                    "check accuracy / score for a logistic classifier",
                    "predicting test data",
                    "predict on validation"
                ]
            },
            {
                "code": "print([errors[i] for i in worst_dog_prediction_indices])\nprint([errors[i] for i in worst_cat_prediction_indices])",
                "true_label": "",
                "top5_preds": [
                    "remove duplicates from a list",
                    "predicting a categorical response",
                    "convert list to numpy array",
                    "replace last value of tuples in a list",
                    "calculating the mean of a vector with nans"
                ]
            },
            {
                "code": "validation_filepaths = cat_validation_images_filepaths + dog_validation_images_filepaths",
                "true_label": "join lists",
                "top5_preds": [
                    "sum all the numbers in a list",
                    "numpy",
                    "formatting datetimes as strings",
                    "convert list to numpy array",
                    "test whether a number is positive"
                ]
            },
            {
                "code": "from img_paths import show\n\nshow([validation_filepaths[i] for i in worst_dog_prediction_indices])",
                "true_label": "",
                "top5_preds": [
                    "visualize the distribution histogram of x using sns distplot",
                    "trend lines in pyplot",
                    "predicting a categorical response",
                    "sum all the numbers in a list",
                    "numpy"
                ]
            },
            {
                "code": "from glob import glob\nimport os\n\nshared_data_path = '/usr/local/share/kaggle/dogs-vs-cats-redux-kernels-edition'\nshared_training_data_path = shared_data_path + '/train'\nshared_training_images_filepaths = glob(os.path.join(shared_training_data_path, \"*.*.*\"))",
                "true_label": "import the dataset",
                "top5_preds": [
                    "import polynomial features from sklearn",
                    "matrix addition and scalar matrix multiplication",
                    "numpy",
                    "import the dataset",
                    "reading and writing binary files"
                ]
            },
            {
                "code": "project_data_path = 'data'\nsample_path = project_data_path + '/sample'\n\ncurrent_data_path = sample_path\ntraining_path = current_data_path + '/training'\nvalidation_path = current_data_path + '/validation'\n\nclasses = ['cat', 'dog']\n\nfor c in classes:\n    for path in [training_path, validation_path]:\n        !mkdir -p {path}/{c}",
                "true_label": "import the dataset",
                "top5_preds": [
                    "import polynomial features from sklearn",
                    "numpy",
                    "add string to list using append",
                    "scipy",
                    "convert list to numpy array"
                ]
            },
            {
                "code": "from img_paths import clear_training_validation_directories, extract_label, sample_paths_labels, symlink_files\nfrom sklearn.model_selection import train_test_split\n\nsample_percentage = 1.0 / simultaneous_users_count\nsample_filepaths, sample_labels = sample_paths_labels(shared_training_images_filepaths, sample_percentage)\ntraining_filepaths, validation_filepaths, training_labels, validation_labels = train_test_split(sample_filepaths, \n                                                                                                sample_labels)\nclear_training_validation_directories(current_data_path, classes)\nsymlink_files(shared_training_data_path, current_data_path, 'training', training_filepaths, training_labels)\nsymlink_files(shared_training_data_path, current_data_path, 'validation', validation_filepaths, validation_labels)",
                "true_label": "import the dataset",
                "top5_preds": [
                    "import polynomial features from sklearn",
                    "predicting on sample validation data",
                    "use sklearn kfold",
                    "using the classify function",
                    "optimal value of k for dataset"
                ]
            },
            {
                "code": "!ls -al {shared_data_path}/train/cat.*.jpg | wc -l\n!ls -al {shared_data_path}/train/dog.*.jpg | wc -l",
                "true_label": "",
                "top5_preds": [
                    "running a local postgres database",
                    "matrix addition and scalar matrix multiplication",
                    "postgres sql lab",
                    "reading and writing binary files",
                    "add string to list using append"
                ]
            },
            {
                "code": "%matplotlib inline\n\nfrom PIL import Image\nimport matplotlib.pyplot as plt\n\ntest_img = Image.open('dog.jpg')\nplt.imshow(test_img)",
                "true_label": "working with images",
                "top5_preds": [
                    "plot using matplotlib",
                    "matplotlib",
                    "plotting in python",
                    "plotting",
                    "line plot with a dataframe"
                ]
            },
            {
                "code": "#!wget https://gist.githubusercontent.com/yrevar/942d3a0ac09ec9e5eb3a/raw/596b27d23537e5a1b5751d2b0481ef172f58b539/imagenet1000_clsid_to_human.txt\nimport ast\nfrom keras.preprocessing.image import load_img, img_to_array\nimport numpy as np\n\nwith open('imagenet1000_clsid_to_human.txt') as imagenet1kclasses_file:\n    imagenet_classes = ast.literal_eval(imagenet1kclasses_file.read())\n\nresized_img = load_img('dog.jpg', target_size=(224, 224))\nplt.imshow(resized_img)\nimg_array = np.asarray([img_to_array(resized_img)])\n\npredictions = pretrained_model.predict(img_array, batch_size=1)\n\ntop5indices = np.argsort(predictions, axis=1)[0][::-1][:5]\ntop5predictions = [(imagenet_classes[i], predictions[0][i]) for i in top5indices]\nprint('top 5 predictions', top5predictions)",
                "true_label": "setup, prerequisites, and image classification",
                "top5_preds": [
                    "what is scikit learn?",
                    "tensorflow + keras",
                    "convert text data into vector",
                    "loading json in python",
                    "importing data with numpy"
                ]
            },
            {
                "code": "resized_img = load_img('nonimagenet.jpg', target_size=(224, 224))\nplt.imshow(resized_img)\nimg_array = np.asarray([img_to_array(resized_img)])\n\npredictions = pretrained_model.predict(img_array, batch_size=1)\n\ntop5indices = np.argsort(predictions, axis=1)[0][::-1][:5]\ntop5predictions = [(imagenet_classes[i], predictions[0][i]) for i in top5indices]\nprint('top 5 predictions', top5predictions)",
                "true_label": "",
                "top5_preds": [
                    "predicting a categorical response",
                    "predicting a continuous response using linear regression",
                    "polynomial regression with sklearn",
                    "classification with a cnn",
                    "using the classify function"
                ]
            },
            {
                "code": "pretrained_model.summary()",
                "true_label": "print the summary statistics",
                "top5_preds": [
                    "tensorflow + keras",
                    "what is scikit learn?",
                    "logistic regression using tensorflow",
                    "import polynomial features from sklearn",
                    "build a vector of prediction from the trained model"
                ]
            },
            {
                "code": "from IPython.display import SVG\nfrom keras.utils.visualize_util import model_to_dot\n\nSVG(model_to_dot(pretrained_model).create(prog='dot', format='svg'))",
                "true_label": "working with images",
                "top5_preds": [
                    "graph",
                    "import polynomial features from sklearn",
                    "create a graph",
                    "what is scikit learn?",
                    "polynomial regression with sklearn"
                ]
            },
            {
                "code": "from tf_viz import show_graph\nimport tensorflow as tf\n\nshow_graph(tf.get_default_graph().as_graph_def())",
                "true_label": "graph",
                "top5_preds": [
                    "tensorflow + keras",
                    "tensorflow",
                    "graph",
                    "create a graph",
                    "directed graph"
                ]
            },
            {
                "code": "from keras.layers import Input\n\npixels = 224\ncolor_channels = 3\nbase_model = VGG16(include_top=False, input_tensor=Input(shape=(pixels, pixels, color_channels)))",
                "true_label": "",
                "top5_preds": [
                    "tensorflow + keras",
                    "import polynomial features from sklearn",
                    "what is scikit learn?",
                    "simple convolutional neural network",
                    "polynomial regression with sklearn"
                ]
            },
            {
                "code": "from keras.preprocessing.image import ImageDataGenerator\n\nbatch_size = int(64 / simultaneous_users_count)\ntarget_size = (pixels, pixels)\n\ndata_generator = ImageDataGenerator()\ntraining_generator = data_generator.flow_from_directory(training_path, \n                                                        target_size=target_size, \n                                                        batch_size=batch_size, \n                                                        class_mode=None, \n                                                        shuffle=False)\nvalidation_generator = data_generator.flow_from_directory(validation_path, \n                                                          target_size=target_size, \n                                                          batch_size=batch_size, \n                                                          class_mode=None, \n                                                          shuffle=False)",
                "true_label": "",
                "top5_preds": [
                    "tensorflow + keras",
                    "pipeline of tf idf",
                    "read the dataset",
                    "keras sequential model",
                    "optimal value of k for dataset"
                ]
            },
            {
                "code": "training_intermediate_output = base_model.predict_generator(training_generator, len(training_filepaths))\nvalidation_intermediate_output = base_model.predict_generator(validation_generator, len(validation_filepaths))",
                "true_label": "",
                "top5_preds": [
                    "tensorflow + keras",
                    "import polynomial features from sklearn",
                    "what is scikit learn?",
                    "logistic regression using tensorflow",
                    "polynomial regression with sklearn"
                ]
            },
            {
                "code": "from bcolz_files import save_array\n\n!rm -rf {current_data_path}/*.bcolz\n\nsave_array(current_data_path + '/training.bcolz', training_intermediate_output)\nsave_array(current_data_path + '/validation.bcolz', validation_intermediate_output)",
                "true_label": "",
                "top5_preds": [
                    "convert list to numpy array",
                    "reading and writing binary files",
                    "numpy",
                    "numpy arrays",
                    "numpy binary files npy, npz"
                ]
            },
            {
                "code": "print(len(image_dimensions_counts))",
                "true_label": "",
                "top5_preds": [
                    "sum all the numbers in a list",
                    "reading featurecounts",
                    "working with image data cnns",
                    "equally spaced numbers on a grid",
                    "counting triangles in a social network"
                ]
            },
            {
                "code": "import operator\n\nsorted(image_dimensions_counts.items(), key=operator.itemgetter(1), reverse=True)[:10]",
                "true_label": "",
                "top5_preds": [
                    "remove duplicates from a list",
                    "find maximum and the minimum value in a set",
                    "find the most common words",
                    "counting triangles in a social network",
                    "equally spaced numbers on a grid"
                ]
            },
            {
                "code": "from keras.applications.vgg16 import VGG16\n\npretrained_model = VGG16()",
                "true_label": "",
                "top5_preds": [
                    "tensorflow + keras",
                    "logistic regression using tensorflow",
                    "what is scikit learn?",
                    "import polynomial features from sklearn",
                    "using the model for prediction"
                ]
            },
            {
                "code": "cat_training_images_filepaths = glob(os.path.join(training_path + '/cat', \"*.*.*\"))\ncat_training_images_count = len(cat_training_images_filepaths)\n\ndog_training_images_filepaths = glob(os.path.join(training_path + '/dog', \"*.*.*\"))\ndog_training_images_count = len(dog_training_images_filepaths)\n\n\ncat_validation_images_filepaths = glob(os.path.join(validation_path + '/cat', '*.*.*'))\ndog_validation_images_filepaths = glob(os.path.join(validation_path + '/dog', '*.*.*'))\ncat_validation_images_count = len(cat_validation_images_filepaths)\ndog_validation_images_count = len(dog_validation_images_filepaths)",
                "true_label": "",
                "top5_preds": [
                    "sum all the numbers in a list",
                    "find the most common words",
                    "load table in pandas",
                    "write a function that counts the number of times a given pattern appears in a string, including overlap",
                    "read numbers until and print their mean and standard deviation without using a list"
                ]
            },
            {
                "code": "bottleneck_training_labels = np.array([0] * cat_training_images_count + [1] * dog_training_images_count)\nbottleneck_validation_labels = np.array([0] * cat_validation_images_count + [1] * dog_validation_images_count)",
                "true_label": "",
                "top5_preds": [
                    "predicting a continuous response using linear regression",
                    "predicting a categorical response",
                    "ridge regression with one predictor on a grid",
                    "ridge regression with polynomial features on a grid",
                    "generating names with recurrent neural networks"
                ]
            },
            {
                "code": "show([validation_filepaths[i] for i in worst_cat_prediction_indices])",
                "true_label": "",
                "top5_preds": [
                    "formatting datetimes as strings",
                    "check accuracy / score for a logistic classifier",
                    "predicting a continuous response using linear regression",
                    "import polynomial features from sklearn",
                    "trend lines in pyplot"
                ]
            },
            {
                "code": "from img_stats import dimension_counts\n\nimage_dimensions_counts = dimension_counts(shared_training_images_filepaths)",
                "true_label": "",
                "top5_preds": [
                    "sum all the numbers in a list",
                    "what is the number of observations in each dataset?",
                    "detect the number of local variables declared in a function",
                    "reading featurecounts",
                    "how many different items appear in the dataset?"
                ]
            },
            {
                "code": "\nfrom PIL import Image\nimport matplotlib.pyplot as plt\n\ntest_img = Image.open('dog.jpg')\nplt.imshow(test_img)",
                "true_label": "",
                "top5_preds": [
                    "plot using matplotlib",
                    "matplotlib",
                    "plotting in python",
                    "line plot with a dataframe",
                    "working with images"
                ]
            }
        ],
        [
            {
                "code": "import pandas as pd\nfrom io import StringIO\ncsv_data = '''A,B,C,D,E,F\n1.0, 2.0, 3.0, 4.0, 5.0, 6.0\n5.0, 6.0,, 8.0,,\n10.0, 11.0, 12.0,,13.0,\n13.0, 5.0, 4.0, 9.0, 11.0, 6.0\n11.0,,,, 18.0, 7.0\n21.0, 8.0, 22.0, 7.0,, 1.0\n'''",
                "true_label": "",
                "top5_preds": [
                    "formatting datetimes as strings",
                    "convert date to datetime format",
                    "convert text data into vector",
                    "equally spaced numbers on a grid",
                    "importing data with numpy"
                ]
            },
            {
                "code": "df = pd.read_csv(StringIO(csv_data))\ndf",
                "true_label": "",
                "top5_preds": [
                    "loading a csv into a dataframe",
                    "load table in pandas",
                    "from dictionary to dataframe",
                    "importing data with pandas",
                    "importing data with numpy"
                ]
            },
            {
                "code": "df.isnull().sum() # count number of NAN",
                "true_label": "",
                "top5_preds": [
                    "computing the covariance when there are nan s",
                    "drop the rows with nan values",
                    "sum with nan",
                    "find data type of each column",
                    "calculating the mean of a vector with nans"
                ]
            },
            {
                "code": "df.dropna(axis=0) # Delete raws which contains NAN. df.dropna() is also OK.",
                "true_label": "",
                "top5_preds": [
                    "drop the rows with nan values",
                    "drop nan values",
                    "drop data points with missing data",
                    "drop na values",
                    "dataframe methods"
                ]
            },
            {
                "code": "df.dropna(axis=1) # Delete coloums which contains NAN.",
                "true_label": "",
                "top5_preds": [
                    "drop the rows with nan values",
                    "delete column by name",
                    "find data type of each column",
                    "drop data points with missing data",
                    "drop nan values"
                ]
            },
            {
                "code": "df.dropna(how='all') # Delete raws if all of number of the raws are NAN",
                "true_label": "",
                "top5_preds": [
                    "drop the rows with nan values",
                    "drop nan values",
                    "drop data points with missing data",
                    "create dataframe with given values",
                    "delete column by name"
                ]
            },
            {
                "code": "df.dropna(thresh=4) #Delete raws if number of non-NAN is less than 4 in the raws.",
                "true_label": "",
                "top5_preds": [
                    "drop the rows with nan values",
                    "drop nan values",
                    "drop data points with missing data",
                    "drop na values",
                    "select every row after a specific row"
                ]
            },
            {
                "code": "df.dropna(subset=['C']) # Delete raws if NAN exist in the column C.",
                "true_label": "",
                "top5_preds": [
                    "drop the rows with nan values",
                    "drop data points with missing data",
                    "delete column by name",
                    "drop nan values",
                    "find data type of each column"
                ]
            },
            {
                "code": "df",
                "true_label": "",
                "top5_preds": [
                    "create a one column dataframe with the values of a series",
                    "create dataframe with given values",
                    "create a dataframe by joining series by column",
                    "dataframe methods",
                    "line plot with a dataframe"
                ]
            },
            {
                "code": "from sklearn.preprocessing import Imputer",
                "true_label": "",
                "top5_preds": [
                    "import polynomial features from sklearn",
                    "scikit learn",
                    "what is scikit learn?",
                    "polynomial regression with sklearn",
                    "shortcut principal component analysis in scikit learn"
                ]
            },
            {
                "code": "imr = Imputer(missing_values='NaN', strategy='mean', axis=0) # mean imputation column-direction\nimr = imr.fit(df)\nimputed_data = imr.transform(df.values)\nimputed_data",
                "true_label": "",
                "top5_preds": [
                    "import polynomial features from sklearn",
                    "dataframe methods",
                    "transform categorical data into binary features",
                    "find data type of each column",
                    "calculating the mean of a vector with nans"
                ]
            },
            {
                "code": "imr = Imputer(missing_values='NaN', strategy='mean', axis=1)\nimr = imr.fit(df)\nimputed_data = imr.transform(df.values)\nimputed_data",
                "true_label": "",
                "top5_preds": [
                    "import polynomial features from sklearn",
                    "dataframe methods",
                    "find data type of each column",
                    "transform categorical data into binary features",
                    "fit a polynomial"
                ]
            },
            {
                "code": "X = df[['color', 'size', 'price']].values\nX",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "dataframe methods",
                    "using a dataframe and matplotlib commands",
                    "load table in pandas",
                    "create a one column dataframe with the values of a series"
                ]
            },
            {
                "code": "color_le = LabelEncoder()\nX[:, 0] = color_le.fit_transform(X[:, 0])\nX",
                "true_label": "",
                "top5_preds": [
                    "import polynomial features from sklearn",
                    "polynomial regression with sklearn",
                    "predicting a continuous response using linear regression",
                    "logistic regression using tensorflow",
                    "logistic regression using scikit learn"
                ]
            },
            {
                "code": "from sklearn.preprocessing import OneHotEncoder\nohe = OneHotEncoder(categorical_features=[0])\nohe.fit_transform(X).toarray()",
                "true_label": "",
                "top5_preds": [
                    "import polynomial features from sklearn",
                    "what is scikit learn?",
                    "transform categorical data into binary features",
                    "polynomial regression with sklearn",
                    "tensorflow + keras"
                ]
            },
            {
                "code": "df\nsize_mapping = {'XL': 3, 'L':2, 'M':1}\ndf['size'] = df['size'].map(size_mapping)\ndf",
                "true_label": "",
                "top5_preds": [
                    "create a one column dataframe with the values of a series",
                    "convert data from string to float",
                    "pandas apply",
                    "create a dataframe by joining series by column",
                    "line plot with a dataframe"
                ]
            },
            {
                "code": "pd.get_dummies(df[['price', 'color', 'size']])",
                "true_label": "",
                "top5_preds": [
                    "transform categorical data into binary features",
                    "from dictionary to dataframe",
                    "load table in pandas",
                    "loading a csv into a dataframe",
                    "dataframe methods"
                ]
            },
            {
                "code": "df_wine = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data', header=None)\ndf_wine.columns = ['Class label', 'Alcohol', 'Malic acid', 'Ash', 'Alcalunuty of ash', 'Magnesium',\n                   'Total phenols', 'Flavanoids', 'Nonflavanoid phenols', 'Proanthocyanins',\n                   'Color intensity', 'Hue', 'OD280/OD315 of diluted wines', 'Proline']\nprint('Class labels', np.unique(df_wine['Class label']))\ndf_wine.head()",
                "true_label": "",
                "top5_preds": [
                    "loading a csv into a dataframe",
                    "load table in pandas",
                    "importing data with numpy",
                    "importing data with pandas",
                    "from dictionary to dataframe"
                ]
            },
            {
                "code": "from sklearn.cross_validation import train_test_split\nX, y = df_wine.iloc[:, 1:].values, df_wine.iloc[:, 0].values\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)",
                "true_label": "",
                "top5_preds": [
                    "what is scikit learn?",
                    "import polynomial features from sklearn",
                    "use sklearn kfold",
                    "scikit learn",
                    "perform a train test split on the data"
                ]
            },
            {
                "code": "inv_class_mapping =  {v: k for k, v in class_mapping.items()}\ninv_class_mapping",
                "true_label": "",
                "top5_preds": [
                    "convert a tuple to a dictionary",
                    "from dictionary to dataframe",
                    "remove duplicates from a list",
                    "Create a dictionary with ICD9 code as keys",
                    "import polynomial features from sklearn"
                ]
            },
            {
                "code": "df['classlabel'] = df['classlabel'].map(inv_class_mapping)\ndf",
                "true_label": "",
                "top5_preds": [
                    "from dictionary to dataframe",
                    "import polynomial features from sklearn",
                    "what is scikit learn?",
                    "transform categorical data into binary features",
                    "convert text data into vector"
                ]
            },
            {
                "code": "from sklearn.preprocessing import LabelEncoder\nclass_le = LabelEncoder()\ndf['classlabel'] = class_le.fit_transform(df['classlabel'].values)\ndf",
                "true_label": "",
                "top5_preds": [
                    "what is scikit learn?",
                    "import polynomial features from sklearn",
                    "using the classify function",
                    "polynomial regression with sklearn",
                    "logistic regression using tensorflow"
                ]
            },
            {
                "code": "imr = Imputer(missing_values='NaN', strategy='median', axis=1)\nimr = imr.fit(df)\nimputed_data = imr.transform(df.values)\nimputed_data",
                "true_label": "",
                "top5_preds": [
                    "import polynomial features from sklearn",
                    "dataframe methods",
                    "find data type of each column",
                    "transform categorical data into binary features",
                    "predicting a categorical response"
                ]
            },
            {
                "code": "imr = Imputer(missing_values='NaN', strategy='most_frequent', axis=1)\nimr = imr.fit(df)\nimputed_data = imr.transform(df.values)\nimputed_data",
                "true_label": "",
                "top5_preds": [
                    "import polynomial features from sklearn",
                    "dataframe methods",
                    "transform categorical data into binary features",
                    "predicting a categorical response",
                    "find data type of each column"
                ]
            },
            {
                "code": "import pandas as pd\n\ndf = pd.DataFrame([\n    ['green', 'M', 10.1, 'class1'],\n    ['red', 'L', 9.2, 'class2'],\n    ['blue', 'XL', 12.1, 'class1']\n])\ndf.columns = ['color', 'size', 'price', 'classlabel']\ndf",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "create a one column dataframe with the values of a series",
                    "using a dataframe and matplotlib commands",
                    "dataframe methods",
                    "load table in pandas"
                ]
            },
            {
                "code": "df['size'] = df['size'].map(inv_size_mapping)\ndf",
                "true_label": "",
                "top5_preds": [
                    "create a one column dataframe with the values of a series",
                    "create a dataframe by joining series by column",
                    "from dictionary to dataframe",
                    "pandas apply",
                    "convert data from string to float"
                ]
            },
            {
                "code": "import numpy as np\nnp.unique(df['classlabel'])",
                "true_label": "",
                "top5_preds": [
                    "transform categorical data into binary features",
                    "import polynomial features from sklearn",
                    "line plot with a dataframe",
                    "using the classify function",
                    "find data type of each column"
                ]
            },
            {
                "code": "enumerate(np.unique(df['classlabel']))",
                "true_label": "",
                "top5_preds": [
                    "using the classify function",
                    "line plot with a dataframe",
                    "transform categorical data into binary features",
                    "what is scikit learn?",
                    "import polynomial features from sklearn"
                ]
            },
            {
                "code": "#enumerate function yields the elements of an iterator, as well as an index number:\nlist1 = ['a', 'b', 'c']\nfor (i, x) in enumerate(list1):\n    print(i,x)",
                "true_label": "",
                "top5_preds": [
                    "sum all the numbers in a list",
                    "multiply all the numbers in a list",
                    "convert list to numpy array",
                    "replace last value of tuples in a list",
                    "remove duplicates from a list"
                ]
            },
            {
                "code": "import numpy as np\nclass_mapping = {label:idx for idx, label in enumerate(np.unique(df['classlabel']))}\nclass_mapping",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "transform categorical data into binary features",
                    "using the classify function",
                    "import polynomial features from sklearn",
                    "importing data with numpy"
                ]
            },
            {
                "code": "df['classlabel'] = df['classlabel'].map(class_mapping)\ndf",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "pandas apply",
                    "load table in pandas",
                    "from dictionary to dataframe",
                    "import polynomial features from sklearn"
                ]
            },
            {
                "code": "size_mapping = {'XL': 3, 'L':2, 'M':1}\ndf['size'] = df['size'].map(size_mapping)\ndf",
                "true_label": "",
                "top5_preds": [
                    "create a one column dataframe with the values of a series",
                    "convert data from string to float",
                    "line plot with a dataframe",
                    "create a dataframe by joining series by column",
                    "pandas apply"
                ]
            },
            {
                "code": "inv_size_mapping =  {v: k for k, v in size_mapping.items()}\ninv_size_mapping",
                "true_label": "",
                "top5_preds": [
                    "convert a tuple to a dictionary",
                    "from dictionary to dataframe",
                    "remove duplicates from a list",
                    "sum all the numbers in a list",
                    "create an array of integers"
                ]
            },
            {
                "code": "import numpy as np\nnp.unique(df['classlabel'])",
                "true_label": "",
                "top5_preds": [
                    "transform categorical data into binary features",
                    "import polynomial features from sklearn",
                    "line plot with a dataframe",
                    "using the classify function",
                    "find data type of each column"
                ]
            }
        ],
        [
            {
                "code": "%matplotlib inline\nimport os\nimport shutil\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport pyemu\nimport platform\nimport pestools as pt\nif 'window' in platform.platform().lower():\n    ppp = 'pest++'\n    pestchek = 'pestchek'\n    inschek = 'inschek'\n    tempchek = 'tempchek'\nelse:\n    ppp = './pestpp'\n    pestchek = './pestchek'\n    inschek = './inschek'\n    tempchek = './tempchek'",
                "true_label": "",
                "top5_preds": [
                    "plot using matplotlib",
                    "timing, numpy, plotting",
                    "plotting in python",
                    "using a dataframe and matplotlib commands",
                    "matplotlib"
                ]
            },
            {
                "code": "base_dir = os.path.join(\"..\",\"..\",\"models\",\"Freyberg\",\"Freyberg_K\")\nassert os.path.exists(base_dir)\n[shutil.copy2(os.path.join(base_dir,f),f) for f in os.listdir(base_dir)];\n\npst = pyemu.Pst(\"freyberg.pst\")\npst.control_data.noptmax = 0\npst.write(\"freyberg.pst\")",
                "true_label": "",
                "top5_preds": [
                    "importing data with numpy",
                    "scipy",
                    "import polynomial features from sklearn",
                    "numpy",
                    "convert list to numpy array"
                ]
            },
            {
                "code": "os.system(\"{0} freyberg.rch.tpl\".format(tempchek))",
                "true_label": "",
                "top5_preds": [
                    "formatting datetimes as strings",
                    "convert date to datetime format",
                    "setup and re introduction to python",
                    "reading and writing binary files",
                    "heatmap with time"
                ]
            },
            {
                "code": "os.system(\"{0} hk.ref.tpl\".format(tempchek))",
                "true_label": "",
                "top5_preds": [
                    "formatting datetimes as strings",
                    "setup and re introduction to python",
                    "obtaining metadata from crossref",
                    "heatmap with time",
                    "scikit learn"
                ]
            },
            {
                "code": "os.system(\"{0} freyberg.heads.ins freyberg.heads\".format(inschek))",
                "true_label": "",
                "top5_preds": [
                    "import polynomial features from sklearn",
                    "nltk to recognize a book",
                    "scikit learn",
                    "what is scikit learn?",
                    "join two dataframes along rows"
                ]
            },
            {
                "code": "os.system(\"{0} freyberg.pst\".format(pestchek))",
                "true_label": "",
                "top5_preds": [
                    "the scientific python ecosystem",
                    "formatting datetimes as strings",
                    "ridge regression with one predictor on a grid",
                    "importing data with numpy",
                    "nltk to recognize a book"
                ]
            },
            {
                "code": "os.system(\"{0} freyberg.pst\".format(ppp))",
                "true_label": "",
                "top5_preds": [
                    "ridge regression with one predictor on a grid",
                    "importing data with numpy",
                    "ridge regression with polynomial features on a grid",
                    "formatting datetimes as strings",
                    "convert date to datetime format"
                ]
            },
            {
                "code": "pst = pyemu.Pst(\"freyberg.pst\")\npst.control_data.noptmax = 20\npst.write(\"freyberg.pst\")",
                "true_label": "",
                "top5_preds": [
                    "ridge regression with one predictor on a grid",
                    "using logistic regression instead",
                    "importing data with numpy",
                    "plot using matplotlib",
                    "using statsmodels, fit an ols regression"
                ]
            },
            {
                "code": "df_obj = pd.read_csv(\"freyberg.iobj\",index_col=0)\ndf_obj",
                "true_label": "",
                "top5_preds": [
                    "loading a csv into a dataframe",
                    "load table in pandas",
                    "from dictionary to dataframe",
                    "working with pandas series indexed by datetime",
                    "importing data with pandas"
                ]
            },
            {
                "code": "res = pt.Res('freyberg.rei')\n\nres.describe_groups('head_cal')",
                "true_label": "",
                "top5_preds": [
                    "line plots show the trend of a numerical variable over time",
                    "integrating datetime tools with pandas for time series",
                    "predicting a categorical response",
                    "ploting out data with box plots",
                    "line plot with a dataframe"
                ]
            },
            {
                "code": "res.plot_one2one('head_cal',print_stats=['Mean', 'MAE', 'RMSE'])",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "using a dataframe and matplotlib commands",
                    "line plots show the trend of a numerical variable over time",
                    "ploting out data with box plots",
                    "pandas plotting"
                ]
            },
            {
                "code": "res.plot_measured_vs_residual('head_cal')",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "line plots show the trend of a numerical variable over time",
                    "ploting out data with box plots",
                    "using a dataframe and matplotlib commands",
                    "plotting time series with pandas"
                ]
            },
            {
                "code": "df_paru = pd.read_csv(\"freyberg.par.usum.csv\")\ndf_paru",
                "true_label": "",
                "top5_preds": [
                    "importing data with numpy",
                    "importing data with pandas",
                    "loading a csv into a dataframe",
                    "create a one column dataframe with the values of a series",
                    "convert date to datetime format"
                ]
            },
            {
                "code": "df_predu = pd.read_csv(\"freyberg.pred.usum.csv\",index_col=0)\ndf_predu",
                "true_label": "",
                "top5_preds": [
                    "loading a csv into a dataframe",
                    "load table in pandas",
                    "from dictionary to dataframe",
                    "dataframe methods",
                    "importing data with numpy"
                ]
            },
            {
                "code": "for forecast in df_predu.index:\n    ax = df_predu.loc[forecast,[\"prior_stdev\",\"post_stdev\"]].plot(kind=\"bar\")\n    ax.set_title(forecast)\n    plt.show()",
                "true_label": "",
                "top5_preds": [
                    "plot the data",
                    "line plot with a dataframe",
                    "pandas plotting",
                    "plot the training",
                    "pandas plotting documentation"
                ]
            },
            {
                "code": "df_predu.loc[:,\"percent_reduction\"] = 100.0 * (1.0 - (df_predu.post_stdev / df_predu.prior_stdev))\ndf_predu.percent_reduction",
                "true_label": "",
                "top5_preds": [
                    "predicting a categorical response",
                    "relationships between dataframes",
                    "pandas apply",
                    "what is conditional probability good for?",
                    "create a one column dataframe with the values of a series"
                ]
            }
        ],
        [
            {
                "code": "%matplotlib inline\n\nimport seaborn as sb\nimport numpy as np\n\nwords = ['queen', 'book', 'king', 'magazine', 'car', 'bike']\nvectors = np.array([[0.1,   0.3],  # queen\n                    [-0.5, -0.1],  # book\n                    [0.2,   0.2],  # king\n                    [-0.3, -0.2],  # magazine\n                    [-0.5,  0.4],  # car\n                    [-0.45, 0.3]]) # bike\n\nsb.plt.plot(vectors[:,0], vectors[:,1], 'o')\nsb.plt.xlim(-0.6, 0.3)\nsb.plt.ylim(-0.3, 0.5)\nfor word, x, y in zip(words, vectors[:,0], vectors[:,1]):\n    sb.plt.annotate(word, (x, y), size=12)",
                "true_label": "",
                "top5_preds": [
                    "equally spaced numbers on a grid",
                    "fit a polynomial",
                    "create an array of linearly spaced points",
                    "plot using matplotlib",
                    "matplotlib"
                ]
            },
            {
                "code": "# Word2vec\nfrom IPython.display import IFrame\nIFrame('https://player.vimeo.com/video/112168934', width=800, height=600)\n",
                "true_label": "",
                "top5_preds": [
                    "using python, ipython,",
                    "convert text data into vector",
                    "what is scikit learn?",
                    "plot multidimensional data in two dimensions",
                    "plot using matplotlib"
                ]
            },
            {
                "code": "### Using the model\n###### Similarities\n%matplotlib inline\n\nfrom gensim.models.word2vec import Word2Vec\nfrom sklearn.manifold import TSNE\nimport numpy as np\nimport bokeh\nfrom bokeh.charts import Scatter, output_notebook, show\nfrom bokeh.plotting import figure, show, output_file\n\nmodel = Word2Vec.load_word2vec_format('/Users/bowang/Dropbox/fivegram_embedding_model.txt', binary=False)\ntsne = TSNE(n_components=2, random_state=0)\nparty_leaders=['miliband','clegg','bennett','sturgeon','farage','cameron']\nleader_vec=[]\n#Create a list of vectors for party leaders\nfor p in party_leaders:\n    leader_vec.append(model[p])\nleader_vec=np.asarray(leader_vec)\n#Mapping it to 2D space\nleader_vec=tsne.fit_transform(leader_vec)\n\np=figure(title=\"Who are these people?\")\noutput_notebook()\np.circle(leader_vec[:,0],leader_vec[:,1])\nfor party_leader, x, y in zip(party_leaders, leader_vec[:,0], leader_vec[:,1]):\n    p.text([x],[y],text=[party_leader])",
                "true_label": "",
                "top5_preds": [
                    "import polynomial features from sklearn",
                    "what is scikit learn?",
                    "use sklearn kfold",
                    "scikit learn",
                    "line plot with a dataframe"
                ]
            },
            {
                "code": "show(p)",
                "true_label": "",
                "top5_preds": [
                    "visualizing uncertainty",
                    "create an array of linearly spaced points",
                    "numpy point",
                    "plot using matplotlib",
                    "trend lines in pyplot"
                ]
            },
            {
                "code": "### Using the model\n###### Clustering\nfrom gensim.models.word2vec import Word2Vec\nfrom sklearn.cluster import KMeans\nimport numpy as np\nimport time\n\nmodel = Word2Vec.load_word2vec_format('/Users/bowang/Downloads/GoogleNews-vectors-negative300.bin', binary=True)\n#We want cluster 'britain' related 300 terms\nwords = [i[0] for i in model.most_similar_cosmul('britain',topn=300)]\nword_vectors = [model[w] for w in words]\nword_vectors=np.asarray(word_vectors)\n\nstart = time.time()\nnum_clusters = 60\n#Initalize k-means to extract centroids\nkmeans_clustering = KMeans( n_clusters = num_clusters )\nidx = kmeans_clustering.fit_predict( word_vectors )\nend = time.time()\nelapsed = end - start\nprint \"Time taken for K Means clustering: \", elapsed, \"seconds.\"\n\n#Create a {word: cluster no.} dictionary.\nword_centroid_map = dict(zip( words, idx ))\n#Print 10 terms in the first 10 clusters\nfor cluster in xrange(0,10): \n    print \"\\nCluster %d\" % cluster\n    words = []\n    for i in xrange(0,len(word_centroid_map.values())):\n        if( word_centroid_map.values()[i] == cluster ):\n            words.append(word_centroid_map.keys()[i])\n    print words[:10]",
                "true_label": "",
                "top5_preds": [
                    "import polynomial features from sklearn",
                    "load the kmeans class from sklearn cluster",
                    "implementing bag of words in scikit learn",
                    "use sklearn kfold",
                    "what is scikit learn?"
                ]
            },
            {
                "code": "#Result:",
                "true_label": "",
                "top5_preds": [
                    "equally spaced numbers on a grid",
                    "counting triangles in a social network",
                    "what is scikit learn?",
                    "attributes of geometries points",
                    "import polynomial features from sklearn"
                ]
            },
            {
                "code": "### Using the model\n###### Topic Modelling \nimport cPickle\nfrom gensim import corpora\nfrom gensim.models import ldamodel, tfidfmodel\nfrom operator import itemgetter\n\n#Load already preprocessed and tokenized data:\ndata = cPickle.load(open('/Users/bowang/Data/uk-election-data/topics/tweet_content.p', 'rb'))\n\n#Build dictionary aka mapping between words and their ids:\ndictionary = corpora.Dictionary(data)\nprint 'This dictionary has %i unique tokens'%(len(dictionary))\n\n#Convert tokenized data to vectors:\ncorpus = [dictionary.doc2bow(text) for text in data]\nn_topics = 10\nlda = ldamodel.LdaModel(corpus, id2word=dictionary, num_topics=n_topics, alpha='auto')\n\n#lda.print_topics()\nfor i in range(0, n_topics):\n    temp = lda.show_topic(i, 10)\n    terms = []\n    for term in temp:\n        terms.append(term[1])\n    print \"Top 10 terms for topic #\" + str(i) + \": \"+ \", \".join(terms)",
                "true_label": "",
                "top5_preds": [
                    "what is scikit learn?",
                    "implementing bag of words in scikit learn",
                    "import polynomial features from sklearn",
                    "tensorflow + keras",
                    "logistic regression using tensorflow"
                ]
            },
            {
                "code": "from gensim.models.phrases import Phrases\nimport cPickle as pickle\n\nwith open('.../tokenized_tweets.pkl','rb') as fp:\n    data=pickle.load(fp)\nbigram = Phrases(data, min_count=5, threshold=10.0)\ntrigram = Phrases(bigram[data], min_count=5, threshold=7.0)\nfourgram = Phrases(trigram[bigram[data]], min_count=5, threshold=6.0)\nfivegram = Phrases(fourgram[trigram[bigram[data]]], min_count=5, threshold=5.0)",
                "true_label": "",
                "top5_preds": [
                    "implementing bag of words in scikit learn",
                    "what is scikit learn?",
                    "logistic regression using tensorflow",
                    "import polynomial features from sklearn",
                    "in a pickle"
                ]
            },
            {
                "code": "from gensim.models.phrases import Phrases\nfrom gensim.models.word2vec import Word2Vec\n\n# Preprocessing your data\n\n# Generate phrases if you wish so, using gensim.models.phrases\n\n# Training:\nmodel = Word2Vec(fivegram[data], sg = 1, size = 300, window = 5, workers = 4, hs = 1, min_count = 5, sample = 1e-3)\n## Save in a format compatible with the original word2vec implementation:\nmodel.save_word2vec_format('../word_embedding.model.txt')\n## Trim unneeded model memory\n## You cannot continue training after doing a replace:\nmodel.init_sims(replace=True)",
                "true_label": "",
                "top5_preds": [
                    "implementing bag of words in scikit learn",
                    "what is scikit learn?",
                    "logistic regression using tensorflow",
                    "fit a logistic regression model using statsmodels using logistic regression formula in patsy",
                    "import polynomial features from sklearn"
                ]
            }
        ],
        [
            {
                "code": "import math\nimport datetime\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport scipy as sp\n\nfrom os import listdir\nfrom os.path import isfile, join\nfrom sklearn import linear_model\nfrom pandas import Series\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\n\n# inline matplotlib plots\n%matplotlib inline\nplt.rcParams['figure.figsize'] = 8, 6  # default image size\n\n# all pandas prints will have this format\npd.options.display.float_format = '{:,.3f}'.format\npd.set_option(\"display.max_columns\", 100)\npd.set_option('display.max_rows', 200)",
                "true_label": "",
                "top5_preds": [
                    "import polynomial features from sklearn",
                    "scipy",
                    "polynomial regression with sklearn",
                    "importing data with numpy",
                    "fit a polynomial"
                ]
            },
            {
                "code": "path = 'data'\n\nairlines = pd.read_csv(join(path, 'airlines.csv'))\nairports = pd.read_csv(join(path, 'airports.csv'))\n# I'm specifiying different types for each column due to memory consumption\nflights =  pd.read_csv(join(path, 'flights_until_june.csv'),\n                     dtype={'air_system_delay': 'float32',\n                            'air_time': 'float32',\n                            'airline': 'category',\n                            'airline_delay': 'float32',\n                            'arrival_delay': 'float32',\n                            'arrival_time': 'float32',\n                            'cancellation_reason': 'category',\n                            'cancelled': 'bool',\n                            'day': 'int32',\n                            'day_of_week': 'int32',\n                            'departure_delay': 'float32',\n                            'departure_time': 'float32',\n                            'destination_airport': 'object',\n                            'distance': 'int32',\n                            'diverted': 'bool',\n                            'elapsed_time': 'float32',\n                            'flight_number': 'int32',\n                            'late_aircraft_delay': 'float32',\n                            'month': 'int32',\n                            'origin_airport': 'object',\n                            'scheduled_arrival': 'float32',\n                            'scheduled_departure': 'float32',\n                            'scheduled_time': 'float32',\n                            'security_delay': 'float32',\n                            'tail_number': 'object',\n                            'taxi_in': 'float32',\n                            'taxi_out': 'float32',\n                            'weather_delay': 'float32',\n                            'wheels_off': 'float32',\n                            'wheels_on': 'float32',\n                            'year': 'int32'}\n    )",
                "true_label": "",
                "top5_preds": [
                    "importing data with numpy",
                    "importing data with pandas",
                    "loading a csv into a dataframe",
                    "from dictionary to dataframe",
                    "load table in pandas"
                ]
            },
            {
                "code": "assert airlines.shape == (14, 2)\nassert airports.shape == (322, 7)\nassert flights.shape == (2889512, 31)\n\nprint('airlines:', airlines.shape)\nprint('airports:', airports.shape)\nprint('flights:', flights.shape)",
                "true_label": "",
                "top5_preds": [
                    "numpy",
                    "convert list to numpy array",
                    "matrix operations in python",
                    "equally spaced numbers on a grid",
                    "numpy documentation"
                ]
            },
            {
                "code": "flights.set_index('date', inplace=True, drop=False)\nflights.index.names = ['date_index'] # avoid ambiguitiy with column 'date'",
                "true_label": "",
                "top5_preds": [
                    "working with pandas series indexed by datetime",
                    "convert date to datetime format",
                    "using pandas",
                    "plotting time series with pandas",
                    "in pandas"
                ]
            },
            {
                "code": "flights['date_ymd'] = flights.index.date\nflights[:'2015-02'].groupby('date_ymd').is_delayed.count().plot.line(ylim=(0,17000))",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "line plots show the trend of a numerical variable over time",
                    "plotting time series with pandas",
                    "formatting datetimes as strings",
                    "pandas plotting"
                ]
            },
            {
                "code": "g = flights.groupby('day_of_week').is_delayed.agg(['sum','count'])\ng.columns = ['delayed', 'flights']\n\ng.delayed = g.delayed / g.delayed.sum()\ng.flights = g.flights / g.flights.sum()\n\ng.plot.bar()",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "line plots show the trend of a numerical variable over time",
                    "use pandas to make a bar chart",
                    "pandas plotting",
                    "plotting time series with pandas"
                ]
            },
            {
                "code": "flights.pivot_table(values='is_delayed', index=['day_of_week'], columns=['airline'], aggfunc=np.mean)",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "dataframe methods",
                    "line plots show the trend of a numerical variable over time",
                    "load table in pandas",
                    "relationships between dataframes"
                ]
            },
            {
                "code": "# selecting necessary fields\nairports = airports[['iata_code', 'city', 'state']]\n\nflights_tmp = pd.merge(flights, airports, left_on='origin_airport', right_on = 'iata_code') # add origin_airport context information\nflights_context_info = pd.merge(flights_tmp, airports, left_on='destination_airport', right_on = 'iata_code', suffixes =('_origin','_destination')) # add destination_airport context information\n\n# free up RAM\ndel flights_tmp",
                "true_label": "",
                "top5_preds": [
                    "from dictionary to dataframe",
                    "join two dataframes along rows",
                    "join two dataframes along columns",
                    "relationships between dataframes",
                    "combine two dataframes into one"
                ]
            },
            {
                "code": "def add_temporal_features(df):\n    df['is_weekend'] = df.day_of_week.isin([5, 6]).astype(int)\n    df['is_monday'] = df.day_of_week.isin([0]).astype(int)\n    df['is_saturday'] = df.day_of_week.isin([5]).astype(int)\n\nfor d in datasets:\n    add_temporal_features(d)",
                "true_label": "",
                "top5_preds": [
                    "transform the date column as a datetime type",
                    "return a dataframe",
                    "date ranges and frequencies",
                    "convert date to datetime format",
                    "create a time column"
                ]
            },
            {
                "code": "for d in datasets:\n    d['is_risky_airline'] = d.airline.isin(['NK', 'F9', 'MQ', 'EV']).astype(int)\n    d['is_risky_origin_airline'] = d.origin_airport.isin(['ORD', 'DFW', 'DEN']).astype(int)\n    d['is_risky_destination_airport'] = d.destination_airport.isin(['ORD', 'DFW', 'DEN']).astype(int)",
                "true_label": "",
                "top5_preds": [
                    "helpers to read in dataset",
                    "read the dataset",
                    "find data type of each column",
                    "import the dataset",
                    "the iris dataset"
                ]
            },
            {
                "code": "risky_cities = 'newyork boston chicago sanfrancisco losangeles atlanta'.split()\n\ndef is_risky_city(city):\n    return city.replace(' ', '').lower() in risky_cities\n\nfor d in datasets:\n    d['is_risky_city'] = d.city_origin.map(is_risky_city) |  d.city_destination.map(is_risky_city)",
                "true_label": "",
                "top5_preds": [
                    "predicting a categorical response",
                    "remove null values from county, category, and category name",
                    "relationships between dataframes",
                    "concordance: words that co-occur with a word of interest",
                    "find all by term in field in case insensitive way"
                ]
            },
            {
                "code": "minimum = len(hist) * 0.01\norigin_airport = hist.origin_airport.value_counts()[lambda x: x > minimum].index.values\n\nhist[hist.origin_airport.isin(origin_airport)].groupby('origin_airport').is_delayed.mean().sort_values(ascending = False).head(10)",
                "true_label": "",
                "top5_preds": [
                    "predicting a categorical response",
                    "integrating datetime tools with pandas for time series",
                    "calculating the mean of a vector with nans",
                    "working with pandas series indexed by datetime",
                    "create a histogram of top items with filtering"
                ]
            },
            {
                "code": "for d in datasets:\n    d['origin_airport_ORD'] = d.origin_airport.map(lambda ori: 1 if ori == 'ORD' else 0)\n    d['origin_airport_DEN'] = d.origin_airport.map(lambda ori: 1 if ori == 'DEN' else 0)\n    d['origin_airport_PHL'] = d.origin_airport.map(lambda ori: 1 if ori == 'PHL' else 0)\n    d['origin_airport_LGA'] = d.origin_airport.map(lambda ori: 1 if ori == 'LGA' else 0)\n    d['origin_airport_DFW'] = d.origin_airport.map(lambda ori: 1 if ori == 'DFW' else 0)",
                "true_label": "",
                "top5_preds": [
                    "create a data dictionary",
                    "data given as a dictionary",
                    "from dictionary to dataframe",
                    "helpers to read in dataset",
                    "read the dataset"
                ]
            },
            {
                "code": "def z_score(df, column, mean, std):\n    return (df[column] - df[column].mean())/df[column].std(ddof=0)\n\nmean = hist.distance.mean()\nstd = hist.distance.std()\n\nfor d in datasets:\n    d['distance_normalized'] = z_score(d, 'distance', mean, std)",
                "true_label": "",
                "top5_preds": [
                    "predicting a categorical response",
                    "line plot with a dataframe",
                    "likelihood of the binomial distribution",
                    "normalize the data point",
                    "use numpy to generate an array of random numbers sampled from a standard normal distribution"
                ]
            },
            {
                "code": "train.distance.plot.hist()",
                "true_label": "",
                "top5_preds": [
                    "line plots show the trend of a numerical variable over time",
                    "line plot with a dataframe",
                    "trend lines in pyplot",
                    "timing, numpy, plotting",
                    "plot multidimensional data in two dimensions"
                ]
            },
            {
                "code": "train.distance_normalized.plot.hist()",
                "true_label": "",
                "top5_preds": [
                    "line plots show the trend of a numerical variable over time",
                    "line plot with a dataframe",
                    "predicting a categorical response",
                    "predicting a continuous response using linear regression",
                    "visualize the distribution histogram of x using sns distplot"
                ]
            },
            {
                "code": "train_bk = train.copy()\nvalidation_bk = validation.copy()\ntest_bk = test.copy()",
                "true_label": "",
                "top5_preds": [
                    "from dictionary to dataframe",
                    "convert list to numpy array",
                    "numpy",
                    "numpy arrays",
                    "what is scikit learn?"
                ]
            },
            {
                "code": "columns_to_keep = 'day_of_week scheduled_departure departure_time departure_delay scheduled_time scheduled_arrival is_delayed perc_delayed_flights_airline perc_delayed_flights_route avg_delay_city avg_delay_airline is_weekend is_monday is_saturday is_risky_airline is_risky_origin_airline is_risky_destination_airport is_risky_city origin_airport_ORD origin_airport_DEN origin_airport_PHL origin_airport_LGA origin_airport_DFW distance_normalized'.split()\n\ntrain = train[columns_to_keep].copy()\nvalidation = validation[columns_to_keep].copy()\ntest = test[columns_to_keep].copy()\n\ndatasets = [train, validation, test]",
                "true_label": "",
                "top5_preds": [
                    "formatting datetimes as strings",
                    "integrating datetime tools with pandas for time series",
                    "relationships between dataframes",
                    "parse time and visibility from json",
                    "transform the date column as a datetime type"
                ]
            },
            {
                "code": "for d in datasets:\n    d['is_delayed'] = d['is_delayed'].astype(int)\n    d['is_risky_city'] = d['is_risky_city'].astype(int)",
                "true_label": "",
                "top5_preds": [
                    "data given as a dictionary",
                    "find data type of each column",
                    "read the dataset",
                    "helpers to read in dataset",
                    "getting the dataset"
                ]
            },
            {
                "code": "taxi_in = most_frequent_values(flights.taxi_in, flights.is_delayed)\ntotal_delayed = flights.is_delayed.sum()\ntotal_not_delayed = flights.is_delayed.count() - total_delayed\n    \ntaxi_in['cum_delayed(%)'] = taxi_in['delayed'].str.replace(',','').astype(int).cumsum().map(lambda x:'{:.2%}'.format(x / total_delayed))\ntaxi_in['cum_not_delayed(%)'] = taxi_in['not_delayed'].str.replace(',','').astype(int).cumsum().map(lambda x:'{:.2%}'.format(x / total_not_delayed))\n\nprint(taxi_in)",
                "true_label": "",
                "top5_preds": [
                    "predicting a categorical response",
                    "remove duplicates from a list",
                    "get a positive integer from a user",
                    "formatting datetimes as strings",
                    "sorting data"
                ]
            },
            {
                "code": "x = flights.isnull().sum() / flights.shape[0]\nx.map(lambda y:'{:.2%}'.format(y)).sort_values(ascending=False).head(10)",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "calculating the mean of a vector with nans",
                    "predicting a categorical response",
                    "dataframe methods",
                    "sorting data"
                ]
            },
            {
                "code": "train = flights[flights.month < 4].copy().reset_index(drop=True)\nvalidation = flights[flights.month == 4].copy().reset_index(drop=True)\ntest = flights[flights.month >= 5].copy().reset_index(drop=True)\n\n# sanity check\nassert len(train) + len(validation) + len(test) == len(flights)",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "using pandas",
                    "load table in pandas",
                    "importing data with pandas",
                    "in pandas"
                ]
            },
            {
                "code": "# joining train and validation sets to be the baseline training set\nbaseline_train = pd.concat([train, validation])",
                "true_label": "",
                "top5_preds": [
                    "create a dataframe by joining series by column",
                    "load table in pandas",
                    "join two dataframes along rows",
                    "from dictionary to dataframe",
                    "combine two dataframes into one"
                ]
            },
            {
                "code": "p = flights.groupby('airline').is_delayed.mean().sort_values(ascending = False)\n\nprint(p.map(lambda y:'{:.2%}'.format(y)))\np.plot.bar()",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "pandas plotting",
                    "line plots show the trend of a numerical variable over time",
                    "plotting time series with pandas",
                    "plot using pandas plotting"
                ]
            },
            {
                "code": "columns = 'month airline_delay late_aircraft_delay air_system_delay security_delay weather_delay'.split()\n\ndelays = flights[flights.is_delayed][columns].groupby('month').sum()\ntotal_delay = delays.sum(axis = 1)\n\nfor c in delays.columns: \n    delays[c] = delays[c] / total_delay\n    \ndelays.plot.bar(stacked=True, ylim=(0,1)).legend(loc='center left', bbox_to_anchor=(1, 0.5))",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "formatting datetimes as strings",
                    "pandas apply",
                    "create a one column dataframe with the values of a series",
                    "calculating the mean of a vector with nans"
                ]
            },
            {
                "code": "columns = 'airline_delay late_aircraft_delay air_system_delay security_delay weather_delay'.split()\nflights[flights.is_delayed][columns].mean()",
                "true_label": "",
                "top5_preds": [
                    "calculating the mean of a vector with nans",
                    "line plot with a dataframe",
                    "find data type of each column",
                    "dataframe methods",
                    "the mean of difference of variables"
                ]
            },
            {
                "code": "flights.groupby('origin_airport').is_delayed.mean().sort_values(ascending = False).head(10)",
                "true_label": "",
                "top5_preds": [
                    "formatting datetimes as strings",
                    "calculating the mean of a vector with nans",
                    "line plot with a dataframe",
                    "join two dataframes along rows",
                    "line plots show the trend of a numerical variable over time"
                ]
            },
            {
                "code": "mask = flights.origin_airport == 'PPG'\n\nflights[mask].groupby('month').is_delayed.count()",
                "true_label": "",
                "top5_preds": [
                    "find duplicate dates",
                    "select every row after a specific row",
                    "sorting data",
                    "line plot with a dataframe",
                    "formatting datetimes as strings"
                ]
            },
            {
                "code": "flights[flights.cancelled].cancellation_reason.value_counts().plot.pie(y='y')",
                "true_label": "",
                "top5_preds": [
                    "plotting time series with pandas",
                    "line plot with a dataframe",
                    "line plots show the trend of a numerical variable over time",
                    "plot using pandas plotting",
                    "using a dataframe and matplotlib commands"
                ]
            },
            {
                "code": "for d in datasets:\n    print(d.isna().sum()[lambda x: x > 0])",
                "true_label": "",
                "top5_preds": [
                    "find data type of each column",
                    "helpers to read in dataset",
                    "dataset statistics",
                    "read the dataset",
                    "drop the rows with nan values"
                ]
            },
            {
                "code": "for d in datasets:\n    d['departure_time'].fillna(1200, inplace=True) # assuming noon\n    d['departure_delay'].fillna(0, inplace=True) # assuming no delay\n    d['scheduled_time'].fillna(1200, inplace=True) # assuming noon and no delay at departure",
                "true_label": "",
                "top5_preds": [
                    "load table in pandas",
                    "from dictionary to dataframe",
                    "formatting datetimes as strings",
                    "transform the date column as a datetime type",
                    "pandas stores timestamps using numpy s data type, which has nanoseond resolution"
                ]
            },
            {
                "code": "# build features set\nfeatures = train.columns.drop('is_delayed')\n\nlogistic_models = {}\n\nfor c in [1.0, 0.5, 0.1]:\n    print('C -> %s' % c)\n    \n    # train logistic regression to predic is_delayed \n    model = LogisticRegression(C=c)\n    train_results = model.fit(train[features], train.is_delayed)\n    \n    logistic_models[c] = model\n    \n    # use trained model to predit is_delayed field in validation set\n    results = model.predict(validation[features])\n    \n    # get model performance\n    metrics = get_metrics(validation.is_delayed, results)\n    \n    # prettify metrics\n    for m in metrics:\n        print('{:20} -> {:6.2%}'.format(m, metrics[m]))\n        \n    print()    ",
                "true_label": "",
                "top5_preds": [
                    "import polynomial features from sklearn",
                    "using logistic regression with categorical features",
                    "fit a logistic regression model using statsmodels using logistic regression formula in patsy",
                    "polynomial regression with sklearn",
                    "add intercept in logistic regression"
                ]
            },
            {
                "code": "# build features set\nfeatures = train.columns.drop('is_delayed')\n\ndecision_tree_models = {}\n\nfor md in [5, 10, 100]:\n    print('Max depth -> %s' % md)\n    \n    # train decision tree to predic is_delayed \n    model = DecisionTreeClassifier(max_depth=md)\n    train_results = model.fit(train[features], train.is_delayed)\n    \n    decision_tree_models[md] = model\n    \n    # use trained model to predit is_delayed field in validation set\n    results = model.predict(validation[features])\n    \n    # get model performance\n    metrics = get_metrics(validation.is_delayed, results)\n    \n    # prettify metrics\n    for m in metrics:\n        print('{:20} -> {:6.2%}'.format(m, metrics[m]))\n        \n    print()    ",
                "true_label": "",
                "top5_preds": [
                    "build a vector of prediction from the trained model",
                    "import polynomial features from sklearn",
                    "decision tree learning with sklearn",
                    "tensorflow + keras",
                    "training a decision tree model"
                ]
            },
            {
                "code": "# build features set\nfeatures = train.columns.drop('is_delayed')\n\nmodel1 = logistic_models.get(0.1)\nmodel2 = decision_tree_models.get(5)\n\nprint(\"Logistic regression (C=0.1)\")\n\n# use trained model to predit is_delayed field in test set\nresults = model1.predict(test[features])\n# get model performance\nmetrics = get_metrics(test.is_delayed, results)\n\n# prettify metrics\nfor m in metrics:\n    print('{:20} -> {:6.2%}'.format(m, metrics[m]))\n    \nprint()\n\nprint(\"Decision trees (max_depth=5)\")\n\n# use trained model to predit is_delayed field in test set\nresults = model2.predict(test[features])\n# get model performance\nmetrics = get_metrics(test.is_delayed, results)\n\n# prettify metrics\nfor m in metrics:\n    print('{:20} -> {:6.2%}'.format(m, metrics[m]))\n    \nprint()    ",
                "true_label": "",
                "top5_preds": [
                    "import polynomial features from sklearn",
                    "polynomial regression with sklearn",
                    "using logistic regression with categorical features",
                    "fit a logistic regression model using statsmodels using logistic regression formula in patsy",
                    "check accuracy / score for a logistic classifier"
                ]
            },
            {
                "code": "columns = flights.columns[(flights.dtypes == 'int32') | (flights.dtypes == 'float32')].values.tolist()\n\n# add target variable\ncolumns.append('is_delayed')\n# remove columns that cannot be used, because they are columns that we only know when the flight arrives\ncolumns_to_be_removed = 'air_system_delay security_delay airline_delay late_aircraft_delay weather_delay arrival_delay arrival_time taxi_in wheels_off wheels_on air_time elapsed_time taxi_out departure_time'.split()\nfor c in columns_to_be_removed:\n    columns.remove(c)",
                "true_label": "",
                "top5_preds": [
                    "load table in pandas",
                    "from dictionary to dataframe",
                    "drop data points with missing data",
                    "relationships between dataframes",
                    "import polynomial features from sklearn"
                ]
            },
            {
                "code": "baseline_train = baseline_train[columns].copy()\nbaseline_test = test[columns].copy()\n\n# sanity check\nassert len(baseline_train) == len(train) + len(validation)\nassert len(baseline_test) == len(test)",
                "true_label": "",
                "top5_preds": [
                    "from dictionary to dataframe",
                    "load table in pandas",
                    "predicting on sample validation data",
                    "find data type of each column",
                    "predicting test data"
                ]
            },
            {
                "code": "baseline_train = baseline_train.fillna(-1)\nbaseline_test = baseline_test.fillna(-1)",
                "true_label": "",
                "top5_preds": [
                    "numpy",
                    "import polynomial features from sklearn",
                    "what is scikit learn?",
                    "integrating datetime tools with pandas for time series",
                    "scipy"
                ]
            },
            {
                "code": "# build features set\nfeatures = baseline_train.columns.drop('is_delayed')\n\n# train logistic regression to predic is_delayed \nmodel = LogisticRegression()\ntrain_results = model.fit(baseline_train[features], baseline_train.is_delayed)\n\n# use trained model to predit is_delayed field in test set\ntest_results = model.predict(baseline_test[features])",
                "true_label": "",
                "top5_preds": [
                    "import polynomial features from sklearn",
                    "ridge regression with polynomial features on a grid",
                    "using logistic regression with categorical features",
                    "polynomial regression with sklearn",
                    "making predictions for the testing data"
                ]
            },
            {
                "code": "def get_metrics(y_true, y_pred):\n    confusion_matrix = pd.crosstab(y_true, y_pred)\n    \n    tp = confusion_matrix.iloc[1, 1]\n    fp = confusion_matrix.iloc[0, 1]\n    tn = confusion_matrix.iloc[0, 0]\n    fn = confusion_matrix.iloc[1, 0]\n    \n    return {\n        'Accuracy': (tp+tn)/(tp+fp+tn+fn), \n        'Recall': tp/(tp+fn), \n        'Precision': tp/(tp+fp), \n        'F1-Score': (2*tp)/(2*tp+fp+fn),\n        'False Positive Rate': fp/(fp+tn)\n    }",
                "true_label": "",
                "top5_preds": [
                    "making predictions for the testing data",
                    "check accuracy / score for a logistic classifier",
                    "function fit_and_predict",
                    "get the sse by using the predictions for every x y_hats and the true y values",
                    "find data type of each column"
                ]
            },
            {
                "code": "# get model performance\nmetrics = get_metrics(baseline_test.is_delayed, test_results)\n# prettify metrics\nfor m in metrics:\n    print('{:20} -> {:6.2%}'.format(m, metrics[m]))",
                "true_label": "",
                "top5_preds": [
                    "formatting datetimes as strings",
                    "equally spaced numbers on a grid",
                    "remove duplicates from a list",
                    "line plots show the trend of a numerical variable over time",
                    "read numbers until and print their mean and standard deviation without using a list"
                ]
            },
            {
                "code": "corr = train.corr()\n\n# all entries with correlation below 0.9 will display nan\ncorr[(corr >= 0.9) | (corr <= -0.9)]",
                "true_label": "",
                "top5_preds": [
                    "predicting a categorical response",
                    "computing the covariance when there are nan s",
                    "correlation analysis",
                    "explore correlations in the dataset",
                    "calculating the mean of a vector with nans"
                ]
            },
            {
                "code": "def convert_to_time_format(x):\n    \"\"\"\n    Convert a numeric value into its hour representation.\n    \n    Parameters:\n    ----------\n    x : float\n    \"\"\"\n    y = '{0:04.0f}'.format(x)\n    z = '{0}:{1}'.format(y[0:2],y[2:])\n    \n    if x == 2400: return '00:00'\n    else: return z\n\n# sanity check\nassert convert_to_time_format(5) == '00:05'\nassert convert_to_time_format(130) == '01:30'\nassert convert_to_time_format(2400) == '00:00'",
                "true_label": "",
                "top5_preds": [
                    "convert date to datetime format",
                    "transform the date column as a datetime type",
                    "formatting datetimes as strings",
                    "convert",
                    "convert integer or float data"
                ]
            },
            {
                "code": "flights['hour'] = flights.scheduled_departure.apply(convert_to_time_format)",
                "true_label": "",
                "top5_preds": [
                    "formatting datetimes as strings",
                    "convert date to datetime format",
                    "transform the date column as a datetime type",
                    "plotting time series with pandas",
                    "when arithmetic operations are performed between differently indexed time series pandas will automatically align on dates"
                ]
            },
            {
                "code": "def convert_to_datetime(row):\n    \"\"\"\n    Based on year, month, day, and hour columns generate a datetime value\n    \n    Parameters:\n    ----------\n    row : pandas.Series\n        dataframe row with flight information\n    \"\"\"\n    from datetime import datetime\n    z = datetime(row.year, row.month, row.day, int(row.hour[:2]), int(row.hour[3:]))\n    return z\n\nflights['date'] = flights.apply(convert_to_datetime, axis=1)",
                "true_label": "",
                "top5_preds": [
                    "transform the date column as a datetime type",
                    "convert date to datetime format",
                    "from dictionary to dataframe",
                    "to_tuple",
                    "return a dataframe"
                ]
            },
            {
                "code": "flights['date'].head()",
                "true_label": "",
                "top5_preds": [
                    "convert date to datetime format",
                    "working with pandas series indexed by datetime",
                    "formatting datetimes as strings",
                    "plotting time series with pandas",
                    "transform the date column as a datetime type"
                ]
            },
            {
                "code": "flights['day_of_week'] = flights['date'].dt.dayofweek\nflights.groupby('day_of_week').is_delayed.count().plot.bar()",
                "true_label": "",
                "top5_preds": [
                    "plotting time series with pandas",
                    "line plots show the trend of a numerical variable over time",
                    "line plot with a dataframe",
                    "formatting datetimes as strings",
                    "convert date to datetime format"
                ]
            },
            {
                "code": "flights[flights.is_delayed].groupby('day_of_week').is_delayed.count().plot.bar()",
                "true_label": "",
                "top5_preds": [
                    "plotting time series with pandas",
                    "line plots show the trend of a numerical variable over time",
                    "line plot with a dataframe",
                    "pandas plotting",
                    "integrating datetime tools with pandas for time series"
                ]
            },
            {
                "code": "# remove columns\nflights.drop(['year', 'hour'], axis=1, inplace=True)",
                "true_label": "",
                "top5_preds": [
                    "load table in pandas",
                    "join two dataframes along rows",
                    "plotting time series with pandas",
                    "convert date to datetime format",
                    "line plot with a dataframe"
                ]
            },
            {
                "code": "g = flights.groupby('airline').cancelled.agg(['sum','count'])\n\ng.columns = ['cancelled_flights', 'total_flights']\ng.cancelled_flights = g.cancelled_flights / g.cancelled_flights.sum()\ng.total_flights = g.total_flights / g.total_flights.sum()\n\ng.plot.bar()",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "relationships between dataframes",
                    "predicting a categorical response",
                    "using pandas",
                    "calculate average by group"
                ]
            },
            {
                "code": "# histogram of arrival delay, where we grouped all values > 95% quantile\n\nflights['arrival_delay_copy'] = flights.arrival_delay\n\np = flights.arrival_delay_copy.quantile([0.95]).values[0] # 95% quantile\n\nflights.loc[flights.arrival_delay_copy > p, 'arrival_delay_copy'] = p+1\nflights.arrival_delay_copy.plot.hist(bins=20)",
                "true_label": "",
                "top5_preds": [
                    "predicting a categorical response",
                    "line plots show the trend of a numerical variable over time",
                    "plotting percentiles",
                    "line plot with a dataframe",
                    "create a histogram of top items with filtering"
                ]
            },
            {
                "code": "hist = flights_context_info[flights_context_info.month == 1].copy().reset_index(drop=True)\ntrain = flights_context_info[(flights_context_info.month > 1) & (flights_context_info.month < 4)].copy().reset_index(drop=True)\nvalidation = flights_context_info[flights_context_info.month == 4].copy().reset_index(drop=True)\ntest = flights_context_info[flights_context_info.month >= 5].copy().reset_index(drop=True)\n\ndatasets = [train, validation, test]\n\n# sanity check\nassert len(hist) + len(train) + len(validation) + len(test) == len(flights_context_info)",
                "true_label": "",
                "top5_preds": [
                    "load table in pandas",
                    "from dictionary to dataframe",
                    "predicting a categorical response",
                    "what is scikit learn?",
                    "import polynomial features from sklearn"
                ]
            },
            {
                "code": "delays_airline = hist.groupby('airline').is_delayed.mean().to_dict()\n\nfor d in datasets:\n    d['perc_delayed_flights_airline'] = d.airline.map(lambda airline: delays_airline[airline]).astype(float)",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "from dictionary to dataframe",
                    "predicting a categorical response",
                    "loading up data with missing values",
                    "line plots show the trend of a numerical variable over time"
                ]
            },
            {
                "code": "delayed_flights_route = hist.groupby('oridst').is_delayed.mean().to_dict()\n\nfor d in datasets:\n    d['perc_delayed_flights_route'] = d.oridst.map(lambda oridst: delayed_flights_route[oridst] if oridst in delayed_flights_route else -1)",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "predicting a categorical response",
                    "from dictionary to dataframe",
                    "line plots show the trend of a numerical variable over time",
                    "dataframe methods"
                ]
            },
            {
                "code": "delayed_city = hist.groupby('city_origin').is_delayed.mean().to_dict()\n\nfor d in datasets:\n    d['avg_delay_city'] = d.city_origin.map(lambda cityorigin: delayed_city[cityorigin] if cityorigin in delayed_city else -1)\n\ndelayed_airline = hist.groupby('airline').arrival_delay.mean().to_dict()\n\nfor d in datasets:\n    d['avg_delay_airline'] = d.airline.map(lambda airline: delayed_airline[airline] if airline in delayed_airline else -1).astype(float)",
                "true_label": "",
                "top5_preds": [
                    "predicting a categorical response",
                    "loading up data with missing values",
                    "line plot with a dataframe",
                    "from dictionary to dataframe",
                    "calculating the mean of a vector with nans"
                ]
            },
            {
                "code": "airlines",
                "true_label": "",
                "top5_preds": [
                    "equally spaced numbers on a grid",
                    "creating basic geometries",
                    "create an array of linearly spaced points",
                    "add edges in graph",
                    "convert list to numpy array"
                ]
            },
            {
                "code": "airports.head(10)",
                "true_label": "",
                "top5_preds": [
                    "importing data with numpy",
                    "convert text data into vector",
                    "import polynomial features from sklearn",
                    "what is scikit learn?",
                    "find maximum and the minimum value in a set"
                ]
            },
            {
                "code": "flights.head(10)",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "predicting a categorical response",
                    "tensorflow + keras",
                    "what is scikit learn?",
                    "line plots show the trend of a numerical variable over time"
                ]
            },
            {
                "code": "# a flight is considered delayed if the delay is greater or equal than 15 min\nflights['is_delayed'] = flights.arrival_delay >= 15",
                "true_label": "",
                "top5_preds": [
                    "formatting datetimes as strings",
                    "evaluating the model on the validation data",
                    "compare variable with time",
                    "selecting data using a date or a date string",
                    "dealing with missing values"
                ]
            },
            {
                "code": "flights.groupby('is_delayed').is_delayed.count()",
                "true_label": "",
                "top5_preds": [
                    "predicting a categorical response",
                    "relationships between dataframes",
                    "line plot with a dataframe",
                    "line plots show the trend of a numerical variable over time",
                    "formatting datetimes as strings"
                ]
            },
            {
                "code": "flights.groupby('is_delayed').is_delayed.count().map(lambda x: '{:.2%}'.format(x/flights.shape[0]))",
                "true_label": "",
                "top5_preds": [
                    "formatting datetimes as strings",
                    "line plot with a dataframe",
                    "predicting a categorical response",
                    "line plots show the trend of a numerical variable over time",
                    "pandas apply"
                ]
            },
            {
                "code": "flights.dtypes",
                "true_label": "",
                "top5_preds": [
                    "convert text data into vector",
                    "import polynomial features from sklearn",
                    "numpy",
                    "find data type of each column",
                    "convert data from string to float"
                ]
            },
            {
                "code": "# columns type distribution\nflights.dtypes.value_counts()",
                "true_label": "",
                "top5_preds": [
                    "find data type of each column",
                    "from dictionary to dataframe",
                    "convert text data into vector",
                    "import polynomial features from sklearn",
                    "create a one column dataframe with the values of a series"
                ]
            },
            {
                "code": "def most_frequent_values(serie, is_delayed, top=10):\n    \"\"\"\"\n    Return statistics for the top-N most frequent domain values break up dowm by is_delayed column. The returned \n    dataframe is order by the domain values with more delayed flights.\n    \n    Parameters:\n    ----------\n    serie : pandas.Series\n        Series to be analysed, can have any type\n    top : int, default 10\n        top domain values considered\n    \"\"\"\n    is_delayed = is_delayed == True\n    isnot_delayed = is_delayed == False\n    \n    top_values = serie[is_delayed].value_counts().head(top).index.values\n    total_delayed = is_delayed.sum()\n    total_not_delayed = is_delayed.count() - total_delayed\n\n    # c0 is a temporary column used to sort the dataframe\n    c0 = serie[is_delayed & serie.isin(top_values)].value_counts()\n    \n    c1 = c0.map(lambda x: '{:,.0f}'.format(x))\n    c2 = serie[is_delayed & serie.isin(top_values)].value_counts().map(lambda x: '{:.2%}'.format(x / total_delayed))\n    c3 = serie[isnot_delayed & serie.isin(top_values)].value_counts().map(lambda x: '{:,.0f}'.format(x))\n    c4 = serie[isnot_delayed & serie.isin(top_values)].value_counts().map(lambda x: '{:.2%}'.format(x / total_not_delayed))\n    \n    df = pd.DataFrame({'sort': c0, 'delayed': c1, 'delayed(%)': c2, 'not_delayed': c3, 'not_delayed(%)': c4})\n    df.sort_values('sort', ascending=False, inplace=True)\n    \n    return df.drop('sort', axis=1)",
                "true_label": "",
                "top5_preds": [
                    "return a dataframe",
                    "line plots show the trend of a numerical variable over time",
                    "collect them in a list print the elements backwards zero not included",
                    "find data type of each column",
                    "getting data from the internet"
                ]
            },
            {
                "code": "# numerical columns\nflights.describe()",
                "true_label": "",
                "top5_preds": [
                    "from dictionary to dataframe",
                    "convert text data into vector",
                    "convert data from string to float",
                    "line plot with a dataframe",
                    "find data type of each column"
                ]
            },
            {
                "code": "### remaining columns types\nmask = ~((flights.dtypes == 'float32') | (flights.dtypes == 'int32'))\n\nfor c in flights.dtypes[mask].index:\n    print('Column:', c)\n    print()\n    print(most_frequent_values(flights[c], flights.is_delayed))\n    print()",
                "true_label": "",
                "top5_preds": [
                    "find data type of each column",
                    "dataframe methods",
                    "calculating the mean of a vector with nans",
                    "predicting a categorical response",
                    "transform categorical data into binary features"
                ]
            },
            {
                "code": "flights_context_info['oridst'] = flights_context_info.city_origin + '-' + flights_context_info.city_destination\nflights_context_info.groupby('oridst').is_delayed.sum().sort_values(ascending = False).head(10)",
                "true_label": "",
                "top5_preds": [
                    "formatting datetimes as strings",
                    "join two dataframes along rows",
                    "from dictionary to dataframe",
                    "join two dataframes along columns",
                    "aggregating with a variable"
                ]
            },
            {
                "code": "minimum = len(hist) * 0.01\norigin_airport = hist.origin_airport.value_counts()[lambda x: x > minimum].index.values\n\nhist[hist.origin_airport.isin(origin_airport)].groupby('origin_airport').is_delayed.mean().sort_values(ascending = False).head(10)",
                "true_label": "",
                "top5_preds": [
                    "predicting a categorical response",
                    "integrating datetime tools with pandas for time series",
                    "calculating the mean of a vector with nans",
                    "working with pandas series indexed by datetime",
                    "create a histogram of top items with filtering"
                ]
            }
        ],
        [
            {
                "code": "import io, time, json\nimport requests\nimport pandas as pd",
                "true_label": "",
                "top5_preds": [
                    "formatting datetimes as strings",
                    "importing data with numpy",
                    "equally spaced numbers on a grid",
                    "load table in pandas",
                    "getting data from the internet"
                ]
            },
            {
                "code": "def read_api_key(filepath):\n    \"\"\"\n    Read the Yelp API Key from file.\n    \n    Args:\n        filepath (string): File containing API Key\n    Returns:\n        api_key (string): The API Key\n    \"\"\"\n    \n    # feel free to modify this function if you are storing the API Key differently\n    with open(filepath, 'r') as f:\n        return f.read().replace('\\n','')",
                "true_label": "",
                "top5_preds": [
                    "read the dataset",
                    "download and inspect the twitter samples dataset",
                    "read the dataset point",
                    "read text file point",
                    "read table"
                ]
            },
            {
                "code": "api_key = read_api_key('api_key.txt')",
                "true_label": "",
                "top5_preds": [
                    "twitter api access",
                    "getting data from the internet",
                    "loading json in python",
                    "constructing an api get request",
                    "get a positive integer from a user"
                ]
            },
            {
                "code": "from datetime import datetime\nimport scipy.sparse as sps\nfrom collections import Counter",
                "true_label": "",
                "top5_preds": [
                    "integrating datetime tools with pandas for time series",
                    "plotting time series with pandas",
                    "line plots show the trend of a numerical variable over time",
                    "working with pandas series indexed by datetime",
                    "formatting datetimes as strings"
                ]
            },
            {
                "code": "e = pd.read_csv('yelpresultCleaned.csv',encoding = \"ISO-8859-1\")\nprint(e.head())",
                "true_label": "",
                "top5_preds": [
                    "loading a csv into a dataframe",
                    "importing data with pandas",
                    "importing data with numpy",
                    "load table in pandas",
                    "convert text data into vector"
                ]
            },
            {
                "code": "def processCategorial(cate_col):\n    categories = set(cate_col)\n    data = np.ones(len(cate_col))\n    row_ind = []\n    col_ind = []\n    dic = {}\n    for i,c in enumerate(categories):\n        dic[c] = i\n    for index,c in enumerate(cate_col):\n        row_ind.append(index)\n        col_ind.append(dic[c])\n    return sps.coo_matrix((data, (row_ind, col_ind)))",
                "true_label": "",
                "top5_preds": [
                    "list of categories",
                    "transform categorical data into binary features",
                    "convert categorical variables",
                    "categorical features",
                    "find data type of each column"
                ]
            },
            {
                "code": "def processText(ids,maxWords):\n    unique_words = []\n    dic = {}\n    for i in ids:\n        words = i.split('-')\n        for w in words:\n            unique_words.append(w)\n    unique = Counter(unique_words)\n    #print(unique['los'])\n    unique_words = sorted(unique, key=unique.get, reverse=True)[:maxWords]\n    for i,w in enumerate(unique_words):\n        dic[w] = i\n    data = []\n    row_ind = []\n    col_ind = []\n    for r,i in enumerate(ids):\n        indexs = [dic[w] for w in i.split('-') if w in unique_words]\n        c = Counter(indexs)\n        for k in sorted(c.keys()):\n            data.append(c[k])\n            row_ind.append(r)\n            col_ind.append(k)\n    return sps.coo_matrix((data, (row_ind, col_ind)),shape=(len(ids),maxWords))",
                "true_label": "",
                "top5_preds": [
                    "find the most common words",
                    "most common words",
                    "tokenize the text",
                    "extract word counts and sentiments",
                    "rewrite get _long _words using map and filter"
                ]
            },
            {
                "code": "def processData(events):\n    inter = []\n    free = []\n    official = []\n    lat = []\n    lon = []\n    duration = []\n    month = []\n    #and event['attending_count']!=1\n    for i,event in events.iterrows():\n            inter.append(event['interested_count'])\n            if event['is_free']:\n                free.append(1)\n            else:\n                free.append(0)\n            if event['is_official']:\n                official.append(1)\n            else:\n                official.append(0)\n            lat.append(event['latitude'])\n            lon.append(event['longitude'])\n            d1 = datetime.strptime(event['time_start'].split(' ')[0], \"%Y-%m-%d\")\n            d2 = datetime.strptime(event['time_end'].split(' ')[0], \"%Y-%m-%d\")\n            month.append(np.cos(d1.month/12))\n            duration.append((d2 - d1).days + 1)\n    columns = [inter,free,official,lat,lon,duration,month]\n   \n    return sps.coo_matrix(np.array(columns).T)",
                "true_label": "",
                "top5_preds": [
                    "get the data",
                    "reading in the data & exploratory analysis",
                    "getting data from the internet",
                    "download and inspect the twitter samples dataset",
                    "preprocess the data"
                ]
            },
            {
                "code": "category = processCategorial(e['category'])\nids = processText(e['id'],200)\ndata = processData(e)",
                "true_label": "",
                "top5_preds": [
                    "loading json in python",
                    "retrieving data from html page",
                    "dealing with data",
                    "data given as a dictionary",
                    "importing data with numpy"
                ]
            },
            {
                "code": "dt = data.todense()\nd = pd.DataFrame(dt,columns = ['interested_count','is_free','is_official','latitute','lonitute','duration','month'])\nac = []\nfor at in e['attending_count']:\n    if at != 1:\n        ac.append(at)\nd['attending_count'] = ac\ncorr = d.corr()\nmask = np.zeros_like(corr, dtype=np.bool)\nmask[np.triu_indices_from(mask)] = True\n\n# Set up the matplotlib figure\nf, ax = plt.subplots(figsize=(11, 9))\n\n# Generate a custom diverging colormap\ncmap = sns.diverging_palette(220, 10, as_cmap=True)\n\n# Draw the heatmap with the mask and correct aspect ratio\nsns.heatmap(corr, mask=mask, cmap=cmap, vmax=.9, center=0,\n            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})",
                "true_label": "",
                "top5_preds": [
                    "predicting a categorical response",
                    "relationships between dataframes",
                    "from dictionary to dataframe",
                    "formatting datetimes as strings",
                    "line plot with a dataframe"
                ]
            },
            {
                "code": "inputs = sps.hstack([data,category,ids])\ny = e['attending_count']\nx = pd.DataFrame(inputs.todense())\npart = int(len(e['attending_count'])/9)",
                "true_label": "",
                "top5_preds": [
                    "predicting a categorical response",
                    "create a one column dataframe with the values of a series",
                    "join two dataframes along rows",
                    "transform categorical data into binary features",
                    "from dictionary to dataframe"
                ]
            },
            {
                "code": "# read in \ncleanedDataframe = pd.read_csv('yelpresult.csv',encoding = \"ISO-8859-1\")\n#cleanedDataframe = cleanedDataframe.encode('utf-8').strip()\n# remove attending count with 1\ncleanedDataframe = cleanedDataframe[(cleanedDataframe.attending_count != 1)]",
                "true_label": "",
                "top5_preds": [
                    "importing data with pandas",
                    "remove null values from county, category, and category name",
                    "loading a csv into a dataframe",
                    "convert data from string to float",
                    "importing data with numpy"
                ]
            },
            {
                "code": "# get features\ncleanedDataframe = cleanedDataframe[['interested_count', 'is_free', 'city', 'latitude', 'category', 'longitude', \\\n                                       'is_official', 'time_end', 'id', 'time_start', 'attending_count']]\ncleanedDataframe = cleanedDataframe.dropna() \ncleanedDataframe.to_csv('yelpResultCleaned.csv', index=False)",
                "true_label": "",
                "top5_preds": [
                    "from dictionary to dataframe",
                    "dataframe methods",
                    "relationships between dataframes",
                    "line plot with a dataframe",
                    "load table in pandas"
                ]
            },
            {
                "code": "len(cleanedDataframe)",
                "true_label": "",
                "top5_preds": [
                    "load table in pandas",
                    "find data type of each column",
                    "line plot with a dataframe",
                    "loading a csv into a dataframe",
                    "predicting a categorical response"
                ]
            },
            {
                "code": "import matplotlib.pyplot as plt\nimport seaborn as sns\nimport folium\nimport numpy as np\nfrom folium.plugins import HeatMap\n\n%matplotlib inline",
                "true_label": "",
                "top5_preds": [
                    "heatmap with time",
                    "plot using matplotlib",
                    "line plot with a dataframe",
                    "matplotlib",
                    "plotting in python"
                ]
            },
            {
                "code": "df = cleanedDataframe\ndf.head()",
                "true_label": "",
                "top5_preds": [
                    "loading a csv into a dataframe",
                    "load table in pandas",
                    "line plot with a dataframe",
                    "importing data with pandas",
                    "create a dataframe by joining series by column"
                ]
            },
            {
                "code": "sns.set_style(\"white\")",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "line plots show the trend of a numerical variable over time",
                    "predicting a categorical response",
                    "integrating datetime tools with pandas for time series",
                    "ploting out data with box plots"
                ]
            },
            {
                "code": "plt.rcParams['figure.figsize'] = 12,8\nax = sns.regplot(x=\"interested_count\", y=\"attending_count\", fit_reg=True, data =df, color=\"#2ecc71\")\nax.set_xlabel(xlabel='Interested Count', fontsize=16)\nax.set_ylabel(ylabel='Attending Count', fontsize=16)\nax.set_title(label='Relationship between Attending Count and Interesting Count', fontsize=20)\nplt.show()",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "plot using matplotlib",
                    "using a dataframe and matplotlib commands",
                    "how to change the size of a plot",
                    "plot using pandas plotting"
                ]
            },
            {
                "code": "plt.rcParams['figure.figsize'] = 20,8\n\nax = sns.pointplot(x=df['interested_count'], \n                   y=df['attending_count'], color=\"#2ecc71\")\nax.set_xlabel(xlabel='Interested Count', fontsize=16)\nax.set_ylabel(ylabel='Attending Count', fontsize=16)\nax.set_title(label='Relationship between Attending Count and Interested Count', fontsize=20)\nplt.show()",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "pandas plotting documentation",
                    "pandas plotting",
                    "plot using matplotlib",
                    "plot using pandas plotting"
                ]
            },
            {
                "code": "plt.rcParams['figure.figsize'] = 20,8\nattending_count_categories_mean = df.groupby(['category']).mean()\n\nax = sns.pointplot(x=attending_count_categories_mean.index, \n                   y=attending_count_categories_mean['attending_count'], color=\"#2ecc71\")\nax.set_xlabel(xlabel='Categories', fontsize=12)\nax.set_ylabel(ylabel='Attending count', fontsize=16)\nax.set_title(label='Distribution of mean of attending_count in each category', fontsize=20)\n# ax.set_xticklabels( fontsize=12, rotation=50)\nplt.show()",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "predicting a categorical response",
                    "pandas plotting",
                    "pandas plotting documentation",
                    "line plots show the trend of a numerical variable over time"
                ]
            },
            {
                "code": "plt.rcParams['figure.figsize'] = 30,20\nattending_count_cities_mean = df.groupby(['city']).mean()\n\nax = sns.pointplot(x=attending_count_cities_mean.index, \n                   y=attending_count_cities_mean['attending_count'], color=\"#2ecc71\")\nax.set_xlabel(xlabel='Cities', fontsize=16)\nax.set_ylabel(ylabel='Attending count', fontsize=16)\nax.set_title(label='Distribution of mean of attending_count in each city', fontsize=20)\nax.set_xticklabels(labels=attending_count_cities_mean.index, fontsize=12, rotation=50)\nplt.show()",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "pandas plotting",
                    "predicting a categorical response",
                    "pandas plotting documentation",
                    "ploting out data with box plots"
                ]
            },
            {
                "code": "def yelp_search(api_key, offset, cityName):\n    \"\"\"\n    Make an authenticated request to the Yelp API.\n\n    Args:\n        query (string): Search term\n\n    Returns:\n        total (integer): total number of businesses on Yelp corresponding to the query\n        businesses (list): list of dicts representing each business\n    \"\"\"\n    \n    # Write solution here    \n    headers = {\n        'Authorization': 'Bearer %s' % api_key\n    } \n    \n    params = {\n        'limit': 50,\n        'offset': offset,\n        'location': cityName\n    }\n    response = requests.get('https://api.yelp.com/v3/events', headers=headers, params=params)\n    result = response.json()\n\n    return result[\"events\"]",
                "true_label": "",
                "top5_preds": [
                    "download and inspect the twitter samples dataset",
                    "getting data from the internet",
                    "fetch and cache helper",
                    "collecting search results",
                    "use the search on the obspy docs for any functionality that you do not remember/know yet"
                ]
            },
            {
                "code": "# city names in CA\ncityNameInCA = ['Los Angeles', 'San Francisco', 'San Diego', 'Sacramento', 'San Jose', 'Oakland', 'Long Beach', \\\n                  'Anaheim', 'Irvine', 'Pasadena', 'Santa Monica', 'Fremont', 'Santa Ana', 'Beverly Hills', \\\n                  'Newport Beach', 'Santa Clara', 'Burbank', 'Mountain View', 'Fresno', 'Bakersfield', 'Riverside', \\\n                  'Stockton', 'Santa Barbara', 'Palm Springs', 'Monterey', 'Modesto', 'Santa Cruz', 'San Bernardino']\n\nresultDataFrame = pd.DataFrame()\n# multiple cities\nfor cityName in cityNameInCA:    \n    for offset in range(1,902,50):\n        # call yelp_search serveral times\n        eventInformation = yelp_search(api_key, offset, cityName)\n        if(len(eventInformation) > 0):\n            theResultDataFrame = pd.DataFrame()\n            eventKeys = eventInformation[0].keys()\n            # go through all event keys\n            for eventKey in eventKeys:\n                if eventKey != 'location':\n                    eventKeyList = list(map(lambda x: x[eventKey], eventInformation))\n                    # append to dataframe\n                    se = pd.Series(eventKeyList)\n                    theResultDataFrame[eventKey] = se.values        \n                if eventKey == 'location':\n                    locationInformation = list(map(lambda x: x['location'], eventInformation))\n                    locationKeys = eventInformation[0]['location'].keys()\n                    for locationKey in locationKeys:\n                        locationKeyList = list(map(lambda x: x[locationKey], locationInformation))\n                        se = pd.Series(locationKeyList)\n                        theResultDataFrame[locationKey] = se.values \n            theResultDataFrame = theResultDataFrame.loc[theResultDataFrame['state'] == 'CA'] \n            resultDataFrame = resultDataFrame.append(theResultDataFrame)\n\n# write out to yelpresult.csv\nresultDataFrame.to_csv('yelpresult.csv', index=False)",
                "true_label": "",
                "top5_preds": [
                    "using json to find your location",
                    "remove null values from county, category, and category name",
                    "create a list of all words",
                    "equally spaced numbers on a grid",
                    "loading json in python"
                ]
            },
            {
                "code": "len(resultDataFrame)",
                "true_label": "",
                "top5_preds": [
                    "load table in pandas",
                    "find data type of each column",
                    "create a dataframe by joining series by column",
                    "line plot with a dataframe",
                    "loading a csv into a dataframe"
                ]
            },
            {
                "code": "# plot distribution of cities\nplt.rcParams['figure.figsize'] = 10,20\ncity = df['city']\nax = sns.countplot(y=city, order= city.value_counts().index, orient='h')\n\nax.set_xlabel(xlabel='Counts', fontsize=16)\nax.set_ylabel(ylabel='City', fontsize=16)\nax.set_title(label='Distribution of cities', fontsize=20)\nplt.show()",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "pandas plotting",
                    "plot using pandas plotting",
                    "pandas plotting documentation",
                    "ploting out data with box plots"
                ]
            },
            {
                "code": "# plot distribution of interested count\nplt.rcParams['figure.figsize'] = 10,8\ninterested_count = df['interested_count']\nax = sns.distplot(interested_count,bins=100, kde=False)\n\nax.set_xlabel(xlabel='Interested count', fontsize=16)\nax.set_ylabel(ylabel='Counts', fontsize=16)\nax.set_title(label='Distribution of interested count', fontsize=20)\nplt.xlim(0,200)\nplt.show()",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "pandas plotting documentation",
                    "how to change the size of a plot",
                    "visualize the distribution histogram of x using sns distplot",
                    "pandas plotting"
                ]
            },
            {
                "code": "geo_attending_count = df[['attending_count','city', 'latitude', 'longitude']]\ncoordinates = []\nfor index, row in geo_attending_count.iterrows():\n    coordinates.append([row['latitude'], row['longitude']])\ngeo_attending_count = geo_attending_count.assign(coords=coordinates)",
                "true_label": "",
                "top5_preds": [
                    "from dictionary to dataframe",
                    "importing data with pandas",
                    "line plot with a dataframe",
                    "equally spaced numbers on a grid",
                    "relationships between dataframes"
                ]
            },
            {
                "code": "center = geo_attending_count['coords'][10269]",
                "true_label": "",
                "top5_preds": [
                    "using json to find your location",
                    "equally spaced numbers on a grid",
                    "from dictionary to dataframe",
                    "loading json in python",
                    "attributes of geometries points"
                ]
            },
            {
                "code": "attending_count_map = folium.Map(location = center)\nlocation_list = geo_attending_count['coords'].tolist()\nattending_count_list = geo_attending_count['attending_count'].tolist()\nattending_count_location = []\nrandom_indices = np.random.permutation(len(geo_attending_count))\n\nfor i in random_indices[:700]:\n    attending_count_location.extend([location_list[i]] * attending_count_list[i])\n# print(attending_count_location)\n# print()\n# matr = attending_count_location.as_matrix()\nattending_count_map.add_child(HeatMap(attending_count_location, radius=15))\n# print(attending_count_location)",
                "true_label": "",
                "top5_preds": [
                    "equally spaced numbers on a grid",
                    "predicting a categorical response",
                    "create an array of linearly spaced points",
                    "predicting a continuous response using linear regression",
                    "line plot with a dataframe"
                ]
            },
            {
                "code": "# plot distribution of categories\nplt.rcParams['figure.figsize'] = 10,8\nis_free = df['is_free']\nax = sns.countplot(is_free, palette=\"Set3\")\n\nax.set_xlabel(xlabel='is_free', fontsize=16)\nax.set_ylabel(ylabel='Counts', fontsize=16)\nax.set_title(label='Distribution of is free', fontsize=20)\nplt.show()",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "pandas plotting",
                    "pandas plotting documentation",
                    "predicting a categorical response",
                    "plot using pandas plotting"
                ]
            },
            {
                "code": "from sklearn import linear_model\nfrom sklearn.metrics import mean_squared_error, r2_score\nfrom sklearn.cross_validation import cross_val_score, cross_val_predict",
                "true_label": "",
                "top5_preds": [
                    "import polynomial features from sklearn",
                    "polynomial regression with sklearn",
                    "what is scikit learn?",
                    "predicting a continuous response using linear regression",
                    "scipy"
                ]
            },
            {
                "code": "lin_model = linear_model.LinearRegression()\nlinear_scores = cross_val_score(lin_model, x_train, y_train, cv=10)\nprint ('Cross-validated scores for linear regression model:',linear_scores)\nprint ('Mean Cross-validated scores for linear regression model:', np.mean(linear_scores))",
                "true_label": "",
                "top5_preds": [
                    "predicting a continuous response using linear regression",
                    "linear regression of many variables",
                    "polynomial regression with sklearn",
                    "fit a logistic regression model using statsmodels using logistic regression formula in patsy",
                    "fit a polynomial"
                ]
            },
            {
                "code": "from sklearn.preprocessing import PolynomialFeatures",
                "true_label": "",
                "top5_preds": [
                    "import polynomial features from sklearn",
                    "polynomial regression with sklearn",
                    "creating polynomial features",
                    "fit a polynomial",
                    "scikit learn"
                ]
            },
            {
                "code": "poly2 = PolynomialFeatures(degree=2)\nX_2 = poly2.fit_transform(x_poly)\nX_val = poly2.fit_transform(poly_val)\npoly2_model = linear_model.LinearRegression()\npoly2_scores = cross_val_score(poly2_model, X_2, y_train, cv=10)\nprint ('Cross-validated scores for degree 2 polynomial model:',poly2_scores)\nprint ('Mean Cross-validated scores for degree 2 polynomial model:', np.mean(poly2_scores))",
                "true_label": "",
                "top5_preds": [
                    "polynomial regression with sklearn",
                    "fit a polynomial",
                    "ridge regression with polynomial features on a grid",
                    "import polynomial features from sklearn",
                    "creating polynomial features"
                ]
            },
            {
                "code": "from sklearn.neural_network import MLPRegressor",
                "true_label": "",
                "top5_preds": [
                    "what is scikit learn?",
                    "import polynomial features from sklearn",
                    "polynomial regression with sklearn",
                    "logistic regression using tensorflow",
                    "scikit learn"
                ]
            },
            {
                "code": "nn = MLPRegressor()\nnn_scores = cross_val_score(nn, x_train, y_train, cv=10)\nprint ('Cross-validated scores for simple neural network model:',nn_scores)\nprint ('Mean Cross-validated scores for simple neural network model:', np.mean(nn_scores))",
                "true_label": "",
                "top5_preds": [
                    "what is scikit learn?",
                    "import polynomial features from sklearn",
                    "polynomial regression with sklearn",
                    "check accuracy / score for a logistic classifier",
                    "intro to classification with knn"
                ]
            },
            {
                "code": "# set the size of the figure to fit the screen\nplt.rcParams['figure.figsize'] = 12,8\n# plot distribution of attending count\nattending_count = df['attending_count']\nax = sns.distplot(attending_count,bins= 100, kde=False)\n\nax.set_xlabel(xlabel='Attending count', fontsize=16)\nax.set_ylabel(ylabel='Counts', fontsize=16)\nax.set_title(label='Distribution of attending count', fontsize=20)\nplt.xlim(0,250)\nplt.show()",
                "true_label": "",
                "top5_preds": [
                    "how to change the size of a plot",
                    "line plot with a dataframe",
                    "pandas plotting",
                    "pandas plotting documentation",
                    "matplotlib"
                ]
            },
            {
                "code": "# plot distribution of categories\nplt.rcParams['figure.figsize'] = 20,8\n\ncategory = df['category']\nax = sns.countplot(category, palette=\"Set3\")\n\nax.set_xlabel(xlabel='Category', fontsize=16)\nax.set_ylabel(ylabel='Counts', fontsize=16)\nax.set_title(label='Distribution of categories', fontsize=20)\nplt.show()",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "pandas plotting",
                    "pandas plotting documentation",
                    "plot using pandas plotting",
                    "predicting a categorical response"
                ]
            },
            {
                "code": "# read in \ncleanedDataframe = pd.read_csv('yelpresult.csv',encoding = \"ISO-8859-1\")\n#cleanedDataframe = cleanedDataframe.encode('utf-8').strip()\n# remove attending count with 1\ncleanedDataframe = cleanedDataframe[(cleanedDataframe.attending_count != 1)]",
                "true_label": "",
                "top5_preds": [
                    "importing data with pandas",
                    "remove null values from county, category, and category name",
                    "loading a csv into a dataframe",
                    "convert data from string to float",
                    "importing data with numpy"
                ]
            }
        ],
        [
            {
                "code": "bbox = [-127, 43, -123.75, 48]",
                "true_label": "",
                "top5_preds": [
                    "equally spaced numbers on a grid",
                    "box plot",
                    "create an array of linearly spaced points",
                    "fit a polynomial",
                    "get a positive integer from a user"
                ]
            },
            {
                "code": "from datetime import datetime, timedelta\n\ndt = 5\n\ndate = datetime.utcnow()  # Uncomment to use now.\nstart = date - timedelta(days=dt)\nstop = date + timedelta(days=dt)",
                "true_label": "",
                "top5_preds": [
                    "convert date to datetime format",
                    "formatting datetimes as strings",
                    "introduction to the python datetime tools",
                    "adding a date range",
                    "parsing strings into datetimes"
                ]
            },
            {
                "code": "from owslib import fes\n\n\ndef fes_date_filter(start, stop):\n    \"\"\"\n    Take datetime-like objects and returns a fes filter for date range\n    (begin and end inclusive).\n    NOTE: Truncates the minutes!!!\n    \n    \"\"\"\n    start = start.strftime('%Y-%m-%d %H:00')\n    stop = stop.strftime('%Y-%m-%d %H:00')\n\n    propertyname = 'apiso:TempExtent_begin'\n    begin = fes.PropertyIsLessThanOrEqualTo(propertyname=propertyname,\n                                            literal=stop)\n    propertyname = 'apiso:TempExtent_end'\n    end = fes.PropertyIsGreaterThanOrEqualTo(propertyname=propertyname,\n                                             literal=start)\n    return begin, end",
                "true_label": "",
                "top5_preds": [
                    "date ranges and frequencies",
                    "convert date to datetime format",
                    "formatting datetimes as strings",
                    "introduction to the python datetime tools",
                    "transform the date column as a datetime type"
                ]
            },
            {
                "code": "begin, end = fes_date_filter(start, stop)",
                "true_label": "",
                "top5_preds": [
                    "convert date to datetime format",
                    "formatting datetimes as strings",
                    "date ranges and frequencies",
                    "integrating datetime tools with pandas for time series",
                    "selecting data using a date or a date string"
                ]
            },
            {
                "code": "sos_name = 'sea_water_temperature'\n\nname_list = ['sea_water_temperature',\n             'sea_surface_temperature',\n             'sea_water_potential_temperature',\n             'equivalent_potential_temperature',\n             'sea_water_conservative_temperature',\n             'pseudo_equivalent_potential_temperature']",
                "true_label": "",
                "top5_preds": [
                    "get the names of all the tables in the database",
                    "sum all the numbers in a list",
                    "create a list of all words",
                    "formatting datetimes as strings",
                    "vectorize words in movie reviews"
                ]
            },
            {
                "code": "kw = dict(wildCard='*',\n          escapeChar='\\\\',\n          singleChar='?',\n          propertyname='apiso:AnyText')\n\nor_filt = fes.Or([fes.PropertyIsLike(literal=('*%s*' % val), **kw)\n                  for val in name_list])\n\nfilter_list = [fes.And([begin, end, fes.BBox(bbox), or_filt])]",
                "true_label": "",
                "top5_preds": [
                    "find all by term in field in case insensitive way",
                    "sql aliases",
                    "sqlalchemy, sqlite, and dates",
                    "exploratory data analysis eda global properties",
                    "test whether a number is positive"
                ]
            },
            {
                "code": "from owslib.csw import CatalogueServiceWeb\n\ncsw = CatalogueServiceWeb('http://www.ngdc.noaa.gov/geoportal/csw',\n                          timeout=60)\n\ncsw.getrecords2(constraints=filter_list, maxrecords=1000, esn='full')\n\nfmt = '{:*^64}'.format\nprint(fmt(' Catalog information '))\nprint(\"CSW version: {}\".format(csw.version))\nprint(\"Number of datasets available: {}\".format(len(csw.records.keys())))",
                "true_label": "",
                "top5_preds": [
                    "getting data from the internet",
                    "accessing databases via web apis",
                    "building a mini lsst broker for data management and discovery",
                    "formatting datetimes as strings",
                    "download the newsgroups dataset"
                ]
            },
            {
                "code": "import pandas as pd\n\ndef service_urls(csw):\n    df = []\n    for key, rec in csw.records.items():\n        df.append(pd.DataFrame(rec.references))\n\n    df = pd.concat(df, ignore_index=True)\n    df['scheme'] = [scheme.split(':')[-2] for scheme in df['scheme']]\n\n    return df.set_index('scheme').sort_index().stack()\n\nservices = service_urls(csw)\n\nprint(fmt(' Services '))\nfor service in set(services.index.levels[0]):\n    print(service)",
                "true_label": "",
                "top5_preds": [
                    "download and inspect the twitter samples dataset",
                    "download the newsgroups dataset",
                    "get the data",
                    "getting data from the internet",
                    "fetch and cache helper"
                ]
            },
            {
                "code": "sos_urls = set(services['sos'].values.tolist())\nprint(fmt(' SOS '))\nfor url in sos_urls:\n    print(url)\n\ndap_urls = set(services['odp'].values.tolist())\nprint(fmt(' OPenDAP '))\nfor url in dap_urls:\n    print(url)",
                "true_label": "",
                "top5_preds": [
                    "formatting datetimes as strings",
                    "getting data from the internet",
                    "retrieving data from html page",
                    "add string to list using append",
                    "create a list of all words"
                ]
            },
            {
                "code": "import copy\nfrom io import BytesIO\n\nfrom owslib.ows import ExceptionReport\nfrom pandas import DataFrame, read_csv\n\n\ndef collector2table(collector, col='sea_water_temperature (C)'):\n    c = copy.copy(collector)\n    c.features = None\n    try:\n        response = c.raw(responseFormat=\"text/csv\")\n    except ExceptionReport:\n        response = c.filter(end=c.start_time).raw(responseFormat=\"text/csv\")\n\n    df = read_csv(BytesIO(response.encode('utf-8')),\n                  parse_dates=True)\n    g = df.groupby('station_id')\n    df = dict()\n    for station in g.groups.keys():\n        df.update({station: g.get_group(station).iloc[0]})\n    df = DataFrame.from_dict(df).T\n    \n    names = []\n    for sta in df.index:\n        names.extend([offering.description for offering in c.server.offerings if sta == offering.name])\n    df['name'] = names\n    \n    observations = []\n    for k, row in df.iterrows():\n        station_id = row['station_id'].split(':')[-1]\n        c.features = [station_id]\n        response = c.raw(responseFormat=\"text/csv\")\n        kw = dict(parse_dates=True, index_col='date_time')\n        data = read_csv(BytesIO(response.encode('utf-8')), **kw).reset_index()\n        data = data.drop_duplicates(subset='date_time').set_index('date_time')\n        \n        series = data[col]\n        series._metadata = [dict(name=row['name'],\n                                 station=row['station_id'],\n                                 sensor=row['sensor_id'],\n                                 lon=row['longitude (degree)'],\n                                 lat=row['latitude (degree)'],\n                                 depth=row['depth (m)'],)]\n\n        observations.append(series)\n    return observations",
                "true_label": "",
                "top5_preds": [
                    "reading and writing csv files",
                    "from dictionary to dataframe",
                    "formatting datetimes as strings",
                    "getting data from the internet",
                    "load table in pandas"
                ]
            },
            {
                "code": "from pyoos.collectors.ndbc.ndbc_sos import NdbcSos\nfrom pyoos.collectors.ioos.swe_sos import IoosSweSos\nfrom pyoos.collectors.coops.coops_sos import CoopsSos\n\nobservations = []\nfor url in sos_urls:\n    if 'co-ops' in url.lower():\n        collector = CoopsSos()\n    elif 'ndbc' in url.lower():\n        collector = NdbcSos()\n    else:\n        collector = IoosSweSos(url)\n    \n    collector.set_bbox(bbox)\n    collector.end_time = stop\n    collector.start_time = start\n    collector.variables = [sos_name]\n    \n    ofrs = collector.server.offerings\n    title = collector.server.identification.title\n    try:\n        observations.extend(collector2table(collector))\n        print('{}: {} offerings:'.format(title, len(ofrs)))\n        print(fmt(' {} '.format(url)))\n    except Exception as e:\n        print('\\nCannot collect:\\n{}. {}'.format(url, e))",
                "true_label": "",
                "top5_preds": [
                    "getting data from the internet",
                    "predicting a categorical response",
                    "predicting a continuous response using linear regression",
                    "importing data with numpy",
                    "retrieving data from html page"
                ]
            },
            {
                "code": "%matplotlib inline\nfrom itertools import cycle\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\n\nimport numpy as np\n\ndef mpl_palette(cmap, n_colors=6):\n    brewer_qual_pals = {\"Accent\": 8, \"Dark2\": 8, \"Paired\": 12,\n                        \"Pastel1\": 9, \"Pastel2\": 8,\n                        \"Set1\": 9, \"Set2\": 8, \"Set3\": 12}\n\n    if cmap.name in brewer_qual_pals:\n        bins = np.linspace(0, 1, brewer_qual_pals[cmap.name])[:n_colors]\n    else:\n        bins = np.linspace(0, 1, n_colors + 2)[1:-1]\n    palette = list(map(tuple, cmap(bins)[:, :3]))\n\n    pal_cycle = cycle(palette)\n    palette = [next(pal_cycle) for _ in range(n_colors)]\n    \n    return palette\n\nwith mpl.style.context('seaborn-notebook'):\n    fig, ax = plt.subplots(figsize=(11, 2.75))\n    colors = mpl_palette(plt.cm.Set2, n_colors=len(observations))\n    for k, series in enumerate(observations):\n        station_name = series._metadata[0]['name']\n        ax.plot(series.index, series, label=station_name, color=colors[k])\n    leg = ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.3),\n              ncol=3, fancybox=True, shadow=True)\n\nhours = mpl.dates.DateFormatter('%H:%M')\nax.xaxis.set_major_formatter(hours)\n\ndays = mpl.dates.DateFormatter('\\n\\n%Y-%m-%d')\nax.xaxis.set_minor_formatter(days)\nax.xaxis.set_minor_locator(mpl.ticker.FixedLocator([mpl.dates.date2num(start)]))\n\nfig.savefig('time_series.png', bbox_extra_artists=(leg,),\n            bbox_inches='tight', dpi=150)",
                "true_label": "",
                "top5_preds": [
                    "plot using matplotlib",
                    "matplotlib",
                    "plotting in python",
                    "heatmap with time",
                    "line plot with a dataframe"
                ]
            },
            {
                "code": "import folium\nimport numpy as np\n\nlocation = np.array(bbox).reshape(2, 2).mean(axis=0).tolist()[::-1]\ntiles = ('http://services.arcgisonline.com/arcgis/rest/'\n         'services/Ocean/World_Ocean_Base/MapServer/tile/{z}/{y}/{x}')\n\nmapa = folium.Map(location=location, zoom_start=6, tiles=tiles, attr='ESRI')",
                "true_label": "",
                "top5_preds": [
                    "importing data with numpy",
                    "equally spaced numbers on a grid",
                    "ridge regression with polynomial features on a grid",
                    "numpy",
                    "convert list to numpy array"
                ]
            }
        ],
        [
            {
                "code": "import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport math\nimport seaborn as sns\nfrom sklearn import ensemble\nfrom sklearn.cross_validation import train_test_split\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.grid_search import GridSearchCV\nfrom datetime import datetime\nfrom sklearn.externals.six import StringIO  \nfrom IPython.display import Image  \nfrom sklearn.tree import export_graphviz\nimport pydotplus\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.ensemble import GradientBoostingRegressor\n%matplotlib inline\n#Loading Data from local\ntrain = pd.read_csv('F:/Warpath to Data Science/regression/bike-sharing/train.csv')\ntest = pd.read_csv('F:/Warpath to Data Science/regression/bike-sharing/test.csv')",
                "true_label": "",
                "top5_preds": [
                    "import polynomial features from sklearn",
                    "polynomial regression with sklearn",
                    "equally spaced numbers on a grid",
                    "ridge regression with polynomial features on a grid",
                    "what is scikit learn?"
                ]
            },
            {
                "code": "#if the date column is not imported as date format we can use below command to overcome the mismatch\n#df = train\n#df['datetime'] = pd.to_datetime(df['datetime'], format='%d%b%Y')\n#df.head(1)\nprint(\"training data: \", train.head(2))\nprint(\"test data: \", test.head(2))",
                "true_label": "",
                "top5_preds": [
                    "convert date to datetime format",
                    "formatting datetimes as strings",
                    "transform the date column as a datetime type",
                    "integrating datetime tools with pandas for time series",
                    "load table in pandas"
                ]
            },
            {
                "code": "train.info()",
                "true_label": "",
                "top5_preds": [
                    "tensorflow + keras",
                    "what is scikit learn?",
                    "load table in pandas",
                    "import polynomial features from sklearn",
                    "training data"
                ]
            },
            {
                "code": "test.info()",
                "true_label": "",
                "top5_preds": [
                    "getting data from the internet",
                    "equally spaced numbers on a grid",
                    "formatting datetimes as strings",
                    "interacting with online services",
                    "line plots show the trend of a numerical variable over time"
                ]
            },
            {
                "code": "#behaviour over years(2011, 2012 to be precise)\nfig, axes = plt.subplots(nrows = 1, ncols = 3, squeeze=False)\nfig.set_size_inches(20,6)\nsns.boxplot(x = 'year', y = 'casual', data = train, ax = axes[0][0])\nsns.boxplot(x = 'year', y = 'registered', data = train, ax = axes[0][1])\nsns.boxplot(x = 'year', y = 'count', data = train, ax = axes[0][2])\naxes[0][0].set(xlabel='year', ylabel='casual',title=\"Box Plot: Casual users behaviour across years\")\naxes[0][1].set(xlabel='year', ylabel='registered',title=\"Box Plot: Registered users behaviour across years\")\naxes[0][2].set(xlabel='year', ylabel='count',title=\"Box Plot: total users behaviour across years\")\nplt.tight_layout()",
                "true_label": "",
                "top5_preds": [
                    "ploting out data with box plots",
                    "using a dataframe and matplotlib commands",
                    "pandas plotting",
                    "how to change the size of a plot",
                    "plot multidimensional data in two dimensions"
                ]
            },
            {
                "code": "#behaviour over different seasons of the year\nfig, axes = plt.subplots(nrows = 1, ncols = 3, squeeze=False)\nfig.set_size_inches(20,6)\nsns.boxplot(x = 'season', y = 'casual', data = train, ax = axes[0][0])\nsns.boxplot(x = 'season', y = 'registered', data = train, ax = axes[0][1])\nsns.boxplot(x = 'season', y = 'count', data = train, ax = axes[0][2])\naxes[0][0].set(xlabel='season', ylabel='casual',title=\"Box Plot: Casual users behaviour across different seasons\")\naxes[0][1].set(xlabel='season', ylabel='registered',title=\"Box Plot: Registered users behaviour across different seasons\")\naxes[0][2].set(xlabel='season', ylabel='count',title=\"Box Plot: total users behaviour across different seasons\")\nplt.tight_layout()",
                "true_label": "",
                "top5_preds": [
                    "ploting out data with box plots",
                    "how to change the size of a plot",
                    "create box plots",
                    "plot multidimensional data in two dimensions",
                    "box plot"
                ]
            },
            {
                "code": "#Correlation among different attributes of the training data\nf, ax = plt.subplots(figsize=(20, 6))\ntrain_corr = train.corr()\nsns.heatmap(train_corr, mask=np.zeros_like(train_corr, dtype=np.bool), cmap=sns.diverging_palette(220, 10, as_cmap=True),\n            square=True, ax=ax)",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "predicting a categorical response",
                    "create a scatter plot",
                    "polynomial regression with sklearn",
                    "traffic sign classification with keras"
                ]
            },
            {
                "code": "#Correlation among different attributes of the test data\nf, ax = plt.subplots(figsize=(20, 6))\ntest_corr = test.corr()\nsns.heatmap(test_corr, mask=np.zeros_like(test_corr, dtype=np.bool), cmap=sns.diverging_palette(220, 10, as_cmap=True),\n            square=True, ax=ax)",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "create a scatter plot",
                    "predicting a categorical response",
                    "heatmap with time",
                    "visualize the scatterplot of x"
                ]
            },
            {
                "code": "test1 = test.copy(deep=True)#this type of copying helps us not modify test dataset when we do some modifications on test1 DF\ntest1.head(1)\n#del test1",
                "true_label": "",
                "top5_preds": [
                    "from dictionary to dataframe",
                    "join two dataframes along rows",
                    "optimal value of k for dataset",
                    "join two dataframes along columns",
                    "load table in pandas"
                ]
            },
            {
                "code": "#Adding columns to make sure both have same # of columns and column names to be consistent while appending\ntest1['casual'] = 0\ntest1['registered'] = 0\ntest1['count'] = 0\ntest1.head()",
                "true_label": "",
                "top5_preds": [
                    "sqlalchemy, sqlite, and dates",
                    "from dictionary to dataframe",
                    "change type of column",
                    "load table in pandas",
                    "postgres sql lab"
                ]
            },
            {
                "code": "#combining train and test datasets\ncombined = pd.concat([train, test1], axis = 0)\nprint(combined.shape)\nprint(6493 + 10886) ",
                "true_label": "",
                "top5_preds": [
                    "combine two dataframes into one",
                    "create a dataframe by joining series by column",
                    "join two dataframes along rows",
                    "join two dataframes along columns",
                    "find data type of each column"
                ]
            },
            {
                "code": "#creating groups for hour by analysing node splits while building trees\ncombined = pd.concat([train, test1], axis = 0)\ncombined['reg_hr'] = 0\n\nconditions = [\n    (combined['hour'] <= 6) & (combined['hour'] >= 2),\n    (combined['hour'] <= 16) & (combined['hour'] >= 9),\n    (combined['hour'] <= 21) & (combined['hour'] > 16),\n    (combined['hour'] < 9) & (combined['hour'] >= 7),\n    (combined['hour'] == 21) | (combined['hour'] == 22),\n    (combined['hour'] > 22),\n    (combined['hour'] <= 1)]\nchoices = [1,2,3,4,5,6,7]\ncombined['reg_hr'] = np.select(conditions, choices, default=0)\n#combined = combined.drop('reg_hr', axis = 1)\n#combined[combined['reg_hr'] == 0]\ncombined.head()\n",
                "true_label": "",
                "top5_preds": [
                    "join two dataframes along rows",
                    "find data type of each column",
                    "create dataframe with given values",
                    "line plot with a dataframe",
                    "create a one column dataframe with the values of a series"
                ]
            },
            {
                "code": "#Creating groups in each of the column based on importance with Decision Tree splits \n#Applying to hour variable in training set with target as casual users\ndtree=DecisionTreeRegressor()\nx = train['hour']\ny = train['casual']\nx = x.reshape(-1, 1)\ndtree.fit(x,y)\n\ndot_data = StringIO()\nexport_graphviz(dtree, out_file=dot_data,  \n                filled=True, rounded=True,\n                special_characters=True)\ngraph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \nImage(graph.create_png())",
                "true_label": "",
                "top5_preds": [
                    "import polynomial features from sklearn",
                    "what is scikit learn?",
                    "training a decision tree model",
                    "decision tree learning with sklearn",
                    "implementing bag of words in scikit learn"
                ]
            },
            {
                "code": "#creating for casual users \ncombined['cas_hr'] = 0\n\nconditions = [\n    (combined['hour'] <= 6),\n    (combined['hour'] == 7),\n    (combined['hour'] <= 9) & (combined['hour'] > 7),\n    (combined['hour'] == 10),\n    (combined['hour'] <= 19) & (combined['hour'] > 10),\n    (combined['hour'] < 9) & (combined['hour'] >= 6),\n    (combined['hour'] <= 21) & (combined['hour'] >= 20),\n    (combined['hour'] >= 22)]\nchoices = [1,2,3,4,5,6,7, 8]\ncombined['cas_hr'] = np.select(conditions, choices, default=0)\ncombined.head()",
                "true_label": "",
                "top5_preds": [
                    "formatting datetimes as strings",
                    "convert categorical variables",
                    "compare variable with time",
                    "working with pandas series indexed by datetime",
                    "sql LIKE operator"
                ]
            },
            {
                "code": "#Creating groups in each of the column based on importance with Decision Tree splits \n#Applying to temp variable in training set with target as registered users\ndtree=DecisionTreeRegressor()\nx = train['temp']\ny = train['registered']\nx = x.reshape(-1, 1)\ndtree.fit(x,y)\n\ndot_data = StringIO()\nexport_graphviz(dtree, out_file=dot_data,  \n                filled=True, rounded=True,\n                special_characters=True)\ngraph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \nImage(graph.create_png())",
                "true_label": "",
                "top5_preds": [
                    "what is scikit learn?",
                    "import polynomial features from sklearn",
                    "decision tree learning with sklearn",
                    "training a decision tree model",
                    "implementing bag of words in scikit learn"
                ]
            },
            {
                "code": "#creating for casual users \ncombined['reg_temp'] = 0\n\nconditions = [\n    (combined['temp'] <= 22.55) & (combined['temp'] > 12.71),\n    (combined['temp'] <= 12.71),\n    (combined['temp'] <= 29.93) & (combined['temp'] > 22.55),\n    (combined['temp'] > 29.93) & (combined['temp'] <= 30.75),\n    (combined['temp'] <= 38.13) & (combined['temp'] > 30.75),\n    (combined['temp'] > 38.13)]\nchoices = [1,2,3,4,5,6]\ncombined['reg_temp'] = np.select(conditions, choices, default=0)\ncombined.head()",
                "true_label": "",
                "top5_preds": [
                    "what is conditional probability good for?",
                    "predicting a categorical response",
                    "convert categorical variables",
                    "sql LIKE operator",
                    "create dataframe with given values"
                ]
            },
            {
                "code": "#Creating groups in each of the column based on importance with Decision Tree splits \n#Applying to temp variable in training set with target as casual users\ndtree=DecisionTreeRegressor()\nx = train['temp']\ny = train['casual']\nx = x.reshape(-1, 1)\ndtree.fit(x,y)\n\ndot_data = StringIO()\nexport_graphviz(dtree, out_file=dot_data,  \n                filled=True, rounded=True,\n                special_characters=True)\ngraph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \nImage(graph.create_png())",
                "true_label": "",
                "top5_preds": [
                    "what is scikit learn?",
                    "import polynomial features from sklearn",
                    "training a decision tree model",
                    "decision tree learning with sklearn",
                    "implementing bag of words in scikit learn"
                ]
            },
            {
                "code": "#creating for casual users \ncombined['cas_temp'] = 0\n\nconditions = [\n    (combined['temp'] <= 23.37) & (combined['temp'] > 15.17),\n    (combined['temp'] <= 15.17) & (combined['temp'] > 12.71),\n    (combined['temp'] <= 12.71),\n    (combined['temp'] <= 29.93) & (combined['temp'] > 23.37),\n    (combined['temp'] > 29.93) & (combined['temp'] <= 32.39),\n    (combined['temp'] <= 36.49) & (combined['temp'] > 32.39),\n    (combined['temp'] > 36.49)]\nchoices = [1,2,3,4,5,6, 7]\ncombined['cas_temp'] = np.select(conditions, choices, default=0)\ncombined.head()\n#combined[combined['cas_temp'] == 0]",
                "true_label": "",
                "top5_preds": [
                    "what is conditional probability good for?",
                    "convert categorical variables",
                    "create a one column dataframe with the values of a series",
                    "create dataframe with given values",
                    "sql LIKE operator"
                ]
            },
            {
                "code": "#Creating groups in each of the column based on importance with Decision Tree splits \n#Applying to atemp variable in training set with target as registered users\ndtree=DecisionTreeRegressor()\nx = train['atemp']\ny = train['registered']\nx = x.reshape(-1, 1)\ndtree.fit(x,y)\n\ndot_data = StringIO()\nexport_graphviz(dtree, out_file=dot_data,  \n                filled=True, rounded=True,\n                special_characters=True)\ngraph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \nImage(graph.create_png())\n",
                "true_label": "",
                "top5_preds": [
                    "import polynomial features from sklearn",
                    "what is scikit learn?",
                    "decision tree learning with sklearn",
                    "training a decision tree model",
                    "implementing bag of words in scikit learn"
                ]
            },
            {
                "code": "#creating groups for atemp variable \ncombined['reg_atemp'] = 0\n\nconditions = [\n    (combined['atemp'] <= 29.93) & (combined['atemp'] > 15),\n    (combined['atemp'] <= 15) & (combined['atemp'] > 9.71),\n    (combined['atemp'] <= 9.71),\n    (combined['atemp'] <= 35.228) & (combined['atemp'] > 29.93),\n    (combined['atemp'] > 35.228) & (combined['atemp'] <= 41.228),\n    (combined['atemp'] <= 45) & (combined['atemp'] > 41.228),\n    (combined['atemp'] > 45)]\nchoices = [1,2,3,4,5,6, 7]\ncombined['reg_atemp'] = np.select(conditions, choices, default=0)\ncombined.head()\n#combined[combined['reg_atemp'] == 0]",
                "true_label": "",
                "top5_preds": [
                    "what is conditional probability good for?",
                    "predicting a categorical response",
                    "convert categorical variables",
                    "find data type of each column",
                    "create dataframe with given values"
                ]
            },
            {
                "code": "#Creating groups in each of the column based on importance with Decision Tree splits \n#Applying to atemp variable in training set with target as casual users\ndtree=DecisionTreeRegressor()\nx = train['atemp']\ny = train['casual']\nx = x.reshape(-1, 1)\ndtree.fit(x,y)\n\ndot_data = StringIO()\nexport_graphviz(dtree, out_file=dot_data,  \n                filled=True, rounded=True,\n                special_characters=True)\ngraph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \nImage(graph.create_png())\n",
                "true_label": "",
                "top5_preds": [
                    "what is scikit learn?",
                    "import polynomial features from sklearn",
                    "training a decision tree model",
                    "decision tree learning with sklearn",
                    "implementing bag of words in scikit learn"
                ]
            },
            {
                "code": "#creating groups for atemp variable \ncombined['cas_atemp'] = 0\n\nconditions = [\n    (combined['atemp'] <= 30.682) & (combined['atemp'] > 18.56),\n    (combined['atemp'] <= 18.56) & (combined['atemp'] > 14.73),\n    (combined['atemp'] <= 14.73),\n    (combined['atemp'] <= 32.995) & (combined['atemp'] > 30.682),\n    (combined['atemp'] > 32.995) & (combined['atemp'] <= 41.287),\n    (combined['atemp'] <= 42.045) & (combined['atemp'] > 41.287),\n    (combined['atemp'] > 42.045)]\nchoices = [1,2,3,4,5,6, 7]\ncombined['cas_atemp'] = np.select(conditions, choices, default=0)\ncombined.head()\n#combined[combined['reg_atemp'] == 0]",
                "true_label": "",
                "top5_preds": [
                    "what is conditional probability good for?",
                    "convert categorical variables",
                    "create dataframe with given values",
                    "predicting a categorical response",
                    "find data type of each column"
                ]
            },
            {
                "code": "#changing datatypes accordingly\nfor var in categoricalFeatureNames:\n    combined1[var] = combined1[var].astype(\"category\")",
                "true_label": "",
                "top5_preds": [
                    "transform categorical data into binary features",
                    "convert categorical variables",
                    "find data type of each column",
                    "import polynomial features from sklearn",
                    "list of categories"
                ]
            },
            {
                "code": "#splitting final combined dataset into training and test datasets to apply ML model\ntrain1 = combined1[combined1['count'] != 0]\ntest1 = combined1[combined1['count'] == 0]",
                "true_label": "",
                "top5_preds": [
                    "fit on training set",
                    "transform categorical data into binary features",
                    "import polynomial features from sklearn",
                    "intro to classification with knn",
                    "fit on training"
                ]
            },
            {
                "code": "#Dropping unecessary columns\ntrain1 = train1.drop(dropFeatures,axis=1)\ntest1  = test1.drop(dropFeatures,axis=1)\n\n#Also dropping log_casual, log_registered in test dataset as we need to predict these columns \ntest1 = test1.drop('log_casual',axis=1)\ntest1 = test1.drop('log_registered',axis=1)",
                "true_label": "",
                "top5_preds": [
                    "import polynomial features from sklearn",
                    "load table in pandas",
                    "transform categorical data into binary features",
                    "what is scikit learn?",
                    "using logistic regression with categorical features"
                ]
            },
            {
                "code": "#getting casual, registered users training and test datasets\n#creating dependent(target) variable training dataset\ny_train_cas = train1[['log_casual']]\ny_train_reg = train1[['log_registered']]\n\n#creating indepdent(input) training variables dataset\ndropCasFeatures = ['cas_hr', 'cas_temp', 'cas_atemp', 'log_casual', 'log_registered']\ndropRegFeatures = ['reg_hr', 'reg_temp', 'reg_atemp', 'log_casual', 'log_registered']\nx_train_reg = train1.drop(dropCasFeatures,axis=1)\nx_train_cas = train1.drop(dropRegFeatures,axis=1)",
                "true_label": "",
                "top5_preds": [
                    "import polynomial features from sklearn",
                    "what is scikit learn?",
                    "linear regression of many variables",
                    "requirements for working with data in scikit learn",
                    "add intercept in logistic regression"
                ]
            },
            {
                "code": "#creating independent (input) test variables dataset\ndropCasFeatures = ['cas_hr', 'cas_temp', 'cas_atemp']\ndropRegFeatures = ['reg_hr', 'reg_temp', 'reg_atemp']\nx_test_reg = test1.drop(dropCasFeatures,axis=1)\nx_test_cas = test1.drop(dropRegFeatures,axis=1)",
                "true_label": "",
                "top5_preds": [
                    "import polynomial features from sklearn",
                    "transform categorical data into binary features",
                    "using logistic regression with categorical features",
                    "what is scikit learn?",
                    "creating polynomial features"
                ]
            },
            {
                "code": "x_train_reg.head()",
                "true_label": "",
                "top5_preds": [
                    "tensorflow + keras",
                    "logistic regression using tensorflow",
                    "what is scikit learn?",
                    "import polynomial features from sklearn",
                    "transform categorical data into binary features"
                ]
            },
            {
                "code": "#converting strings to float as models won't accept string datatype columns\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder\nlabelencoder_x = LabelEncoder()\n\nx_train_reg[['day']] = labelencoder_x.fit_transform(x_train_reg[['day']])\nx_train_cas[['day']] = labelencoder_x.fit_transform(x_train_cas[['day']])\n\nx_test_reg[['day']] = labelencoder_x.fit_transform(x_test_reg[['day']])\nx_test_cas[['day']] = labelencoder_x.fit_transform(x_test_cas[['day']])",
                "true_label": "",
                "top5_preds": [
                    "using logistic regression with categorical features",
                    "transform categorical data into binary features",
                    "predicting a continuous response using linear regression",
                    "import polynomial features from sklearn",
                    "predicting a categorical response"
                ]
            },
            {
                "code": "#onehot encoding to not consider the order of the numericals\nonehotencoder = OneHotEncoder(categorical_features = [1, 2, 4 ,5, 7, 8, 10, 11, 12, 13, 14, 15, 16])\nx_test_reg_encode = onehotencoder.fit_transform(x_test_reg).toarray()\n\nonehotencoder = OneHotEncoder(categorical_features = [1, 2, 4 ,5, 7, 8, 10, 11, 12, 13, 14, 15, 16])\nx_test_cas_encode = onehotencoder.fit_transform(x_test_cas).toarray()",
                "true_label": "",
                "top5_preds": [
                    "transform categorical data into binary features",
                    "using logistic regression with categorical features",
                    "predicting a categorical response",
                    "polynomial regression with sklearn",
                    "logistic regression using tensorflow"
                ]
            },
            {
                "code": "#feature scaling\nfrom sklearn.preprocessing import StandardScaler\nsc_x = StandardScaler()\nx_train_reg_scaled = sc_x.fit_transform(x_train_reg)\nx_test_reg_scaled = sc_x.transform(x_test_reg)\n\nx_train_cas_scaled = sc_x.fit_transform(x_train_cas)\nx_test_cas_scaled = sc_x.transform(x_test_cas)",
                "true_label": "",
                "top5_preds": [
                    "import polynomial features from sklearn",
                    "what is scikit learn?",
                    "polynomial regression with sklearn",
                    "scipy",
                    "scikit learn"
                ]
            },
            {
                "code": "#Applying Random Forest Model\nforest = RandomForestRegressor(n_estimators = 400, criterion='mse',random_state=1, n_jobs=-1)\n\n#fitting model to registered users\nforest.fit(x_train_reg_encode_scaled, y_train_reg)\ny_train_reg_pred = forest.predict(x_train_reg_encode_scaled)\ny_test_reg_pred = forest.predict(x_test_reg_encode_scaled)\n\n#fitting model to casual users\nforest.fit(x_train_cas_encode_scaled, y_train_cas)\ny_train_cas_pred = forest.predict(x_train_cas_encode_scaled)\ny_test_cas_pred = forest.predict(x_test_cas_encode_scaled)\n\n#transforming log predictions to normal for casual users\ny_test_cas_pred_nrml = np.exp(y_test_cas_pred)-1\n\n#transforming log predictions to normal for registered users\ny_test_reg_pred_nrml = np.exp(y_test_reg_pred)-1\n\ncount_predictions = y_test_cas_pred_nrml + y_test_reg_pred_nrml\ncount_predictions[:5]",
                "true_label": "",
                "top5_preds": [
                    "polynomial regression with sklearn",
                    "logistic regression using tensorflow",
                    "fit a logistic regression model using statsmodels using logistic regression formula in patsy",
                    "build a vector of prediction from the trained model",
                    "import polynomial features from sklearn"
                ]
            },
            {
                "code": "#splitting into training and test data for registered users\nfrom sklearn.cross_validation import train_test_split\nX_trainsub_reg, X_testsub_reg, Y_trainsub_reg, Y_testsub_reg = train_test_split(x_train_reg_scaled, y_train_reg, test_size = .30, random_state = 0)\n\n#splitting into training and test data for casual users\nfrom sklearn.cross_validation import train_test_split\nX_trainsub_cas, X_testsub_cas, Y_trainsub_cas, Y_testsub_cas = train_test_split(x_train_cas_scaled, y_train_cas, test_size = .30, random_state = 0)",
                "true_label": "",
                "top5_preds": [
                    "import polynomial features from sklearn",
                    "what is scikit learn?",
                    "use train_test_split to divide dataset into a training and test set",
                    "perform a train test split on the data",
                    "fit on training set"
                ]
            }
        ],
        [
            {
                "code": "x = 15\ny = 10\nx = x - y - 5\n#z = y/x",
                "true_label": "",
                "top5_preds": [
                    "plotting in python",
                    "sum all the numbers in a list",
                    "line plots show the trend of a numerical variable over time",
                    "diagonal sum in a spiral",
                    "equally spaced numbers on a grid"
                ]
            },
            {
                "code": "print(\"I am not going to work like this\")\n",
                "true_label": "",
                "top5_preds": [
                    "get a positive integer from a user",
                    "formatting datetimes as strings",
                    "line plots show the trend of a numerical variable over time",
                    "getting data from the internet",
                    "remove duplicates from a list"
                ]
            },
            {
                "code": "number = input(\"give me a number to square\")\nnumber = int(number)\nresult = number * number\nprint(\"You squared number is {}\".format(result))",
                "true_label": "",
                "top5_preds": [
                    "get a positive integer from a user",
                    "sum all the numbers in a list",
                    "print square numbers",
                    "test whether a number is positive",
                    "read numbers until and print their mean and standard deviation without using a list"
                ]
            },
            {
                "code": "age = 23\nheight = 5.23623\nprint(\"The age is {1} and the height is {0:.2f}\".format(height, age))",
                "true_label": "",
                "top5_preds": [
                    "convert data from string to float",
                    "formatting datetimes as strings",
                    "read numbers until and print their mean and standard deviation without using a list",
                    "convert a tuple to a string",
                    "print square numbers"
                ]
            },
            {
                "code": "import math\nmath.pi?",
                "true_label": "",
                "top5_preds": [
                    "pi by means of the arithmetic geometric mean",
                    "test whether a number is positive",
                    "fit a polynomial",
                    "numpy point",
                    "equally spaced numbers on a grid"
                ]
            },
            {
                "code": "function add_numbers(a,b) {\n    .....\n}",
                "true_label": "",
                "top5_preds": [
                    "sum all the numbers in a list",
                    "add an item in a tuple",
                    "integer addition",
                    "multiply all the numbers in a list",
                    "convert list to numpy array"
                ]
            },
            {
                "code": "# compare greater than\n12 > 11",
                "true_label": "",
                "top5_preds": [
                    "find maximum and the minimum value in a set",
                    "remove duplicates from a list",
                    "test whether a number is positive",
                    "rounding, overflow, linear algebra",
                    "bytes to integer conversion"
                ]
            },
            {
                "code": "# compare less than\n2 < 100000000000000",
                "true_label": "",
                "top5_preds": [
                    "formatting datetimes as strings",
                    "remove duplicates from a list",
                    "bytes to integer conversion",
                    "find maximum and the minimum value in a set",
                    "rounding, overflow, linear algebra"
                ]
            },
            {
                "code": "# compare equals\n\nnumber = 12\nnumber == 13",
                "true_label": "",
                "top5_preds": [
                    "test whether a number is positive",
                    "sum all the numbers in a list",
                    "integer division",
                    "convert strings to numbers",
                    "bytes to integer conversion"
                ]
            },
            {
                "code": "# compare two logical expressions with and\n(12 == 12) and (13 == 13)\n# True and False",
                "true_label": "",
                "top5_preds": [
                    "test whether a number is positive",
                    "logical and identity operators",
                    "filtering with boolean arrays",
                    "rounding, overflow, linear algebra",
                    "differential expression"
                ]
            },
            {
                "code": "# compare two logical expressions with or\n( (12 == 12) or (12 == 12) ) and False ",
                "true_label": "",
                "top5_preds": [
                    "logical and identity operators",
                    "test whether a number is positive",
                    "differential expression",
                    "comparison & logic",
                    "filtering with boolean arrays"
                ]
            },
            {
                "code": "# use 'not'\nnot (( (12 == 12) or (12 == 12) ) and False )",
                "true_label": "",
                "top5_preds": [
                    "test whether a number is positive",
                    "check a list is empty or not",
                    "matching metacharacters literally",
                    "filling the mask",
                    "what is conditional probability good for?"
                ]
            },
            {
                "code": "# ask for a name\n# if name matches, say hi and ask how they are...\n\nfriend = \"Joffery\"\nname = input(\"What is your name?\")\n\nif (name == friend):\n    print(\"Hey {}, how's it going?\".format(name))     ",
                "true_label": "",
                "top5_preds": [
                    "get a positive integer from a user",
                    "what is a string?",
                    "formatting datetimes as strings",
                    "assign to a variable",
                    "converting to and from strings"
                ]
            },
            {
                "code": "# ask for a name\n# if name matches, say hi, otherwise say 'who are you?'\nfriend = \"Joffery\"\nname = input(\"What is your name?\")\n\nif (name == friend):\n    print(\"Hey {}, how's it going?\".format(name))    \nelse:\n    print(\"Who are you?\") ",
                "true_label": "",
                "top5_preds": [
                    "get a positive integer from a user",
                    "what is a string?",
                    "formatting datetimes as strings",
                    "getting data from the internet",
                    "assign to a variable"
                ]
            },
            {
                "code": "# ask for a name\n# if name matches, say hi, \n# if name is your name, say 'hey we have the same name!'\n# otherwise say 'who are you?'\nmy_name = \"Jonathan\"\nfriend = \"Joffery\"\nname = input(\"What is your name?\")\n\nif (name == friend):\n    print(\"Hey {}, how's it going?\".format(name))    \nelif (name == my_name):\n    print(\"Hey {}, we have the same name!\".format(name))    \nelse:\n    print(\"Who are you?\") ",
                "true_label": "",
                "top5_preds": [
                    "get a positive integer from a user",
                    "what is a string?",
                    "formatting datetimes as strings",
                    "test whether a number is positive",
                    "assign to a variable"
                ]
            },
            {
                "code": "# choose a number\n# ask for a number between 1 - 10 but not 7\n# if 7, yell at the user\n# if not 7 but not lucky number, call them a loser\n# if lucky number, celebrate\n\nnumber = int(input(\"pick a number between 1 and 10, but NOT 7\"))\nlucky_number = 3\n\nif (number == 7):\n    print(\"I SAID NOT 7!!!!!\")\nelse:\n    \n    if (number == lucky_number):\n        print(\"Yay!!! You got it right\")\n    else:\n        print('Loser.')",
                "true_label": "",
                "top5_preds": [
                    "get a positive integer from a user",
                    "pick a random integer using the random module",
                    "test whether a number is positive",
                    "playing with condition numbers",
                    "predicting a categorical response"
                ]
            },
            {
                "code": "apples = int(input(\"How many pounds of apples do you want?\"))\ncash = int(input(\"How much $$ do you have?\"))\nper_pound = 2.00\n\ntotal_cost = apples * per_pound\n\nchange = cash - total_cost\nprint(change)\n\nif ( cash > total_cost ):\n    print(\"You get {} in change!\".format(change))\nelif (cash < total_cost):\n    print(\"You owe {}\".format(change))\nelse:\n    print(\"We are good!\")\n",
                "true_label": "",
                "top5_preds": [
                    "get a positive integer from a user",
                    "sum all the numbers in a list",
                    "reverse digits in a number",
                    "bytes to integer conversion",
                    "multiply all the numbers in a list"
                ]
            },
            {
                "code": "year = int(input(\"give me a year\"))\n\nby_4 = ((year % 4) == 0)\nby_100 = ((year % 100) == 0)\n\nif (by_4 and not by_100):\n    print(\"leap year\")\nelse:\n    print(\"Not leap year\")",
                "true_label": "",
                "top5_preds": [
                    "get a positive integer from a user",
                    "test whether a number is positive",
                    "reverse digits in a number",
                    "convert binary to hexadecimal",
                    "bytes to integer conversion"
                ]
            }
        ],
        [
            {
                "code": "import os\n\nCOLAB = False\n\nif COLAB:\n    from google.colab import files\n    uploaded = files.upload()\n    \n    if not os.path.exists('data'):\n        os.makedirs('data')\n\n    for fname, content in uploaded.items():\n        with open(os.path.join('data', fname), 'wb') as f:\n            f.write(content)",
                "true_label": "",
                "top5_preds": [
                    "standard file types",
                    "getting data from the internet",
                    "get a positive integer from a user",
                    "convert text data into vector",
                    "reading in the files"
                ]
            },
            {
                "code": "if not os.path.exists('models'):\n        os.makedirs('models')\nif not os.path.exists('histories'):\n        os.makedirs('histories')",
                "true_label": "",
                "top5_preds": [
                    "get the names of all the tables in the database",
                    "numpy",
                    "load table in pandas",
                    "reading in the files",
                    "running a local postgres database"
                ]
            },
            {
                "code": "!ls",
                "true_label": "",
                "top5_preds": [
                    "check a list is empty or not",
                    "convert list to numpy array",
                    "formatting datetimes as strings",
                    "add string to list using append",
                    "sum all the numbers in a list"
                ]
            },
            {
                "code": "from datetime import datetime\nimport pandas as pd",
                "true_label": "",
                "top5_preds": [
                    "formatting datetimes as strings",
                    "convert date to datetime format",
                    "integrating datetime tools with pandas for time series",
                    "plotting time series with pandas",
                    "transform the date column as a datetime type"
                ]
            },
            {
                "code": "train_df = pd.read_csv('data/train.csv', parse_dates=['Date'], low_memory=False)\ntest_df = pd.read_csv('data/test.csv', parse_dates=['Date'])",
                "true_label": "",
                "top5_preds": [
                    "loading a csv into a dataframe",
                    "load table in pandas",
                    "importing data with pandas",
                    "convert date to datetime format",
                    "from dictionary to dataframe"
                ]
            },
            {
                "code": "# Spread date over multiple columns\nfor df in [train_df, test_df]:\n    df['day'] = df.Date.dt.day\n    df['week'] = df.Date.dt.week\n    df['month'] = df.Date.dt.month\n    df['year'] = df.Date.dt.year",
                "true_label": "",
                "top5_preds": [
                    "convert date to datetime format",
                    "transform the date column as a datetime type",
                    "create a dataframe",
                    "from dictionary to dataframe",
                    "join two dataframes along rows"
                ]
            },
            {
                "code": "sales_history = train_df.set_index(train_df.date).sales.resample('D').sum()\nplt.figure(figsize=(15, 4))\nsales_history.plot();",
                "true_label": "",
                "top5_preds": [
                    "plotting time series with pandas",
                    "line plots show the trend of a numerical variable over time",
                    "line plot with a dataframe",
                    "integrating datetime tools with pandas for time series",
                    "plot variable dependence trends"
                ]
            },
            {
                "code": "plt.figure(figsize=(15, 4))\npd.plotting.autocorrelation_plot(sales_history);",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "relationships between dataframes",
                    "line plots show the trend of a numerical variable over time",
                    "plot using matplotlib",
                    "pandas plotting documentation"
                ]
            },
            {
                "code": "def plot_sales_per(date_unit):\n    plt.figure(figsize=(12, 4))\n    plt.subplot(121)\n    train_df.groupby(train_df[date_unit])['sales'].sum().plot()\n    plt.subplot(122)\n    train_df.groupby(train_df[date_unit])['sales'].mean().plot();",
                "true_label": "",
                "top5_preds": [
                    "plot the data",
                    "plot the training",
                    "calculate the mean windspeed for each month in the dataset",
                    "get the data",
                    "read the dataset"
                ]
            },
            {
                "code": "plot_sales_per('day')",
                "true_label": "",
                "top5_preds": [
                    "line plots show the trend of a numerical variable over time",
                    "plotting time series with pandas",
                    "line plot with a dataframe",
                    "sum all the numbers in a list",
                    "plotting percentiles"
                ]
            },
            {
                "code": "plot_sales_per('week')",
                "true_label": "",
                "top5_preds": [
                    "line plots show the trend of a numerical variable over time",
                    "plotting time series with pandas",
                    "line plot with a dataframe",
                    "sum all the numbers in a list",
                    "integrating datetime tools with pandas for time series"
                ]
            },
            {
                "code": "plot_sales_per('month')",
                "true_label": "",
                "top5_preds": [
                    "plotting time series with pandas",
                    "line plots show the trend of a numerical variable over time",
                    "line plot with a dataframe",
                    "create a one column dataframe with the values of a series",
                    "sum all the numbers in a list"
                ]
            },
            {
                "code": "plot_sales_per('year')",
                "true_label": "",
                "top5_preds": [
                    "line plots show the trend of a numerical variable over time",
                    "plotting time series with pandas",
                    "line plot with a dataframe",
                    "create a one column dataframe with the values of a series",
                    "sum all the numbers in a list"
                ]
            },
            {
                "code": "plt.figure(figsize=(15, 5))\nplt.subplot(121)\nsns.barplot(x='promo', y='sales', data=sampled_df)\nplt.subplot(122)\nsns.barplot(x='promo2', y='sales', data=sampled_df);",
                "true_label": "",
                "top5_preds": [
                    "plot using matplotlib",
                    "predicting a categorical response",
                    "ploting out data with box plots",
                    "plot histogram",
                    "line plot with a dataframe"
                ]
            },
            {
                "code": "print_anova_results('promo', 'sales')",
                "true_label": "",
                "top5_preds": [
                    "predicting a categorical response",
                    "get a positive integer from a user",
                    "visualizing uncertainty",
                    "getting data from the internet",
                    "rounding, overflow, linear algebra"
                ]
            },
            {
                "code": "print_anova_results('promo2', 'sales')",
                "true_label": "",
                "top5_preds": [
                    "predicting a categorical response",
                    "get a positive integer from a user",
                    "rounding, overflow, linear algebra",
                    "visualizing uncertainty",
                    "find maximum and the minimum value in a set"
                ]
            },
            {
                "code": "sns.barplot(x='promointerval', y='sales', data=train_df);",
                "true_label": "",
                "top5_preds": [
                    "predicting a categorical response",
                    "predicting a continuous response using linear regression",
                    "integrating datetime tools with pandas for time series",
                    "line plot with a dataframe",
                    "line plots show the trend of a numerical variable over time"
                ]
            },
            {
                "code": "print_anova_results('promointerval', 'sales')",
                "true_label": "",
                "top5_preds": [
                    "predicting a categorical response",
                    "predicting a continuous response using linear regression",
                    "fit a polynomial",
                    "visualizing uncertainty",
                    "ridge regression with one predictor on a grid"
                ]
            },
            {
                "code": "print(\"# Different stores: %d\" % len(set(train_df['store'])))\nstoretypes = sorted(list(set(train_df['storetype'])))\nprint(\"Different store types: %s\" % storetypes)",
                "true_label": "",
                "top5_preds": [
                    "add string to list using append",
                    "formatting datetimes as strings",
                    "find data type of each column",
                    "python data type list",
                    "how many different items appear in the dataset?"
                ]
            },
            {
                "code": "plt.figure(figsize=(15, 10))\nplt.subplot(221)\nplt.title('Count')\nsns.countplot(x='storetype', data=sampled_df)\nplt.subplot(222)\nsns.barplot(x='storetype', y='sales', data=sampled_df)\nplt.subplot(223)\nsns.barplot(x='storetype', y='promo', data=sampled_df)\nplt.subplot(224)\nsns.barplot(x='storetype', y='promo2', data=sampled_df);",
                "true_label": "",
                "top5_preds": [
                    "plot histogram",
                    "predicting a categorical response",
                    "line plots show the trend of a numerical variable over time",
                    "plotting time series with pandas",
                    "line plot with a dataframe"
                ]
            },
            {
                "code": "from keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom keras.layers import concatenate, Dense, Embedding, Input, Lambda, LSTM, Reshape\nfrom keras.models import Model, Sequential\nfrom sklearn.tree import DecisionTreeRegressor\nimport xgboost as xgb",
                "true_label": "",
                "top5_preds": [
                    "tensorflow + keras",
                    "what is scikit learn?",
                    "logistic regression using tensorflow",
                    "import polynomial features from sklearn",
                    "polynomial regression with sklearn"
                ]
            },
            {
                "code": "import h5py\nimport pickle",
                "true_label": "",
                "top5_preds": [
                    "load table in pandas",
                    "loading json in python",
                    "formatting datetimes as strings",
                    "equally spaced numbers on a grid",
                    "what is scikit learn?"
                ]
            },
            {
                "code": "def rmspe(prediction, target):\n    if prediction.shape != target.shape:\n        raise ValueError(\"Dimensions of prediction and target must match!\"\n                        + \" 'prediction' is %s; 'target' is %s\" % (prediction.shape, target.shape))\n    return np.sqrt(np.sum(((target - prediction) / target)**2) / len(prediction))\n\n# Test some some simple examples.\nprint(rmspe(np.array([1.0, 1.0]), np.array([1.0, 1.0])))\nprint(rmspe(np.array([1, 1]), np.array([2, 2])))",
                "true_label": "",
                "top5_preds": [
                    "compute the mean absolute error of the predictions",
                    "function fit_and_predict",
                    "making predictions for the testing data",
                    "get the sse by using the predictions for every x y_hats and the true y values",
                    "cosine similarity"
                ]
            },
            {
                "code": "def plot_history(history):\n    plt.plot(history['loss'], label='train')\n    plt.plot(history['val_loss'], label='validation')\n    plt.legend();",
                "true_label": "",
                "top5_preds": [
                    "plot the training",
                    "plot the data",
                    "plot the error and execution time",
                    "plot past data",
                    "plot the function"
                ]
            },
            {
                "code": "train_set_median = np.median(train_target)\nnon_zero_val_target = val_target[np.where(val_target > 0)[0]].reshape((-1, ))\nbaseline_prediction = np.ones(len(non_zero_val_target)) * train_set_median\nprint(rmspe(baseline_prediction, non_zero_val_target))",
                "true_label": "",
                "top5_preds": [
                    "predicting a categorical response",
                    "numpy",
                    "predicting a continuous response using linear regression",
                    "computing the covariance when there are nan s",
                    "ridge regression with one predictor on a grid"
                ]
            },
            {
                "code": "# Has both global trend for Germany as well as trends for single states.\nparse_trends_date = lambda d: datetime.strptime(d.split(' - ')[0], '%Y-%m-%d')\ngoogletrend_df = pd.read_csv('data/googletrend.csv', parse_dates=['week'],\n                             date_parser=parse_trends_date)\ngoogletrend_df['week'] = googletrend_df['week'].dt.week\n\nglobal_trends_df = googletrend_df[googletrend_df.file == 'Rossmann_DE']\nassert len(set(global_trends_df.file)) == 1\n# 'file' column no longer needed -> remove\ndel global_trends_df['file']\n\ntrain_df = train_df.merge(global_trends_df, on='week')\ntest_df = test_df.merge(global_trends_df, on='week')\n\ndel global_trends_df\n\nlocal_trends_df = googletrend_df[googletrend_df.file != 'Rossmann_DE']\nassert 'Rossmann_DE' not in local_trends_df.file\n# Extract state.\nlocal_trends_df.file = local_trends_df.file.apply(lambda x: x.split('_')[-1])\nlocal_trends_df = local_trends_df.rename(index=str,\n                                         columns={'file': 'State',\n                                                  'trend': 'global_trend'})\n\ntrain_df = train_df.merge(local_trends_df, on=['week', 'State'])\ntest_df = test_df.merge(local_trends_df, on=['week', 'State'])\n\ndel local_trends_df",
                "true_label": "",
                "top5_preds": [
                    "convert date to datetime format",
                    "line plots show the trend of a numerical variable over time",
                    "integrating datetime tools with pandas for time series",
                    "formatting datetimes as strings",
                    "importing data with pandas"
                ]
            },
            {
                "code": "# Put train and test datasets in a list to easier apply changes to both.\ndf_list = [train_df, test_df]",
                "true_label": "",
                "top5_preds": [
                    "join two dataframes along rows",
                    "using a dataframe and matplotlib commands",
                    "join two dataframes along columns",
                    "line plot with a dataframe",
                    "combine two dataframes into one"
                ]
            },
            {
                "code": "# Lowercase all column names for convenience and consistency.\nfor df in df_list:\n    df.columns = map(lambda col_name: col_name.lower(), df.columns)",
                "true_label": "",
                "top5_preds": [
                    "from dictionary to dataframe",
                    "line plot with a dataframe",
                    "relationships between dataframes",
                    "convert columns",
                    "pandas apply"
                ]
            },
            {
                "code": "# Show all distinct values per object type.\nfor col_name in train_df.select_dtypes(include='object'):\n    print(\"%s: \" % col_name)\n    print(set(train_df[col_name]))",
                "true_label": "",
                "top5_preds": [
                    "find data type of each column",
                    "import polynomial features from sklearn",
                    "present the type of each column",
                    "load table in pandas",
                    "from dictionary to dataframe"
                ]
            },
            {
                "code": "# Transform objects types to categories so that they are easier to process.\nfor col_name in train_df.select_dtypes(include='object'):\n    train_df[col_name] = train_df[col_name].astype('category').cat.as_ordered()",
                "true_label": "",
                "top5_preds": [
                    "transform categorical data into binary features",
                    "find data type of each column",
                    "convert categorical variables",
                    "import polynomial features from sklearn",
                    "load table in pandas"
                ]
            },
            {
                "code": "# Check if everything looks right.\nprint(train_df.dtypes)\n# print(train_df.describe())\ntrain_df.head()",
                "true_label": "",
                "top5_preds": [
                    "find data type of each column",
                    "load table in pandas",
                    "convert text data into vector",
                    "import polynomial features from sklearn",
                    "from dictionary to dataframe"
                ]
            },
            {
                "code": "import matplotlib.pyplot as plt\nimport numpy as np\nimport seaborn as sns\nimport statsmodels.formula.api as sm\nfrom statsmodels.graphics.tsaplots import plot_acf",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "fit a polynomial",
                    "import polynomial features from sklearn",
                    "scipy",
                    "plotting time series with pandas"
                ]
            },
            {
                "code": "# Increase font size for better readability.\nsns.set(font_scale=1.5)\n\n# Set custom colors for graphs.\ncolors = np.array(sns.color_palette('hls', 8))\ncolors = colors[[0, 5, 2, 1, 6, 4]]\nsns.set_palette(colors)\nsns.palplot(sns.color_palette())",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "plot using matplotlib",
                    "pandas plotting",
                    "using a dataframe and matplotlib commands",
                    "equally spaced numbers on a grid"
                ]
            },
            {
                "code": "print(\"# Total training observations: %d\" % len(train_df))\nprint(\"# Total test observations: %d\" % len(test_df))",
                "true_label": "",
                "top5_preds": [
                    "load table in pandas",
                    "line plot with a dataframe",
                    "what is the number of observations in each dataset?",
                    "read numbers until and print their mean and standard deviation without using a list",
                    "reading featurecounts"
                ]
            },
            {
                "code": "sampled_df = train_df.sample(frac=0.05)",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "predicting a categorical response",
                    "split a dataframe into a testing",
                    "line plots show the trend of a numerical variable over time",
                    "create an array of linearly spaced points"
                ]
            },
            {
                "code": "def plot_correlation_matrix(df, method='pearson', figsize=(11, 9)):\n    \"\"\"Plots a correlation matrix given the provided method.\"\"\"\n    # Compute the correlation matrix.\n    corr = df.corr(method=method)\n\n    # Generate a mask for the upper triangle.\n    mask = np.zeros_like(corr, dtype=np.bool)\n    mask[np.triu_indices_from(mask)] = True\n\n    # Set up the matplotlib figure.\n    f, ax = plt.subplots(figsize=figsize)\n\n    # Generate a custom diverging colormap\n    cmap = sns.diverging_palette(220, 10, as_cmap=True)\n\n    # Draw the heatmap with the mask and correct aspect ratio\n    sns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n              square=True, linewidths=.5, cbar_kws={\"shrink\": .5});",
                "true_label": "",
                "top5_preds": [
                    "plot the cdf",
                    "compute covariance matrix",
                    "correlation matrix",
                    "plot the logged tpm correlation",
                    "plot the function"
                ]
            },
            {
                "code": "def print_anova_results(explanatory_variable, response_variable):\n    \"\"\"Builds an ANOVA model and prints out the shortened results.\"\"\"\n\n    # Make sure variable names are passed in as strings.\n    assert isinstance(explanatory_variable, str)\n    assert isinstance(response_variable, str)\n\n    model = sm.ols(formula='%s ~ C(%s)'\n                 % (response_variable, explanatory_variable),\n                 data=train_df)\n    results = model.fit()\n\n    lines = str(results.summary()).split('\\n')\n    header = lines[0].replace('OLS Regression', '    ANOVA')\n    dep_var_r_squared = lines[1:3]\n    coeffs = lines[11:-8]\n\n    output_lines = [header] + dep_var_r_squared + coeffs\n\n    print('\\n'.join(output_lines))",
                "true_label": "",
                "top5_preds": [
                    "download and inspect the twitter samples dataset",
                    "function fit_and_predict",
                    "prepare the data for modelling indicator variables",
                    "build a vector of prediction from the trained model",
                    "students calculate median, mode, max, min for the example"
                ]
            },
            {
                "code": "total_sales = sum(train_df['sales'])\nprint(\"# Total sales: %d\" % total_sales)\nprint(\"# Sales per store per day: %d\" % (total_sales / len(train_df)))",
                "true_label": "",
                "top5_preds": [
                    "sum all the numbers in a list",
                    "convert data from string to float",
                    "predicting a categorical response",
                    "formatting datetimes as strings",
                    "read numbers until and print their mean and standard deviation without using a list"
                ]
            },
            {
                "code": "plt.figure(figsize=(15, 5))\nsns.distplot(train_df['sales']);",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "visualize the distribution histogram of x using sns distplot",
                    "equally spaced numbers on a grid",
                    "distribution plot",
                    "predicting a categorical response"
                ]
            },
            {
                "code": "# First find all columns that contain NA values.\nlist(train_df.columns[train_df.isna().any()])",
                "true_label": "",
                "top5_preds": [
                    "drop the rows with nan values",
                    "find data type of each column",
                    "delete column by name",
                    "load table in pandas",
                    "import polynomial features from sklearn"
                ]
            },
            {
                "code": "fill_categorical_na('events', 'NONE')",
                "true_label": "",
                "top5_preds": [
                    "create a one column dataframe with the values of a series",
                    "integrating datetime tools with pandas for time series",
                    "create dataframe with given values",
                    "create a dataframe by joining series by column",
                    "working with pandas series indexed by datetime"
                ]
            },
            {
                "code": "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, OneHotEncoder",
                "true_label": "",
                "top5_preds": [
                    "what is scikit learn?",
                    "import polynomial features from sklearn",
                    "polynomial regression with sklearn",
                    "scikit learn",
                    "tensorflow + keras"
                ]
            },
            {
                "code": "categorical_columns = ['store',\n                       'dayofweek',\n                       'open',\n                       'promo',\n                       'stateholiday',\n                       'schoolholiday',\n                       'day',\n                       'week',\n                       'month',\n                       'year',\n                       'storetype',\n                       'assortment',\n#                        'competitionopensincemonth',\n#                        'competitionopensinceyear',\n                       'promo2',\n#                        'promo2sinceweek',\n#                        'promo2sinceyear',\n                       'promointerval',\n                       'state',\n                       'events'\n                      ]\n\nnumerical_columns = ['customers',\n                     'competitiondistance',\n                     'weather',\n                     'competitionsince',\n                     'promo2since'\n                    ]",
                "true_label": "",
                "top5_preds": [
                    "create a dataframe by joining series by column",
                    "load table in pandas",
                    "transform the date column as a datetime type",
                    "find data type of each column",
                    "convert categorical variables"
                ]
            },
            {
                "code": "categorical_encoders = {}\n# one_hot_encoders = {}\n\nfor category in categorical_columns:\n    new_cat_encoder = LabelEncoder()\n    encoded_vars = new_cat_encoder.fit_transform(train_df[category])\n    \n#     new_oh_encoder = OneHotEncoder(sparse=False)\n#     new_oh_encoder.fit(encoded_vars.reshape(-1, 1))\n    \n    categorical_encoders[category] = new_cat_encoder\n#     one_hot_encoders[category] = new_oh_encoder",
                "true_label": "",
                "top5_preds": [
                    "transform categorical data into binary features",
                    "tensorflow + keras",
                    "import polynomial features from sklearn",
                    "convert categorical variables",
                    "using logistic regression with categorical features"
                ]
            },
            {
                "code": "def build_dataset(set_='train',\n                  all_features=False,\n                  validation_days=14,\n                  one_hot_categories=False,\n                  remove_zero_targets=False):\n    if set_ in ['train', 'val']:\n        max_date = max(train_df.date)\n        pivot_date = max_date - pd.Timedelta(validation_days, unit='d')\n        \n        if set_ == 'train':\n            data_df = train_df[train_df.date <= pivot_date]\n        elif set_ == 'val':\n            data_df = train_df[train_df.date > pivot_date]\n    elif set_ == 'test':\n        data_df = test_df\n    else:\n        raise ValueError(\"Only 'train', 'val', and 'test' are accepted\"\n                         + \" as arguments\")\n        \n    num_columns = numerical_columns if all_features else ['customers']\n    num_values = data_df[num_columns].astype('float32').values\n\n    # Scale numerical features.\n    scaler = MinMaxScaler(feature_range=(0, 1))\n    scaled_values = [scaler.fit_transform(num_values)]\n    \n    encoded_values = []\n    # Encode categorical features.\n    cat_columns = categorical_columns if all_features else ['open', 'promo', 'storetype', 'state']\n    for category in cat_columns:\n        current_cat_values = data_df[category].values\n        current_encoded_values = (categorical_encoders[category]\n                                  .transform(current_cat_values)\n                                  .reshape(-1, 1))\n        if one_hot_categories:\n            one_hot_values = (one_hot_encoders[category]\n                              .transform(current_encoded_values))\n            encoded_values.append(one_hot_values)\n        else:\n            encoded_values.append(current_encoded_values)\n    \n    feature_values = np.hstack(scaled_values + encoded_values)\n    \n    target_values = data_df[['sales']].values\n    \n    if remove_zero_targets:\n        # This somewhat destroys the time series.\n        # An alternative could be setting sales to 1 instead,\n        # which should not make much of a difference.\n        feature_values = feature_values[np.where(target_values > 0)[0]]\n        target_values = target_values[np.where(target_values > 0)[0]].reshape((-1, ))\n    \n    return feature_values, target_values",
                "true_label": "",
                "top5_preds": [
                    "getting the dataset",
                    "read the dataset",
                    "helpers to read in dataset",
                    "import the dataset",
                    "load dataset"
                ]
            },
            {
                "code": "plt.figure(figsize=(15, 5))\nplt.subplot(121)\ntrain_df.groupby('dayofweek')['sales'].sum().plot()\nplt.subplot(122)\ntrain_df.groupby('dayofweek')['open'].sum().plot();",
                "true_label": "",
                "top5_preds": [
                    "plotting time series with pandas",
                    "plot using pandas plotting",
                    "line plot with a dataframe",
                    "line plots show the trend of a numerical variable over time",
                    "plotting data"
                ]
            },
            {
                "code": "train_df.groupby('dayofweek')['sales', 'open'].sum()",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "create a dataframe by joining series by column",
                    "integrating datetime tools with pandas for time series",
                    "create a one column dataframe with the values of a series",
                    "line plots show the trend of a numerical variable over time"
                ]
            },
            {
                "code": "workday_sales = train_df[(train_df.dayofweek != 7)\n                         & (train_df.stateholiday.astype('str') == '0')\n                         & (train_df.schoolholiday == 0)]['sales']\nplt.figure(figsize=(15, 4))\nsns.distplot(workday_sales);",
                "true_label": "",
                "top5_preds": [
                    "return a dataframe",
                    "find data type of each column",
                    "working with pandas series indexed by datetime",
                    "calculate the mean windspeed for each month in the dataset",
                    "select every row after a specific row"
                ]
            },
            {
                "code": "print(1 - workday_sales.sum() / total_sales)",
                "true_label": "",
                "top5_preds": [
                    "sum all the numbers in a list",
                    "formatting datetimes as strings",
                    "predicting a categorical response",
                    "convert data from string to float",
                    "get a positive integer from a user"
                ]
            },
            {
                "code": "len(train_df[(train_df.open == 1) & (train_df.sales == 0)])",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "predicting a categorical response",
                    "find data type of each column",
                    "predicting a continuous response using linear regression",
                    "find all by term in field in case insensitive way"
                ]
            },
            {
                "code": "sns.countplot(train_df.state);",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "predicting a categorical response",
                    "line plots show the trend of a numerical variable over time",
                    "what is the number of observations in each dataset?",
                    "import polynomial features from sklearn"
                ]
            },
            {
                "code": "print(\"States only in the train set: %s\" % (set(train_df.state) - set(test_df.state)))\nprint(\"States only in the test set: %s\" % (set(test_df.state) - set(train_df.state)))",
                "true_label": "",
                "top5_preds": [
                    "load table in pandas",
                    "formatting datetimes as strings",
                    "check a list is empty or not",
                    "test whether a number is positive",
                    "line plot with a dataframe"
                ]
            },
            {
                "code": "sns.barplot(x='state', y='sales', data=sampled_df);",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "predicting a categorical response",
                    "line plots show the trend of a numerical variable over time",
                    "ploting out data with box plots",
                    "visualize the distribution histogram of x using sns distplot"
                ]
            },
            {
                "code": "competitiondistance_len = len(train_df.competitiondistance)\ncompetitiondistance_without_nan_len = len(train_df.competitiondistance.dropna())\nprint(\"NaN value fraction: %f\"\n      % (1 - competitiondistance_without_nan_len / competitiondistance_len))\n\nsns.distplot(train_df.competitiondistance.dropna());",
                "true_label": "",
                "top5_preds": [
                    "import polynomial features from sklearn",
                    "predicting a categorical response",
                    "line plot with a dataframe",
                    "scikit learn",
                    "what is scikit learn?"
                ]
            },
            {
                "code": "sns.distplot(train_df.competitionopensincemonth.dropna());",
                "true_label": "",
                "top5_preds": [
                    "integrating datetime tools with pandas for time series",
                    "join two dataframes along rows",
                    "create a one column dataframe with the values of a series",
                    "line plot with a dataframe",
                    "line plots show the trend of a numerical variable over time"
                ]
            },
            {
                "code": "sns.distplot(train_df.competitionopensinceyear.dropna());",
                "true_label": "",
                "top5_preds": [
                    "integrating datetime tools with pandas for time series",
                    "join two dataframes along rows",
                    "join two dataframes along columns",
                    "create a one column dataframe with the values of a series",
                    "dataframe methods"
                ]
            },
            {
                "code": "for df in df_list:\n    df['competitiontenure'] = ((max(train_df.competitionopensinceyear)\n                               - train_df.competitionopensinceyear) * 12)",
                "true_label": "",
                "top5_preds": [
                    "return a dataframe",
                    "create a one column dataframe with the values of a series",
                    "load table in pandas",
                    "create a dataframe by joining series by column",
                    "create dataframe with given values"
                ]
            },
            {
                "code": "weather_columns = ['max_temperaturec', 'mean_temperaturec', 'min_temperaturec',\n       'dew_pointc', 'meandew_pointc', 'min_dewpointc', 'max_humidity',\n       'mean_humidity', 'min_humidity', 'max_sea_level_pressurehpa',\n       'mean_sea_level_pressurehpa', 'min_sea_level_pressurehpa',\n       'max_visibilitykm', 'mean_visibilitykm', 'min_visibilitykm',\n       'max_wind_speedkm_h', 'mean_wind_speedkm_h', 'max_gust_speedkm_h',\n       'precipitationmm', 'cloudcover', 'events', 'winddirdegrees']",
                "true_label": "",
                "top5_preds": [
                    "load table in pandas",
                    "from dictionary to dataframe",
                    "find data type of each column",
                    "dataframe methods",
                    "import polynomial features from sklearn"
                ]
            },
            {
                "code": "weather_history = (train_df.set_index(train_df.date)[weather_columns]\n                   .resample('D').mean())\nweather_history.plot(subplots=True, figsize=(25, 20))\ndel weather_history",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "line plots show the trend of a numerical variable over time",
                    "using a dataframe and matplotlib commands",
                    "plotting time series with pandas",
                    "integrating datetime tools with pandas for time series"
                ]
            },
            {
                "code": "plot_correlation_matrix(train_df[['sales', 'customers'] + weather_columns])",
                "true_label": "",
                "top5_preds": [
                    "relationships between dataframes",
                    "line plot with a dataframe",
                    "dataframe methods",
                    "load table in pandas",
                    "using a dataframe and matplotlib commands"
                ]
            },
            {
                "code": "store_df = pd.read_csv('data/store.csv')\n\n# Join the sales and store tables.\ntrain_df = pd.merge(train_df, store_df, on='Store')\ntest_df = pd.merge(test_df, store_df, on='Store')\n\n# Remove store table from memory.\ndel store_df",
                "true_label": "",
                "top5_preds": [
                    "load table in pandas",
                    "create a dataframe by joining series by column",
                    "from dictionary to dataframe",
                    "join two dataframes along rows",
                    "using pandas"
                ]
            },
            {
                "code": "train_data, train_target = build_dataset('train', remove_zero_targets=True)\nprint(train_data.shape)\nval_data, val_target = build_dataset('val', remove_zero_targets=True)\nprint(val_data.shape)",
                "true_label": "",
                "top5_preds": [
                    "import polynomial features from sklearn",
                    "optimal value of k for dataset",
                    "numpy",
                    "what is scikit learn?",
                    "polynomial regression with sklearn"
                ]
            },
            {
                "code": "# Train.\ntree = DecisionTreeRegressor()\ntree.fit(train_data[:, 1:2], train_target)\n\n# Evaluate.\nnon_zero_val_data = val_data[np.nonzero(val_target)[0]]\nnon_zero_val_target = val_target[np.nonzero(val_target)[0]].reshape((-1, ))\ntree_prediction = tree.predict(non_zero_val_data[:, 1:2])\nprint(rmspe(tree_prediction, non_zero_val_target))",
                "true_label": "",
                "top5_preds": [
                    "decision tree learning with sklearn",
                    "training a decision tree model",
                    "using the classify function",
                    "making predictions for the testing data",
                    "polynomial regression with sklearn"
                ]
            },
            {
                "code": "plot_correlation_matrix(train_df[['sales', 'customers'] + weather_columns], method='spearman')",
                "true_label": "",
                "top5_preds": [
                    "relationships between dataframes",
                    "line plot with a dataframe",
                    "dataframe methods",
                    "using a dataframe and matplotlib commands",
                    "pandas plotting"
                ]
            },
            {
                "code": "print(train_df[train_df.open == 0]['sales'].sum())\nprint(train_df[train_df.open == 0]['customers'].sum())",
                "true_label": "",
                "top5_preds": [
                    "predicting a categorical response",
                    "line plot with a dataframe",
                    "create a one column dataframe with the values of a series",
                    "get a positive integer from a user",
                    "find data type of each column"
                ]
            },
            {
                "code": "plot_correlation_matrix(train_df[['sales', 'customers', 'open']], figsize=(8, 8))",
                "true_label": "",
                "top5_preds": [
                    "relationships between dataframes",
                    "line plot with a dataframe",
                    "correlation analysis",
                    "pandas plotting documentation",
                    "predicting a categorical response"
                ]
            },
            {
                "code": "plt.figure(figsize=(15, 4))\nsns.regplot(x='customers', y='sales', data=sampled_df, scatter_kws={'alpha': 1/20});",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "ploting out data with box plots",
                    "line plots show the trend of a numerical variable over time",
                    "plotting time series with pandas",
                    "predicting a categorical response"
                ]
            },
            {
                "code": "customers_history = train_df.set_index(train_df.date).customers.resample('D').sum()\nplt.figure(figsize=(16, 3))\npd.plotting.autocorrelation_plot(sales_history)\nplt.title('Sales')\nplt.show()\nplt.figure(figsize=(16, 3))\npd.plotting.autocorrelation_plot(customers_history)\nplt.title('Customers');",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "line plots show the trend of a numerical variable over time",
                    "plotting time series with pandas",
                    "relationships between dataframes",
                    "formatting datetimes as strings"
                ]
            },
            {
                "code": "print_anova_results('storetype', 'sales')",
                "true_label": "",
                "top5_preds": [
                    "postgres sql lab",
                    "getting data from the internet",
                    "running a local postgres database",
                    "predicting a categorical response",
                    "exploring the database with sql"
                ]
            },
            {
                "code": "(train_df\n .groupby(['date', 'storetype'])['sales']\n .sum()\n .unstack()\n .plot(alpha=0.5, figsize=(15, 5)));",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "create a dataframe by joining series by column",
                    "pandas plotting",
                    "plotting time series with pandas",
                    "create a one column dataframe with the values of a series"
                ]
            },
            {
                "code": "(train_df\n .groupby(['date', 'storetype'])['sales']\n .mean()\n .unstack()\n .plot(alpha=0.5, figsize=(15, 5)));",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "pandas plotting",
                    "line plots show the trend of a numerical variable over time",
                    "load table in pandas",
                    "plotting time series with pandas"
                ]
            },
            {
                "code": "plt.figure(figsize=(15, 5))\nplt.subplot(121)\nsns.countplot(x='assortment', data=sampled_df)\nplt.subplot(122)\nsns.barplot(x='assortment', y='sales', data=sampled_df);",
                "true_label": "",
                "top5_preds": [
                    "predicting a categorical response",
                    "plot histogram",
                    "line plot with a dataframe",
                    "line plots show the trend of a numerical variable over time",
                    "ploting out data with box plots"
                ]
            },
            {
                "code": "print_anova_results('assortment', 'sales')",
                "true_label": "",
                "top5_preds": [
                    "predicting a categorical response",
                    "sql LIKE operator",
                    "exploring the database with sql",
                    "postgres sql lab",
                    "collecting and analysing alm data"
                ]
            },
            {
                "code": "# Train.\ntree = DecisionTreeRegressor()\ntree.fit(train_data, train_target)\n\n# Evaluate.\nnon_zero_val_data = val_data[np.nonzero(val_target)[0]]\nnon_zero_val_target = val_target[np.nonzero(val_target)[0]].reshape((-1, ))\ntree_prediction = tree.predict(non_zero_val_data)\nprint(rmspe(tree_prediction, non_zero_val_target))",
                "true_label": "",
                "top5_preds": [
                    "decision tree learning with sklearn",
                    "training a decision tree model",
                    "making predictions for the testing data",
                    "predicting a categorical response",
                    "polynomial regression with sklearn"
                ]
            },
            {
                "code": "#create a train and validation DMatrix objects.\nxgtrain = xgb.DMatrix(train_data, label=train_target)\nxgval = xgb.DMatrix(val_data, label=val_target)\nxgtest = xgb.DMatrix(non_zero_val_data, label=val_target)\n\n#train using early stopping and predict\nwatchlist = [(xgtrain, 'train'),(xgval, 'val')]\n\nxgb_params = {'objective': 'reg:linear', 'eta': 0.1, 'min_child_weight': 6,\n              'subsample': 0.87, 'colsample_bytree': 0.60,\n              'scale_pos_weight': 1.0, 'silent': 1, 'max_depth': 7}\n\nnum_rounds = 50\nxgb_model = xgb.train(xgb_params, xgtrain, num_rounds, watchlist, early_stopping_rounds=3)",
                "true_label": "",
                "top5_preds": [
                    "numpy",
                    "tensorflow + keras",
                    "creating a simple numpy array",
                    "scipy",
                    "linear regression of many variables"
                ]
            },
            {
                "code": "xgb_prediction = xgb_model.predict(xgtest)#.reshape(-1)\nprint(rmspe(xgb_prediction, non_zero_val_target))",
                "true_label": "",
                "top5_preds": [
                    "ridge regression with polynomial features on a grid",
                    "polynomial regression with sklearn",
                    "predicting a continuous response using linear regression",
                    "ridge regression with one predictor on a grid",
                    "import polynomial features from sklearn"
                ]
            },
            {
                "code": "num_features = train_data.shape[1]\n\ndense_net = Sequential([\n    Dense(10, input_shape=(num_features, ),\n          kernel_initializer='normal',\n          activation='relu'),\n    Dense(1,\n          kernel_initializer='normal')\n])\ndense_net.compile(loss='mse', optimizer='adam')\n\n# Train NN.\nhistory = dense_net.fit(train_data, train_target,\n                        epochs=10, batch_size=200, shuffle=False,\n                        validation_data=(val_data, val_target),\n                        verbose=1)",
                "true_label": "",
                "top5_preds": [
                    "tensorflow + keras",
                    "import polynomial features from sklearn",
                    "classification with a cnn",
                    "logistic regression using tensorflow",
                    "simple convolutional neural network"
                ]
            },
            {
                "code": "history_path = 'histories/shallow_densenet.pkl'\n# with open(history_path, 'wb') as f:\n#     pickle.dump(history.history, f, protocol=pickle.HIGHEST_PROTOCOL)\n\nwith open(history_path, 'rb') as f:\n    history = pickle.load(f)\nplot_history(history)",
                "true_label": "",
                "top5_preds": [
                    "plot using matplotlib",
                    "timing, numpy, plotting",
                    "trend lines in pyplot",
                    "in a pickle",
                    "what is scikit learn?"
                ]
            },
            {
                "code": "dense_prediction = dense_net.predict(non_zero_val_data).reshape(-1)\nprint(rmspe(dense_prediction, non_zero_val_target))",
                "true_label": "",
                "top5_preds": [
                    "polynomial regression with sklearn",
                    "predicting a continuous response using linear regression",
                    "import polynomial features from sklearn",
                    "predicting a categorical response",
                    "logistic regression using tensorflow"
                ]
            },
            {
                "code": "store_states_df = pd.read_csv('data/store_states.csv')\n\ntrain_df = pd.merge(train_df, store_states_df, on='Store')\ntest_df = pd.merge(test_df, store_states_df, on='Store')\n\ndel store_states_df",
                "true_label": "",
                "top5_preds": [
                    "from dictionary to dataframe",
                    "load table in pandas",
                    "create a dataframe by joining series by column",
                    "using pandas",
                    "join two dataframes along rows"
                ]
            },
            {
                "code": "state_names_df = pd.read_csv('data/state_names.csv')\n\ntrain_df = train_df.merge(state_names_df, on='State')\ntest_df = test_df.merge(state_names_df, on='State')\n\ndel state_names_df",
                "true_label": "",
                "top5_preds": [
                    "from dictionary to dataframe",
                    "using pandas",
                    "line plot with a dataframe",
                    "create a dataframe by joining series by column",
                    "load table in pandas"
                ]
            },
            {
                "code": "plot_correlation_matrix(train_df[['sales', 'customers', 'trend', 'global_trend']])",
                "true_label": "",
                "top5_preds": [
                    "relationships between dataframes",
                    "line plot with a dataframe",
                    "correlation analysis",
                    "load table in pandas",
                    "using a dataframe and matplotlib commands"
                ]
            },
            {
                "code": "def fill_categorical_na(col_name, replacement_value):\n    train_df[col_name] = train_df[col_name].astype('category')\n    if replacement_value not in train_df[col_name].cat.categories:\n        train_df[col_name] = train_df[col_name].cat.add_categories([replacement_value])\n    train_df[col_name] = train_df[col_name].fillna(replacement_value)\n    \n    test_df[col_name] = test_df[col_name].astype('category')\n    if replacement_value not in test_df[col_name].cat.categories:\n        test_df[col_name] = test_df[col_name].cat.add_categories([replacement_value])\n    test_df[col_name] = test_df[col_name].fillna(replacement_value)",
                "true_label": "",
                "top5_preds": [
                    "convert categorical variables",
                    "transform categorical data into binary features",
                    "categorical features",
                    "create dataframe with given values",
                    "function to fix missing values in column"
                ]
            },
            {
                "code": "def fill_numerical_na(col_name, replacement_value):\n    train_df[col_name] = train_df[col_name].fillna(replacement_value)\n    test_df[col_name] = test_df[col_name].fillna(replacement_value)",
                "true_label": "",
                "top5_preds": [
                    "create dataframe with given values",
                    "function to fix missing values in column",
                    "normalize the data point",
                    "dataframe methods",
                    "compute how many non missing values there are in total"
                ]
            },
            {
                "code": "fill_categorical_na('promointerval', 'NONE')",
                "true_label": "",
                "top5_preds": [
                    "predicting a categorical response",
                    "create a one column dataframe with the values of a series",
                    "integrating datetime tools with pandas for time series",
                    "create a dataframe by joining series by column",
                    "line plots show the trend of a numerical variable over time"
                ]
            },
            {
                "code": "train_df['promo2since'] = (train_df.date - pd.to_datetime(\n    pd.concat([train_df['promo2sinceyear']\n               .fillna(train_df.date.dt.year),\n               train_df['promo2sinceweek']\n               .fillna(train_df.date.dt.week)], axis=1)\n    .apply(lambda x: '%d-%d-1' % (x[0], x[1]-1), axis=1), format='%Y-%W-%w')).dt.days\ntest_df['promo2since'] = (test_df.date - pd.to_datetime(\n    pd.concat([test_df['promo2sinceyear']\n               .fillna(test_df.date.dt.year),\n               test_df['promo2sinceweek']\n               .fillna(test_df.date.dt.week)], axis=1)\n    .apply(lambda x: '%d-%d-1' % (x[0], x[1]-1), axis=1), format='%Y-%W-%w')).dt.days",
                "true_label": "",
                "top5_preds": [
                    "transform the date column as a datetime type",
                    "transform year column",
                    "convert date to datetime format",
                    "integrating datetime tools with pandas for time series",
                    "formatting datetimes as strings"
                ]
            },
            {
                "code": "# Sanity check that no negative time deltas exist.\nmin(train_df['promo2since'])\nmin(test_df['promo2since'])",
                "true_label": "",
                "top5_preds": [
                    "find maximum and the minimum value in a set",
                    "integrating datetime tools with pandas for time series",
                    "compare variable with time",
                    "formatting datetimes as strings",
                    "load table in pandas"
                ]
            },
            {
                "code": "fill_numerical_na('competitiondistance', 0)",
                "true_label": "",
                "top5_preds": [
                    "import polynomial features from sklearn",
                    "fit a polynomial",
                    "creating polynomial features",
                    "loading up data with missing values",
                    "predicting a categorical response"
                ]
            },
            {
                "code": "train_df['competitionsince'] = (train_df.date - pd.to_datetime(\n    {'year': train_df.competitionopensinceyear,\n     'month': train_df.competitionopensincemonth,\n     'day': 1})).fillna(pd.Timedelta(0)).dt.days\ntest_df['competitionsince'] = (test_df.date - pd.to_datetime(\n    {'year': test_df.competitionopensinceyear,\n     'month': test_df.competitionopensincemonth,\n     'day': 1})).fillna(pd.Timedelta(0)).dt.days",
                "true_label": "",
                "top5_preds": [
                    "transform the date column as a datetime type",
                    "convert date to datetime format",
                    "integrating datetime tools with pandas for time series",
                    "load table in pandas",
                    "formatting datetimes as strings"
                ]
            },
            {
                "code": "# Sanity check that no negative time deltas exist.\nmin(train_df['competitionsince'])\nmin(test_df['competitionsince'])",
                "true_label": "",
                "top5_preds": [
                    "load table in pandas",
                    "find maximum and the minimum value in a set",
                    "integrating datetime tools with pandas for time series",
                    "convert data from string to float",
                    "compare variable with time"
                ]
            },
            {
                "code": "sns.distplot(train_df['weather']);",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "dataframe methods",
                    "predicting a categorical response",
                    "predicting a continuous response using linear regression",
                    "what is scikit learn?"
                ]
            },
            {
                "code": "weather_pca_history = train_df.set_index(train_df.date).weather.resample('D').mean().plot(figsize=(16, 4));",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "plotting time series with pandas",
                    "line plots show the trend of a numerical variable over time",
                    "using a dataframe and matplotlib commands",
                    "pandas plotting"
                ]
            },
            {
                "code": "train_df[['weather', 'sales']].corr()",
                "true_label": "",
                "top5_preds": [
                    "predicting a categorical response",
                    "relationships between dataframes",
                    "dataframe methods",
                    "counting word frequency",
                    "line plot with a dataframe"
                ]
            },
            {
                "code": "train_data = load_dataset('data/train_data_21.npy')\ntrain_target = load_dataset('data/train_target.npy')\nval_data = load_dataset('data/test_data_21.npy')\nval_target = load_dataset('data/test_target.npy')",
                "true_label": "",
                "top5_preds": [
                    "import polynomial features from sklearn",
                    "load table in pandas",
                    "importing data with numpy",
                    "what is scikit learn?",
                    "classification with a cnn"
                ]
            },
            {
                "code": "xgtrain = xgb.DMatrix(train_data, label=train_target)\nxgval = xgb.DMatrix(val_data, label=val_target)\nxgtest = xgb.DMatrix(val_data, label=val_target)\n\n#train using early stopping and predict\nwatchlist = [(xgtrain, 'train'),(xgval, 'val')]\n\nxgb_params = {'objective': 'reg:linear', 'eta': 0.1, 'min_child_weight': 6,\n              'subsample': 0.87, 'colsample_bytree': 0.60,\n              'scale_pos_weight': 1.0, 'silent': 1, 'max_depth': 7}\n\nnum_rounds = 50\nxgb_model = xgb.train(xgb_params, xgtrain, num_rounds, watchlist, early_stopping_rounds=3)",
                "true_label": "",
                "top5_preds": [
                    "numpy",
                    "tensorflow + keras",
                    "linear regression of many variables",
                    "scipy",
                    "timing, numpy, plotting"
                ]
            },
            {
                "code": "xgb_prediction = xgb_model.predict(xgtest)\nprint(rmspe(xgb_prediction, val_target))",
                "true_label": "",
                "top5_preds": [
                    "polynomial regression with sklearn",
                    "ridge regression with polynomial features on a grid",
                    "fit a polynomial",
                    "ridge regression with one predictor on a grid",
                    "predicting a continuous response using linear regression"
                ]
            },
            {
                "code": "num_features = train_data.shape[1]\n\ndense_net = Sequential([\n    Dense(50, input_shape=(num_features, ),\n          kernel_initializer='normal',\n          activation='relu'),\n    Dense(10,\n          kernel_initializer='normal',\n          activation='relu'),\n    Dense(1,\n          kernel_initializer='normal')\n])\ndense_net.compile(loss='mse', optimizer='adam')\n\nes_callback = EarlyStopping(monitor='val_loss', min_delta=0, patience=3, mode='auto')\nmc_callback = ModelCheckpoint('/tmp/densenet_weights.h5', monitor='val_loss',\n                               save_best_only=True, save_weights_only=True)\n\n# Train NN.\nhistory = dense_net.fit(train_data, train_target,\n                        epochs=50, batch_size=200, shuffle=False,\n                        validation_data=(val_data, val_target),\n                        callbacks=[es_callback, mc_callback],\n                        verbose=1)",
                "true_label": "",
                "top5_preds": [
                    "tensorflow + keras",
                    "import polynomial features from sklearn",
                    "logistic regression using tensorflow",
                    "classification with a cnn",
                    "simple convolutional neural network"
                ]
            },
            {
                "code": "history_path = 'histories/all_features_densenet.pkl'\n# with open(history_path, 'wb') as f:\n#     pickle.dump(history.history, f, protocol=pickle.HIGHEST_PROTOCOL)\n\nwith open(history_path, 'rb') as f:\n    history = pickle.load(f)\nplot_history(history)",
                "true_label": "",
                "top5_preds": [
                    "timing, numpy, plotting",
                    "plot using matplotlib",
                    "what is scikit learn?",
                    "trend lines in pyplot",
                    "in a pickle"
                ]
            },
            {
                "code": "dense_net.load_weights('/tmp/densenet_weights.h5')\ndense_prediction = dense_net.predict(val_data).reshape(-1)\nprint(rmspe(dense_prediction, val_target))",
                "true_label": "",
                "top5_preds": [
                    "import polynomial features from sklearn",
                    "polynomial regression with sklearn",
                    "scikit learn",
                    "logistic regression using tensorflow",
                    "tensorflow + keras"
                ]
            },
            {
                "code": "weather_df = pd.read_csv('data/weather.csv', parse_dates=['Date'])\n# Correct name of 'file' column to 'StateName'\nweather_df = weather_df.rename(index=str, columns={'file': 'StateName'})\n\nprint(\"'weather.csv' adds the following columns:\")\nprint(weather_df.columns)\n\ntrain_df = train_df.merge(weather_df, on=['Date', 'StateName'])\ntest_df = test_df.merge(weather_df, on=['Date', 'StateName'])\n\ndel weather_df\n# StateName is not needed any longer.\ndel train_df['StateName']\ndel test_df['StateName']",
                "true_label": "",
                "top5_preds": [
                    "using pandas",
                    "importing data with pandas",
                    "in pandas",
                    "from dictionary to dataframe",
                    "load table in pandas"
                ]
            },
            {
                "code": "from sklearn.decomposition import PCA",
                "true_label": "",
                "top5_preds": [
                    "import polynomial features from sklearn",
                    "shortcut principal component analysis in scikit learn",
                    "what is scikit learn?",
                    "polynomial regression with sklearn",
                    "scikit learn"
                ]
            },
            {
                "code": "pca = PCA(n_components=1)\ntrain_df['weather'] = (pca.fit_transform(train_df[weather_columns]\n                                         .drop(['events', 'max_gust_speedkm_h'], axis=1)\n                                         .values))\ntest_df['weather'] = (pca.transform(test_df[weather_columns]\n                                    .drop(['events', 'max_gust_speedkm_h'], axis=1)\n                                    .values))",
                "true_label": "",
                "top5_preds": [
                    "transform categorical data into binary features",
                    "import polynomial features from sklearn",
                    "find data type of each column",
                    "load table in pandas",
                    "function fit_and_predict"
                ]
            },
            {
                "code": "# Find out what weather columns contain NaNs.\ntrain_df[weather_columns].isna().any()",
                "true_label": "",
                "top5_preds": [
                    "find data type of each column",
                    "load table in pandas",
                    "dataframe methods",
                    "import polynomial features from sklearn",
                    "line plot with a dataframe"
                ]
            },
            {
                "code": "for col_name in ['max_visibilitykm', 'mean_visibilitykm', 'min_visibilitykm', 'cloudcover']:\n    train_df[col_name] = 0\n    test_df[col_name] = 0",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "load table in pandas",
                    "dataframe methods",
                    "from dictionary to dataframe",
                    "find data type of each column"
                ]
            },
            {
                "code": "# Check that NAs have been removed.\ntrain_df[weather_columns].isna().any()",
                "true_label": "",
                "top5_preds": [
                    "dataframe methods",
                    "load table in pandas",
                    "find data type of each column",
                    "drop the rows with nan values",
                    "line plot with a dataframe"
                ]
            },
            {
                "code": "num_features = train_data.shape[1]\n\ndense_net = Sequential([\n    Dense(50, input_shape=(num_features, ),\n          kernel_initializer='normal',\n          activation='relu'),\n    Dense(10,\n          kernel_initializer='normal',\n          activation='relu'),\n    Dense(1,\n          kernel_initializer='normal')\n])\ndense_net.compile(loss='mse', optimizer='adam')\n\n# Train NN.\nhistory = dense_net.fit(train_data, train_target,\n                        epochs=5, batch_size=200, shuffle=False,\n                        validation_data=(val_data, val_target),\n                        verbose=1)",
                "true_label": "",
                "top5_preds": [
                    "tensorflow + keras",
                    "import polynomial features from sklearn",
                    "logistic regression using tensorflow",
                    "classification with a cnn",
                    "simple convolutional neural network"
                ]
            },
            {
                "code": "history_path = 'histories/bigger_densenet.pkl'\n# with open(history_path, 'wb') as f:\n#     pickle.dump(history.history, f, protocol=pickle.HIGHEST_PROTOCOL)\n\nwith open(history_path, 'rb') as f:\n    history = pickle.load(f)\nplot_history(history)",
                "true_label": "",
                "top5_preds": [
                    "plot using matplotlib",
                    "timing, numpy, plotting",
                    "in a pickle",
                    "trend lines in pyplot",
                    "what is scikit learn?"
                ]
            },
            {
                "code": "sns.barplot(x='state', y='sales', data=sampled_df);",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "predicting a categorical response",
                    "line plots show the trend of a numerical variable over time",
                    "ploting out data with box plots",
                    "visualize the distribution histogram of x using sns distplot"
                ]
            }
        ],
        [
            {
                "code": "# Import necessary packages \nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n% matplotlib inline\n% config InlineBackend.figure_format = 'retina'\n",
                "true_label": "",
                "top5_preds": [
                    "pandas plotting",
                    "plot using matplotlib",
                    "matplotlib",
                    "plot using pandas plotting",
                    "plotting in python"
                ]
            },
            {
                "code": "# Import data\n\ndf = pd.read_csv('noshow.csv')\ndf.head()\n",
                "true_label": "",
                "top5_preds": [
                    "loading a csv into a dataframe",
                    "importing data with pandas",
                    "load table in pandas",
                    "importing data with numpy",
                    "line plot with a dataframe"
                ]
            },
            {
                "code": "# create new labels\nnew_labels = ['patient_id', 'appt_id', 'gender', 'scheduled_day', 'appt_day', 'age', \n              'neighbourhood', 'scholarship', 'hipertension', 'diabetes', 'alcoholism', \n              'handicap', 'sms_rec', 'no_show']\n\n# rename columns\ndf.columns = new_labels\n\n# check the changes\ndf.head()\n\n",
                "true_label": "",
                "top5_preds": [
                    "formatting datetimes as strings",
                    "from dictionary to dataframe",
                    "using the class label",
                    "import polynomial features from sklearn",
                    "create a list of all words"
                ]
            },
            {
                "code": "df.dtypes",
                "true_label": "",
                "top5_preds": [
                    "find data type of each column",
                    "convert date to datetime format",
                    "load table in pandas",
                    "convert categorical variables",
                    "what is the type of the columns?"
                ]
            },
            {
                "code": "df.head()",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "loading a csv into a dataframe",
                    "load table in pandas",
                    "create a one column dataframe with the values of a series",
                    "convert date to datetime format"
                ]
            },
            {
                "code": "# create M and F dataframes\ndf_m = df.query('gender == \"M\"')\ndf_f = df.query('gender == \"F\"')\n\n# set colours\nf_color = '#893b53', '#c55577'\nm_color = '#0081a3', '#4ca6be'\n\n# Set up plots\nfig, axes = plt.subplots(ncols=2, sharex = True, sharey = True, figsize = (7,5))\nfig.text(0.5, 0.04, 'Attendance', ha='center')\naxes[0].xaxis.label.set_visible(False)\naxes[1].xaxis.label.set_visible(False)\n\n# create plots\ndf_m.groupby('no_show')['no_show'].count().plot(kind = 'bar', ax=axes[0], title='Males', color=m_color)\ndf_f.groupby('no_show')['no_show'].count().plot(kind = 'bar', ax=axes[1], title='Females', color=f_color);\n\n# Set the x-axis label\n#ax.set_xlabel(\"Attendance\");\n",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "using a dataframe and matplotlib commands",
                    "pandas plotting",
                    "plot using pandas plotting",
                    "plot multidimensional data in two dimensions"
                ]
            },
            {
                "code": "# find proportion of Yes\nm_count = df.query('gender==\"M\" & no_show==\"Y\"')['no_show'].count()\nf_count = df.query('gender==\"F\" & no_show==\"Y\"')['no_show'].count()\ntotal = df['no_show'].count()\n\nm_prop = round(((m_count / total) *100),0)\nf_prop = round(((f_count / total) * 100),0)\n\nprint('Male proportions = {}% attended\\nFemale proportions = {}% attended'.format(m_prop,f_prop))\n\n",
                "true_label": "",
                "top5_preds": [
                    "predicting a categorical response",
                    "line plot with a dataframe",
                    "find data type of each column",
                    "sql LIKE operator",
                    "find all by term in field in case insensitive way"
                ]
            },
            {
                "code": "# male and female attendance based on sms received\n\n# define males and females who received an sms subset\ndf_m_y = df_m.query('sms_rec == 1')\ndf_f_y = df_f.query('sms_rec == 1')\n",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "join two dataframes along rows",
                    "create dataframe with given values",
                    "relationships between dataframes",
                    "join two dataframes along columns"
                ]
            },
            {
                "code": "# Check counts\n\n#print('male\\n',df_m_y.no_show.value_counts())\nprint('female\\n',df_f_y.no_show.value_counts())\n",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "line plots show the trend of a numerical variable over time",
                    "find data type of each column",
                    "dataframe methods",
                    "predicting a categorical response"
                ]
            },
            {
                "code": "m_color_sms = '#ea7b76','#4ca6be'\nf_color_sms = '#ea7b76','#c55577'\n\ndf_m_y.groupby('no_show')['no_show'].count().plot(kind='pie', figsize=(6,6), \n                                                  colors = m_color_sms, title='Male attendance if SMS received',\n                                                  autopct='%1.0f%%');",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "pandas plotting",
                    "pandas plotting documentation",
                    "create a scatter plot",
                    "plotting time series with pandas"
                ]
            },
            {
                "code": "df_f_y.groupby('no_show')['no_show'].count().plot(kind='pie', figsize=(6,6), \n                                                  colors = f_color_sms, title='Female attendance if SMS received',\n                                                  autopct='%1.0f%%');",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "pandas plotting",
                    "pandas plotting documentation",
                    "create a scatter plot",
                    "plotting query results"
                ]
            },
            {
                "code": "# create a datetime index from the appointment day col\ntemp = pd.DatetimeIndex(df['appt_day'])\ndf['weekday'] = temp.weekday\n\ndf.head()",
                "true_label": "",
                "top5_preds": [
                    "convert date to datetime format",
                    "working with pandas series indexed by datetime",
                    "plotting time series with pandas",
                    "transform the date column as a datetime type",
                    "formatting datetimes as strings"
                ]
            },
            {
                "code": "# subset dataframe to only show patients who attended an appointment\ndf_y = df.query('no_show == \"Y\"')\n# create labels\nx_labs = ['Mon', 'Tues', 'Wed', 'Thur', 'Fri','']\n\n# greate color set\nday_color = ['#DD6E42','#e8dab2','#4F6D7A','#C0D6DF','#cecece']\n\n# create plot\nax = df_y.groupby('weekday')['weekday'].count().plot(kind='bar', \n                                                     title='Attendance by day of the week', \n                                                     color=day_color);\n# rename xticks\nax.set_xticklabels(x_labs);\nplt.xlim(xmax=5);\n",
                "true_label": "",
                "top5_preds": [
                    "using a dataframe and matplotlib commands",
                    "line plot with a dataframe",
                    "ploting out data with box plots",
                    "pandas plotting",
                    "relationships between dataframes"
                ]
            },
            {
                "code": "# change the sheduled_day column & appt_day columns to pandas datetime objects\n\ndf.scheduled_day = pd.to_datetime(df.scheduled_day)\ndf.appt_day = pd.to_datetime(df.appt_day)\n\n# check that this worked by returning the weekday using dt from the datetime module\n\n#df.scheduled_day.dt.weekday\ndf.appt_day.dt.weekday[0:5]",
                "true_label": "",
                "top5_preds": [
                    "convert date to datetime format",
                    "transform the date column as a datetime type",
                    "formatting datetimes as strings",
                    "working with pandas series indexed by datetime",
                    "replace the first columns by a proper datetime index"
                ]
            },
            {
                "code": "df.duplicated().any()\n",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "find data type of each column",
                    "load table in pandas",
                    "create a one column dataframe with the values of a series",
                    "dataframe methods"
                ]
            },
            {
                "code": "df.isnull().any()",
                "true_label": "",
                "top5_preds": [
                    "drop the rows with nan values",
                    "find data type of each column",
                    "computing the covariance when there are nan s",
                    "dataframe methods",
                    "check a list is empty or not"
                ]
            },
            {
                "code": "df.nunique()",
                "true_label": "",
                "top5_preds": [
                    "find data type of each column",
                    "line plot with a dataframe",
                    "change type of column",
                    "convert categorical variables",
                    "predicting a categorical response"
                ]
            },
            {
                "code": "# use pandas drop duplicates and subset patient_id column\ndf.drop_duplicates(subset='patient_id', keep='first', inplace=True)\n\n# check that the drop worked\ndf.nunique()\n\n# it did! ",
                "true_label": "",
                "top5_preds": [
                    "find data type of each column",
                    "remove duplicates from a list",
                    "drop data points with missing data",
                    "drop the rows with nan values",
                    "how many different items appear in the dataset?"
                ]
            },
            {
                "code": "df.describe()",
                "true_label": "",
                "top5_preds": [
                    "formatting datetimes as strings",
                    "line plot with a dataframe",
                    "load table in pandas",
                    "dataframe methods",
                    "create a one column dataframe with the values of a series"
                ]
            },
            {
                "code": "# find the index of that records\n\ndf.query('age ==-1')",
                "true_label": "",
                "top5_preds": [
                    "in pandas",
                    "dataframe methods",
                    "load table in pandas",
                    "create dataframe with given values",
                    "select every row after a specific row"
                ]
            },
            {
                "code": "# remove the record\n\ndf.drop([99832], inplace=True)\n",
                "true_label": "",
                "top5_preds": [
                    "delete column by name",
                    "drop the rows with nan values",
                    "load table in pandas",
                    "select every row after a specific row",
                    "in pandas"
                ]
            },
            {
                "code": "# search for that record to check.\ndf.loc[99832]",
                "true_label": "",
                "top5_preds": [
                    "loading a csv into a dataframe",
                    "select every row after a specific row",
                    "load table in pandas",
                    "find data type of each column",
                    "line plot with a dataframe"
                ]
            },
            {
                "code": "# The new min is now 0, check this against scholarship, since 0 aged patients would not have a scholarship. \n\ndf.query('age == 0 & scholarship == 1').count()\n",
                "true_label": "",
                "top5_preds": [
                    "predicting a categorical response",
                    "credible interval vs confidence interval",
                    "get a positive integer from a user",
                    "sql LIKE operator",
                    "line plot with a dataframe"
                ]
            },
            {
                "code": "# there are 31 records that could safely be assumed to contain errors with information so these will be removed\n\ndf.drop(df[(df['age'] == 0) & (df['scholarship'] == 1)].index, inplace=True)\n\ndf.nunique()",
                "true_label": "",
                "top5_preds": [
                    "in pandas",
                    "find data type of each column",
                    "predicting a categorical response",
                    "optimal value of k for dataset",
                    "dataframe methods"
                ]
            },
            {
                "code": "#data['sex'].replace([0,1],['Female','Male'],inplace=True)\n\ndf.groupby('no_show')['no_show'].count()\n",
                "true_label": "",
                "top5_preds": [
                    "using pandas",
                    "line plot with a dataframe",
                    "in pandas",
                    "convert categorical variables",
                    "create dataframe with given values"
                ]
            },
            {
                "code": "# replace and check if this worked\ndf['no_show'].replace(['No','Yes'],['Y','N'],inplace=True)\ndf.groupby('no_show')['no_show'].count()",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "select every row after a specific row",
                    "using a dataframe and matplotlib commands",
                    "create dataframe with given values",
                    "predicting a categorical response"
                ]
            },
            {
                "code": "# check the dataset to confirm cleaning\ndf.info()",
                "true_label": "",
                "top5_preds": [
                    "load table in pandas",
                    "read the dataset",
                    "line plot with a dataframe",
                    "helpers to read in dataset",
                    "read numbers until and print their mean and standard deviation without using a list"
                ]
            },
            {
                "code": "# create a datetime index from the appointment day col\ntemp = pd.DatetimeIndex(df['appt_day'])\ndf['weekday'] = temp.weekday\n\ndf.head()",
                "true_label": "",
                "top5_preds": [
                    "convert date to datetime format",
                    "working with pandas series indexed by datetime",
                    "plotting time series with pandas",
                    "transform the date column as a datetime type",
                    "formatting datetimes as strings"
                ]
            }
        ],
        [
            {
                "code": "import mbuild as mb\n\nclass CH3(mb.Compound):\n    def __init__(self):\n        super(CH3, self).__init__()\n\n        mb.load('ch3.pdb', compound=self)",
                "true_label": "",
                "top5_preds": [
                    "load table in pandas",
                    "postgres sql lab",
                    "import polynomial features from sklearn",
                    "reading and writing binary files",
                    "running a local postgres database"
                ]
            },
            {
                "code": "import mbuild as mb\n\nclass CH3(mb.Compound):\n    def __init__(self):\n        super(CH3, self).__init__()\n\n        mb.load('ch3.pdb', compound=self)\n        mb.translate(self, -self[0].pos)  # Move carbon to origin.",
                "true_label": "",
                "top5_preds": [
                    "convert date to datetime format",
                    "add edges in graph",
                    "function to find dbZ given Pr radar equation",
                    "importing data with numpy",
                    "numpy point"
                ]
            },
            {
                "code": "import mbuild as mb\n\nclass CH3(mb.Compound):\n    def __init__(self):\n        super(CH3, self).__init__()\n\n        mb.load('ch3.pdb', compound=self)\n        mb.translate(self, -self[0].pos)  # Move carbon to origin.\n\n        port = mb.Port(anchor=self[0])\n        self.add(port, label='up')\n        # Place the port at approximately have a C-C bond length.\n        mb.translate(self['up'], [0, -0.07, 0])  ",
                "true_label": "",
                "top5_preds": [
                    "convert date to datetime format",
                    "add edges in graph",
                    "function to find dbZ given Pr radar equation",
                    "importing data with numpy",
                    "numpy point"
                ]
            },
            {
                "code": "CH3().visualize(show_ports=True)",
                "true_label": "",
                "top5_preds": [
                    "import polynomial features from sklearn",
                    "scikit image panorama",
                    "visualizing uncertainty",
                    "what is scikit learn?",
                    "equally spaced numbers on a grid"
                ]
            },
            {
                "code": "import mbuild as mb\n\nclass Ethane(mb.Compound):\n    def __init__(self):\n        super(Ethane, self).__init__()\n\n        self.add(CH3(), \"methyl1\")\n        self.add(CH3(), \"methyl2\")\n        mb.equivalence_transform(compound=self['methyl1'], \n                                 from_positions=self['methyl1']['up'], \n                                 to_positions=self['methyl2']['up'])",
                "true_label": "",
                "top5_preds": [
                    "symbolic computation with polynomials",
                    "the algebraic connectivity",
                    "multiplication of two polynomials",
                    "import polynomial features from sklearn",
                    "creating polynomial features"
                ]
            },
            {
                "code": "ethane = Ethane()\nethane.visualize()",
                "true_label": "",
                "top5_preds": [
                    "scikit image panorama",
                    "create an array of linearly spaced points",
                    "visualizing vectors",
                    "plot using matplotlib",
                    "visualizing uncertainty"
                ]
            },
            {
                "code": "ethane.visualize(show_ports=True)",
                "true_label": "",
                "top5_preds": [
                    "scikit image panorama",
                    "equally spaced numbers on a grid",
                    "getting data from the internet",
                    "add edges in graph",
                    "plot using matplotlib"
                ]
            },
            {
                "code": "# Save to .mol2\nethane.save('ethane.mol2')",
                "true_label": "",
                "top5_preds": [
                    "convert list to numpy array",
                    "implementing logistic regression via a newton based mle",
                    "reading and writing binary files",
                    "add edges in graph",
                    "convert text data into vector"
                ]
            }
        ],
        [
            {
                "code": "x = torch.Tensor(5,3)\nx",
                "true_label": "",
                "top5_preds": [
                    "tensorflow + keras",
                    "logistic regression using tensorflow",
                    "tensorflow",
                    "polynomial regression with sklearn",
                    "what is scikit learn?"
                ]
            },
            {
                "code": "x = torch.rand(5,3)\nx",
                "true_label": "",
                "top5_preds": [
                    "tensorflow + keras",
                    "logistic regression using tensorflow",
                    "polynomial regression with sklearn",
                    "tensorflow",
                    "what is scikit learn?"
                ]
            },
            {
                "code": "x.size()",
                "true_label": "",
                "top5_preds": [
                    "equally spaced numbers on a grid",
                    "convert list to numpy array",
                    "sum all the numbers in a list",
                    "find maximum and the minimum value in a set",
                    "calculating the mean of a vector with nans"
                ]
            },
            {
                "code": "x = torch.rand(5,3)\ny = torch.rand(5,3)\nx+y",
                "true_label": "",
                "top5_preds": [
                    "tensorflow + keras",
                    "scipy",
                    "numpy",
                    "tensorflow",
                    "polynomial regression with sklearn"
                ]
            },
            {
                "code": "x = torch.rand(5,3)\ny = torch.rand(5,3)\ntorch.add(x, y)",
                "true_label": "",
                "top5_preds": [
                    "tensorflow + keras",
                    "introduction to deep learning with pytorch",
                    "tensorflow",
                    "numpy point",
                    "logistic regression using tensorflow"
                ]
            },
            {
                "code": "result =torch.rand(5,3)\nx = torch.rand(5,3)\ny = torch.rand(5,3)\ntorch.add(x, y, out=result)\nresult",
                "true_label": "",
                "top5_preds": [
                    "tensorflow + keras",
                    "numpy point",
                    "matrix addition and scalar matrix multiplication",
                    "introduction to deep learning with pytorch",
                    "polynomial regression with sklearn"
                ]
            },
            {
                "code": "x = torch.rand(5,3)\ny = torch.rand(5,3)\ny.add_(x)\ny",
                "true_label": "",
                "top5_preds": [
                    "tensorflow + keras",
                    "matrix addition and scalar matrix multiplication",
                    "polynomial regression with sklearn",
                    "tensorflow",
                    "classification with a cnn"
                ]
            },
            {
                "code": "x = torch.rand(5,3)\nx[:,:2]",
                "true_label": "",
                "top5_preds": [
                    "numpy",
                    "what is scikit learn?",
                    "scipy",
                    "polynomial regression with sklearn",
                    "tensorflow + keras"
                ]
            }
        ],
        [
            {
                "code": "import pandas as pd\n%pylab inline",
                "true_label": "",
                "top5_preds": [
                    "plot using matplotlib",
                    "pandas plotting",
                    "trend lines in pyplot",
                    "equally spaced numbers on a grid",
                    "what is scikit learn?"
                ]
            },
            {
                "code": "df = pd.read_csv(\"data/eu_trade_sums.csv\")",
                "true_label": "",
                "top5_preds": [
                    "loading a csv into a dataframe",
                    "convert data from string to float",
                    "convert date to datetime format",
                    "load table in pandas",
                    "importing data with pandas"
                ]
            },
            {
                "code": "df.head(4)",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "loading a csv into a dataframe",
                    "using a dataframe and matplotlib commands",
                    "equally spaced numbers on a grid",
                    "load table in pandas"
                ]
            },
            {
                "code": "df.dtypes",
                "true_label": "",
                "top5_preds": [
                    "find data type of each column",
                    "convert date to datetime format",
                    "load table in pandas",
                    "convert categorical variables",
                    "what is the type of the columns?"
                ]
            },
            {
                "code": "df = df.set_index('geo')",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "load table in pandas",
                    "from dictionary to dataframe",
                    "dataframe methods",
                    "using a dataframe and matplotlib commands"
                ]
            },
            {
                "code": "yrs = [str(yr) for yr in range(2002, 2016)]",
                "true_label": "",
                "top5_preds": [
                    "convert date to datetime format",
                    "formatting datetimes as strings",
                    "convert list to numpy array",
                    "add string to list using append",
                    "sum all the numbers in a list"
                ]
            },
            {
                "code": "export_df = df[(df['trade_type'] == 'Export') &\n               (df['partner'] == 'EXT_EU28')\n              ].loc[['EU28', 'UK']][yrs]",
                "true_label": "",
                "top5_preds": [
                    "return a dataframe",
                    "plot the df dataframe using pandas + matplotlib",
                    "importing data with pandas",
                    "load table in pandas",
                    "using a dataframe and matplotlib commands"
                ]
            },
            {
                "code": "export_df.head(4)",
                "true_label": "",
                "top5_preds": [
                    "from dictionary to dataframe",
                    "join two dataframes along rows",
                    "line plot with a dataframe",
                    "importing data with pandas",
                    "load table in pandas"
                ]
            },
            {
                "code": "export_df[['UK_TO_EXT', 'UK_TO_INT']].plot()",
                "true_label": "",
                "top5_preds": [
                    "pandas plotting",
                    "line plot with a dataframe",
                    "plot using pandas plotting",
                    "plotting time series with pandas",
                    "line plots show the trend of a numerical variable over time"
                ]
            },
            {
                "code": "from bokeh.plotting import figure, output_file, show\nfrom bokeh.layouts import gridplot",
                "true_label": "",
                "top5_preds": [
                    "plot using matplotlib",
                    "line plot with a dataframe",
                    "pandas plotting",
                    "trend lines in pyplot",
                    "plot using pandas plotting"
                ]
            },
            {
                "code": "TOOLS = 'resize,pan,wheel_zoom,box_zoom,reset,hover'",
                "true_label": "",
                "top5_preds": [
                    "equally spaced numbers on a grid",
                    "scikit image panorama",
                    "using interact for animation with data",
                    "sum all the numbers in a list",
                    "trend lines in pyplot"
                ]
            },
            {
                "code": "p = figure(tools=TOOLS, x_range=(2002, 2015), y_range=(200000, 500000),\n           title=\"UK Import Export Trends from 2002-2014\")",
                "true_label": "",
                "top5_preds": [
                    "create a bar chart",
                    "plot using matplotlib",
                    "matplotlib",
                    "pandas plotting",
                    "plot using pandas plotting"
                ]
            },
            {
                "code": "p.yaxis.axis_label = \"Value in $1000\"",
                "true_label": "",
                "top5_preds": [
                    "equally spaced numbers on a grid",
                    "line plot with a dataframe",
                    "timing, numpy, plotting",
                    "plotting time series with pandas",
                    "formatting datetimes as strings"
                ]
            },
            {
                "code": "p.line(yrs, export_df['UK_TO_EXT'], color='#A6CEE3', legend='UK_TO_EXT')\np.line(yrs, export_df['UK_TO_INT'], color='#B2DF8A', legend='UK_TO_INT')\np.legend.location = 'top_left'",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "pandas plotting",
                    "plot using pandas plotting",
                    "using a dataframe and matplotlib commands",
                    "plot the df dataframe using pandas + matplotlib"
                ]
            },
            {
                "code": "output_file(\"uk_grade.html\", title=\"UK Trade from 2002-2014\")",
                "true_label": "",
                "top5_preds": [
                    "convert date to datetime format",
                    "load table in pandas",
                    "getting data from the internet",
                    "formatting datetimes as strings",
                    "retrieving data from html page"
                ]
            },
            {
                "code": "# open a browser\nshow(p)\n",
                "true_label": "",
                "top5_preds": [
                    "getting data from the internet",
                    "plot using matplotlib",
                    "choosing type of visualization",
                    "visualizing uncertainty",
                    "accessing twitter"
                ]
            },
            {
                "code": "df = df[~ df.index.isin(['EU28'])]",
                "true_label": "",
                "top5_preds": [
                    "load table in pandas",
                    "select every row after a specific row",
                    "importing data with pandas",
                    "drop the rows with nan values",
                    "delete column by name"
                ]
            },
            {
                "code": "pct_change_df = df.copy()",
                "true_label": "",
                "top5_preds": [
                    "create a one column dataframe with the values of a series",
                    "using a dataframe and matplotlib commands",
                    "line plot with a dataframe",
                    "relationships between dataframes",
                    "create dataframe with given values"
                ]
            },
            {
                "code": "for yr in yrs:\n    pct_change_df[yr] = (df[yr] - df[str(int(yr)-1)]) / df[str(int(yr)-1)]",
                "true_label": "",
                "top5_preds": [
                    "line plots show the trend of a numerical variable over time",
                    "line plot with a dataframe",
                    "create a one column dataframe with the values of a series",
                    "create dataframe with given values",
                    "using a dataframe and matplotlib commands"
                ]
            },
            {
                "code": "pct_change_df.head(4)",
                "true_label": "",
                "top5_preds": [
                    "line plots show the trend of a numerical variable over time",
                    "line plot with a dataframe",
                    "using a dataframe and matplotlib commands",
                    "predicting a categorical response",
                    "create a one column dataframe with the values of a series"
                ]
            },
            {
                "code": "[(yr, abs(pct_change_df[yr].max() - pct_change_df[yr].min(0))) for yr in yrs]",
                "true_label": "",
                "top5_preds": [
                    "integrating datetime tools with pandas for time series",
                    "create a one column dataframe with the values of a series",
                    "line plots show the trend of a numerical variable over time",
                    "working with pandas series indexed by datetime",
                    "line plot with a dataframe"
                ]
            },
            {
                "code": "export_df = export_df.T",
                "true_label": "",
                "top5_preds": [
                    "from dictionary to dataframe",
                    "join two dataframes along rows",
                    "line plot with a dataframe",
                    "load table in pandas",
                    "dataframe methods"
                ]
            },
            {
                "code": "export_df = export_df.rename(columns={'EU28': 'EU28_TO_EXT', 'UK': 'UK_TO_EXT'})",
                "true_label": "",
                "top5_preds": [
                    "from dictionary to dataframe",
                    "convert date to datetime format",
                    "load table in pandas",
                    "line plot with a dataframe",
                    "import polynomial features from sklearn"
                ]
            },
            {
                "code": "int_df = df[(df['trade_type'] == 'Export') &\n            (df['partner'] == 'EU28')\n           ].loc[['EU28', 'UK']][yrs]",
                "true_label": "",
                "top5_preds": [
                    "return a dataframe",
                    "convert data from string to float",
                    "find all by term in field in case insensitive way",
                    "convert integer or float data",
                    "line plot with a dataframe"
                ]
            },
            {
                "code": "int_df.head(4)",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "find data type of each column",
                    "loading a csv into a dataframe",
                    "load table in pandas",
                    "create a one column dataframe with the values of a series"
                ]
            },
            {
                "code": "int_df = int_df.T",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "create a one column dataframe with the values of a series",
                    "from dictionary to dataframe",
                    "create dataframe with given values",
                    "load table in pandas"
                ]
            },
            {
                "code": "export_df = pd.concat([export_df, int_df], axis=1)",
                "true_label": "",
                "top5_preds": [
                    "from dictionary to dataframe",
                    "importing data with pandas",
                    "join two dataframes along rows",
                    "line plot with a dataframe",
                    "create a one column dataframe with the values of a series"
                ]
            },
            {
                "code": "export_df = export_df.rename(columns={'EU28': 'EU28_TO_INT', \n                                     'UK' : 'UK_TO_INT'})",
                "true_label": "",
                "top5_preds": [
                    "from dictionary to dataframe",
                    "transform the date column as a datetime type",
                    "convert date to datetime format",
                    "convert data from string to float",
                    "transform year column"
                ]
            },
            {
                "code": "export_df.plot(legend=False)",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "pandas plotting",
                    "plot using pandas plotting",
                    "plot the df dataframe using pandas + matplotlib",
                    "using a dataframe and matplotlib commands"
                ]
            },
            {
                "code": "export_df.plot()",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "pandas plotting",
                    "plot using pandas plotting",
                    "plot the df dataframe using pandas + matplotlib",
                    "using a dataframe and matplotlib commands"
                ]
            },
            {
                "code": "pct_change_df['2010'].std()",
                "true_label": "",
                "top5_preds": [
                    "line plots show the trend of a numerical variable over time",
                    "predicting a categorical response",
                    "create a one column dataframe with the values of a series",
                    "integrating datetime tools with pandas for time series",
                    "line plot with a dataframe"
                ]
            },
            {
                "code": "pct_change_df['2010'].mean()",
                "true_label": "",
                "top5_preds": [
                    "line plots show the trend of a numerical variable over time",
                    "predicting a categorical response",
                    "line plot with a dataframe",
                    "create a one column dataframe with the values of a series",
                    "change type of column"
                ]
            },
            {
                "code": "pct_change_df[pct_change_df['2010'].abs() >= \n              (pct_change_df['2010'].mean() + 2*pct_change_df['2010'].std())]",
                "true_label": "",
                "top5_preds": [
                    "credible interval vs confidence interval",
                    "predicting a categorical response",
                    "line plots show the trend of a numerical variable over time",
                    "integrating datetime tools with pandas for time series",
                    "line plot with a dataframe"
                ]
            },
            {
                "code": "pct_change_df['2010'].sort_values()",
                "true_label": "",
                "top5_preds": [
                    "line plots show the trend of a numerical variable over time",
                    "create a one column dataframe with the values of a series",
                    "predicting a categorical response",
                    "plotting time series with pandas",
                    "line plot with a dataframe"
                ]
            },
            {
                "code": "pct_change_df[pct_change_df['2010'] < 0]",
                "true_label": "",
                "top5_preds": [
                    "using a dataframe and matplotlib commands",
                    "integrating datetime tools with pandas for time series",
                    "create a one column dataframe with the values of a series",
                    "predicting a categorical response",
                    "select every row after a specific row"
                ]
            },
            {
                "code": "pct_change_df['2010'].sort_values()",
                "true_label": "",
                "top5_preds": [
                    "line plots show the trend of a numerical variable over time",
                    "create a one column dataframe with the values of a series",
                    "predicting a categorical response",
                    "plotting time series with pandas",
                    "line plot with a dataframe"
                ]
            }
        ],
        [
            {
                "code": "import pandas as pd",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "equally spaced numbers on a grid",
                    "load table in pandas",
                    "importing data with numpy",
                    "import polynomial features from sklearn"
                ]
            },
            {
                "code": "import json\nfrom pandas.io.json import json_normalize",
                "true_label": "",
                "top5_preds": [
                    "loading json in python",
                    "formatting datetimes as strings",
                    "from dictionary to dataframe",
                    "equally spaced numbers on a grid",
                    "parse time and visibility from json"
                ]
            },
            {
                "code": "# define json string\ndata = [{'state': 'Florida', \n         'shortname': 'FL',\n         'info': {'governor': 'Rick Scott'},\n         'counties': [{'name': 'Dade', 'population': 12345},\n                      {'name': 'Broward', 'population': 40000},\n                      {'name': 'Palm Beach', 'population': 60000}]},\n        {'state': 'Ohio',\n         'shortname': 'OH',\n         'info': {'governor': 'John Kasich'},\n         'counties': [{'name': 'Summit', 'population': 1234},\n                      {'name': 'Cuyahoga', 'population': 1337}]}]",
                "true_label": "",
                "top5_preds": [
                    "loading json in python",
                    "data given as a dictionary",
                    "using json to find your location",
                    "parse time and visibility from json",
                    "from dictionary to dataframe"
                ]
            },
            {
                "code": "# use normalization to create tables from nested element\njson_normalize(data, 'counties')",
                "true_label": "",
                "top5_preds": [
                    "from dictionary to dataframe",
                    "loading json in python",
                    "data given as a dictionary",
                    "parse time and visibility from json",
                    "dealing with data"
                ]
            },
            {
                "code": "# further populate tables created from nested element\njson_normalize(data, 'counties', ['state', 'shortname', ['info', 'governor']])",
                "true_label": "",
                "top5_preds": [
                    "from dictionary to dataframe",
                    "loading json in python",
                    "data given as a dictionary",
                    "dealing with data",
                    "parse time and visibility from json"
                ]
            },
            {
                "code": "# load json as string\njson.load((open('data/world_bank_projects_less.json')))",
                "true_label": "",
                "top5_preds": [
                    "loading json in python",
                    "using json to find your location",
                    "parse time and visibility from json",
                    "getting data from the internet",
                    "load table in pandas"
                ]
            },
            {
                "code": "# load as Pandas dataframe\nsample_json_df = pd.read_json('data/world_bank_projects_less.json')\nsample_json_df",
                "true_label": "",
                "top5_preds": [
                    "loading json in python",
                    "from dictionary to dataframe",
                    "load table in pandas",
                    "data given as a dictionary",
                    "loading a csv into a dataframe"
                ]
            },
            {
                "code": "# read world_bank_projects into dataframe with only columns related to countries\nworld_bank_projects = pd.read_json('data/world_bank_projects.json')[['countrycode', 'countryshortname']]\n# Sort countries by number of projects\nworld_bank_projects = world_bank_projects.groupby('countryshortname').count().sort_values('countrycode', ascending=False)\n# Print countries by descending order (top 10 only)\nworld_bank_projects.columns = ['Total Projects']\nworld_bank_projects[:10]",
                "true_label": "",
                "top5_preds": [
                    "from dictionary to dataframe",
                    "importing data with pandas",
                    "relationships between dataframes",
                    "importing data with numpy",
                    "import polynomial features from sklearn"
                ]
            },
            {
                "code": "world_bank_projects = json.load((open('data/world_bank_projects.json')))",
                "true_label": "",
                "top5_preds": [
                    "loading json in python",
                    "using json to find your location",
                    "importing data with numpy",
                    "postgres sql lab",
                    "parse time and visibility from json"
                ]
            }
        ],
        [
            {
                "code": "import numpy as np\n\nP = np.asarray([[-7,-1],[1,1]])\nD = np.asarray([[1,0],[0,-5]])\nP_1 = np.asarray([[2,7],[-1,-6]])",
                "true_label": "",
                "top5_preds": [
                    "numpy",
                    "matrix addition and scalar matrix multiplication",
                    "computing the covariance matrix",
                    "scipy",
                    "using principal component analysis to plot in two dimensions"
                ]
            }
        ],
        [
            {
                "code": "# Since over 5000 features are too large and the binary features might not be that infomative. Will work on standardised numeric features from now\nfrom sklearn.preprocessing import StandardScaler\ntarget = ap_X.loc[:,:'average gate arrival delay']\nstd_ap = pd.DataFrame(StandardScaler().fit_transform(target), columns=list(target.columns))\n",
                "true_label": "",
                "top5_preds": [
                    "import polynomial features from sklearn",
                    "predicting a continuous response using linear regression",
                    "polynomial regression with sklearn",
                    "predicting a categorical response",
                    "shortcut principal component analysis in scikit learn"
                ]
            },
            {
                "code": "from sklearn.decomposition import PCA\npca = PCA()\npca.fit(std_ap)",
                "true_label": "",
                "top5_preds": [
                    "import polynomial features from sklearn",
                    "shortcut principal component analysis in scikit learn",
                    "polynomial regression with sklearn",
                    "what is scikit learn?",
                    "fit a polynomial"
                ]
            },
            {
                "code": "pca_X = pca.transform(std_ap)\nexp_var_ratio = pca.explained_variance_ratio_\nfig = plt.figure(figsize=(10,7))\nax = fig.add_subplot(111)\nax.plot(range(len(exp_var_ratio)),exp_var_ratio, label = 'individual')\nax.plot(range(len(exp_var_ratio)),np.cumsum(exp_var_ratio), label='Cumulative')\n\nax.set(xlabel='number of PCAs', ylabel='Variacned explained')\nplt.legend(loc='center right')\nplt.show()",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "ploting out data with box plots",
                    "line plots show the trend of a numerical variable over time",
                    "plot multidimensional data in two dimensions",
                    "plot the distributions"
                ]
            },
            {
                "code": "pca = PCA(n_components=4)\npca.fit(std_ap)\npca_ap = pca.transform(std_ap)\npca_ap[:5]",
                "true_label": "",
                "top5_preds": [
                    "shortcut principal component analysis in scikit learn",
                    "polynomial regression with sklearn",
                    "import polynomial features from sklearn",
                    "fit a polynomial",
                    "what is scikit learn?"
                ]
            },
            {
                "code": "clus = KMeans(n_clusters=2)\nclus.fit(pca_ap)\nlabels = clus.labels_\nfig = plt.figure(figsize=(10,7))\nax = fig.add_subplot(111)\nax.scatter(pca_ap[:,0],pca_ap[:,1],c=labels, cmap=cm.get_cmap('rainbow'))\nax.set(xlabel='1st PC', ylabel='2nd PC')\nplt.show()",
                "true_label": "",
                "top5_preds": [
                    "load the kmeans class from sklearn cluster",
                    "image compression using k means clustering",
                    "import polynomial features from sklearn",
                    "line plot with a dataframe",
                    "ploting out data with box plots"
                ]
            },
            {
                "code": "from sklearn.metrics import silhouette_score\nsilhouette_score(pca_ap, clus.labels_, metric='euclidean')",
                "true_label": "",
                "top5_preds": [
                    "import polynomial features from sklearn",
                    "scikit learn",
                    "what is scikit learn?",
                    "shortcut principal component analysis in scikit learn",
                    "fit a polynomial"
                ]
            },
            {
                "code": "clus = KMeans(n_clusters=5)\nclus.fit(pca_ap)\nlabels = clus.labels_\nfig = plt.figure(figsize=(10,7))\nax = fig.add_subplot(111)\nax.scatter(pca_ap[:,0],pca_ap[:,1],c=labels, cmap=cm.get_cmap('rainbow'))\nax.set(xlabel='1st PC', ylabel='2nd PC')\nplt.show()",
                "true_label": "",
                "top5_preds": [
                    "load the kmeans class from sklearn cluster",
                    "image compression using k means clustering",
                    "import polynomial features from sklearn",
                    "line plot with a dataframe",
                    "ploting out data with box plots"
                ]
            },
            {
                "code": "engine_FAA = create_engine('postgresql://localhost/faa')\nap_cancel = pd.read_sql('airport_cancellation',engine_FAA)\nap = pd.read_sql('airport',engine_FAA)\nap_ops = pd.read_sql('airport_operations',engine_FAA)",
                "true_label": "",
                "top5_preds": [
                    "load table in pandas",
                    "running a local postgres database",
                    "sqlalchemy, sqlite, and dates",
                    "exploring the database with sql",
                    "postgres sql lab"
                ]
            },
            {
                "code": "ap.head()",
                "true_label": "",
                "top5_preds": [
                    "find maximum and the minimum value in a set",
                    "join two dataframes along rows",
                    "building a mini lsst broker for data management and discovery",
                    "twitter api access",
                    "getting data from the internet"
                ]
            },
            {
                "code": "plt.figure()\nax = plt.subplot()\nap['FAA REGION'].value_counts().plot(kind='barh', figsize=(8,6), ax=ax, color='midnightblue', alpha=.8)\nax.set(xlabel='Count',ylabel='FAA Region')\nplt.show()",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "pandas plotting",
                    "plot using pandas plotting",
                    "plotting time series with pandas",
                    "plot histogram"
                ]
            },
            {
                "code": "ap['AP Type'].value_counts().plot(kind='barh',color='midnightblue',alpha=.8,figsize=(8,6))\nplt.show()",
                "true_label": "",
                "top5_preds": [
                    "pandas plotting",
                    "line plot with a dataframe",
                    "plotting time series with pandas",
                    "plot using pandas plotting",
                    "line plots show the trend of a numerical variable over time"
                ]
            },
            {
                "code": "plt.figure()\nax = plt.subplot()\nap['CITY'].value_counts()[:10].plot(kind='barh',color='midnightblue',alpha=.8,figsize=(8,6),ax=ax)\nax.set(xlabel='Count',ylabel='City')\nplt.show()",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "plot using pandas plotting",
                    "pandas plotting",
                    "plot histogram",
                    "ploting out data with box plots"
                ]
            },
            {
                "code": "plt.figure()\nax = plt.subplot()\nap['COUNTY'].value_counts()[:10].plot(kind='barh',color='midnightblue',alpha=.8,figsize=(8,6),ax=ax)\nax.set(xlabel='Count',ylabel='County')\nplt.show()",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "plot histogram",
                    "plot using pandas plotting",
                    "pandas plotting",
                    "plot using matplotlib"
                ]
            },
            {
                "code": "plt.figure()\nax = plt.subplot()\nap['STATE'].value_counts()[:10].plot(kind='barh',color='midnightblue',alpha=.8,figsize=(8,6),ax=ax)\nax.set(xlabel='Count',ylabel='City')\nplt.show()",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "plot using pandas plotting",
                    "pandas plotting",
                    "plotting time series with pandas",
                    "ploting out data with box plots"
                ]
            },
            {
                "code": "ap_cancel.head()",
                "true_label": "",
                "top5_preds": [
                    "twitter api access",
                    "constructing an api get request",
                    "obtaining metadata from crossref",
                    "convert list to numpy array",
                    "interacting with online services"
                ]
            },
            {
                "code": "sns.pairplot(ap_cancel.iloc[:,1:])",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "predicting a categorical response",
                    "plotting time series with pandas",
                    "relationships between dataframes",
                    "calculating the mean of a vector with nans"
                ]
            },
            {
                "code": "ap_merge = ap_ops.merge(ap_cancel,on=['Year','Airport'], how='inner')\nap_merge = ap_merge.merge(ap_dc,on=['Airport'],how='inner')\nap_merge.head()",
                "true_label": "",
                "top5_preds": [
                    "join two dataframes along rows",
                    "join two dataframes along columns",
                    "relationships between dataframes",
                    "combine two dataframes into one",
                    "create a dataframe by joining series by column"
                ]
            },
            {
                "code": "ap_merge.isnull().values.any()",
                "true_label": "",
                "top5_preds": [
                    "calculating the mean of a vector with nans",
                    "relationships between dataframes",
                    "computing the covariance when there are nan s",
                    "find maximum and the minimum value in a set",
                    "find data type of each column"
                ]
            },
            {
                "code": "ap_merge.corr().head()",
                "true_label": "",
                "top5_preds": [
                    "predicting a categorical response",
                    "relationships between dataframes",
                    "line plot with a dataframe",
                    "line plots show the trend of a numerical variable over time",
                    "import polynomial features from sklearn"
                ]
            },
            {
                "code": "from sklearn.cluster import KMeans, DBSCAN\nfrom scipy.cluster.hierarchy import dendrogram, linkage, cophenet, fcluster\nfrom scipy.spatial.distance import pdist\nimport matplotlib.cm as cm\n\nclus = KMeans(n_clusters=2)\nclus.fit(ap_merge.drop('Airport',axis=1))\nlabels = clus.labels_\n\n",
                "true_label": "",
                "top5_preds": [
                    "import polynomial features from sklearn",
                    "polynomial regression with sklearn",
                    "load the kmeans class from sklearn cluster",
                    "ridge regression with polynomial features on a grid",
                    "scikit learn"
                ]
            },
            {
                "code": "fig = plt.figure(figsize=(10,7))\nax = fig.add_subplot(111)\nax.scatter(ap_merge['percent on-time airport departures'],ap_merge['average airborne delay'],c=labels, cmap=cm.get_cmap('rainbow'))\nax.set(xlabel='percent on-time airport departures', ylabel='average airborne delay')\nplt.show()",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "ploting out data with box plots",
                    "plot using matplotlib",
                    "plotting data",
                    "matplotlib"
                ]
            },
            {
                "code": "from sklearn.metrics import silhouette_score\nsilhouette_score(ap_merge.drop('Airport',axis=1), clus.labels_, metric='euclidean')",
                "true_label": "",
                "top5_preds": [
                    "import polynomial features from sklearn",
                    "scikit learn",
                    "line plot with a dataframe",
                    "what is scikit learn?",
                    "shortcut principal component analysis in scikit learn"
                ]
            },
            {
                "code": "clus = KMeans(n_clusters=5)\nclus.fit(ap_merge.drop('Airport',axis=1))\nlabels = clus.labels_\nfig = plt.figure(figsize=(10,7))\nax = fig.add_subplot(111)\nax.scatter(ap_merge['percent on-time airport departures'],ap_merge['average airborne delay'],c=labels, cmap=cm.get_cmap('rainbow'))\nax.set(xlabel='percent on-time airport departures', ylabel='average airborne delay')\nplt.show()",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "load the kmeans class from sklearn cluster",
                    "image compression using k means clustering",
                    "import polynomial features from sklearn",
                    "example data analysis k means"
                ]
            },
            {
                "code": "ap_X = ap_merge.drop('Airport',axis=1)\nZ = linkage(ap_X, 'ward')\nc, coph_dists = cophenet(Z, pdist(ap_X))\nplt.title('Dendrogram')\nplt.xlabel('Index Numbers')\nplt.ylabel('Distance')\ndendrogram(\n    Z,\n    leaf_rotation=90.,  \n    leaf_font_size=8.,)\nplt.show()",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "plot multidimensional data in two dimensions",
                    "relationships between dataframes",
                    "ridge regression with polynomial features on a grid",
                    "using principal component analysis to plot in two dimensions"
                ]
            },
            {
                "code": "max_dist = 2.5*10**6\nclusters = fcluster(Z, max_dist, criterion = 'distance')\nfig = plt.figure(figsize=(10,7))\nax = fig.add_subplot(111)\nax.scatter(ap_merge['percent on-time airport departures'],ap_merge['average airborne delay'],c=clusters, cmap=cm.get_cmap('rainbow'))\nax.set(xlabel='percent on-time airport departures', ylabel='average airborne delay')\nplt.show()",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "ploting out data with box plots",
                    "image compression using k means clustering",
                    "equally spaced numbers on a grid",
                    "ridge regression with polynomial features on a grid"
                ]
            },
            {
                "code": "max_dist = .9*10**6\nclusters = fcluster(Z, max_dist, criterion = 'distance')\nfig = plt.figure(figsize=(10,7))\nax = fig.add_subplot(111)\nax.scatter(ap_merge['percent on-time airport departures'],ap_merge['average airborne delay'],c=clusters, cmap=cm.get_cmap('rainbow'))\nax.set(xlabel='percent on-time airport departures', ylabel='average airborne delay')\nplt.show()",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "ploting out data with box plots",
                    "image compression using k means clustering",
                    "equally spaced numbers on a grid",
                    "line plots show the trend of a numerical variable over time"
                ]
            },
            {
                "code": "Z = linkage(pca_ap, 'ward')\nc, coph_dists = cophenet(Z, pdist(pca_ap))\nplt.title('Dendrogram')\nplt.xlabel('Index Numbers')\nplt.ylabel('Distance')\ndendrogram(\n    Z,\n    leaf_rotation=90.,  \n    leaf_font_size=8.,)\nplt.show()",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "plot the distributions",
                    "plot using matplotlib",
                    "ridge regression with polynomial features on a grid",
                    "plot multidimensional data in two dimensions"
                ]
            },
            {
                "code": "clus_num = []\nfor i in range(1,60):\n    clusters = fcluster(Z, i, criterion='distance')\n    n_clus = len(np.unique(clusters))\n    clus_num.append(n_clus)\nplt.figure(figsize=(10,7))\nplt.plot(range(1,60), clus_num)\nplt.xlabel('Max Distance')\nplt.ylabel('Number of clusters')\nplt.show()",
                "true_label": "",
                "top5_preds": [
                    "image compression using k means clustering",
                    "ploting out data with box plots",
                    "equally spaced numbers on a grid",
                    "line plot with a dataframe",
                    "predicting a categorical response"
                ]
            },
            {
                "code": "max_dist = 65\nclusters = fcluster(Z, max_dist, criterion = 'distance')\nfig = plt.figure(figsize=(10,7))\nax = fig.add_subplot(111)\nax.scatter(pca_ap[:,0],pca_ap[:,1],c=clusters, cmap=cm.get_cmap('rainbow'))\nax.set(xlabel='1st PC', ylabel='2nd PC')\nplt.show()",
                "true_label": "",
                "top5_preds": [
                    "ploting out data with box plots",
                    "line plot with a dataframe",
                    "image compression using k means clustering",
                    "equally spaced numbers on a grid",
                    "ridge regression with polynomial features on a grid"
                ]
            },
            {
                "code": "max_dist = 28\nclusters = fcluster(Z, max_dist, criterion = 'distance')\nfig = plt.figure(figsize=(10,7))\nax = fig.add_subplot(111)\nax.scatter(pca_ap[:,0],pca_ap[:,1],c=clusters, cmap=cm.get_cmap('rainbow'))\nax.set(xlabel='1st PC', ylabel='2nd PC')\nplt.show()",
                "true_label": "",
                "top5_preds": [
                    "ploting out data with box plots",
                    "line plot with a dataframe",
                    "image compression using k means clustering",
                    "ridge regression with polynomial features on a grid",
                    "equally spaced numbers on a grid"
                ]
            },
            {
                "code": "ap_ops.head()",
                "true_label": "",
                "top5_preds": [
                    "tensorflow + keras",
                    "building a mini lsst broker for data management and discovery",
                    "join two dataframes along rows",
                    "load table in pandas",
                    "obtaining metadata from crossref"
                ]
            },
            {
                "code": "sns.pairplot(ap_ops.iloc[:,1:])\nplt.show()",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "plot multidimensional data in two dimensions",
                    "create an array of linearly spaced points",
                    "equally spaced numbers on a grid",
                    "plotting time series with pandas"
                ]
            },
            {
                "code": "# Since operations can cancellation data are of numerical types, most dummies would come from the airport dataset\nap.head()",
                "true_label": "",
                "top5_preds": [
                    "load table in pandas",
                    "find data type of each column",
                    "helpers to read in dataset",
                    "import polynomial features from sklearn",
                    "importing data with numpy"
                ]
            },
            {
                "code": "# Looking at the above dataframe, there are a few columns that needs to be dropped.\n# Need to keep LocID for joining others can be turned into categorical data apart from lat and long\nap_d = ap.drop(['Key', 'AP_NAME', 'ALIAS', 'Facility Type','Boundary Data Available'],axis=1)\nap_d.head()",
                "true_label": "",
                "top5_preds": [
                    "from dictionary to dataframe",
                    "load table in pandas",
                    "importing data with pandas",
                    "drop data points with missing data",
                    "relationships between dataframes"
                ]
            },
            {
                "code": "faaregion = pd.get_dummies(ap_d['FAA REGION'],drop_first=True)\ncounty = pd.get_dummies(ap_d['COUNTY'],drop_first=True)\ncity = pd.get_dummies(ap_d['CITY'],drop_first=True)\nstate = pd.get_dummies(ap_d['STATE'],drop_first=True)\naptype = pd.get_dummies(ap_d['AP Type'],drop_first=True)\nap_d.drop(['FAA REGION', 'COUNTY', 'CITY', 'STATE','AP Type'],axis=1,inplace=True)\nap_dc = pd.concat([ap_d,faaregion,county,city,state,aptype],axis=1)",
                "true_label": "",
                "top5_preds": [
                    "from dictionary to dataframe",
                    "load table in pandas",
                    "importing data with numpy",
                    "importing data with pandas",
                    "loading a csv into a dataframe"
                ]
            },
            {
                "code": "ap_dc['Airport'] = ap_dc['LocID']\nap_dc.drop('LocID',axis=1,inplace=True)\nap_dc.head()",
                "true_label": "",
                "top5_preds": [
                    "importing data with pandas",
                    "from dictionary to dataframe",
                    "load table in pandas",
                    "importing data with numpy",
                    "drop data points with missing data"
                ]
            },
            {
                "code": "ap_ops['Airport'] = ap_ops['airport']\nap_ops['Year'] = ap_ops['year']\nap_ops.drop(['airport','year'],axis=1,inplace=True)\nap_ops.head()",
                "true_label": "",
                "top5_preds": [
                    "convert date to datetime format",
                    "load table in pandas",
                    "importing data with pandas",
                    "from dictionary to dataframe",
                    "importing data with numpy"
                ]
            },
            {
                "code": "db = DBSCAN(eps= 1, min_samples= 30)  \nmodel = db.fit(ap_X)\nlabels = db.labels_\nfig = plt.figure(figsize=(10,7))\nax = fig.add_subplot(111)\nax.scatter(ap_merge['percent on-time airport departures'],ap_merge['average airborne delay'],c=labels, cmap=cm.get_cmap('rainbow'))\nax.set(xlabel='percent on-time airport departures', ylabel='average airborne delay')\nplt.show()",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "import polynomial features from sklearn",
                    "load table in pandas",
                    "plot multidimensional data in two dimensions",
                    "importing data with numpy"
                ]
            },
            {
                "code": "db = DBSCAN(eps= 3, min_samples= 20)  \nmodel = db.fit(pca_ap)\nlabels = db.labels_\nfig = plt.figure(figsize=(10,7))\nax = fig.add_subplot(111)\nax.scatter(pca_ap[:,0],pca_ap[:,1],c=labels, cmap=cm.get_cmap('rainbow'))\nax.set(xlabel='1st PC', ylabel='2nd PC')\nplt.show()",
                "true_label": "",
                "top5_preds": [
                    "import polynomial features from sklearn",
                    "load table in pandas",
                    "what is scikit learn?",
                    "polynomial regression with sklearn",
                    "fit a logistic regression model using statsmodels using logistic regression formula in patsy"
                ]
            },
            {
                "code": "apyr = pd.DataFrame(ap_merge['Airport']+ ap_merge['Year'].astype(str),columns=['Airport & Year'])\napplt = pd.concat([std_ap,apyr],axis=1)\nfig = plt.figure(figsize=(10,7))\nax = fig.add_subplot(111)\nax.scatter(pca_ap[:,0],pca_ap[:,1],c=labels, cmap=cm.get_cmap('rainbow'))\nfor i, apyr in enumerate(applt['Airport & Year']):\n    if labels[i]<0:\n        ax.annotate(apyr, (pca_ap[i,0],pca_ap[i,1]),fontsize=14)\nax.set(xlabel='1st PC', ylabel='2nd PC')\nplt.show()",
                "true_label": "",
                "top5_preds": [
                    "join two dataframes along rows",
                    "line plot with a dataframe",
                    "importing data with numpy",
                    "join two dataframes along columns",
                    "importing data with pandas"
                ]
            },
            {
                "code": "# Since over 5000 features are too large and the binary features might not be that infomative. Will work on standardised numeric features from now\nfrom sklearn.preprocessing import StandardScaler\ntarget = ap_X.loc[:,:'average gate arrival delay']\nstd_ap = pd.DataFrame(StandardScaler().fit_transform(target), columns=list(target.columns))",
                "true_label": "",
                "top5_preds": [
                    "import polynomial features from sklearn",
                    "predicting a continuous response using linear regression",
                    "polynomial regression with sklearn",
                    "predicting a categorical response",
                    "shortcut principal component analysis in scikit learn"
                ]
            }
        ],
        [
            {
                "code": "import pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\npd.set_option('max_colwidth', 70)",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "pandas plotting",
                    "how to change the size of a plot",
                    "plot using matplotlib",
                    "optimal value of k for dataset"
                ]
            },
            {
                "code": "events = pd.read_pickle('ck-data/events_4605167-to-5374870.pickle.gz')",
                "true_label": "",
                "top5_preds": [
                    "timing, numpy, plotting",
                    "integrating datetime tools with pandas for time series",
                    "formatting datetimes as strings",
                    "line plots show the trend of a numerical variable over time",
                    "plotting time series with pandas"
                ]
            },
            {
                "code": "print('Block range: ' + str(events.blockNumber_dec.min()) + ' to ' + str(events.blockNumber_dec.max()))",
                "true_label": "",
                "top5_preds": [
                    "range of feature",
                    "formatting datetimes as strings",
                    "date ranges and frequencies",
                    "integrating datetime tools with pandas for time series",
                    "getting data from the internet"
                ]
            },
            {
                "code": "events.groupby(['contract','event']).transactionHash.count()",
                "true_label": "",
                "top5_preds": [
                    "formatting datetimes as strings",
                    "counting triangles in a social network",
                    "how many different items appear in the dataset?",
                    "sqlalchemy, sqlite, and dates",
                    "from dictionary to dataframe"
                ]
            },
            {
                "code": "#4832686 first block of the year 2018\nbirths_2018 = births[births['blockNumber_dec']>=4832686]",
                "true_label": "",
                "top5_preds": [
                    "select every row after a specific row",
                    "integrating datetime tools with pandas for time series",
                    "formatting datetimes as strings",
                    "convert date to datetime format",
                    "in pandas"
                ]
            },
            {
                "code": "TopMidwives_2018 = births_2018.groupby(['midwife']).data.count().\\\n                sort_values(ascending=False).head(10)\nTopMidwives_2018 = set(TopMidwives_2018.index.values)\nTopMidwives_2018",
                "true_label": "",
                "top5_preds": [
                    "find maximum and the minimum value in a set",
                    "select every row after a specific row",
                    "relationships between dataframes",
                    "select every row up",
                    "find duplicate dates"
                ]
            },
            {
                "code": "births_2018[births_2018['midwife'].isin(TopMidwives_2018)].groupby(['midwife']).data.count().sort_values().plot(kind='barh')\nplt.xlabel('Number of kitties delivered')",
                "true_label": "",
                "top5_preds": [
                    "predicting a categorical response",
                    "line plot with a dataframe",
                    "line plots show the trend of a numerical variable over time",
                    "ploting out data with box plots",
                    "pandas plotting"
                ]
            },
            {
                "code": "count = pd.DataFrame(births_2018.groupby(['transactionHash']).transactionHash.count())\nfees = births_2018.groupby(['transactionHash']).fee.max()\nmidwife = births_2018.groupby(['transactionHash']).midwife.max()\nmidwife_smartcontract = births_2018.groupby(['transactionHash']).midwife_smartcontract.max()\ngasUsed = births_2018.groupby(['transactionHash']).gasUsed.max()\ngasPrice = births_2018.groupby(['transactionHash']).gasPrice.max()\ndf_profitability = count.join(fees).join(midwife).join(midwife_smartcontract).join(gasUsed).join(gasPrice)\ndf_profitability.columns = ['kitties_delivered','fee','midwife','midwife_smartcontract','gasUsed','gasPrice']\ndf_profitability['revenue'] = df_profitability['kitties_delivered'] * 0.008\ndf_profitability['profit'] = df_profitability['revenue'] - df_profitability['fee']\ndf_profitability['code_efficiency'] = df_profitability['kitties_delivered']/df_profitability['gasUsed']*1e6\ndf_profitability['efficiency'] = df_profitability['profit']/df_profitability['kitties_delivered']\nlen(df_profitability)",
                "true_label": "",
                "top5_preds": [
                    "create a one column dataframe with the values of a series",
                    "line plots show the trend of a numerical variable over time",
                    "predicting a categorical response",
                    "find maximum and the minimum value in a set",
                    "relationships between dataframes"
                ]
            },
            {
                "code": "#dataset of all transactions from midwife to midwife-smartcontract\n#this includes transactions to the core game smart contract that are not calls to giveBirth, so we remove those\ndf_all_midwifing_txns = pd.read_pickle('ck-data/midwives-txns_4605167-to-5374870.pickle.gz')\n#drop transactions to the core game that are not calls to giveBirth\ndf_all_midwifing_txns = df_all_midwifing_txns[((df_all_midwifing_txns['to']=='0x06012c8cf97bead5deae237070f9587f8e7a266d') & \\\n                                               (df_all_midwifing_txns['input'].apply(lambda x: x[:10]=='0x88c2a0bf'))) | \\\n                                               (df_all_midwifing_txns['to']!='0x06012c8cf97bead5deae237070f9587f8e7a266d')]\ndf_all_midwifing_txns['blockNumber_dec'] = df_all_midwifing_txns['blockNumber'].apply(lambda x: int(x,16))\ndf_all_midwifing_txns = df_all_midwifing_txns[df_all_midwifing_txns['blockNumber_dec']>=4832686]\ndf_all_midwifing_txns.head(2)",
                "true_label": "",
                "top5_preds": [
                    "from dictionary to dataframe",
                    "data given as a dictionary",
                    "load table in pandas",
                    "reading in and sampling from the data",
                    "postgres sql lab"
                ]
            },
            {
                "code": "df_failed_midwifing_txns = (df_all_midwifing_txns[~df_all_midwifing_txns['hash'].isin(df_profitability.index)])[['hash','from','to','gasUsed','gasPrice']]\ndf_failed_midwifing_txns.columns = ['transactionHash','midwife','midwife_smartcontract','gasUsed','gasPrice']\n#df_failed_midwifing_txns = df_failed_midwifing_txns[df_failed_midwifing_txns['midwife'].isin(allTimeTopMidwives)]\ndf_failed_midwifing_txns['gasPrice'] = df_failed_midwifing_txns['gasPrice'].apply(lambda x: int(x,16))\ndf_failed_midwifing_txns['kitties_delivered'] = 0\ndf_failed_midwifing_txns['revenue'] = 0\ndf_failed_midwifing_txns['fee'] = df_failed_midwifing_txns['gasUsed'] * df_failed_midwifing_txns['gasPrice'] * 1e-18\ndf_failed_midwifing_txns['profit'] = -df_failed_midwifing_txns['fee']\ndf_failed_midwifing_txns = df_failed_midwifing_txns.set_index('transactionHash')\nlen(df_failed_midwifing_txns)",
                "true_label": "",
                "top5_preds": [
                    "relationships between dataframes",
                    "integrating datetime tools with pandas for time series",
                    "in pandas",
                    "formatting datetimes as strings",
                    "ridge regression with polynomial features on a grid"
                ]
            },
            {
                "code": "(transfer_count - \\\nsale_auction_cancelled_count - \\\nsiring_auction_cancelled_count - \\\nsale_auction_created_count - \\\nsiring_auction_created_count - \\\nsale_auction_successful_count - \\\nbirth_count ) / \\\ntransfer_count",
                "true_label": "",
                "top5_preds": [
                    "sum all the numbers in a list",
                    "formatting datetimes as strings",
                    "add an item in a tuple",
                    "get a positive integer from a user",
                    "addition of two polynomials"
                ]
            },
            {
                "code": "pregnant_count/siring_auction_successful_count",
                "true_label": "",
                "top5_preds": [
                    "get a positive integer from a user",
                    "predicting a categorical response",
                    "test whether a number is positive",
                    "convert data from string to float",
                    "sum all the numbers in a list"
                ]
            },
            {
                "code": "events['contract-event'] = events['contract'] + events['event']\nevents['block-group'] = events['blockNumber_dec'].apply(lambda x: int(x/1000))",
                "true_label": "",
                "top5_preds": [
                    "create a one column dataframe with the values of a series",
                    "integrating datetime tools with pandas for time series",
                    "working with pandas series indexed by datetime",
                    "formatting datetimes as strings",
                    "plotting time series with pandas"
                ]
            },
            {
                "code": "areaplot = events.groupby(['block-group','contract-event']).transactionHash.count().reset_index().pivot(index='block-group', columns='contract-event', values='transactionHash')#.plot.area()\nareaplot.plot.area()\nplt.legend(loc=1)",
                "true_label": "",
                "top5_preds": [
                    "pandas plotting",
                    "line plot with a dataframe",
                    "plot using pandas plotting",
                    "pandas plotting documentation",
                    "equally spaced numbers on a grid"
                ]
            },
            {
                "code": "areaplot.divide(areaplot.sum(axis=1), axis=0).plot.area(figsize=(16, 9))\nplt.legend(loc=1)",
                "true_label": "",
                "top5_preds": [
                    "pandas plotting",
                    "line plot with a dataframe",
                    "equally spaced numbers on a grid",
                    "pandas plotting documentation",
                    "plot using pandas plotting"
                ]
            },
            {
                "code": "transaction_birthcount = (events[events['event']=='Birth'])[['transactionHash','event']].groupby(['transactionHash']).count().reset_index()\ntransaction_birthcount[transaction_birthcount['event']>1].head()",
                "true_label": "",
                "top5_preds": [
                    "in pandas",
                    "counting triangles in a social network",
                    "how many different items appear in the dataset?",
                    "formatting datetimes as strings",
                    "from dictionary to dataframe"
                ]
            },
            {
                "code": "df_profitability = df_profitability.append(df_failed_midwifing_txns, sort=True)\nlen(df_profitability)",
                "true_label": "",
                "top5_preds": [
                    "create a one column dataframe with the values of a series",
                    "predicting a categorical response",
                    "relationships between dataframes",
                    "create a dataframe by joining series by column",
                    "integrating datetime tools with pandas for time series"
                ]
            },
            {
                "code": "df_profitability[df_profitability['midwife'].isin(TopMidwives_2018)].groupby(['midwife']).revenue.sum().sort_values().plot(kind='barh')\nplt.xlabel('Revenue (ETH)')",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "line plots show the trend of a numerical variable over time",
                    "predicting a categorical response",
                    "ploting out data with box plots",
                    "pandas plotting documentation"
                ]
            },
            {
                "code": "df_profitability[df_profitability['midwife'].isin(TopMidwives_2018)].groupby(['midwife']).profit.sum().sort_values().plot(kind='barh')\nplt.xlabel('Profit (ETH)')",
                "true_label": "",
                "top5_preds": [
                    "line plots show the trend of a numerical variable over time",
                    "line plot with a dataframe",
                    "predicting a categorical response",
                    "ploting out data with box plots",
                    "pandas plotting documentation"
                ]
            },
            {
                "code": "efficiency_plot = df_profitability[df_profitability['midwife'].isin(TopMidwives_2018)].groupby(['midwife_smartcontract']).code_efficiency.mean().sort_values()\nefficiency_plot.divide(efficiency_plot.max(),axis=0).plot(kind='barh')\nplt.xlabel('Code efficiency')",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "predicting a categorical response",
                    "line plots show the trend of a numerical variable over time",
                    "ploting out data with box plots",
                    "plotting time series with pandas"
                ]
            },
            {
                "code": "efficiency_plot = df_profitability[df_profitability['midwife'].isin(TopMidwives_2018)].groupby(['midwife']).efficiency.mean().sort_values()\nefficiency_plot.divide(efficiency_plot.max(),axis=0).plot(kind='barh')\nplt.xlabel('Efficiency')",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "predicting a categorical response",
                    "ploting out data with box plots",
                    "line plots show the trend of a numerical variable over time",
                    "pandas plotting documentation"
                ]
            },
            {
                "code": "#df_profitability[df_profitability['midwife'].isin(TopMidwives_2018)].groupby(['midwife','kitties_delivered']).size().unstack('kitties_delivered').fillna(0).reindex(df_profitability[df_profitability['midwife'].isin(TopMidwives_2018)].groupby(['midwife']).profit.sum().sort_values().index.tolist()).plot(kind='barh', stacked=True)",
                "true_label": "",
                "top5_preds": [
                    "predicting a categorical response",
                    "relationships between dataframes",
                    "credible interval vs confidence interval",
                    "line plot with a dataframe",
                    "dataframe methods"
                ]
            },
            {
                "code": "df_profitability[(df_profitability['midwife']=='0x05be6e1f661dacd4630e1ebe2ffce5bfb962076f') & \\\n                 (df_profitability['kitties_delivered']==0) & \\\n                 (df_profitability['midwife_smartcontract']=='0x39243a59d34169eeb0cac2752a21b982408a0194') & \\\n                 (df_profitability['gasUsed']>55000)].head()",
                "true_label": "",
                "top5_preds": [
                    "find all by term in field in case insensitive way",
                    "predicting a categorical response",
                    "sql LIKE operator",
                    "find data type of each column",
                    "ploting out data with box plots"
                ]
            },
            {
                "code": "births = pd.read_pickle('ck-data/births_4605167-to-5374870.pickle.gz')",
                "true_label": "",
                "top5_preds": [
                    "loading a csv into a dataframe",
                    "load table in pandas",
                    "importing data with numpy",
                    "from dictionary to dataframe",
                    "formatting datetimes as strings"
                ]
            },
            {
                "code": "births['owner'] = '0x' + births['data'].apply(lambda x: x[26:66])\nbirths['kittyId'] = births['data'].apply(lambda x: x[66:130])\nbirths['kittyId_dec'] = births['kittyId'].apply(lambda x: int(x,16))\nbirths['matronId'] = births['data'].apply(lambda x: x[130:194])\nbirths['matronId_dec'] = births['matronId'].apply(lambda x: int(x,16))\nbirths['sireId'] = births['data'].apply(lambda x: x[194:258])\nbirths['sireId_dec'] = births['sireId'].apply(lambda x: int(x,16))\nbirths['kittyGenes'] = births['data'].apply(lambda x: x[258:322])\nbirths['block-group'] = births['blockNumber_dec'].apply(lambda x: int(x/1000))",
                "true_label": "",
                "top5_preds": [
                    "convert integer or float data",
                    "convert data from string to float",
                    "convert date to datetime format",
                    "create a one column dataframe with the values of a series",
                    "formatting datetimes as strings"
                ]
            },
            {
                "code": "maxBirths = births.groupby(['transactionHash']).transactionHash.count().max()\nbirths.groupby(['transactionHash']).transactionHash.count().hist(bins=range(maxBirths+2))",
                "true_label": "",
                "top5_preds": [
                    "formatting datetimes as strings",
                    "integrating datetime tools with pandas for time series",
                    "line plots show the trend of a numerical variable over time",
                    "remove duplicates from a list",
                    "create a one column dataframe with the values of a series"
                ]
            },
            {
                "code": "births['midwife'] = births['transaction'].apply(lambda x: eval(x)['from'])",
                "true_label": "",
                "top5_preds": [
                    "from dictionary to dataframe",
                    "pandas apply",
                    "loading a csv into a dataframe",
                    "tensorflow + keras",
                    "relationships between dataframes"
                ]
            },
            {
                "code": "births['midwife_smartcontract'] = births['transaction'].apply(lambda x: eval(x)['to'])",
                "true_label": "",
                "top5_preds": [
                    "from dictionary to dataframe",
                    "linear regression of many variables",
                    "tensorflow + keras",
                    "load table in pandas",
                    "pandas apply"
                ]
            },
            {
                "code": "births['gasPrice'] = births['transaction'].apply(lambda x: int(eval(x)['gasPrice'],16))",
                "true_label": "",
                "top5_preds": [
                    "convert data from string to float",
                    "convert integer or float data",
                    "get a positive integer from a user",
                    "pandas apply",
                    "using pandas"
                ]
            },
            {
                "code": "births['fee'] = births['gasUsed'] * births['gasPrice'] * 1E-18",
                "true_label": "",
                "top5_preds": [
                    "convert data from string to float",
                    "postgres sql lab",
                    "get a positive integer from a user",
                    "from dictionary to dataframe",
                    "create a one column dataframe with the values of a series"
                ]
            },
            {
                "code": "AxiomZenAccounts = ['0xa21037849678af57f9865c6b9887f4e339f6377a','0xba52c75764d6f594735dc735be7f1830cdf58ddf']",
                "true_label": "",
                "top5_preds": [
                    "twitter api access",
                    "constructing an api get request",
                    "accessing twitter",
                    "loading json in python",
                    "implementing bag of words in scikit learn"
                ]
            },
            {
                "code": "allTimeTopMidwives = births.groupby(['midwife']).data.count().\\\n                sort_values(ascending=False)\nlen(allTimeTopMidwives)",
                "true_label": "",
                "top5_preds": [
                    "formatting datetimes as strings",
                    "line plots show the trend of a numerical variable over time",
                    "remove duplicates from a list",
                    "predicting a categorical response",
                    "relationships between dataframes"
                ]
            },
            {
                "code": "allTimeTopMidwives = set(allTimeTopMidwives.head(10).index.values)\nallTimeTopMidwives",
                "true_label": "",
                "top5_preds": [
                    "find maximum and the minimum value in a set",
                    "integrating datetime tools with pandas for time series",
                    "formatting datetimes as strings",
                    "join two dataframes along rows",
                    "plotting time series with pandas"
                ]
            },
            {
                "code": "births['midwife-group'] = births['midwife'].apply(lambda x: '1- AxiomZen' \\\n                                                if x in AxiomZenAccounts \\\n                                                else '2- All Time Top 10' if x in allTimeTopMidwives \\\n                                                else '3- Other')\nareaplot = births.groupby(['block-group','midwife-group']).transactionHash.count().reset_index().pivot(index='block-group', columns='midwife-group', values='transactionHash')\nareaplot.divide(areaplot.sum(axis=1), axis=0).plot.area(figsize=(16, 9))\nplt.legend(loc=1)",
                "true_label": "",
                "top5_preds": [
                    "pandas apply",
                    "create a one column dataframe with the values of a series",
                    "dataframe methods",
                    "relationships between dataframes",
                    "in pandas"
                ]
            },
            {
                "code": "areaplot.plot.area(figsize=(16, 9))\nplt.legend(loc=1)",
                "true_label": "",
                "top5_preds": [
                    "pandas plotting",
                    "matplotlib",
                    "line plot with a dataframe",
                    "create an array of linearly spaced points",
                    "equally spaced numbers on a grid"
                ]
            },
            {
                "code": "movingTopFiveMidwives = births.groupby(['block-group','midwife']).data.count().reset_index().\\\n                sort_values(by=['block-group','data'],ascending=False).groupby(['block-group']).head(5)\nmovingTopFiveMidwives = set(movingTopFiveMidwives.midwife.values)\nlen(movingTopFiveMidwives)",
                "true_label": "",
                "top5_preds": [
                    "join two dataframes along rows",
                    "select every row after a specific row",
                    "select every row up",
                    "find duplicate dates",
                    "relationships between dataframes"
                ]
            },
            {
                "code": "births['midwife-group'] = births['midwife'].apply(lambda x: '1- AxiomZen' \\\n                                                if x in AxiomZenAccounts \\\n                                                else '2- Moving Top 5' if x in movingTopFiveMidwives \\\n                                                else '3- Other')\nareaplot = births.groupby(['block-group','midwife-group']).transactionHash.count().reset_index().pivot(index='block-group', columns='midwife-group', values='transactionHash')\nareaplot.divide(areaplot.sum(axis=1), axis=0).plot.area(figsize=(16, 9))\nplt.legend(loc=1)",
                "true_label": "",
                "top5_preds": [
                    "pandas apply",
                    "create a one column dataframe with the values of a series",
                    "dataframe methods",
                    "relationships between dataframes",
                    "in pandas"
                ]
            },
            {
                "code": "births['type-of-call'] = births['midwife_smartcontract'].apply(lambda x: 'Direct call' \\\n                                                if x == '0x06012c8cf97bead5deae237070f9587f8e7a266d' \\\n                                                else 'Intermediary smart-contract')\nareaplot = births.groupby(['block-group','type-of-call']).transactionHash.count().reset_index().pivot(index='block-group', columns='type-of-call', values='transactionHash')\nareaplot.divide(areaplot.sum(axis=1), axis=0).plot.area(figsize=(16, 9))\nplt.legend(loc=1)",
                "true_label": "",
                "top5_preds": [
                    "pandas apply",
                    "convert categorical variables",
                    "create a one column dataframe with the values of a series",
                    "convert data from string to float",
                    "predicting a categorical response"
                ]
            },
            {
                "code": "births[births['midwife'].isin(allTimeTopMidwives)].groupby(['midwife']).data.count().sort_values().plot(kind='barh')\nplt.xlabel('kitties delivered')",
                "true_label": "",
                "top5_preds": [
                    "line plots show the trend of a numerical variable over time",
                    "predicting a categorical response",
                    "line plot with a dataframe",
                    "plotting time series with pandas",
                    "ploting out data with box plots"
                ]
            },
            {
                "code": "df_profitability[(df_profitability['midwife']=='0x05be6e1f661dacd4630e1ebe2ffce5bfb962076f') & \\\n                 (df_profitability['kitties_delivered']==0) & \\\n                 (df_profitability['midwife_smartcontract']=='0x39243a59d34169eeb0cac2752a21b982408a0194') & \\\n                 (df_profitability['gasUsed']>55000)].profit.sum()",
                "true_label": "",
                "top5_preds": [
                    "find all by term in field in case insensitive way",
                    "predicting a categorical response",
                    "sql LIKE operator",
                    "find data type of each column",
                    "ploting out data with box plots"
                ]
            },
            {
                "code": "event_counts = events.groupby(['contract','event']).transactionHash.count()\nevent_counts.sort_values().plot(kind='barh', figsize=(8, 6))",
                "true_label": "",
                "top5_preds": [
                    "plotting time series with pandas",
                    "line plots show the trend of a numerical variable over time",
                    "pandas plotting",
                    "line plot with a dataframe",
                    "pandas plotting documentation"
                ]
            },
            {
                "code": "event_counts_df = event_counts.reset_index()\nevent_counts_df.columns = ['contract', 'event', 'count']\nevent_counts_df",
                "true_label": "",
                "top5_preds": [
                    "create a dataframe by joining series by column",
                    "from dictionary to dataframe",
                    "create a one column dataframe with the values of a series",
                    "working with pandas series indexed by datetime",
                    "using pandas"
                ]
            },
            {
                "code": "transfer_count = event_counts_df[event_counts_df['event']=='Transfer'].iloc[0]['count']\n\nsale_auction_cancelled_count = event_counts_df[(event_counts_df['event']=='AuctionCancelled') & \\\n                                             (event_counts_df['contract']=='saleAuction')].iloc[0]['count']\n\nsiring_auction_cancelled_count = event_counts_df[(event_counts_df['event']=='AuctionCancelled') & \\\n                                             (event_counts_df['contract']=='siringAuction')].iloc[0]['count']\n\nsale_auction_created_count = event_counts_df[(event_counts_df['event']=='AuctionCreated') & \\\n                                             (event_counts_df['contract']=='saleAuction')].iloc[0]['count']\n\nsiring_auction_created_count = event_counts_df[(event_counts_df['event']=='AuctionCreated') & \\\n                                             (event_counts_df['contract']=='siringAuction')].iloc[0]['count']\n\nsale_auction_successful_count = event_counts_df[(event_counts_df['event']=='AuctionSuccessful') & \\\n                                             (event_counts_df['contract']=='saleAuction')].iloc[0]['count']\n\nsiring_auction_successful_count = event_counts_df[(event_counts_df['event']=='AuctionSuccessful') & \\\n                                             (event_counts_df['contract']=='siringAuction')].iloc[0]['count']\n\nbirth_count = event_counts_df[(event_counts_df['event']=='Birth')].iloc[0]['count']\n\npregnant_count = event_counts_df[(event_counts_df['event']=='Pregnant')].iloc[0]['count']",
                "true_label": "",
                "top5_preds": [
                    "find data type of each column",
                    "predicting a categorical response",
                    "in pandas",
                    "line plot with a dataframe",
                    "using pandas"
                ]
            },
            {
                "code": "births['midwife_smartcontract'] = births['transaction'].apply(lambda x: eval(x)['to'])",
                "true_label": "",
                "top5_preds": [
                    "from dictionary to dataframe",
                    "linear regression of many variables",
                    "tensorflow + keras",
                    "load table in pandas",
                    "pandas apply"
                ]
            }
        ],
        [
            {
                "code": "import numpy as np\nimport random\nimport cv2\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nfrom scipy.misc import imresize\nfrom utils import load_ubyte\nfrom model import *\n%matplotlib inline",
                "true_label": "",
                "top5_preds": [
                    "polynomial regression with sklearn",
                    "import polynomial features from sklearn",
                    "scipy",
                    "what is scikit learn?",
                    "timing, numpy, plotting"
                ]
            },
            {
                "code": "# Take a look at the data we just loaded:\nprint test_x.shape\nprint test_y.shape\nprint test_x.dtype\nprint test_y.dtype\nprint test_x.max(), test_x.min()\nprint test_y.max(), test_y.min()",
                "true_label": "",
                "top5_preds": [
                    "numpy",
                    "import polynomial features from sklearn",
                    "importing data with numpy",
                    "scipy",
                    "ridge regression with polynomial features on a grid"
                ]
            },
            {
                "code": "idx = random.randint(0, test_x.shape[0]) # choose a number from 0 to 9999\nplt.imshow(test_x[idx, :, :, 0], cmap='gray') # Display the image, use grayscale colormap because our image is grayscale\nplt.show() # plt requires calling this function to make image actually show up\n\nprint 'This number is: ', test_y[idx, 0] # Print the corresponding label",
                "true_label": "",
                "top5_preds": [
                    "visualize the scatterplot of x",
                    "line plot with a dataframe",
                    "heatmap with time",
                    "visualizing uncertainty",
                    "ridge regression with polynomial features on a grid"
                ]
            },
            {
                "code": "# TODO\ntrain_x, train_y = load_ubyte('train-images-idx3-ubyte', 'train-labels-idx1-ubyte')\nprint train_x.shape\nprint train_y.shape\nprint train_x.dtype\nprint train_y.dtype\nprint train_x.max(), train_x.min()\nprint train_y.max(), train_y.min()\n",
                "true_label": "",
                "top5_preds": [
                    "import polynomial features from sklearn",
                    "numpy",
                    "importing data with numpy",
                    "scipy",
                    "load table in pandas"
                ]
            },
            {
                "code": "def random_shift(input_image):\n    # TODO\n    \n    rows,cols = input_image.shape\n    shift_x = random.randint(0,10)\n    shift_y = random.randint(0,10)\n    M = np.float32([[1,0,shift_x],[0,1,shift_y]])\n    input_image = cv2.warpAffine(input_image,M,(cols,rows))\n    \n    return input_image\n\ninput_image = test_x[random.randint(0, 10000), :, :, 0] # select a random image\noutput_image = random_shift(input_image)\nplt.subplot(211)\nplt.imshow(input_image, cmap='gray')\nplt.subplot(212)\nplt.imshow(output_image, cmap='gray')\nplt.show()",
                "true_label": "",
                "top5_preds": [
                    "read images point",
                    "read the dataset point",
                    "compute covariance matrix",
                    "import the dataset",
                    "stitching images along a minimum cost path"
                ]
            },
            {
                "code": "def random_rotate(input_image):\n    # TODO\n    \n    rows,cols = input_image.shape\n\n    rotate_degree = random.randint(0, 40)\n    M = cv2.getRotationMatrix2D((cols/2,rows/2),rotate_degree,1)\n    input_image = cv2.warpAffine(input_image,M,(cols,rows))\n    \n    return input_image\n\ninput_image = test_x[random.randint(0, 10000), :, :, 0] # select a random image\noutput_image = random_rotate(input_image)\nplt.subplot(211)\nplt.imshow(input_image, cmap='gray')\nplt.subplot(212)\nplt.imshow(output_image, cmap='gray')\nplt.show()",
                "true_label": "",
                "top5_preds": [
                    "read images point",
                    "compute covariance matrix",
                    "crop the images",
                    "plot roc curve",
                    "read the dataset"
                ]
            },
            {
                "code": "def add_noise(input_image):\n    # Get image height and width:\n    height, width = input_image.shape\n    \n    # Convert the image to float32 to allow arithmetic operations:\n    input_image = input_image.astype(np.float32)\n    \n    # Generate a matrix of random number, the random numbers were drawn from normal distribution with mean and std:\n    mean = 0.0\n    std = 50.0\n    noise = np.random.normal(mean, std, [height, width])\n    \n    # Add noise to the image:\n    input_image += noise\n    \n    # Cut off out-of-range values by setting them equal to the bound:\n    input_image[input_image < 0] = 0.0\n    input_image[input_image > 255] = 255.0\n    \n    # Convert back to uint8 to allow displaying:\n    input_image = input_image.astype(np.uint8)\n    return input_image\n\ninput_image = test_x[random.randint(0, 10000), :, :, 0]\noutput_image = add_noise(input_image)\nplt.subplot(211)\nplt.imshow(input_image, cmap='gray')\nplt.subplot(212)\nplt.imshow(output_image, cmap='gray')\nplt.show()",
                "true_label": "",
                "top5_preds": [
                    "implement the tanh activation function",
                    "draw",
                    "traffic sign classification with keras",
                    "filling the mask",
                    "create an array of linearly spaced points"
                ]
            },
            {
                "code": "def invert_image(input_image):\n    return 255 - input_image\n\ninput_image = test_x[random.randint(0, 10000), :, :, 0]\noutput_image = random_shift(input_image)\noutput_image = random_rotate(output_image)\noutput_image = add_noise(output_image)\noutput_image = invert_image(output_image)\n\nplt.subplot(211)\nplt.imshow(input_image, cmap='gray')\nplt.subplot(212)\nplt.imshow(output_image, cmap='gray')\nplt.show()",
                "true_label": "",
                "top5_preds": [
                    "visualizing uncertainty",
                    "predicting a categorical response",
                    "use numpy to generate a random number",
                    "scikit image panorama",
                    "pick a random integer using the random module"
                ]
            },
            {
                "code": "def data_augmentation(input_images, input_labels, output_size):\n    num, height, width, ch = input_images.shape\n    output_images = np.zeros([output_size, height, width, 1], dtype=np.uint8)\n    output_labels = np.zeros([output_size, 1], dtype=np.float32)\n    for i in xrange(output_size):\n        idx = random.randint(0, num)\n        img = input_images[idx, :, :, 0]\n        img = random_shift(img)\n        img = random_rotate(img)\n        img = add_noise(img)\n        img = invert_image(img)\n        output_images[i, :, :, 0] = img\n        output_labels[i, 0] = input_labels[idx, 0]\n    return output_images, output_labels\n\ntraining_size = 8000\naug_train_x, aug_train_y = data_augmentation(train_x, train_y, training_size)\n\ntesting_size = 2000\naug_test_x, aug_test_y = data_augmentation(test_x, test_y, testing_size)",
                "true_label": "",
                "top5_preds": [
                    "build a vector of prediction from the trained model",
                    "transform categorical data into binary features",
                    "making predictions for the testing data",
                    "setup, prerequisites, and image classification",
                    "read the dataset"
                ]
            },
            {
                "code": "def normalize(x):\n    # First convert x into float:\n    ret = x.astype(np.float32)\n    \n    # We know the min value is 0 and the max value for x is 255,\n    # so the calculation is straightforward:\n    return ret / 255.0 * 2.0 - 1.0\n\naug_train_x = normalize(aug_train_x)\naug_test_x = normalize(aug_test_x)\n\n# Check the max and min values:\nprint aug_train_x.max(), aug_train_x.min()\nprint aug_test_x.max(), aug_test_x.min()",
                "true_label": "",
                "top5_preds": [
                    "normalize the data point",
                    "resampling and frequency conversion",
                    "normalize the features",
                    "normalize using beta functions",
                    "normalize"
                ]
            },
            {
                "code": "def convert_to_one_hot(y, num_class):\n    num = y.shape[0]\n    ret = np.zeros([num, num_class])\n    for i in xrange(num):\n        ret[i, int(y[i, 0])] = 1\n    return ret\n\none_hot_train_y = convert_to_one_hot(aug_train_y, 10)\none_hot_test_y = convert_to_one_hot(aug_test_y, 10)",
                "true_label": "",
                "top5_preds": [
                    "convert list to numpy array",
                    "load the kmeans class from sklearn cluster",
                    "using the classify function",
                    "transform categorical data into binary features",
                    "the scikit learn interface"
                ]
            }
        ],
        [
            {
                "code": "# load some key packages:\nimport numpy as np                # a numerical package\nimport pandas as pd               # a data analysis package\nimport matplotlib.pyplot as plt   # a scientific plotting package\n\n# to display the plots in the same document\n%matplotlib inline",
                "true_label": "",
                "top5_preds": [
                    "import polynomial features from sklearn",
                    "importing data with numpy",
                    "setup and re introduction to python",
                    "timing, numpy, plotting",
                    "load table in pandas"
                ]
            },
            {
                "code": "# define an array of points (start, end, by)\nx = np.arange(0,6*np.pi,0.1)\n\n# check the array\nprint(x)",
                "true_label": "",
                "top5_preds": [
                    "create an array of linearly spaced points",
                    "equally spaced numbers on a grid",
                    "numpy point",
                    "ridge regression with polynomial features on a grid",
                    "fit a polynomial"
                ]
            },
            {
                "code": "# plot the sin of these points\nplt.plot(x, np.sin(x), 'blue')\n\n# plot the cos of these points\nplt.plot(x, np.cos(x),'red')\n\n# show that plot below\nplt.show()",
                "true_label": "",
                "top5_preds": [
                    "plot using matplotlib",
                    "line plot with a dataframe",
                    "matplotlib",
                    "plotting in python",
                    "create an array of linearly spaced points"
                ]
            },
            {
                "code": "# load the netcdf-handling package:\nimport xarray as xr\n\n# from THREDDS server. \ndata_url = 'http://hydromet-thredds.princeton.edu:9000/thredds/dodsC/MonitoringStations/butler.nc'\n\n# open the file and assign it the name: ds\nds = xr.open_dataset(data_url)\n\n# check it out\nprint(ds)",
                "true_label": "",
                "top5_preds": [
                    "helpers to read in dataset",
                    "importing data with numpy",
                    "read the dataset",
                    "import polynomial features from sklearn",
                    "load table in pandas"
                ]
            },
            {
                "code": "variable = 'AirTC_Avg'\n\n# check it out\nprint(ds[variable])",
                "true_label": "",
                "top5_preds": [
                    "loading json in python",
                    "data given as a dictionary",
                    "helpers to read in dataset",
                    "importing data with numpy",
                    "convert categorical variables"
                ]
            },
            {
                "code": "# plot all the data\nds[variable].plot()",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "pandas plotting",
                    "plot multidimensional data in two dimensions",
                    "using a dataframe and matplotlib commands",
                    "plot using pandas plotting"
                ]
            },
            {
                "code": "# convert to a pandas object and then to a dataframe\ndf = ds[variable].to_pandas().to_frame(name=variable)\n\n# get a summary of the data including the percentiles listed\ndf.describe(percentiles=[.1,.25,.5,.75,.9])",
                "true_label": "",
                "top5_preds": [
                    "pandas plotting",
                    "dataframe methods",
                    "pandas introduction",
                    "from dictionary to dataframe",
                    "line plot with a dataframe"
                ]
            },
            {
                "code": "df['2012-06-03'].boxplot(column=variable, by=df['2012-06-03'].index.hour)\n# set the labels\nplt.xlabel(' ')\nplt.ylabel('Temperature [C]')\nplt.title('Monthly boxplots')\nplt.suptitle('')\n\nplt.show()",
                "true_label": "",
                "top5_preds": [
                    "ploting out data with box plots",
                    "plotting time series with pandas",
                    "line plot with a dataframe",
                    "plot using pandas plotting",
                    "create box plots"
                ]
            },
            {
                "code": "# create a box plot\ndf.boxplot(column=variable, by=df.index.month, whis= [10, 90], sym='')\n\n# set the labels\nplt.xlabel('month')\nplt.ylabel('Temperature [C]')\nplt.title('Monthly boxplots')\nplt.suptitle('')\n\nplt.show()",
                "true_label": "",
                "top5_preds": [
                    "ploting out data with box plots",
                    "plot using pandas plotting",
                    "line plot with a dataframe",
                    "plotting time series with pandas",
                    "create box plots"
                ]
            },
            {
                "code": "# choose a date period (such as a month)\na_month = ds[variable].sel(time='2016-01')\n\n# or grab the range between two specific days\na_week =  ds[variable].sel(time=slice('2015-07-06', '2015-07-13'))\n\n# Create a figure with two subplots \nfig, axes = plt.subplots(ncols=2, nrows=1, figsize=(14,4))\n\n# plot the month of data in the first subplot\na_month.plot(ax=axes[0])\naxes[0].set_title('A month')\n\n# plot the week of data in the first subplot\na_week.plot(ax=axes[1])\naxes[1].set_title('A week')\n\nplt.show()",
                "true_label": "",
                "top5_preds": [
                    "plotting time series with pandas",
                    "using a dataframe and matplotlib commands",
                    "working with pandas series indexed by datetime",
                    "integrating datetime tools with pandas for time series",
                    "plot using pandas plotting"
                ]
            },
            {
                "code": "# slice the dataset by time and grab variables of interest\nvars_for_a_week = ds[['Rain_mm_3_Tot', 'VW']].sel(time=slice('2015-07-06', '2015-07-13'))\nprint(vars_for_a_week)",
                "true_label": "",
                "top5_preds": [
                    "integrating datetime tools with pandas for time series",
                    "plotting time series with pandas",
                    "line plots show the trend of a numerical variable over time",
                    "ploting out data with box plots",
                    "fit a polynomial"
                ]
            },
            {
                "code": "# convert to pandas.dataframe\ndf = vars_for_a_week.to_dataframe()[['Rain_mm_3_Tot', 'VW']]\ndf.head()",
                "true_label": "",
                "top5_preds": [
                    "from dictionary to dataframe",
                    "create dataframe with given values",
                    "dataframe methods",
                    "using a dataframe and matplotlib commands",
                    "load table in pandas"
                ]
            },
            {
                "code": "# plot on left and right axes\ndf.plot(secondary_y='Rain_mm_3_Tot', figsize=(12,4))\n\n# by setting the limits as (max, min) we flip the axis so that rain comes down from the top\nplt.ylim(12,0)\nplt.show()",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "plot using matplotlib",
                    "matplotlib",
                    "plot using pandas plotting",
                    "ploting out data with box plots"
                ]
            },
            {
                "code": "data_url = 'http://hydromet-thredds.princeton.edu:9000/thredds/dodsC/MonitoringStations/broadmead.nc'\nds = xr.open_dataset(data_url)\nbroadmead_rain_ds = ds[['Rain_1_mm_Tot', 'Rain_2_mm_Tot']].sel(time=slice('2016-02-23', '2016-02-26'))\nbroadmead_rain = broadmead_rain_ds.to_dataframe().drop(['lat','lon','station_name'], axis=1)\nds.close()",
                "true_label": "",
                "top5_preds": [
                    "importing data with numpy",
                    "importing data with pandas",
                    "load table in pandas",
                    "integrating datetime tools with pandas for time series",
                    "reading in and sampling from the data"
                ]
            },
            {
                "code": "data_url = 'http://hydromet-thredds.princeton.edu:9000/thredds/dodsC/MonitoringStations/washington_lake.nc'\nds = xr.open_dataset(data_url)\nwashington_lake_level_ds = ds['Lvl_cm_Avg'].sel(time=slice('2016-02-23', '2016-02-26'))\nwashington_lake_level = washington_lake_level_ds.to_dataframe().drop(['lat','lon','station_name'], axis=1)\nds.close()",
                "true_label": "",
                "top5_preds": [
                    "importing data with pandas",
                    "integrating datetime tools with pandas for time series",
                    "working with pandas series indexed by datetime",
                    "reading in and sampling from the data",
                    "importing data with numpy"
                ]
            },
            {
                "code": "data_url = 'http://hydromet-thredds.princeton.edu:9000/thredds/dodsC/MonitoringStations/washington_up.nc'\nds = xr.open_dataset(data_url)\nwashington_up_level_ds = ds['Corrected_cm_Avg'].sel(time=slice('2016-02-23', '2016-02-26'))\nwashington_up_level = washington_up_level_ds.to_dataframe().drop(['lat','lon','station_name'], axis=1)\nds.close()",
                "true_label": "",
                "top5_preds": [
                    "integrating datetime tools with pandas for time series",
                    "importing data with pandas",
                    "importing data with numpy",
                    "reading in and sampling from the data",
                    "working with pandas series indexed by datetime"
                ]
            },
            {
                "code": "data_url = 'http://hydromet-thredds.princeton.edu:9000/thredds/dodsC/MonitoringStations/washington_down.nc'\nds = xr.open_dataset(data_url)\nwashington_down_level_ds = ds['Corrected_cm_Avg'].sel(time=slice('2016-02-23', '2016-02-26'))\nwashington_down_level = washington_down_level_ds.to_dataframe().drop(['lat','lon','station_name'], axis=1)\nds.close()",
                "true_label": "",
                "top5_preds": [
                    "integrating datetime tools with pandas for time series",
                    "importing data with pandas",
                    "importing data with numpy",
                    "reading in and sampling from the data",
                    "working with pandas series indexed by datetime"
                ]
            },
            {
                "code": "washington_up_storm = washington_up_level-washington_up_level.iloc[0,0]\nwashington_down_storm = washington_down_level-washington_down_level.iloc[0,0]\nwashington_lake_storm = washington_lake_level-washington_lake_level.iloc[0,0]",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "line plots show the trend of a numerical variable over time",
                    "analytical tools for seismic data",
                    "calculate the mean windspeed for each month in the dataset",
                    "create a one column dataframe with the values of a series"
                ]
            },
            {
                "code": "# create a figure with 2 subplots \nfig, axes = plt.subplots(ncols=1, nrows=2, figsize=(12,10), sharex=True)\n\nbroadmead_rain.plot(ax=axes[0], linewidth=2)\nwashington_up_storm.plot(ax=axes[1], linewidth=2)\nwashington_down_storm.plot(ax=axes[1], linewidth=2)\nwashington_lake_storm.plot(ax=axes[1], linewidth=2)\n\n# set titles and legends\nplt.suptitle('Timing of Rainfall and Stream Depth peak during February Storm', fontsize=18)\naxes[0].set_title('Rainfall (mm)')\naxes[0].set_ylabel('5 min rain (mm)')\n\naxes[1].set_title('Stream level minus base level (cm)')\naxes[1].legend(['upstream','downstream', 'lake'])\naxes[1].set_ylabel('Storm depth (cm)')\naxes[1].set_xlabel('Time in UTC')\n\n# save fig to current folder\nplt.savefig('Rain and discharge.png')\nplt.show()",
                "true_label": "",
                "top5_preds": [
                    "matplotlib",
                    "pandas plotting",
                    "line plot with a dataframe",
                    "equally spaced numbers on a grid",
                    "plot using matplotlib"
                ]
            },
            {
                "code": "def select(site, var, start, end):\n    \"\"\"\n    Select data from netcdf file hosted on the Princeton Hydrometeorology thredds server\n\n    Parameters\n    -----------\n    site: one of the monitoring stations in quotes ('broadmead')\n    var: one of the variables from this site in quotes ('Rain_1_mm_Tot'), \n         or a list of variables(['Hc', 'Hs'])\n    start: starting time for data.frame ('YYYY-MM-DD hh:mm:ss')\n    end: ending time for data.frame ('YYYY-MM-DD hh:mm:ss')\n\n    Returns\n    -------\n    df: pandas.DataFrame object with time index and the variable(s) as the column(s)\n    \"\"\"\n\n    import xarray as xr\n\n    data_url = 'http://hydromet-thredds.princeton.edu:9000/thredds/dodsC/MonitoringStations/'+ site+'.nc'\n    ds = xr.open_dataset(data_url)\n    _ds = ds[var].sel(time=slice(start, end))\n    df = _ds.to_dataframe().drop(['lat','lon','station_name'], axis=1)\n    ds.close()\n    return df",
                "true_label": "",
                "top5_preds": [
                    "select the data",
                    "read the dataset",
                    "read the dataset point",
                    "import the dataset",
                    "read data point"
                ]
            },
            {
                "code": "broadmead_rain = select('broadmead', ['Rain_1_mm_Tot','Rain_2_mm_Tot'], '2016-02-23', '2016-02-26 12:00')\nwashington_lake_level = select('washington_lake', 'Lvl_cm_Avg', '2016-02-23', '2016-02-26 12:00')\nwashington_down_level = select('washington_down', 'Corrected_cm_Avg', '2016-02-23', '2016-02-26 12:00:00')\nwashington_up_level = select('washington_up', 'Corrected_cm_Avg', '2016-02-23', '2016-02-26 12:00')",
                "true_label": "",
                "top5_preds": [
                    "importing data with pandas",
                    "load table in pandas",
                    "integrating datetime tools with pandas for time series",
                    "working with pandas series indexed by datetime",
                    "using pandas"
                ]
            }
        ],
        [
            {
                "code": "# This line configures matplotlib to show figures embedded in the notebook\n%matplotlib inline",
                "true_label": "",
                "top5_preds": [
                    "matplotlib",
                    "plot using matplotlib",
                    "ipython / jupyter environment",
                    "trend lines in pyplot",
                    "using a dataframe and matplotlib commands"
                ]
            },
            {
                "code": "f = open('data/phl_temperature_noheaders.txt','r')\nfor i in range(10):\n    line = f.readline()\n    print(line)",
                "true_label": "",
                "top5_preds": [
                    "read numbers until and print their mean and standard deviation without using a list",
                    "read text file point",
                    "getting data from the internet",
                    "reading in the files",
                    "reading and writing csv files"
                ]
            },
            {
                "code": "for i in range(10):\n    line = f.readline().strip()\n    print(line)\nf.close()",
                "true_label": "",
                "top5_preds": [
                    "read numbers until and print their mean and standard deviation without using a list",
                    "read text file point",
                    "getting data from the internet",
                    "reading in the files",
                    "file io"
                ]
            },
            {
                "code": "import numpy \n\n# Open the file \nf = open('data/phl_temperature_noheaders.txt','r')\n\n# Read all the lines into a list. Each line will be one entry in the list\ncontent = f.readlines()\n\n# Close the file since we do not need it anymore \nf.close()\n\n# Loop through and convert the string content to numbers\ndata = []\nfor i in content:\n    a = []\n    for j in i.split():\n        a.append(int(j))\n    data.append(a)\n\n# Print some stuff\ndata = numpy.array(data)\nprint(type(data))\nprint(data.shape)\nprint(data[0])",
                "true_label": "",
                "top5_preds": [
                    "read numbers until and print their mean and standard deviation without using a list",
                    "sum all the numbers in a list",
                    "convert list to numpy array",
                    "reading in the files",
                    "read text file point"
                ]
            }
        ],
        [
            {
                "code": "# %matplotlib notebook\n# %matplotlib tk\n%matplotlib inline",
                "true_label": "",
                "top5_preds": [
                    "plot using matplotlib",
                    "plotting in python",
                    "trend lines in pyplot",
                    "matplotlib",
                    "plotting time series with pandas"
                ]
            },
            {
                "code": "import matplotlib.pyplot as plt\nimport matplotlib as mpl\n\n# # increase default resolution of figures\n# mpl.rcParams['figure.dpi'] = 110\n\nimport numpy as np\nimport pandas as pd\n\nimport os",
                "true_label": "",
                "top5_preds": [
                    "how to change the size of a plot",
                    "equally spaced numbers on a grid",
                    "pandas plotting",
                    "matplotlib",
                    "optimal value of k for dataset"
                ]
            },
            {
                "code": "anscombe = pd.read_csv('data/anscombe.csv')\nanscombe.mean()",
                "true_label": "",
                "top5_preds": [
                    "calculating the mean of a vector with nans",
                    "read numbers until and print their mean and standard deviation without using a list",
                    "the mean",
                    "line plots show the trend of a numerical variable over time",
                    "convert data from string to float"
                ]
            },
            {
                "code": "anscombe.std()",
                "true_label": "",
                "top5_preds": [
                    "line plots show the trend of a numerical variable over time",
                    "integrating datetime tools with pandas for time series",
                    "predicting a categorical response",
                    "credible interval vs confidence interval",
                    "predicting a continuous response using linear regression"
                ]
            },
            {
                "code": "# create 500 samples from 0 to 1, like it is 1 second sampled with 500 Hz frequency\nt = np.linspace(0,1,500)\n# create a sine wave with frequency 5 Hz\nsignal = np.sin(t*2*np.pi*5)\nplt.plot(signal)",
                "true_label": "",
                "top5_preds": [
                    "create an array of linearly spaced points",
                    "resampling and frequency conversion",
                    "line plots show the trend of a numerical variable over time",
                    "pi by means of the arithmetic geometric mean",
                    "likelihood of the binomial distribution"
                ]
            },
            {
                "code": "# iterating through groupby object and plotting each group\nfor name, data in iris.groupby('species'):\n    plt.plot(data['sepal length'], data['sepal width'], 'o', label=name)\n    \n# show legend\nplt.legend()",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "equally spaced numbers on a grid",
                    "plotting data",
                    "ploting out data with box plots",
                    "plot the data"
                ]
            },
            {
                "code": "random_points = np.random.randn(1000,2)\nplt.hist(random_points[:,0]);",
                "true_label": "",
                "top5_preds": [
                    "line plots show the trend of a numerical variable over time",
                    "plotting time series with pandas",
                    "create an array of linearly spaced points",
                    "ploting out data with box plots",
                    "trend lines in pyplot"
                ]
            },
            {
                "code": "plt.hist(random_points[:,0],bins=50);",
                "true_label": "",
                "top5_preds": [
                    "ploting out data with box plots",
                    "line plots show the trend of a numerical variable over time",
                    "plotting time series with pandas",
                    "create an array of linearly spaced points",
                    "line plot with a dataframe"
                ]
            },
            {
                "code": "plt.hist(random_points,20);",
                "true_label": "",
                "top5_preds": [
                    "line plots show the trend of a numerical variable over time",
                    "ploting out data with box plots",
                    "plotting time series with pandas",
                    "create an array of linearly spaced points",
                    "trend lines in pyplot"
                ]
            },
            {
                "code": "plt.bar([0,1,2,3], [10,11,12,13])",
                "true_label": "",
                "top5_preds": [
                    "create a bar chart",
                    "equally spaced numbers on a grid",
                    "trend lines in pyplot",
                    "plotting in python",
                    "plot using matplotlib"
                ]
            },
            {
                "code": "plt.bar([0,1,2,3], [10,11,12,13], yerr=[1,2,1,3])",
                "true_label": "",
                "top5_preds": [
                    "ridge regression with one predictor on a grid",
                    "create a bar chart",
                    "ridge regression with polynomial features on a grid",
                    "matplotlib",
                    "line plots show the trend of a numerical variable over time"
                ]
            },
            {
                "code": "plt.bar(range(3),iris.groupby('species')['sepal length'].mean(),\n        yerr=iris.groupby('species')['sepal length'].std())",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "plotting data",
                    "line plots show the trend of a numerical variable over time",
                    "create an array of linearly spaced points",
                    "error plots with base 2"
                ]
            },
            {
                "code": "anscombe = pd.read_csv('data/anscombe.csv')\nanscombe",
                "true_label": "",
                "top5_preds": [
                    "importing data with numpy",
                    "loading a csv into a dataframe",
                    "importing data with pandas",
                    "load table in pandas",
                    "convert date to datetime format"
                ]
            },
            {
                "code": "plt.bar(range(4),anscombe[['y1','y2','y3','y4']].mean(),\n        yerr=anscombe[['y1','y2','y3','y4']].std())",
                "true_label": "",
                "top5_preds": [
                    "line plots show the trend of a numerical variable over time",
                    "ridge regression with one predictor on a grid",
                    "ridge regression with polynomial features on a grid",
                    "line plot with a dataframe",
                    "create a bar chart"
                ]
            },
            {
                "code": "plt.boxplot(anscombe[['y1','y2','y3','y4']].values);",
                "true_label": "",
                "top5_preds": [
                    "ploting out data with box plots",
                    "create a box plot",
                    "create box plots",
                    "box plot",
                    "ridge regression with one predictor on a grid"
                ]
            },
            {
                "code": "plt.plot(t, signal, linestyle='dotted', linewidth=2.5, color='green')",
                "true_label": "",
                "top5_preds": [
                    "line plots show the trend of a numerical variable over time",
                    "equally spaced numbers on a grid",
                    "line plot with a dataframe",
                    "trend lines in pyplot",
                    "create an array of linearly spaced points"
                ]
            },
            {
                "code": "# -- is for dashed, 'r' for red\nplt.plot(t, signal, '--r')",
                "true_label": "",
                "top5_preds": [
                    "line plots show the trend of a numerical variable over time",
                    "plot using matplotlib",
                    "how to change the color of a plot",
                    "plotting in python",
                    "trend lines in pyplot"
                ]
            },
            {
                "code": "plt.plot(t, signal)\nplt.plot(t+1, signal+1)\nplt.plot(t, signal+2)",
                "true_label": "",
                "top5_preds": [
                    "line plots show the trend of a numerical variable over time",
                    "plotting in python",
                    "plotting time series with pandas",
                    "plot using matplotlib",
                    "line plot with a dataframe"
                ]
            },
            {
                "code": "# creare an array with 100 random points (normal distribution)\nrandom_points = np.random.randn(100)\nplt.plot(random_points)",
                "true_label": "",
                "top5_preds": [
                    "create an array of linearly spaced points",
                    "numpy point",
                    "use numpy to generate a random number",
                    "line plot with a dataframe",
                    "use numpy to generate an array of random numbers sampled from a standard normal distribution"
                ]
            },
            {
                "code": "plt.plot(random_points, linestyle='none', marker='o')",
                "true_label": "",
                "top5_preds": [
                    "create an array of linearly spaced points",
                    "equally spaced numbers on a grid",
                    "ploting out data with box plots",
                    "ridge regression with polynomial features on a grid",
                    "line plot with a dataframe"
                ]
            },
            {
                "code": "# random points 100 by 2 array\nrandom_points = np.random.randn(100,2)\n# plot first column as X and second as Y\nplt.plot(random_points[:,0],random_points[:,1],linestyle='',marker='o')",
                "true_label": "",
                "top5_preds": [
                    "create an array of linearly spaced points",
                    "line plot with a dataframe",
                    "numpy point",
                    "equally spaced numbers on a grid",
                    "ridge regression with polynomial features on a grid"
                ]
            },
            {
                "code": "plt.scatter(random_points[:,0],random_points[:,1])",
                "true_label": "",
                "top5_preds": [
                    "create an array of linearly spaced points",
                    "equally spaced numbers on a grid",
                    "create a scatter plot",
                    "ploting out data with box plots",
                    "timing, numpy, plotting"
                ]
            },
            {
                "code": "iris = pd.read_csv(os.path.join('data','iris.csv'))\niris.head()",
                "true_label": "",
                "top5_preds": [
                    "loading a csv into a dataframe",
                    "importing data with pandas",
                    "load table in pandas",
                    "importing data with numpy",
                    "line plot with a dataframe"
                ]
            },
            {
                "code": "plt.scatter(iris['sepal length'], iris['sepal width'])",
                "true_label": "",
                "top5_preds": [
                    "equally spaced numbers on a grid",
                    "create an array of linearly spaced points",
                    "plot multidimensional data in two dimensions",
                    "plotting data",
                    "line plot with a dataframe"
                ]
            },
            {
                "code": "species_color_mapping = {'setosa':'blue', 'versicolor':'black', 'virginica':'red'}\nspecies_color_mapping",
                "true_label": "",
                "top5_preds": [
                    "import polynomial features from sklearn",
                    "postgres sql lab",
                    "converting symbols to identifiers",
                    "loading json in python",
                    "nltk to recognize a book"
                ]
            },
            {
                "code": "iris['color'] = iris['species'].replace(species_color_mapping)\niris.head()",
                "true_label": "",
                "top5_preds": [
                    "create a one column dataframe with the values of a series",
                    "importing data with numpy",
                    "using a dataframe and matplotlib commands",
                    "line plot with a dataframe",
                    "create a dataframe by joining series by column"
                ]
            },
            {
                "code": "plt.scatter(iris['sepal length'], iris['sepal width'], color=iris['color'])",
                "true_label": "",
                "top5_preds": [
                    "equally spaced numbers on a grid",
                    "create an array of linearly spaced points",
                    "line plot with a dataframe",
                    "plotting data",
                    "plot multidimensional data in two dimensions"
                ]
            },
            {
                "code": "plt.scatter(iris['sepal length'], iris['sepal width'], c=iris['petal length'])",
                "true_label": "",
                "top5_preds": [
                    "equally spaced numbers on a grid",
                    "create an array of linearly spaced points",
                    "plot using matplotlib",
                    "line plot with a dataframe",
                    "plotting data"
                ]
            },
            {
                "code": "plt.style.available",
                "true_label": "",
                "top5_preds": [
                    "line plots show the trend of a numerical variable over time",
                    "trend lines in pyplot",
                    "plotting time series with pandas",
                    "line plot with a dataframe",
                    "equally spaced numbers on a grid"
                ]
            },
            {
                "code": "plt.style.use('seaborn-poster')\nplt.boxplot(anscombe[['y1','y2','y3','y4']].values);",
                "true_label": "",
                "top5_preds": [
                    "plot using matplotlib",
                    "ploting out data with box plots",
                    "plot using pandas plotting",
                    "box plot",
                    "plotting time series with pandas"
                ]
            },
            {
                "code": "# recover default parameters (simple update of the dictionary)\nmpl.rcParams.update(mpl.rcParamsDefault)\nplt.boxplot(anscombe[['y1','y2','y3','y4']].values);",
                "true_label": "",
                "top5_preds": [
                    "plot using matplotlib",
                    "matplotlib",
                    "plot using pandas plotting",
                    "plotting",
                    "plotting in python"
                ]
            },
            {
                "code": "grid = np.random.randn(5, 5)\ngrid",
                "true_label": "",
                "top5_preds": [
                    "equally spaced numbers on a grid",
                    "create an array of linearly spaced points",
                    "ridge regression with polynomial features on a grid",
                    "ridge regression with one predictor on a grid",
                    "numpy"
                ]
            },
            {
                "code": "plt.imshow(grid)\nplt.colorbar()",
                "true_label": "",
                "top5_preds": [
                    "equally spaced numbers on a grid",
                    "line plot with a dataframe",
                    "ridge regression with polynomial features on a grid",
                    "scikit image panorama",
                    "icon arrays"
                ]
            },
            {
                "code": "births = pd.read_csv(os.path.join('data','births.csv'))\nbirths.head()",
                "true_label": "",
                "top5_preds": [
                    "loading a csv into a dataframe",
                    "load table in pandas",
                    "importing data with pandas",
                    "importing data with numpy",
                    "convert date to datetime format"
                ]
            },
            {
                "code": "births_year_month = births.pivot_table(index='year',columns='month',values='births',aggfunc=np.sum)\nbirths_year_month.head()",
                "true_label": "",
                "top5_preds": [
                    "create a one column dataframe with the values of a series",
                    "load table in pandas",
                    "create a dataframe by joining series by column",
                    "using pandas",
                    "working with pandas series indexed by datetime"
                ]
            },
            {
                "code": "plt.imshow(births_year_month, interpolation=None, cmap='Reds')\nplt.colorbar()\n\nplt.xticks(range(len(births_year_month.columns)), \n           births_year_month.columns)\n\nplt.yticks(range(len(births_year_month.index)), \n           births_year_month.index)\n\nplt.xlabel('Month')\nplt.ylabel('Year')\nplt.title('Total births for each month from ' + str(births_year_month.index[0]) + \n          ' to ' + str(births_year_month.index[-1]));",
                "true_label": "",
                "top5_preds": [
                    "plotting time series with pandas",
                    "line plot with a dataframe",
                    "line plots show the trend of a numerical variable over time",
                    "ploting out data with box plots",
                    "formatting datetimes as strings"
                ]
            },
            {
                "code": "births_year_gender = births.pivot_table(values='births', index='year', columns='gender', aggfunc=np.sum)\nbirths_year_gender.head()",
                "true_label": "",
                "top5_preds": [
                    "create a one column dataframe with the values of a series",
                    "create a dataframe by joining series by column",
                    "dataframe methods",
                    "using pandas",
                    "load table in pandas"
                ]
            },
            {
                "code": "births_year_gender.plot()",
                "true_label": "",
                "top5_preds": [
                    "plotting time series with pandas",
                    "line plots show the trend of a numerical variable over time",
                    "integrating datetime tools with pandas for time series",
                    "line plot with a dataframe",
                    "plot using pandas plotting"
                ]
            },
            {
                "code": "births_year_gender.plot()\nplt.title('Change of total yearly births for males and females')\nplt.ylabel('Total births')",
                "true_label": "",
                "top5_preds": [
                    "line plots show the trend of a numerical variable over time",
                    "line plot with a dataframe",
                    "plotting time series with pandas",
                    "plot using pandas plotting",
                    "pandas plotting"
                ]
            },
            {
                "code": "iris.boxplot();",
                "true_label": "",
                "top5_preds": [
                    "ploting out data with box plots",
                    "box plot",
                    "create a box plot",
                    "create box plots",
                    "integrating datetime tools with pandas for time series"
                ]
            },
            {
                "code": "iris.boxplot(by='species');",
                "true_label": "",
                "top5_preds": [
                    "ploting out data with box plots",
                    "plotting time series with pandas",
                    "box plot",
                    "line plot with a dataframe",
                    "create box plots"
                ]
            },
            {
                "code": "# create 10 sine waves with added noise\nx = np.linspace(0, 15, 31)\ndata = np.sin(x) + np.random.rand(10, 31) + np.random.randn(10, 1)\ndata.shape",
                "true_label": "",
                "top5_preds": [
                    "create an array of linearly spaced points",
                    "numpy",
                    "ridge regression with polynomial features on a grid",
                    "ridge regression with one predictor on a grid",
                    "scipy"
                ]
            },
            {
                "code": "plt.plot(data.T,'k',linewidth=1);",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "equally spaced numbers on a grid",
                    "plotting data",
                    "line plots show the trend of a numerical variable over time",
                    "ridge regression with polynomial features on a grid"
                ]
            },
            {
                "code": "# by default it plots means with 95% confidence interval\nsns.tsplot(data=data)",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "line plots show the trend of a numerical variable over time",
                    "trend lines in pyplot",
                    "ploting out data with box plots",
                    "predicting a categorical response"
                ]
            },
            {
                "code": "sns.tsplot(data=data, err_style=\"ci_bars\", interpolate=False)",
                "true_label": "",
                "top5_preds": [
                    "integrating datetime tools with pandas for time series",
                    "plotting time series with pandas",
                    "using a dataframe and matplotlib commands",
                    "line plot with a dataframe",
                    "equally spaced numbers on a grid"
                ]
            },
            {
                "code": "# multiple confidence bands (68% and 95%)\nsns.tsplot(data=data, ci=[68, 95])",
                "true_label": "",
                "top5_preds": [
                    "predicting a categorical response",
                    "line plot with a dataframe",
                    "credible interval vs confidence interval",
                    "ploting out data with box plots",
                    "line plots show the trend of a numerical variable over time"
                ]
            },
            {
                "code": "# you can show each trace\nsns.tsplot(data=data, err_style=\"unit_traces\")",
                "true_label": "",
                "top5_preds": [
                    "line plots show the trend of a numerical variable over time",
                    "plotting time series with pandas",
                    "trend lines in pyplot",
                    "line plot with a dataframe",
                    "formatting datetimes as strings"
                ]
            },
            {
                "code": "# or bootstrapped traces\nsns.tsplot(data=data, err_style=\"boot_traces\", n_boot=100)",
                "true_label": "",
                "top5_preds": [
                    "line plots show the trend of a numerical variable over time",
                    "trend lines in pyplot",
                    "plotting time series with pandas",
                    "using a dataframe and matplotlib commands",
                    "integrating datetime tools with pandas for time series"
                ]
            },
            {
                "code": "sns.boxplot(data=iris, x='species', y='sepal length')",
                "true_label": "",
                "top5_preds": [
                    "ploting out data with box plots",
                    "fit a polynomial",
                    "box plot",
                    "line plot with a dataframe",
                    "equally spaced numbers on a grid"
                ]
            },
            {
                "code": "plt.scatter(iris['sepal length'], iris['sepal width'], c=iris['petal length'], cmap='winter')\nplt.colorbar()",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "equally spaced numbers on a grid",
                    "plot using matplotlib",
                    "heatmap with time",
                    "plotting in python"
                ]
            },
            {
                "code": "plt.scatter(iris['sepal length'], iris['sepal width'], \n            c=iris['petal length'], cmap='winter', s=iris['petal width']*50)",
                "true_label": "",
                "top5_preds": [
                    "equally spaced numbers on a grid",
                    "line plot with a dataframe",
                    "create an array of linearly spaced points",
                    "plotting data",
                    "fit a polynomial"
                ]
            },
            {
                "code": "sns.swarmplot(data=anscombe[['y1','y2','y3','y4']])",
                "true_label": "",
                "top5_preds": [
                    "create an array of linearly spaced points",
                    "line plot with a dataframe",
                    "predicting a continuous response using linear regression",
                    "create a scatter plot",
                    "ridge regression with polynomial features on a grid"
                ]
            },
            {
                "code": "food_df = pd.read_csv('data/Paolo.csv')\n\n## do some cleanup\nfood_df.drop('Unnamed: 0', axis='columns', inplace=True)\nfood_df['cond'].replace({1: 'high vs high', 2: 'low vs low', \n                    3: 'high vs low', 4: 'low vs high'}, inplace=True)\nfood_df['congr'].replace({0: 'same', 1: 'different'}, inplace=True)\nfood_df['session'].replace({0: 'fed', 1: 'hungry'}, inplace=True)\n\nfood_df.head()",
                "true_label": "",
                "top5_preds": [
                    "convert categorical variables",
                    "using pandas",
                    "create dataframe with given values",
                    "dataframe methods",
                    "line plot with a dataframe"
                ]
            },
            {
                "code": "sns.factorplot(data=food_df,x='session',y='rt',kind='point')",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "create a one column dataframe with the values of a series",
                    "using a dataframe and matplotlib commands",
                    "line plots show the trend of a numerical variable over time",
                    "dataframe methods"
                ]
            },
            {
                "code": "sns.factorplot(data=food_df,x='session',y='rt',kind='violin')",
                "true_label": "",
                "top5_preds": [
                    "using a dataframe and matplotlib commands",
                    "create a one column dataframe with the values of a series",
                    "dataframe methods",
                    "line plot with a dataframe",
                    "pandas plotting"
                ]
            },
            {
                "code": "sns.factorplot(data=food_df,x='session',y='rt',kind='violin',col='subj_num')",
                "true_label": "",
                "top5_preds": [
                    "create a one column dataframe with the values of a series",
                    "dataframe methods",
                    "using a dataframe and matplotlib commands",
                    "line plot with a dataframe",
                    "pandas plotting"
                ]
            },
            {
                "code": "sns.factorplot(data=food_df,x='session',y='rt',kind='violin',col='subj_num',row='congr')",
                "true_label": "",
                "top5_preds": [
                    "dataframe methods",
                    "create a one column dataframe with the values of a series",
                    "using a dataframe and matplotlib commands",
                    "line plot with a dataframe",
                    "relationships between dataframes"
                ]
            },
            {
                "code": "sns.factorplot(data=food_df,x='session',y='rt',kind='point',row='subj_num',hue='congr')",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "create a one column dataframe with the values of a series",
                    "dataframe methods",
                    "using a dataframe and matplotlib commands",
                    "pandas plotting"
                ]
            },
            {
                "code": "births_year_month = births_year_month.iloc[:12]",
                "true_label": "",
                "top5_preds": [
                    "convert date to datetime format",
                    "integrating datetime tools with pandas for time series",
                    "transform year column",
                    "plotting time series with pandas",
                    "formatting datetimes as strings"
                ]
            },
            {
                "code": "plt.imshow(births_year_month)\nplt.colorbar()",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "visualize the scatterplot of x",
                    "plotting time series with pandas",
                    "line plots show the trend of a numerical variable over time",
                    "formatting datetimes as strings"
                ]
            },
            {
                "code": "# list supported graphics types\nplt.figure().canvas.get_supported_filetypes()",
                "true_label": "",
                "top5_preds": [
                    "matplotlib",
                    "choosing type of visualization",
                    "reading and writing binary files",
                    "creating basic geometries",
                    "equally spaced numbers on a grid"
                ]
            },
            {
                "code": "plt.violinplot(anscombe[['y1','y2','y3','y4']].values);\n\n# set X axis ticks and labels\n# (in this function you first specify the ticks (the positions of the ticks)\n# and then the labels for these position; we will see wait to tweak\n# this more precisely later)\nplt.xticks([1,2,3,4], ['y1','y2','y3','y4']);\n\n# set Y axis limits\nplt.ylim([0,15]);\n\n# set x label\nplt.ylabel('Values')\n\n# set figure title\nplt.title('Anscombe quartet')\n\n# turn on grid\nplt.grid(True)",
                "true_label": "",
                "top5_preds": [
                    "plot using matplotlib",
                    "plotting in python",
                    "plotting time series with pandas",
                    "equally spaced numbers on a grid",
                    "trend lines in pyplot"
                ]
            },
            {
                "code": "plt.plot(t,signal)",
                "true_label": "",
                "top5_preds": [
                    "plot using matplotlib",
                    "plotting in python",
                    "plotting data",
                    "plotting time series with pandas",
                    "matplotlib"
                ]
            },
            {
                "code": "plt.plot(t,signal,linestyle='dashed')",
                "true_label": "",
                "top5_preds": [
                    "line plots show the trend of a numerical variable over time",
                    "plot using matplotlib",
                    "plotting in python",
                    "line plot with a dataframe",
                    "trend lines in pyplot"
                ]
            },
            {
                "code": "import seaborn as sns",
                "true_label": "",
                "top5_preds": [
                    "use seaborn",
                    "seaborn",
                    "visualizing with seaborn",
                    "formatting datetimes as strings",
                    "fit a polynomial"
                ]
            },
            {
                "code": "sns.stripplot(data=iris, x='species', y='sepal length', jitter=0.1)",
                "true_label": "",
                "top5_preds": [
                    "equally spaced numbers on a grid",
                    "scikit learn",
                    "create an array of linearly spaced points",
                    "fit a logistic regression model using statsmodels using logistic regression formula in patsy",
                    "fit a polynomial"
                ]
            },
            {
                "code": "sns.swarmplot(data=iris, x='species', y='sepal length')",
                "true_label": "",
                "top5_preds": [
                    "create an array of linearly spaced points",
                    "equally spaced numbers on a grid",
                    "fit a polynomial",
                    "plot multidimensional data in two dimensions",
                    "analytical tools for seismic data"
                ]
            },
            {
                "code": "iris.boxplot(column=['petal length', 'petal width'], by='species', grid=False)",
                "true_label": "",
                "top5_preds": [
                    "ploting out data with box plots",
                    "line plot with a dataframe",
                    "box plot",
                    "create box plots",
                    "relationships between dataframes"
                ]
            },
            {
                "code": "plt.plot(random_points, linestyle='none', marker='o')",
                "true_label": "",
                "top5_preds": [
                    "create an array of linearly spaced points",
                    "equally spaced numbers on a grid",
                    "ploting out data with box plots",
                    "ridge regression with polynomial features on a grid",
                    "line plot with a dataframe"
                ]
            }
        ],
        [
            {
                "code": "import json\nimport hashlib\n\ndef hash_function(k):\n    \"\"\"Hashes our transaction\"\"\"\n    if type(k) is not str:\n        k = json.dumps(k, sort_keys=True)\n    \n    return hashlib.sha256(k.encode('utf-8')).hexdigest()\n\n# I tried running this with a simple stirng \"test\" and it failed.",
                "true_label": "",
                "top5_preds": [
                    "data given as a dictionary",
                    "convert a tuple to a string",
                    "convert a tuple to a dictionary",
                    "get a positive integer from a user",
                    "formatting datetimes as strings"
                ]
            },
            {
                "code": "def update_state(transaction, state):\n    state = state.copy()\n    \n    for key in transaction:\n        if key in state.keys():\n            state[key] += transaction[key]\n        else:\n            state[key] = transaction[key]\n    \n    return state\n\n\ndef valid_transaction(transaction, state):\n    \"\"\"A valid transaction must sum to 0\"\"\"\n    \n    if sum(transaction.values()) is not 0:\n        return False\n    \n    for key in transaction.keys():\n        if key in state.keys():\n            account_balance = state[key]\n        else:\n            account_balance = 0\n        \n        if account_balance + transaction[key] < 0:\n            return False\n    \n    return True\n",
                "true_label": "",
                "top5_preds": [
                    "state action value function",
                    "adding a special state",
                    "data given as a dictionary",
                    "integer addition",
                    "script and serialization"
                ]
            },
            {
                "code": "def make_block(transactions, chain):\n    \"\"\"Make a block to go into the chain.\"\"\"\n    parent_hash = chain[-1]['hash']\n    block_number = chain[-1]['contents']['block_number'] + 1\n    \n    block_contents = {\n        'block_number': block_number,\n        'parent_hash': parent_hash,\n        'transaction_count': block_number + 1,\n        'transaction': transactions\n    }\n    \n    return {'hash': hash_function(block_contents), 'contents': block_contents}\n\ndef check_block_hash(block):\n    expected_hash = hash_function(block['contents'])\n    \n    if block['hash'] is not expected_hash:\n        raise\n    return",
                "true_label": "",
                "top5_preds": [
                    "create a graph",
                    "make pipeline",
                    "building the network",
                    "validate the network",
                    "getting data from the internet"
                ]
            },
            {
                "code": "def check_block_validity(block, parent, state):\n    parent_number = parent['contents']['block_number']\n    parent_hash = parent['hash']\n    block_number = block['contents']['block_number']\n    \n    for transaction in block['contents']['transaction']:\n        if valid_transaction(transaction, state):\n            state = update_state(transaction, state)\n        else:\n            raise\n            \n    check_block_hash(block)\n    \n    if block_number is not parent_number + 1:\n        raise\n    \n    if block['contents']['parent_hash'] is not parent_hash:\n        raise\n        \n    return state        ",
                "true_label": "",
                "top5_preds": [
                    "validate the network",
                    "test whether a number is positive",
                    "check for valid times",
                    "check a list is empty or not",
                    "checkpoint"
                ]
            },
            {
                "code": "def check_chain(chain):\n    \"\"\"Check to see that the chain is valid.\"\"\"\n    if type(chain) is str:\n        try:\n            chain = json.loads(chain)\n            assert (type(chain) == list)\n        except ValueError:\n            #string passed was not JSON\n            return False\n    elif type(chain) is not list:\n        return False\n    \n    state = {}\n    \n    for transaction in chain[0]['contents']['transaction']:\n        state = update_state(transaction, state)\n    \n    check_block_hash(chain[0])\n    parent = chain[0]\n    \n    for block in chain[1:]:\n        state = check_block_validity(block, parent, state)\n        parent = block\n        \n    return state",
                "true_label": "",
                "top5_preds": [
                    "validate the network",
                    "download and inspect the twitter samples dataset",
                    "parse time and visibility from json",
                    "test the model for accuracy",
                    "check for valid times"
                ]
            },
            {
                "code": "def add_transaction_to_chain(transaction, state, chain):\n    if valid_transaction(transaction, state):\n        state = update_state(transaction, state)\n    else:\n        raise Exception('Invalid Transaction.')\n        \n    my_block = make_block(state, chain)\n    chain.append(my_block)\n    \n    for transaction in chain:\n        check_chain(transaction)\n        \n    return state, chain",
                "true_label": "",
                "top5_preds": [
                    "adding a special state",
                    "create a filter function point",
                    "validate the network",
                    "the trace object",
                    "to_tuple"
                ]
            },
            {
                "code": "gensis_block = {\n    'hash': hash_function({\n        'block_number': 0,\n        'parent_hash': None,\n        'transaction_count': 1,\n        'transaction': [{'Jasper':10}]\n    }),\n    'contents': {\n        'block_number': 0,\n        'parent_hash': None,\n        'transaction_count': 1,\n        'transaction': [{'Jasper': 10}]\n    }\n}\n\nblock_chain = [gensis_block]\nchain_state = {'Jasper': 10}",
                "true_label": "",
                "top5_preds": [
                    "data given as a dictionary",
                    "getting data from the internet",
                    "get a positive integer from a user",
                    "script and serialization",
                    "postgres sql lab"
                ]
            },
            {
                "code": "chain_state, block_chain = add_transaction_to_chain(transaction={\"Jasper\": -2, 'Kyle':2}, state=chain_state, chain=block_chain)",
                "true_label": "",
                "top5_preds": [
                    "using interact for animation with data",
                    "add edges in graph",
                    "get a positive integer from a user",
                    "data given as a dictionary",
                    "transient simulation"
                ]
            }
        ],
        [
            {
                "code": "from IPython.display import Image\nImage(url=\"https://www.farmingsmarter.com/wp-content/files/2017/07/Rsch-Plot.jpg\", width=1000, height=300)",
                "true_label": "",
                "top5_preds": [
                    "plot using matplotlib",
                    "ipython / jupyter environment",
                    "ipython",
                    "plot using pandas plotting",
                    "pandas plotting"
                ]
            },
            {
                "code": "from IPython.display import Image\nImage(url=\"http://www.farmingsmarter.com/wp-content/uploads/2013/05/farming-smarter-logo-Copy.jpg\", width=1000, height=100)",
                "true_label": "",
                "top5_preds": [
                    "ipython / jupyter environment",
                    "the ipython kernel",
                    "ipython",
                    "plot using matplotlib",
                    "getting data from the internet"
                ]
            },
            {
                "code": "from IPython.display import Image\nImage(url=\"http://www.farmingsmarter.com/wp-content/files/2016/07/ken-hail-sim.jpg\", width=1000, height=300)",
                "true_label": "",
                "top5_preds": [
                    "ipython / jupyter environment",
                    "ipython",
                    "using python, ipython,",
                    "plot using matplotlib",
                    "the ipython kernel"
                ]
            },
            {
                "code": "from IPython.display import Image\nImage(url=\"https://static.producer.com/wp-content/uploads/2019/01/03144338/16_3-col_BJG062415_hailsimchains.jpg\", width=1000, height=100)",
                "true_label": "",
                "top5_preds": [
                    "ipython / jupyter environment",
                    "ipython",
                    "the ipython kernel",
                    "using python, ipython,",
                    "heatmap with time"
                ]
            },
            {
                "code": "from IPython.display import YouTubeVideo\nYouTubeVideo('qg9VAm5ni8E', width=800, height=300)",
                "true_label": "",
                "top5_preds": [
                    "getting data from the internet",
                    "plot using matplotlib",
                    "trend lines in pyplot",
                    "formatting datetimes as strings",
                    "ipython / jupyter environment"
                ]
            },
            {
                "code": "from IPython.display import Image\nImage(url=\"https://i.ytimg.com/vi/Akd7Ycs8f4g/maxresdefault.jpg\", width=600, height=600)",
                "true_label": "",
                "top5_preds": [
                    "ipython / jupyter environment",
                    "plot using matplotlib",
                    "using python, ipython,",
                    "choosing type of visualization",
                    "the ipython kernel"
                ]
            },
            {
                "code": "import matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n\nimg=mpimg.imread('Picture1.png')\nimgplot = plt.imshow(img)                ##PYTHON CODE LATER",
                "true_label": "",
                "top5_preds": [
                    "plot using matplotlib",
                    "scikit image panorama",
                    "matplotlib",
                    "line plot with a dataframe",
                    "plotting in python"
                ]
            },
            {
                "code": "%%html\n    <style>\n        #list {\n            margin: 20px 0;\n            padding: 0;\n        }\n        #list li {\n            list-style: none;\n            margin: 5px 0;\n        }\n\n        .energy {\n            font-family: 'Courier New', Courier, monospace;\n            font-size: 15px;\n        }\n\n        .answerSelect {\n            margin: 10px 10px;\n        }\n\n        .correct {\n            color: green;\n            font-size: 25px;\n            display: none;\n        }\n\n        .wrong {\n            color: red;\n            font-size: 25px;\n            display: none;\n        }\n\n        .ansBtn {\n            cursor: pointer;\n            border: solid black 1px;\n            background: #d3d3d3;\n            padding: 10px 5px;\n            border-radius: 0px;\n            font-family: arial;\n            font-size: 20px;\n        }\n\n        .ansBtn:hover {\n            background: #f3f3f3;\n        }\n    </style>\n    \n    <body>\n    <div style=\"height: 360px\">\n        <ul id=\"list\">\n            <li>\n            <label for=\"q1\">1) There are ______ number of blocks in the simulated hail study experiment.</label>\n                <select name=\"q1\" id=\"q1\" class=\"answerSelect\">\n                    <option value=\"default\" selected>Select an Answer</option>\n                    <option value=\"1\">One</option>\n                    <option value=\"4\">Four</option>\n                    <option value=\"6\">Six</option>\n                    <option value=\"27\">Twenty-Seven</option>\n                </select>\n                <span class=\"correct\" id=\"Q1C\">&#10003</span>\n                <span class=\"wrong\" id=\"Q1W\">&#10007</span>\n            </li>\n            <li>\n            <label for=\"q2\">2) There are ______ number of plots PER BLOCK in the simulated hail study experiment.</label>\n                <select name=\"q2\" id=\"q2\" class=\"answerSelect\">\n                    <option value=\"default\" selected>Select an Answer</option>\n                    <option value=\"1\">One</option>\n                    <option value=\"4\">Four</option>\n                    <option value=\"6\">Six</option>\n                    <option value=\"27\">Twenty-Seven</option>\n                </select>\n                <span class=\"correct\" id=\"Q2C\">&#10003</span>\n                <span class=\"wrong\" id=\"Q2W\">&#10007</span>\n            </li>\n            <li>\n            <label for=\"q3\">3) 4 blocks _______ 27 plots per block = ______ total plots.</label>\n                <select name=\"q3\" id=\"q3\" class=\"answerSelect\">\n                    <option value=\"default\" selected>Select an Answer</option>\n                    <option value=\"+, 31\">+, 31</option>\n                    <option value=\"-, -23\">-, -23</option>\n                    <option value=\"x, 108\">x, 108</option>\n                    <option value=\"x, 122\">x, 122</option>\n                </select>\n                <span class=\"correct\" id=\"Q3C\">&#10003</span>\n                <span class=\"wrong\" id=\"Q3W\">&#10007</span>\n            </li>\n            <li>\n            <label for=\"q4\">4) ____ damage timings x ____ damage levels x ____ recovery products = 27 plots per block.</label>\n                <select name=\"q4\" id=\"q4\" class=\"answerSelect\">\n                    <option value=\"default\" selected>Select an Answer</option>\n                    <option value=\"3, 3, 3\">3, 3, 3</option>\n                    <option value=\"3, 3, 2\">3, 3, 2</option>\n                    <option value=\"1, 3, 2\">1, 3, 2</option>\n                    <option value=\"1, 2, 3\">1, 2, 3</option>\n                </select>\n                <span class=\"correct\" id=\"Q4C\">&#10003</span>\n                <span class=\"wrong\" id=\"Q4W\">&#10007</span>\n            </li>\n            <li>\n            <label for=\"q5\">5) Which of the following is an independent variable in the simulated hail study experiment?</label>\n                <select name=\"q5\" id=\"q5\" class=\"answerSelect\">\n                    <option value=\"default\" selected>Select an Answer</option>\n                    <option value=\"Seeding rate\">Seeding rate</option>\n                    <option value=\"The level of damage\">The level of damage</option>\n                    <option value=\"Weather conditions\">Weather conditions</option>\n                    <option value=\"The time of day the damage happens\">The time of day the damage happens</option>\n                </select>\n                <span class=\"correct\" id=\"Q5C\">&#10003</span>\n                <span class=\"wrong\" id=\"Q5W\">&#10007</span>\n            </li>\n        </ul>\n        <span class=\"ansBtn\" id=\"ansBtn\" onclick=\"checkAns()\">Check Answers!</span>\n    </div>\n    \n    <script src=\"main2.js\"></script>\n</body>",
                "true_label": "",
                "top5_preds": [
                    "how to change the style of individual lines",
                    "getting data from the internet",
                    "retrieving data from html page",
                    "chart mark",
                    "default tagger"
                ]
            },
            {
                "code": "%%html\n    <style>\n        .section {\n            overflow: hidden;\n            transition: height 0.3s ease-out;\n            /* height: auto; */\n        }\n       </style>\n\n<body>\n    <div class=\"section\">\n        <p> Click <span><a href=\"#\" id=\"click1\"> More</a></span></p>\n    </div>\n    <div class=\"section collapsible\">\n        <p>\nMaterials:  <p>\n   \n    * Three pieces of paper, all different colours  <p>\n    * Scissors  <p>\n    * Pencil <p>\n    * One piece of blank, white paper <p>\n\nProcedure: \n     <p>\n    1. Divide your piece of blank, white paper into a grid that is 4 horizontal blocks and 27 vertical plots, reference the map above to aid the accuracy of your drawing. You are mimic-ing the field map we learned about above.\n     <p>\n    2. Cut the each piece of paper into 3 sections.\n     <p>\n    3. Label the first colour of paper with the three different levels of damage:\n         <p>* 0% damage level\n         <p>* 33% damage level\n         <p>* 67% damage level\n     <p>\n    4. Label the second colour of paper with the three different timings of damage:\n         <p>* early season timing\n         <p>* mid season timing\n         <p>* late season timing\n     <p>\n    5. Label the third colour of paper with the three diffferent recovery products: \n         <p>* no fungicide and no nutrient blend        \n         <p>* fungicide application       \n         <p>* nutrient blend application\n     <p>\n    6. Turn the nine pieces of paper face down and mix them around. Randomly choose one piece of paper from the firt colour of paper, one from the second colour of paper and one from the last colour of paper.    \n     <p>\n    7. Assign the treatment you randomized to one plot per each of the four blocks.\n     <p>\n    8. Do this a few times until you understand the randomization of treatments to plots.\n\nLearning Outcome: \n\nStudents will understand how to randomize treatments amongst existing plots. \n\n\n        </p>\n    </div>\n\n    <script>\n        function onload() {\n            \n        }\n        function collapseSection(element) {\n            var sectionHeight = element.scrollHeight;\n            var elementTransition = element.style.transition;\n            element.style.transition = '';\n            requestAnimationFrame(function () {\n                element.style.height = sectionHeight + 'px';\n                element.style.transition = elementTransition;\n                requestAnimationFrame(function () {\n                    element.style.height = 0 + 'px';\n                });\n            });\n            element.setAttribute('data-collapsed', 'true');\n        }\n\n        function expandSection(element) {\n            var sectionHeight = element.scrollHeight;\n            element.style.height = sectionHeight + 'px';\n            element.addEventListener('transitionend', function () {\n                element.removeEventListener('transitionend', arguments.callee);\n                element.style.height = null;\n            });\n            element.setAttribute('data-collapsed', 'false');\n        }\n\n        document.querySelector('#click1').addEventListener('click', function () {\n            var section = document.querySelector('.section.collapsible');\n            var isCollapsed = section.getAttribute('data-collapsed') === 'true';\n            if (isCollapsed) {\n                expandSection(section)\n                section.setAttribute('data-collapsed', 'false')\n            } else {\n                collapseSection(section)\n            }\n        });\n    </script>\n</body>\n\n",
                "true_label": "",
                "top5_preds": [
                    "how to change the style of individual lines",
                    "getting data from the internet",
                    "graph",
                    "trend lines in pyplot",
                    "chart mark"
                ]
            },
            {
                "code": "from IPython.display import YouTubeVideo\nYouTubeVideo('mPWYLXb1Z7I', width=600, height=500)",
                "true_label": "",
                "top5_preds": [
                    "getting data from the internet",
                    "plot using matplotlib",
                    "trend lines in pyplot",
                    "formatting datetimes as strings",
                    "accessing twitter"
                ]
            },
            {
                "code": "from IPython.display import YouTubeVideo\nYouTubeVideo('SJ1Cbo_Ho0o?t=42', width=800, height=400)",
                "true_label": "",
                "top5_preds": [
                    "plot using matplotlib",
                    "getting data from the internet",
                    "formatting datetimes as strings",
                    "trend lines in pyplot",
                    "accessing twitter"
                ]
            }
        ],
        [
            {
                "code": "%matplotlib notebook\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt",
                "true_label": "",
                "top5_preds": [
                    "plotting in python",
                    "timing, numpy, plotting",
                    "plot using matplotlib",
                    "trend lines in pyplot",
                    "equally spaced numbers on a grid"
                ]
            },
            {
                "code": "\"\"\"\n    Load sales data from text file\n\"\"\"\ndef load_sales_data():\n    df = pd.read_csv(\n    'purchases.txt',\n    header=None,sep='\\t',\n    parse_dates=[2],\n    names=['customer_id','purchase_amount','date_of_purchase'])\n    df['year_of_purchase'] = df.date_of_purchase.dt.year\n    return df\n\n\"\"\"\n    Create a retrospective snapshot of the sales data as of a given date in the past\n\"\"\"\ndef retro(sales_data,retrospective_date):\n    retro_date = pd.to_datetime(retrospective_date)\n    retro_sales_data = sales_data[sales_data.date_of_purchase < retro_date].copy()\n    retro_sales_data['days_since'] = (retro_date - retro_sales_data.date_of_purchase).dt.days\n    return retro_sales_data\n\n\"\"\"\n    Calculate per customer RFM (recency, frequency, money) statistics\n\"\"\"\ndef rfm(sales_df,year=None):\n    g = sales_df.groupby(by='customer_id')\n    df = pd.DataFrame({\n        'recency' : g.days_since.min(), \n        'first_purchase' : g.days_since.max(),\n        'frequency' : g.days_since.count(), \n        'avg_amount' : g.purchase_amount.mean(),\n        'max_amount' : g.purchase_amount.max()}, \n        columns= ['recency','first_purchase','frequency','avg_amount','max_amount'])\n    if year:\n        df['year'] = year\n    return df\n\n\"\"\"\n    Create data panel of per customer per year RFM (recency, frequency, money) statistics\n\"\"\"\ndef rfm_panel(sales_df):\n    retrospective_dates = pd.to_datetime(np.sort(sales_df.date_of_purchase.dt.year.unique()) + 1,format='%Y')\n    customers = pd.concat([rfm(retro(sales_df,date),date.year -1) for date in retrospective_dates])\n    customers.set_index('year',append=True,inplace=True)\n    customers.sort_index(inplace=True)\n    return customers\n\n\"\"\"\n    Create data panel of per customer per year Revenue summaries\n\"\"\"\ndef revenue_panel(sales_def):\n    g = sales_df.groupby(by=['customer_id','year_of_purchase'])\n    revenues = pd.DataFrame({'revenue' :g.purchase_amount.sum()})\n    revenues.index.set_names(['customer_id','year'],inplace=True)\n    return revenues",
                "true_label": "",
                "top5_preds": [
                    "download and inspect the twitter samples dataset",
                    "get the data",
                    "import data",
                    "load table in pandas",
                    "getting data from the internet"
                ]
            },
            {
                "code": "sales_df = load_sales_data()\nsales_df.head(6)",
                "true_label": "",
                "top5_preds": [
                    "load table in pandas",
                    "line plot with a dataframe",
                    "loading a csv into a dataframe",
                    "optimal value of k for dataset",
                    "importing data with pandas"
                ]
            },
            {
                "code": "customers = rfm_panel(sales_df)\ncustomers.head(22)",
                "true_label": "",
                "top5_preds": [
                    "loading a csv into a dataframe",
                    "create a dataframe by joining series by column",
                    "from dictionary to dataframe",
                    "load table in pandas",
                    "importing data with pandas"
                ]
            },
            {
                "code": "revenues = revenue_panel(sales_df)\nrevenues.head()",
                "true_label": "",
                "top5_preds": [
                    "create a dataframe by joining series by column",
                    "create a one column dataframe with the values of a series",
                    "loading a csv into a dataframe",
                    "from dictionary to dataframe",
                    "load table in pandas"
                ]
            },
            {
                "code": "# Join RFM and Revenue panels\nif 'revenue' in customers.columns:\n    customers.drop('revenue',axis=1,inplace=True)\ncustomers = customers.join(revenues)\ncustomers.revenue.fillna(0,inplace=True)\n\n# Take a peek at resulting panel\ncustomers.head()",
                "true_label": "",
                "top5_preds": [
                    "create a dataframe by joining series by column",
                    "from dictionary to dataframe",
                    "relationships between dataframes",
                    "create a one column dataframe with the values of a series",
                    "line plot with a dataframe"
                ]
            },
            {
                "code": "# Shift revenue of next year into current years observations\n# These are the two pieces of data that we will be trying to predict\ncustomers['next_revenue'] = customers.groupby(level='customer_id').revenue.shift(-1)\ncustomers['next_is_active'] = np.NaN\ncustomers.loc[customers.next_revenue > 0,'next_is_active'] = 1\ncustomers.loc[customers.next_revenue == 0,'next_is_active'] = 0\n\ncustomers.head()",
                "true_label": "",
                "top5_preds": [
                    "predicting a categorical response",
                    "line plots show the trend of a numerical variable over time",
                    "predicting a continuous response using linear regression",
                    "create a one column dataframe with the values of a series",
                    "predicting on sample validation data"
                ]
            },
            {
                "code": "in_sample = customers.xs(2014,level='year')\nin_sample.head()",
                "true_label": "",
                "top5_preds": [
                    "importing data with pandas",
                    "working with pandas series indexed by datetime",
                    "select every row after a specific row",
                    "line plots show the trend of a numerical variable over time",
                    "loading a csv into a dataframe"
                ]
            },
            {
                "code": "import statsmodels.formula.api as smf\nlogit = smf.logit(\n    'next_is_active ~ recency + first_purchase + frequency +avg_amount + max_amount',\n    data=in_sample)\nmodel_prob = logit.fit()\nmodel_prob.summary()",
                "true_label": "",
                "top5_preds": [
                    "likelihood of the binomial distribution",
                    "using logistic regression instead",
                    "likelihood of the binomial",
                    "fit a logistic regression model using statsmodels using logistic regression formula in patsy",
                    "fit a polynomial"
                ]
            },
            {
                "code": "pd.DataFrame(\n    model_prob.pred_table(threshold=.5).astype('int'),\n    index=[['Actual','Actual'],['inactive','active']],\n    columns=[['Predicted','Predicted'],['inactive','active']])",
                "true_label": "",
                "top5_preds": [
                    "predicting a categorical response",
                    "dataframe methods",
                    "load table in pandas",
                    "find data type of each column",
                    "making predictions for the testing data"
                ]
            },
            {
                "code": "out_sample = customers.xs(2015,level='year').copy()\nout_sample['prob_predicted'] = pd.Series(model_prob.predict(out_sample),index=out_sample.index)\nout_sample.drop(['revenue','next_revenue','next_is_active'],axis=1,inplace=True)\nout_sample.head()",
                "true_label": "",
                "top5_preds": [
                    "predicting a categorical response",
                    "create a one column dataframe with the values of a series",
                    "line plots show the trend of a numerical variable over time",
                    "predicting a continuous response using linear regression",
                    "line plot with a dataframe"
                ]
            },
            {
                "code": "z = in_sample.next_is_active == 1\nin_sample.ix[z,:].head()",
                "true_label": "",
                "top5_preds": [
                    "import polynomial features from sklearn",
                    "select every row up",
                    "line plot with a dataframe",
                    "create a one column dataframe with the values of a series",
                    "select every row after a specific row"
                ]
            },
            {
                "code": "in_sample.ix[z,:].describe()",
                "true_label": "",
                "top5_preds": [
                    "import polynomial features from sklearn",
                    "line plots show the trend of a numerical variable over time",
                    "from dictionary to dataframe",
                    "predicting a categorical response",
                    "line plot with a dataframe"
                ]
            },
            {
                "code": "ols = smf.ols(\n    formula='next_revenue ~ avg_amount + max_amount',\n    data = in_sample.ix[z,:])\nmodel_revenue = ols.fit()",
                "true_label": "",
                "top5_preds": [
                    "fit a polynomial",
                    "predicting a continuous response using linear regression",
                    "import polynomial features from sklearn",
                    "ridge regression with polynomial features on a grid",
                    "ridge regression with one predictor on a grid"
                ]
            },
            {
                "code": "model_revenue.summary()",
                "true_label": "",
                "top5_preds": [
                    "predicting a categorical response",
                    "import polynomial features from sklearn",
                    "load table in pandas",
                    "what is scikit learn?",
                    "predicting a continuous response using linear regression"
                ]
            },
            {
                "code": "plt.scatter(x=in_sample.next_revenue[z],y=model_revenue.fittedvalues)",
                "true_label": "",
                "top5_preds": [
                    "line plots show the trend of a numerical variable over time",
                    "ridge regression with polynomial features on a grid",
                    "ridge regression with one predictor on a grid",
                    "predicting a continuous response using linear regression",
                    "equally spaced numbers on a grid"
                ]
            },
            {
                "code": "ols = smf.ols(\n    formula='np.log(next_revenue) ~ np.log(avg_amount) + np.log(max_amount)',\n    data = in_sample.ix[z,:])\nmodel_revenue = ols.fit()",
                "true_label": "",
                "top5_preds": [
                    "fit a polynomial",
                    "predicting a continuous response using linear regression",
                    "import polynomial features from sklearn",
                    "ridge regression with polynomial features on a grid",
                    "one class svm fitting and estimates"
                ]
            },
            {
                "code": "plt.scatter(x=np.log(in_sample.next_revenue[z]),y=model_revenue.fittedvalues)",
                "true_label": "",
                "top5_preds": [
                    "line plots show the trend of a numerical variable over time",
                    "ridge regression with one predictor on a grid",
                    "ridge regression with polynomial features on a grid",
                    "predicting a continuous response using linear regression",
                    "linear regression of many variables"
                ]
            },
            {
                "code": "out_sample['revenue_predicted'] = pd.Series(np.exp(model_revenue.predict(out_sample)),index=out_sample.index)\nout_sample['score_predicted'] = out_sample.revenue_predicted * out_sample.prob_predicted",
                "true_label": "",
                "top5_preds": [
                    "predicting a categorical response",
                    "import polynomial features from sklearn",
                    "predicting on sample validation data",
                    "predicting a continuous response using linear regression",
                    "what is scikit learn?"
                ]
            },
            {
                "code": "out_sample[['revenue_predicted','prob_predicted','score_predicted']].describe()",
                "true_label": "",
                "top5_preds": [
                    "predicting a categorical response",
                    "import polynomial features from sklearn",
                    "predicting on sample validation data",
                    "line plot with a dataframe",
                    "predicting test data"
                ]
            },
            {
                "code": "ols = smf.ols(\n    formula='np.log(next_revenue) ~ np.log(avg_amount) + np.log(max_amount)',\n    data = in_sample.ix[z,:])\nmodel_revenue = ols.fit()",
                "true_label": "",
                "top5_preds": [
                    "fit a polynomial",
                    "predicting a continuous response using linear regression",
                    "import polynomial features from sklearn",
                    "ridge regression with polynomial features on a grid",
                    "one class svm fitting and estimates"
                ]
            }
        ],
        [
            {
                "code": "import pandas as pd\nimport datetime as dt\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport matplotlib.style as style\nimport numpy as np\nimport math\nimport warnings\nwarnings.filterwarnings('ignore')\nimport datetime as dt\nfrom statsmodels.tsa.stattools import adfuller\n%matplotlib inline",
                "true_label": "",
                "top5_preds": [
                    "timing, numpy, plotting",
                    "formatting datetimes as strings",
                    "plotting time series with pandas",
                    "trend lines in pyplot",
                    "line plots show the trend of a numerical variable over time"
                ]
            },
            {
                "code": "VERBOSE = False",
                "true_label": "",
                "top5_preds": [
                    "equally spaced numbers on a grid",
                    "get a positive integer from a user",
                    "running a local postgres database",
                    "setup and re introduction to python",
                    "getting data from the internet"
                ]
            },
            {
                "code": "style.use('seaborn-ticks')",
                "true_label": "",
                "top5_preds": [
                    "trend lines in pyplot",
                    "plotting time series with pandas",
                    "formatting datetimes as strings",
                    "plot using matplotlib",
                    "using a dataframe and matplotlib commands"
                ]
            },
            {
                "code": "cbColors = [ [86,180,233], [230,159,0], [0,114,178], [0,158,115], [240,228,66], [213,94,0], [204,121,167], [0,0,0],]\nfor rgbList in cbColors:\n    rgbList[:] = [x / 255 for x in rgbList]\nmpl.rcParams['axes.prop_cycle'] = mpl.cycler(color=cbColors)",
                "true_label": "",
                "top5_preds": [
                    "how to change the color of a plot",
                    "scikit image panorama",
                    "predicting a categorical response",
                    "equally spaced numbers on a grid",
                    "plotting in python"
                ]
            },
            {
                "code": "def queryTripsMinMax(dbPath, minRow, maxRow):\n\timport sqlite3\n\n\tdb = sqlite3.connect(dbPath)\n\tcursor = db.cursor()\n\n\tcursor.execute('''SELECT startTime, bridgeName, direction, simpleMPH FROM tripsUnique WHERE rowid > ? AND rowid < ?''', (minRow,maxRow))\n\tresult = cursor.fetchall()\n\n\tdb.close()\n\treturn result",
                "true_label": "",
                "top5_preds": [
                    "download and inspect the twitter samples dataset",
                    "getting data from the internet",
                    "read the dataset point",
                    "connect to a remote database",
                    "get the data"
                ]
            },
            {
                "code": "DB_PATH = 'archives/mydb_Aug13_Final'\nrows = queryTripsMinMax(DB_PATH, 1, 23000)",
                "true_label": "",
                "top5_preds": [
                    "connect to a remote database",
                    "accessing databases via web apis",
                    "running a local postgres database",
                    "find maximum and the minimum value in a set",
                    "getting data from the internet"
                ]
            },
            {
                "code": "formattedRows = [[dt.datetime.fromtimestamp(int(list[0])), list[1], list[2], float(list[3])]  for list in rows]\ndf = pd.DataFrame(formattedRows, columns=['datetime','highway','direction','simpleMPH'])",
                "true_label": "",
                "top5_preds": [
                    "convert date to datetime format",
                    "importing data with numpy",
                    "formatting datetimes as strings",
                    "importing data with pandas",
                    "from dictionary to dataframe"
                ]
            },
            {
                "code": "df = df.loc[df['simpleMPH'] <= 75]\ndf = df.sort('datetime')\ndf['date'] = df['datetime'].apply(lambda x: x.date)\ndf['weekday'] = df['datetime'].apply(lambda x: x.weekday())\nfrom pandas import date_range, to_datetime\ndf['timeofdaysec'] = df['datetime'].apply(lambda x: (to_datetime(x) -to_datetime(x.date())).total_seconds())",
                "true_label": "",
                "top5_preds": [
                    "convert date to datetime format",
                    "transform the date column as a datetime type",
                    "formatting datetimes as strings",
                    "integrating datetime tools with pandas for time series",
                    "plotting time series with pandas"
                ]
            },
            {
                "code": "df_WI90 = df.loc[(df['highway'] == 'I90') & (df['direction'] == 'W')]\ndf_EI90 = df.loc[(df['highway'] == 'I90') & (df['direction'] == 'E')]\ndf_WSR520 = df.loc[(df['highway'] == 'SR520') & (df['direction'] == 'W')]\ndf_ESR520 = df.loc[(df['highway'] == 'SR520') & (df['direction'] == 'E')]",
                "true_label": "",
                "top5_preds": [
                    "selecting specific columns in a dataframe",
                    "line plot with a dataframe",
                    "create dataframe with given values",
                    "using a dataframe and matplotlib commands",
                    "using pandas"
                ]
            },
            {
                "code": "RANGE_FREQ = '15T'\n#RANGE_SEC = 90\nTIME_WINDOW = dt.timedelta(minutes=30)\ndef makeRollingAverage(df):\n    if VERBOSE:\n        print(df.index.date.min())\n        print(df.index.date.max())\n        print(df.index.time.min())\n        print(df.index.time.max())\n    \n    myDateRange = pd.date_range(start=dt.datetime(2017,7,10, 5,45,0) , end=dt.datetime(2017,8,11, 23,20,0), freq=RANGE_FREQ)\n    if VERBOSE: print(myDateRange)\n    a = [0]\n    b = [0]\n    lastVals=[]\n    for datetime in myDateRange:\n        vals = df['simpleMPH'].loc[(df.index > datetime) & (df.index < (datetime + TIME_WINDOW))].values\n        if len(vals) == 0:\n            a.append(a[-1])\n            b.append(b[-1])\n        elif len(vals) == 1:\n            newVals = np.append(lastVals, [vals])\n            mean = np.mean(newVals)\n            std = np.std(newVals)\n            a.append(mean)\n            b.append(std)\n            \n            lastVals = vals\n        elif len(vals) > 1:\n            mean = vals.mean()\n            std = vals.std()\n            a.append(mean)\n            b.append(std)\n            lastVals = vals\n    dfa = pd.DataFrame(index=myDateRange, data={'avg':a[1:], 'std':b[1:]})\n    dfa['avg'].loc[(dfa.index.time<dt.time(5,45)) | (dfa.index.time>dt.time(23,15))] = 0\n    dfa['std'].loc[(dfa.index.time<dt.time(5,45)) | (dfa.index.time>dt.time(23,15))] = 0\n    dfa =dfa.reset_index()\n    dfa['weekday'] = dfa['index'].apply(lambda x: x.weekday())\n    dfa['avg'].loc[dfa['weekday'] > 4] = 0\n    dfa['std'].loc[dfa['weekday'] > 4] = 0\n    dfa['avg'].loc[(dfa['index'] >= dt.datetime(2017, 8, 2)) & (dfa['index'] < dt.datetime(2017, 8, 6))] = 0\n    dfa['std'].loc[(dfa['index'] >= dt.datetime(2017, 8, 2)) & (dfa['index'] < dt.datetime(2017, 8, 6))] = 0\n    dfa['avg'].loc[(dfa['index'] >= dt.datetime(2017,8,7, 17,0)) & (dfa['index'] < dt.datetime(2017,8,8, 1,0))] = 0\n    dfa['std'].loc[(dfa['index'] >= dt.datetime(2017,8,7, 17,0)) & (dfa['index'] < dt.datetime(2017,8,8, 1,0))] = 0\n    dfa=dfa.set_index('index')\n    del dfa['weekday']\n    return dfa",
                "true_label": "",
                "top5_preds": [
                    "convert date to datetime format",
                    "date ranges and frequencies",
                    "transform the date column as a datetime type",
                    "calculate the mean windspeed for each month in the dataset",
                    "line plots show the trend of a numerical variable over time"
                ]
            },
            {
                "code": "dfa = makeRollingAverage(df_WI90)\ndfb = makeRollingAverage(df_WSR520)\ndfc = makeRollingAverage(df_EI90)\ndfd = makeRollingAverage(df_ESR520)",
                "true_label": "",
                "top5_preds": [
                    "the mean of difference of variables",
                    "create a one column dataframe with the values of a series",
                    "line plots show the trend of a numerical variable over time",
                    "law of averages",
                    "calculating the mean of a vector with nans"
                ]
            },
            {
                "code": "fig, ax = plt.subplots(figsize=(12,6))\nkwargs={'lw':0, 'marker':'o'}\n\ndf_WI90['simpleMPH'].plot(ax=ax, **kwargs)\ndfa.plot(ax=ax, y='avg')\nplt.xlabel('Time')\nplt.legend(['I90 West Points', 'Rolling Mean'])\nplt.ylabel('simpleMPH')\n\nplt.xlim(dt.datetime(2017,7,10),dt.datetime(2017,7,15))\nplt.show()",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "pandas plotting",
                    "plot using pandas plotting",
                    "pandas plotting documentation",
                    "plotting time series with pandas"
                ]
            },
            {
                "code": "fig, ax = plt.subplots(figsize=(12,4))\nkwargs={'lw':0, 'marker':'o'}\ndf_WI90['simpleMPH'].plot(ax=ax, **kwargs)\ndfa.plot(ax=ax, y='avg')\nplt.xlabel('Time')\nplt.legend(['I90 West Points', 'Rolling Mean'])\nplt.ylabel('simpleMPH')\nplt.xlim(dt.datetime(2017,7,10,5,0),dt.datetime(2017,7,10,23,0))\nplt.show()",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "pandas plotting",
                    "plot using pandas plotting",
                    "pandas plotting documentation",
                    "plotting time series with pandas"
                ]
            },
            {
                "code": "fig, ax = plt.subplots(figsize=(12,4))\ndf_WI90['simpleMPH'].plot(ax=ax, **kwargs)\ndfa.plot(ax=ax,y='avg')\nplt.xlim(dt.datetime(2017,7,10,8,0,0),dt.datetime(2017,7,10,15,0,0))\nplt.xlabel('Time')\nplt.legend(['I90 West Points', 'Rolling Mean'])\nplt.ylabel('simpleMPH')\nplt.show()",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "plotting time series with pandas",
                    "pandas plotting",
                    "plot using pandas plotting",
                    "using a dataframe and matplotlib commands"
                ]
            },
            {
                "code": "avgab = dfa['avg'] - dfb['avg']\navgcd = dfc['avg'] - dfd['avg']",
                "true_label": "",
                "top5_preds": [
                    "the mean of difference of variables",
                    "join two dataframes along columns",
                    "join two dataframes along rows",
                    "combine two dataframes into one",
                    "integrating datetime tools with pandas for time series"
                ]
            },
            {
                "code": "#covab = np.cov(dfa['avg'],dfb['avg']) \ncovab = 0\ncovcd = 0 \n#print(covab)\nstdab = np.sqrt( dfa['std'] ** 2 + dfb['std'] **2 + 2*covab )\nstdcd = np.sqrt( dfc['std'] ** 2 + dfd['std'] **2 + 2*covcd )\n#print(stdab)",
                "true_label": "",
                "top5_preds": [
                    "computing the mean together with the covariance",
                    "computing the covariance matrix",
                    "compute covariance matrix",
                    "computing the covariance when there are nan s",
                    "co variance matrix"
                ]
            },
            {
                "code": "dfab = pd.DataFrame(index=dfa.index, data={'diff':avgab, 'std':stdab})\ndfcd = pd.DataFrame(index=dfc.index, data={'diff':avgcd, 'std':stdcd})",
                "true_label": "",
                "top5_preds": [
                    "the mean of difference of variables",
                    "create a one column dataframe with the values of a series",
                    "create dataframe with given values",
                    "integrating datetime tools with pandas for time series",
                    "line plots show the trend of a numerical variable over time"
                ]
            },
            {
                "code": "fig, (ax1, ax2) = plt.subplots(nrows=2,ncols=1,figsize=(12,8), sharex=True,sharey=True)\n\ndfab.plot(ax=ax1, y='diff')\nax1.set_title('West')\nax1.legend(['Delta (I90 - SR520)'])\n\ndfcd.plot(ax=ax2, y='diff')\nax2.set_title('East')\nax2.legend(['Delta (I90 - SR520)'])\n\nstart = dt.datetime(2017,7,10,6,0)\nend = dt.datetime(2017,8,11,23,0)\nplt.xlabel('Time')\nplt.ylabel('Delta MPH')\nplt.xlim(start,end)\nplt.tight_layout()\nplt.show()",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "pandas plotting",
                    "pandas plotting documentation",
                    "plot using pandas plotting",
                    "on separate stacked axes sharing the same x axis"
                ]
            },
            {
                "code": "def plotDifference(start, end):\n    fig, (ax1, ax2) = plt.subplots(nrows=2,ncols=1,figsize=(12,8), sharey=True, sharex=True)\n\n    swgs={'lw':0, 'marker':'o', 'alpha':.3}\n    wgs={ 'width':.01,'alpha':.5, 'color':cbColors[2]}\n    df_WI90.loc[(df_WI90.index > start) & (df_WI90.index < end)].plot(y='simpleMPH',ax=ax1,**swgs)\n    df_WSR520.loc[(df_WSR520.index > start) & (df_WSR520.index < end)].plot(y='simpleMPH',ax=ax1,**swgs)\n    dfa[(dfa.index > start) & (dfa.index < end)].plot(ax=ax1, y='avg', lw=3)\n    dfb[(dfb.index > start) & (dfb.index < end)].plot(ax=ax1, y='avg', lw=3)\n    ax1.bar(dfab[(dfab.index > start) & (dfab.index < end)].index, \n            dfab[(dfab.index > start) & (dfab.index < end)]['diff'].values,\n            label='Delta (I90 - SR520)', **wgs) # bottom = dfb[(dfb.index > start) & (dfb.index < end)].avg,\n    ax1.set_title('West')\n    ax1.legend(['I90 Points','SR520 Points','I90 Rolling Avg','SR520 Rolling Avg','Delta (I90 - SR520)'],\n               loc=6,frameon=True)\n    \n    df_EI90.loc[(df_EI90.index > start) & (df_EI90.index < end)].plot(y='simpleMPH',ax=ax2,**swgs)\n    df_ESR520.loc[(df_ESR520.index > start) & (df_ESR520.index < end)].plot(y='simpleMPH',ax=ax2,**swgs)\n    dfc[(dfc.index > start) & (dfc.index < end)].plot(ax=ax2, y='avg', lw=3)\n    dfd[(dfd.index > start) & (dfd.index < end)].plot(ax=ax2, y='avg', lw=3)\n    ax2.bar(dfcd[(dfcd.index > start) & (dfcd.index < end)].index, \n            dfcd[(dfcd.index > start) & (dfcd.index < end)]['diff'].values,\n           label='Delta (I90 - SR520)', **wgs) # bottom = dfd[(dfd.index > start) & (dfd.index < end)].avg, \n    ax2.set_title('East')\n    ax2.legend(['I90 Points','SR520 Points','I90 Rolling Avg','SR520 Rolling Avg','Delta (I90 - SR520)'],\n               loc=6,frameon=True)\n    plt.xlabel('Time')\n    plt.ylabel('Delta MPH')\n    plt.xlim(start,end)\n    plt.tight_layout()\n    plt.show()",
                "true_label": "",
                "top5_preds": [
                    "plot the data",
                    "plot the error and execution time",
                    "calculate distance of event and station",
                    "plot past data",
                    "plot the distributions"
                ]
            },
            {
                "code": "df = df.loc[(df['datetime'] > dt.datetime(2017, 7, 8))]\ndf = df.loc[(df['datetime'] < dt.datetime(2017, 8, 3)) | (df['datetime'] > dt.datetime(2017, 8, 6))]\ndf= df.loc[df['weekday'] < 5]\ndf = df.set_index('datetime')",
                "true_label": "",
                "top5_preds": [
                    "convert date to datetime format",
                    "select every row after a specific row",
                    "integrating datetime tools with pandas for time series",
                    "selecting data using a date or a date string",
                    "formatting datetimes as strings"
                ]
            },
            {
                "code": "df = df.loc[df.simpleMPH.apply(lambda x: not np.isnan(x))]",
                "true_label": "",
                "top5_preds": [
                    "drop the rows with nan values",
                    "dataframe methods",
                    "line plot with a dataframe",
                    "load table in pandas",
                    "drop data points with missing data"
                ]
            },
            {
                "code": "plotDifference(start=dt.datetime(2017,7,12, 6,0), \n               end = dt.datetime(2017,7,12,11,0))",
                "true_label": "",
                "top5_preds": [
                    "plotting time series with pandas",
                    "introduction to the python datetime tools",
                    "line plots show the trend of a numerical variable over time",
                    "convert date to datetime format",
                    "plot variable dependence trends"
                ]
            },
            {
                "code": "plotDifference(start=dt.datetime(2017,7,12, 6,0), \n               end = dt.datetime(2017,7,12,23,0))",
                "true_label": "",
                "top5_preds": [
                    "plotting time series with pandas",
                    "introduction to the python datetime tools",
                    "line plots show the trend of a numerical variable over time",
                    "plot variable dependence trends",
                    "plot past data"
                ]
            },
            {
                "code": "plotDifference(start=dt.datetime(2017,7,13, 6,0), \n               end = dt.datetime(2017,7,13,23,0))",
                "true_label": "",
                "top5_preds": [
                    "plotting time series with pandas",
                    "introduction to the python datetime tools",
                    "line plots show the trend of a numerical variable over time",
                    "plot variable dependence trends",
                    "plot past data"
                ]
            },
            {
                "code": "plotDifference(start=dt.datetime(2017,7,21, 6,0), \n               end = dt.datetime(2017,7,21,23,0))",
                "true_label": "",
                "top5_preds": [
                    "plotting time series with pandas",
                    "introduction to the python datetime tools",
                    "line plots show the trend of a numerical variable over time",
                    "plot variable dependence trends",
                    "integrating datetime tools with pandas for time series"
                ]
            }
        ],
        [
            {
                "code": "# -*- coding: utf-8 -*-\n# Import libraries\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.preprocessing import Imputer",
                "true_label": "",
                "top5_preds": [
                    "import polynomial features from sklearn",
                    "what is scikit learn?",
                    "polynomial regression with sklearn",
                    "scikit learn",
                    "use sklearn kfold"
                ]
            },
            {
                "code": "# Load the train and test datasets to create two DataFrames\ntrain = pd.read_csv('train.csv')\ntest = pd.read_csv('test.csv')",
                "true_label": "",
                "top5_preds": [
                    "loading a csv into a dataframe",
                    "load table in pandas",
                    "importing data with pandas",
                    "importing data with numpy",
                    "from dictionary to dataframe"
                ]
            },
            {
                "code": "train.head()",
                "true_label": "",
                "top5_preds": [
                    "tensorflow + keras",
                    "what is scikit learn?",
                    "import polynomial features from sklearn",
                    "logistic regression using tensorflow",
                    "use sklearn kfold"
                ]
            },
            {
                "code": "test.head()",
                "true_label": "",
                "top5_preds": [
                    "tensorflow + keras",
                    "predicting a categorical response",
                    "what is scikit learn?",
                    "formatting datetimes as strings",
                    "nltk to recognize a book"
                ]
            },
            {
                "code": "print(train[\"Survived\"].value_counts())\nprint(train[\"Survived\"].value_counts(normalize = True))",
                "true_label": "",
                "top5_preds": [
                    "reading featurecounts",
                    "convert text data into vector",
                    "predicting a categorical response",
                    "counting word frequency",
                    "transforming text into numbers"
                ]
            },
            {
                "code": "print(train[\"Survived\"][train[\"Sex\"] == 'male'].value_counts())\nprint(train[\"Survived\"][train[\"Sex\"] == 'male'].value_counts(normalize = True))",
                "true_label": "",
                "top5_preds": [
                    "convert categorical variables",
                    "predicting a categorical response",
                    "convert text data into vector",
                    "find all by term in field in case insensitive way",
                    "transform categorical data into binary features"
                ]
            },
            {
                "code": "print(train[\"Survived\"][train[\"Sex\"] == 'female'].value_counts())\nprint(train[\"Survived\"][train[\"Sex\"] == 'female'].value_counts(normalize = True))",
                "true_label": "",
                "top5_preds": [
                    "convert categorical variables",
                    "predicting a categorical response",
                    "convert text data into vector",
                    "what is scikit learn?",
                    "find all by term in field in case insensitive way"
                ]
            },
            {
                "code": "survived_class = pd.crosstab(index=train[\"Survived\"],\n                            columns=train[\"Sex\"])   # Include row and column totals\nsurvived_class.columns = [\"Female\",\"Male\"]\nsurvived_class.index = [\"Died\",\"Survived\"]\nsurvived_class.plot(kind=\"bar\",\n                 figsize=(15,6),\n                 stacked=True)\nplt.show()",
                "true_label": "",
                "top5_preds": [
                    "dataframe methods",
                    "predicting a categorical response",
                    "create a one column dataframe with the values of a series",
                    "line plots show the trend of a numerical variable over time",
                    "line plot with a dataframe"
                ]
            },
            {
                "code": "train['Age'].fillna((train['Age'].mean()), inplace=True)\nfigure = plt.figure(figsize=(15,6))\nplt.hist([train[train['Survived']==1]['Age'], train[train['Survived']==0]['Age']], stacked=True, color = ['g','r'],\n         bins = 30,label = ['Survived','Dead'])\nplt.xlabel('Age')\nplt.ylabel('Number of passengers')\nplt.legend()\nplt.show()",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "ploting out data with box plots",
                    "predicting a categorical response",
                    "line plots show the trend of a numerical variable over time",
                    "plot using pandas plotting"
                ]
            },
            {
                "code": "figure = plt.figure(figsize=(15,6))\nplt.hist([train[train['Survived']==1]['Fare'],train[train['Survived']==0]['Fare']], stacked=True, color = ['g','r'],\n         bins = 30,label = ['Survived','Dead'])\nplt.xlabel('Fare')\nplt.ylabel('Number of passengers')\nplt.legend()\nplt.show()",
                "true_label": "",
                "top5_preds": [
                    "ploting out data with box plots",
                    "line plot with a dataframe",
                    "predicting a categorical response",
                    "line plots show the trend of a numerical variable over time",
                    "plot histogram"
                ]
            },
            {
                "code": "embark = train[train['Survived'] == 1]['Embarked'].value_counts()\ndead_embark = train[train['Survived'] == 0]['Embarked'].value_counts()\ndf = pd.DataFrame([embark,dead_embark])\ndf.index = ['Survived','Dead']\ndf.plot(kind='bar', stacked=True, figsize=(15,6))\nplt.show()",
                "true_label": "",
                "top5_preds": [
                    "in pandas",
                    "predicting a categorical response",
                    "using pandas",
                    "line plot with a dataframe",
                    "using a dataframe and matplotlib commands"
                ]
            },
            {
                "code": "import warnings\nwarnings.filterwarnings('ignore')\n\n# Convert the male and female groups to integer form into train\ntrain[\"Sex\"][train[\"Sex\"] == \"male\"] = 0\ntrain[\"Sex\"][train[\"Sex\"] == \"female\"] = 1\n\n# Convert the male and female groups to integer form into test\ntest[\"Sex\"][test[\"Sex\"] == \"male\"] = 0\ntest[\"Sex\"][test[\"Sex\"] == \"female\"] = 1",
                "true_label": "",
                "top5_preds": [
                    "predicting a categorical response",
                    "training data",
                    "check accuracy / score for a logistic classifier",
                    "import polynomial features from sklearn",
                    "importing data with numpy"
                ]
            },
            {
                "code": "# Impute the Embarked variable into train\ntrain[\"Embarked\"] = train[\"Embarked\"].fillna(\"S\")\n\n# Convert the Embarked classes to integer form into train\ntrain[\"Embarked\"][train[\"Embarked\"] == \"S\"] = 0\ntrain[\"Embarked\"][train[\"Embarked\"] == \"C\"] = 1\ntrain[\"Embarked\"][train[\"Embarked\"] == \"Q\"] = 2\n\n# Impute the Embarked variable into test\ntest[\"Embarked\"] = test[\"Embarked\"].fillna(\"S\")\n\n# Convert the Embarked classes to integer form into test\ntest[\"Embarked\"][test[\"Embarked\"] == \"S\"] = 0\ntest[\"Embarked\"][test[\"Embarked\"] == \"C\"] = 1\ntest[\"Embarked\"][test[\"Embarked\"] == \"Q\"] = 2",
                "true_label": "",
                "top5_preds": [
                    "import polynomial features from sklearn",
                    "pandas apply",
                    "using the classify function",
                    "convert categorical variables",
                    "what is scikit learn?"
                ]
            },
            {
                "code": "# Print the train data to see the available features and clean data\ntrain = train.drop(['Cabin'], axis=1)\ntrain['Age'].fillna((train['Age'].mean()), inplace=True)",
                "true_label": "",
                "top5_preds": [
                    "importing data with pandas",
                    "loading up data with missing values",
                    "importing data with numpy",
                    "integrating datetime tools with pandas for time series",
                    "line plot with a dataframe"
                ]
            },
            {
                "code": "# Print the train data to see the available features and clean data\ntest = test.drop(['Cabin'], axis=1)\ntest['Age'].fillna((test['Age'].mean()), inplace=True)",
                "true_label": "",
                "top5_preds": [
                    "integrating datetime tools with pandas for time series",
                    "importing data with pandas",
                    "create dataframe with given values",
                    "line plot with a dataframe",
                    "loading up data with missing values"
                ]
            },
            {
                "code": "# Building  my_forest\ny_train = train['Survived']\nX_train = train[[\"Pclass\", \"Age\", \"Sex\", \"Fare\", \"SibSp\", \"Parch\", \"Embarked\"]].values\ntest_features = test[[\"Pclass\", \"Age\", \"Sex\", \"Fare\", \"SibSp\", \"Parch\", \"Embarked\"]].values\ntest_features = Imputer().fit_transform(test_features)\n\n# Fit model and print score\nforest = RandomForestClassifier(max_depth = 10, min_samples_split=2, n_estimators = 100, random_state = 1)\nmy_forest = forest.fit(X_train, y_train)\nprint(my_forest.score(X_train, y_train))",
                "true_label": "",
                "top5_preds": [
                    "import polynomial features from sklearn",
                    "what is scikit learn?",
                    "implementing bag of words in scikit learn",
                    "transform categorical data into binary features",
                    "making predictions for the testing data"
                ]
            }
        ],
        [
            {
                "code": "#Plot the Age distribution\nfig = fig_fact.create_distplot([mcq[mcq['Age'] > 0]['Age']], ['age'], colors=['#BA68C8'])\npy.iplot(fig, filename='Basic Distplot')\n#sns.distplot(mcq[mcq['Age'] > 0]['Age'])",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "plot the distributions",
                    "pandas plotting",
                    "pandas plotting documentation",
                    "ploting out data with box plots"
                ]
            },
            {
                "code": "sns.countplot(y='FormalEducation', data=mcq)",
                "true_label": "",
                "top5_preds": [
                    "predicting a categorical response",
                    "line plot with a dataframe",
                    "line plots show the trend of a numerical variable over time",
                    "credible interval vs confidence interval",
                    "using a dataframe and matplotlib commands"
                ]
            },
            {
                "code": "plt.figure(figsize=(6,8))\nsns.countplot(y='MajorSelect', data=mcq)",
                "true_label": "",
                "top5_preds": [
                    "predicting a categorical response",
                    "line plot with a dataframe",
                    "line plots show the trend of a numerical variable over time",
                    "ploting out data with box plots",
                    "credible interval vs confidence interval"
                ]
            },
            {
                "code": "sns.countplot(y='EmploymentStatus', data=mcq)",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "line plots show the trend of a numerical variable over time",
                    "predicting a categorical response",
                    "using a dataframe and matplotlib commands",
                    "credible interval vs confidence interval"
                ]
            },
            {
                "code": "jfdf = {}\nfor feature in job_factors:\n    a = mcq[feature].value_counts()\n    a = a/a.sum()\n    jfdf[feature[len('JobFactor'):]] = a\n\njfdf = pd.DataFrame(jfdf).transpose()\n\nplt.figure(figsize=(6,12))\nsns.heatmap(jfdf.sort_values('Very Important', ascending=False), annot=True)\n\njfdf.plot(kind='bar', figsize=(18,6), title=\"Things to look for while considering Data Science Jobs\")\nplt.show()",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "import polynomial features from sklearn",
                    "dataframe methods",
                    "find data type of each column",
                    "create a one column dataframe with the values of a series"
                ]
            },
            {
                "code": "sns.countplot(y='UniversityImportance', data=mcq)",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "line plots show the trend of a numerical variable over time",
                    "predicting a categorical response",
                    "credible interval vs confidence interval",
                    "create a one column dataframe with the values of a series"
                ]
            },
            {
                "code": "top_uni = mcq['UniversityImportance'].value_counts().head(5)\ntop_uni_dist = []\nfor uni in top_uni.index:\n    top_uni_dist.append(mcq[(mcq['Age'].notnull()) & (mcq['UniversityImportance'] == uni)]['Age'])\n\ngroup_labels = top_uni.index\n\nfig = fig_fact.create_distplot(top_uni_dist, group_labels, show_hist=False)\npy.iplot(fig, filename='University Importance by Age')",
                "true_label": "",
                "top5_preds": [
                    "ploting out data with box plots",
                    "line plot with a dataframe",
                    "predicting a categorical response",
                    "dataframe methods",
                    "transform categorical data into binary features"
                ]
            },
            {
                "code": "mcq[mcq['FirstTrainingSelect'].notnull()].shape",
                "true_label": "",
                "top5_preds": [
                    "find data type of each column",
                    "import polynomial features from sklearn",
                    "computing the covariance when there are nan s",
                    "shortcut principal component analysis in scikit learn",
                    "requirements for working with data in scikit learn"
                ]
            },
            {
                "code": "sns.countplot(y='FirstTrainingSelect', data=mcq)",
                "true_label": "",
                "top5_preds": [
                    "predicting a categorical response",
                    "line plot with a dataframe",
                    "line plots show the trend of a numerical variable over time",
                    "polynomial regression with sklearn",
                    "predicting a continuous response using linear regression"
                ]
            },
            {
                "code": "sns.countplot(y='Tenure', data=mcq)",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "predicting a categorical response",
                    "line plots show the trend of a numerical variable over time",
                    "credible interval vs confidence interval",
                    "using a dataframe and matplotlib commands"
                ]
            },
            {
                "code": "sns.countplot(y='LanguageRecommendationSelect', data=mcq)",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "predicting a categorical response",
                    "line plots show the trend of a numerical variable over time",
                    "using a dataframe and matplotlib commands",
                    "credible interval vs confidence interval"
                ]
            },
            {
                "code": "top_lang = mcq['LanguageRecommendationSelect'].value_counts()\ntop_lang_dist = []\nfor lang in top_lang.index:\n    top_lang_dist.append(mcq[(mcq['Age'].notnull()) & (mcq['LanguageRecommendationSelect'] == lang)]['Age'])\n\ngroup_labels = top_lang.index\n\nfig = fig_fact.create_distplot(top_lang_dist, group_labels, show_hist=False)\npy.iplot(fig, filename='Language Preferences by Age')\n",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "load table in pandas",
                    "ploting out data with box plots",
                    "find data type of each column",
                    "using a dataframe and matplotlib commands"
                ]
            },
            {
                "code": "mcq[mcq['CurrentJobTitleSelect'].notnull()]['CurrentJobTitleSelect'].shape",
                "true_label": "",
                "top5_preds": [
                    "find data type of each column",
                    "find maximum and the minimum value in a set",
                    "import polynomial features from sklearn",
                    "remove null values from county, category, and category name",
                    "delete column by name"
                ]
            },
            {
                "code": "#Plot the number of R and Python users by Occupation\ndata = mcq[(mcq['CurrentJobTitleSelect'].notnull()) & ((mcq['LanguageRecommendationSelect'] == 'Python') | (mcq['LanguageRecommendationSelect'] == 'R'))]\nplt.figure(figsize=(8, 10))\nsns.countplot(y=\"CurrentJobTitleSelect\", hue=\"LanguageRecommendationSelect\", data=data)",
                "true_label": "",
                "top5_preds": [
                    "predicting a categorical response",
                    "line plot with a dataframe",
                    "ploting out data with box plots",
                    "using a dataframe and matplotlib commands",
                    "line plots show the trend of a numerical variable over time"
                ]
            },
            {
                "code": "mcq['HardwarePersonalProjectsSelect'] = mcq['HardwarePersonalProjectsSelect'].astype('str').apply(lambda x: x.split(','))\ns = mcq.apply(lambda x: pd.Series(x['HardwarePersonalProjectsSelect']),axis=1).stack().reset_index(level=1, drop=True)\ns.name = 'hardware'",
                "true_label": "",
                "top5_preds": [
                    "from dictionary to dataframe",
                    "create a dataframe by joining series by column",
                    "create a one column dataframe with the values of a series",
                    "loading a csv into a dataframe",
                    "convert categorical variables"
                ]
            },
            {
                "code": "s[s != 'nan'].value_counts()",
                "true_label": "",
                "top5_preds": [
                    "find data type of each column",
                    "create a one column dataframe with the values of a series",
                    "predicting a categorical response",
                    "drop the rows with nan values",
                    "calculating the mean of a vector with nans"
                ]
            },
            {
                "code": "plt.figure(figsize=(8,8))\nsns.countplot(y='TimeSpentStudying', data=mcq, hue='EmploymentStatus').legend(loc='center left', bbox_to_anchor=(1, 0.5))",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "line plots show the trend of a numerical variable over time",
                    "pandas plotting",
                    "pandas plotting documentation",
                    "plot using pandas plotting"
                ]
            },
            {
                "code": "mcq['BlogsPodcastsNewslettersSelect'] = mcq['BlogsPodcastsNewslettersSelect'].astype('str').apply(lambda x: x.split(','))",
                "true_label": "",
                "top5_preds": [
                    "formatting datetimes as strings",
                    "convert text data into vector",
                    "convert data from string to float",
                    "loading a csv into a dataframe",
                    "pandas apply"
                ]
            },
            {
                "code": "s = mcq.apply(lambda x: pd.Series(x['BlogsPodcastsNewslettersSelect']),axis=1).stack().reset_index(level=1, drop=True)\ns.name = 'platforms'",
                "true_label": "",
                "top5_preds": [
                    "create a dataframe by joining series by column",
                    "from dictionary to dataframe",
                    "load table in pandas",
                    "create a one column dataframe with the values of a series",
                    "join two dataframes along rows"
                ]
            },
            {
                "code": "s = s[s != 'nan'].value_counts()",
                "true_label": "",
                "top5_preds": [
                    "drop the rows with nan values",
                    "calculating the mean of a vector with nans",
                    "convert data from string to float",
                    "drop nan values",
                    "find data type of each column"
                ]
            },
            {
                "code": "plt.figure(figsize=(6,8))\nplt.title(\"Most Popular Blogs and Podcasts\")\nsns.barplot(y=s.index, x=s)",
                "true_label": "",
                "top5_preds": [
                    "use pandas to make a bar chart",
                    "pandas plotting",
                    "plot using pandas plotting",
                    "create a bar chart",
                    "equally spaced numbers on a grid"
                ]
            },
            {
                "code": "#Create a DataFrame for number of respondents by country\ncon_df = pd.DataFrame(mcq['Country'].value_counts())\ncon_df['country'] = con_df.index\ncon_df.columns = ['num_resp', 'country']\ncon_df = con_df.reset_index().drop('index', axis=1)\ncon_df.head(10)",
                "true_label": "",
                "top5_preds": [
                    "from dictionary to dataframe",
                    "create a dataframe by joining series by column",
                    "create dataframe with given values",
                    "create a one column dataframe with the values of a series",
                    "create a dataframe"
                ]
            },
            {
                "code": "#Create a Choropleth Map of the respondents using Plotly. \n#Find out more at https://plot.ly/python/choropleth-maps/\ndata = [ dict(\n        type = 'choropleth',\n        locations = con_df['country'],\n        locationmode = 'country names',\n        z = con_df['num_resp'],\n        text = con_df['country'],\n        colorscale = [[0,'rgb(255, 255, 255)'],[1,'rgb(56, 142, 60)']],\n        autocolorscale = False,\n        reversescale = False,\n        marker = dict(\n            line = dict (\n                color = 'rgb(180,180,180)',\n                width = 0.5\n            ) ),\n        colorbar = dict(\n            autotick = False,\n            tickprefix = '',\n            title = 'Survey Respondents'),\n      ) ]\n\nlayout = dict(\n    title = 'Survey Respondents by Nationality',\n    geo = dict(\n        showframe = False,\n        showcoastlines = False,\n        projection = dict(\n            type = 'Mercator'\n        )\n    )\n)\n\nfig = dict( data=data, layout=layout )\npy.iplot( fig, validate=False, filename='survey-world-map')",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "pandas plotting",
                    "pandas plotting documentation",
                    "using a dataframe and matplotlib commands",
                    "plot using pandas plotting"
                ]
            },
            {
                "code": "#Get Summary Statistics of the Respndents' Ages.\nmcq['Age'].describe()",
                "true_label": "",
                "top5_preds": [
                    "from dictionary to dataframe",
                    "loading a csv into a dataframe",
                    "find data type of each column",
                    "load table in pandas",
                    "create a one column dataframe with the values of a series"
                ]
            },
            {
                "code": "mcq['PublicDatasetsSelect'] = mcq['PublicDatasetsSelect'].astype('str').apply(lambda x: x.split(','))",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "loading a csv into a dataframe",
                    "from dictionary to dataframe",
                    "formatting datetimes as strings",
                    "load table in pandas"
                ]
            },
            {
                "code": "q = mcq.apply(lambda x: pd.Series(x['PublicDatasetsSelect']),axis=1).stack().reset_index(level=1, drop=True)\nq.name = 'courses'",
                "true_label": "",
                "top5_preds": [
                    "from dictionary to dataframe",
                    "load table in pandas",
                    "create a dataframe by joining series by column",
                    "loading a csv into a dataframe",
                    "create a one column dataframe with the values of a series"
                ]
            },
            {
                "code": "q = q[q != 'nan'].value_counts()",
                "true_label": "",
                "top5_preds": [
                    "predicting a categorical response",
                    "computing the covariance when there are nan s",
                    "drop the rows with nan values",
                    "find data type of each column",
                    "line plot with a dataframe"
                ]
            },
            {
                "code": "plt.title(\"Most Popular Dataset Platforms\")\nsns.barplot(y=q.index, x=q)",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "equally spaced numbers on a grid",
                    "pandas plotting",
                    "line plots show the trend of a numerical variable over time",
                    "ploting out data with box plots"
                ]
            },
            {
                "code": "ff['PersonalProjectsChallengeFreeForm'].value_counts().head(15)",
                "true_label": "",
                "top5_preds": [
                    "loading a csv into a dataframe",
                    "find data type of each column",
                    "convert text data into vector",
                    "from dictionary to dataframe",
                    "load table in pandas"
                ]
            },
            {
                "code": "time_features = [x for x in mcq.columns if x.find('Time') != -1][4:10]",
                "true_label": "",
                "top5_preds": [
                    "loading a csv into a dataframe",
                    "load table in pandas",
                    "find data type of each column",
                    "from dictionary to dataframe",
                    "formatting datetimes as strings"
                ]
            },
            {
                "code": "tdf = {}\nfor feature in time_features:\n    tdf[feature[len('Time'):]] = mcq[feature].mean()\n\ntdf = pd.Series(tdf)\nprint(tdf)\nprint()\n\nplt.pie(tdf, labels=tdf.index, \n        autopct='%1.1f%%', shadow=True, startangle=140)\nplt.axis('equal')\nplt.title(\"Percentage of Time Spent on Each DS Job\")\nplt.show()",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "line plots show the trend of a numerical variable over time",
                    "using a dataframe and matplotlib commands",
                    "dataframe methods",
                    "ploting out data with box plots"
                ]
            },
            {
                "code": "job_factors = [x for x in mcq.columns if x.find('JobFactor') != -1]",
                "true_label": "",
                "top5_preds": [
                    "find data type of each column",
                    "load table in pandas",
                    "exploring the database with sql",
                    "delete column by name",
                    "loading a csv into a dataframe"
                ]
            },
            {
                "code": "sns.countplot(y='ProveKnowledgeSelect', data=mcq)",
                "true_label": "",
                "top5_preds": [
                    "predicting a categorical response",
                    "line plot with a dataframe",
                    "credible interval vs confidence interval",
                    "line plots show the trend of a numerical variable over time",
                    "using a dataframe and matplotlib commands"
                ]
            },
            {
                "code": "#Render a bar plot of the 15 most popular ML Tools for next year\ndata = mcq['MLToolNextYearSelect'].value_counts().head(15)\nsns.barplot(y=data.index, x=data)",
                "true_label": "",
                "top5_preds": [
                    "using a dataframe and matplotlib commands",
                    "line plot with a dataframe",
                    "pandas plotting",
                    "plotting time series with pandas",
                    "line plots show the trend of a numerical variable over time"
                ]
            },
            {
                "code": "data = mcq['MLMethodNextYearSelect'].value_counts().head(15)\nsns.barplot(y=data.index, x=data)",
                "true_label": "",
                "top5_preds": [
                    "create a one column dataframe with the values of a series",
                    "using a dataframe and matplotlib commands",
                    "working with pandas series indexed by datetime",
                    "line plot with a dataframe",
                    "plotting time series with pandas"
                ]
            },
            {
                "code": "#Explode the Pandas Dataframe to get the number of times each Learning Platform was mentioned\nmcq['LearningPlatformSelect'] = mcq['LearningPlatformSelect'].astype('str').apply(lambda x: x.split(','))\ns = mcq.apply(lambda x: pd.Series(x['LearningPlatformSelect']),axis=1).stack().reset_index(level=1, drop=True)\ns.name = 'platform'",
                "true_label": "",
                "top5_preds": [
                    "from dictionary to dataframe",
                    "create a dataframe by joining series by column",
                    "convert text data into vector",
                    "pandas apply",
                    "load table in pandas"
                ]
            },
            {
                "code": "plt.figure(figsize=(6,8))\ndata = s[s != 'nan'].value_counts()\nsns.barplot(y=data.index, x=data)",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "use pandas to make a bar chart",
                    "predicting a categorical response",
                    "pandas plotting",
                    "plot using pandas plotting"
                ]
            },
            {
                "code": "cdf = {}\nfor feature in cat_features:\n    cdf[feature[len('LearningCategory'):]] = mcq[feature].mean()\n\ncdf = pd.Series(cdf)\n\n#Plot a Pie Chart of the contribution of each platform to learning\nplt.pie(cdf, labels=cdf.index, \n        autopct='%1.1f%%', shadow=True, startangle=140)\nplt.axis('equal')\nplt.title(\"Contribution of each Platform to Learning\")\nplt.show()",
                "true_label": "",
                "top5_preds": [
                    "predicting a categorical response",
                    "line plot with a dataframe",
                    "find data type of each column",
                    "transform categorical data into binary features",
                    "line plots show the trend of a numerical variable over time"
                ]
            },
            {
                "code": "mcq[mcq['HardwarePersonalProjectsSelect'].notnull()]['HardwarePersonalProjectsSelect'].shape",
                "true_label": "",
                "top5_preds": [
                    "find data type of each column",
                    "remove null values from county, category, and category name",
                    "import polynomial features from sklearn",
                    "convert categorical variables",
                    "delete column by name"
                ]
            },
            {
                "code": "#Render Matplotlib Plots Inline\n%matplotlib inline\n\n#Import the standard Python Scientific Libraries\nimport pandas as pd\nimport numpy as np\nfrom scipy import stats\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n#Import Plotly and use it in the Offline Mode\nimport plotly\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.tools as tls\nimport plotly.graph_objs as go\nimport plotly.tools as tls\nimport plotly.figure_factory as fig_fact\nplotly.tools.set_config_file(world_readable=True, sharing='public')\n\n#Suppress Deprecation and Incorrect Usage Warnings \nimport warnings\nwarnings.filterwarnings('ignore')",
                "true_label": "",
                "top5_preds": [
                    "plot using matplotlib",
                    "trend lines in pyplot",
                    "line plot with a dataframe",
                    "plot using pandas plotting",
                    "using a dataframe and matplotlib commands"
                ]
            },
            {
                "code": "#Load MCQ Responses into a Pandas DataFrame\nmcq = pd.read_csv('../input/multipleChoiceResponses.csv', encoding=\"ISO-8859-1\", low_memory=False)\nmcq.shape",
                "true_label": "",
                "top5_preds": [
                    "loading a csv into a dataframe",
                    "importing data with numpy",
                    "load table in pandas",
                    "import polynomial features from sklearn",
                    "importing data with pandas"
                ]
            },
            {
                "code": "#Load Free Form Responses into a Pandas DataFrame\nff = pd.read_csv('../input/freeformResponses.csv', encoding=\"ISO-8859-1\", low_memory=False)\nff.shape",
                "true_label": "",
                "top5_preds": [
                    "loading a csv into a dataframe",
                    "importing data with numpy",
                    "load table in pandas",
                    "importing data with pandas",
                    "convert text data into vector"
                ]
            },
            {
                "code": "#The Seaborn Countplot function counts the number of instances of each category and renders a barplot.\nsns.countplot(y='GenderSelect', data=mcq)",
                "true_label": "",
                "top5_preds": [
                    "predicting a categorical response",
                    "pandas plotting",
                    "line plot with a dataframe",
                    "pandas plotting documentation",
                    "line plots show the trend of a numerical variable over time"
                ]
            },
            {
                "code": "mcq['CoursePlatformSelect'] = mcq['CoursePlatformSelect'].astype('str').apply(lambda x: x.split(','))",
                "true_label": "",
                "top5_preds": [
                    "find data type of each column",
                    "convert text data into vector",
                    "convert data from string to float",
                    "loading a csv into a dataframe",
                    "load table in pandas"
                ]
            },
            {
                "code": "t = mcq.apply(lambda x: pd.Series(x['CoursePlatformSelect']),axis=1).stack().reset_index(level=1, drop=True)\nt.name = 'courses'",
                "true_label": "",
                "top5_preds": [
                    "load table in pandas",
                    "from dictionary to dataframe",
                    "create a dataframe by joining series by column",
                    "create a one column dataframe with the values of a series",
                    "tensorflow + keras"
                ]
            },
            {
                "code": "t = t[t != 'nan'].value_counts()",
                "true_label": "",
                "top5_preds": [
                    "find data type of each column",
                    "computing the covariance when there are nan s",
                    "predicting a categorical response",
                    "convert categorical variables",
                    "dataframe methods"
                ]
            },
            {
                "code": "plt.title(\"Most Popular Course Platforms\")\nsns.barplot(y=t.index, x=t)",
                "true_label": "",
                "top5_preds": [
                    "use pandas to make a bar chart",
                    "line plots show the trend of a numerical variable over time",
                    "plotting time series with pandas",
                    "create a bar chart",
                    "line plot with a dataframe"
                ]
            },
            {
                "code": "use_features = [x for x in mcq.columns if x.find('LearningPlatformUsefulness') != -1]",
                "true_label": "",
                "top5_preds": [
                    "import polynomial features from sklearn",
                    "load table in pandas",
                    "exploring the database with sql",
                    "find data type of each column",
                    "convert text data into vector"
                ]
            },
            {
                "code": "#Construct a Pandas DataFrame to illustrate the usefulness of various learning platforms.\nfdf = {}\nfor feature in use_features:\n    a = mcq[feature].value_counts()\n    a = a/a.sum()\n    fdf[feature[len('LearningPlatformUsefulness'):]] = a\n\nfdf = pd.DataFrame(fdf).transpose()#.sort_values('Very useful', ascending=False)\n\n#Plot a Heatmap of Learning Platform Usefulness\nplt.figure(figsize=(6,12))\nsns.heatmap(fdf.sort_values(\"Very useful\", ascending=False), annot=True)\n\n#Plot a grouped barplot of Learning Platform Usefulness\nfdf.plot(kind='bar', figsize=(18,8), title=\"Usefullness of Learning Platforms\")\nplt.show()",
                "true_label": "",
                "top5_preds": [
                    "dataframe methods",
                    "line plot with a dataframe",
                    "find data type of each column",
                    "import polynomial features from sklearn",
                    "from dictionary to dataframe"
                ]
            },
            {
                "code": "mcq[mcq['AlgorithmUnderstandingLevel'].notnull()].shape",
                "true_label": "",
                "top5_preds": [
                    "find data type of each column",
                    "computing the covariance when there are nan s",
                    "import polynomial features from sklearn",
                    "shortcut principal component analysis in scikit learn",
                    "remove null values from county, category, and category name"
                ]
            },
            {
                "code": "sns.countplot(y='AlgorithmUnderstandingLevel', data=mcq)",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "line plots show the trend of a numerical variable over time",
                    "predicting a categorical response",
                    "credible interval vs confidence interval",
                    "using a dataframe and matplotlib commands"
                ]
            },
            {
                "code": "cat_features = [x for x in mcq.columns if x.find('LearningCategory') != -1]",
                "true_label": "",
                "top5_preds": [
                    "import polynomial features from sklearn",
                    "load table in pandas",
                    "find data type of each column",
                    "loading a csv into a dataframe",
                    "delete column by name"
                ]
            },
            {
                "code": "salary_stats('India')",
                "true_label": "",
                "top5_preds": [
                    "load table in pandas",
                    "getting data from the internet",
                    "predicting a categorical response",
                    "integrating datetime tools with pandas for time series",
                    "sum all the numbers in a list"
                ]
            },
            {
                "code": "salary_stats('United States')",
                "true_label": "",
                "top5_preds": [
                    "convert date to datetime format",
                    "sum all the numbers in a list",
                    "formatting datetimes as strings",
                    "load table in pandas",
                    "get a positive integer from a user"
                ]
            },
            {
                "code": "job_features = [x for x in mcq.columns if x.find('JobSkillImportance') != -1 and x.find('JobSkillImportanceOther') == -1]",
                "true_label": "",
                "top5_preds": [
                    "from dictionary to dataframe",
                    "load table in pandas",
                    "import polynomial features from sklearn",
                    "loading a csv into a dataframe",
                    "find data type of each column"
                ]
            },
            {
                "code": "#Get a Pandas DataFrame of Skill Importance of Data Science Jobs\njdf = {}\nfor feature in job_features:\n    a = mcq[feature].value_counts()\n    a = a/a.sum()\n    jdf[feature[len('JobSkillImportance'):]] = a\n#fdf = pd.DataFrame(fdf)\njdf = pd.DataFrame(jdf).transpose()\n\njdf.plot(kind='bar', figsize=(12,6), title=\"Skill Importance in Data Science Jobs\")",
                "true_label": "",
                "top5_preds": [
                    "from dictionary to dataframe",
                    "import polynomial features from sklearn",
                    "dataframe methods",
                    "find data type of each column",
                    "create a dataframe by joining series by column"
                ]
            },
            {
                "code": "mcq[mcq['CompensationAmount'].notnull()].shape",
                "true_label": "",
                "top5_preds": [
                    "find data type of each column",
                    "import polynomial features from sklearn",
                    "remove null values from county, category, and category name",
                    "computing the covariance when there are nan s",
                    "load table in pandas"
                ]
            },
            {
                "code": "#Convert all salary values to float. If not possible, convert it to NaN\ndef clean_salary(x):\n    x = x.replace(',', '')\n    try:\n        return float(x)\n    except:\n        return np.nan",
                "true_label": "",
                "top5_preds": [
                    "convert data from string to float",
                    "convert integer or float data",
                    "drop nan values",
                    "transform the date column as a datetime type",
                    "convert date to datetime format"
                ]
            },
            {
                "code": "#Function that outputs salary statistics and plots a salary distribution for that country\ndef salary_stats(country):\n    data = mcq[(mcq['CompensationAmount'].notnull()) & (mcq['Country'] == country) ]\n    data['CompensationAmount'] = data['CompensationAmount'].apply(clean_salary)\n    print(data[data['CompensationAmount'] < 1e9]['CompensationAmount'].describe())\n    sns.distplot(data[data['CompensationAmount'] < 1e9]['CompensationAmount'])",
                "true_label": "",
                "top5_preds": [
                    "calculate cost function from error function",
                    "return a dataframe",
                    "download and inspect the twitter samples dataset",
                    "get the data",
                    "remove redundant columns vol sold gal and county no"
                ]
            },
            {
                "code": "ff['PersonalProjectsChallengeFreeForm'].value_counts().head(15)",
                "true_label": "",
                "top5_preds": [
                    "loading a csv into a dataframe",
                    "find data type of each column",
                    "convert text data into vector",
                    "from dictionary to dataframe",
                    "load table in pandas"
                ]
            }
        ],
        [
            {
                "code": "import pandas as pd\nimport random\nfrom plotly.graph_objs import *",
                "true_label": "",
                "top5_preds": [
                    "plot using matplotlib",
                    "line plot with a dataframe",
                    "trend lines in pyplot",
                    "add edges in graph",
                    "line plots show the trend of a numerical variable over time"
                ]
            },
            {
                "code": "from plotly.offline import init_notebook_mode,iplot,plot\ninit_notebook_mode(connected=True)",
                "true_label": "",
                "top5_preds": [
                    "trend lines in pyplot",
                    "plot using matplotlib",
                    "line plot with a dataframe",
                    "equally spaced numbers on a grid",
                    "matplotlib"
                ]
            },
            {
                "code": "dataset = pd.read_csv('finalDataset.csv')\n\ndataset.head(3)",
                "true_label": "",
                "top5_preds": [
                    "loading a csv into a dataframe",
                    "optimal value of k for dataset",
                    "reading and writing csv files",
                    "importing data with pandas",
                    "line plot with a dataframe"
                ]
            },
            {
                "code": "yearList = [1990, 1995, 2000, 2005, 2010, 2014]",
                "true_label": "",
                "top5_preds": [
                    "add string to list using append",
                    "sum all the numbers in a list",
                    "convert date to datetime format",
                    "convert list to numpy array",
                    "formatting datetimes as strings"
                ]
            },
            {
                "code": "genreList = ['Action', 'Adventure', 'Animation', 'Biography', 'Comedy', 'Crime', \\\n 'Documentary', 'Drama', 'Family', 'Fantasy', 'History', 'Horror', \\\n 'Musical', 'Mystery' ,'Romance', 'Sci-Fi', 'Sport', 'Thriller', 'War', 'Western']",
                "true_label": "",
                "top5_preds": [
                    "create a list of all words",
                    "vectorize words in movie reviews",
                    "add string to list using append",
                    "sum all the numbers in a list",
                    "remove video games which has no title?"
                ]
            },
            {
                "code": "def calculateMeanRating(genre, year):\n    \n    return round(dataset[(dataset.GENRE.str.contains(genre, na = False)) & (dataset.YEAR == year)]['RATING'].mean(),2)\n",
                "true_label": "",
                "top5_preds": [
                    "the mean",
                    "calculate average",
                    "read the dataset point",
                    "read the dataset",
                    "convert data from string to float"
                ]
            },
            {
                "code": "def calculateMovieCount(genre, year):\n    \n    return len(dataset[(dataset.GENRE.str.contains(genre, na = False)) & (dataset.YEAR == year)])",
                "true_label": "",
                "top5_preds": [
                    "queries about movies",
                    "read the dataset",
                    "read table",
                    "read numbers until",
                    "find data type of each column"
                ]
            },
            {
                "code": "def calculateMeanBoxOffice(genre, year):\n    \n    return int(dataset[(dataset.GENRE.str.contains(genre, na = False)) & (dataset.YEAR == year)]['ADJ. BOX OFFICE'].mean())",
                "true_label": "",
                "top5_preds": [
                    "create a box plot",
                    "the mean",
                    "calculate the mean windspeed for each month in the dataset",
                    "create box plots",
                    "normalize the data point"
                ]
            },
            {
                "code": "def calculateStandradRating(year):\n    \n    return round(dataset[dataset.YEAR == year]['RATING'].mean(),2)",
                "true_label": "",
                "top5_preds": [
                    "convert data from string to float",
                    "convert integer or float data",
                    "read the dataset point",
                    "read the dataset",
                    "transform year column"
                ]
            },
            {
                "code": "\nlist1990 = [[calculateMeanRating(genre, yearList[0]) for genre in genreList], \\\n           [calculateMovieCount(genre, yearList[0]) for genre in genreList], \\\n           [calculateMeanBoxOffice(genre, yearList[0]) for genre in genreList]]\n\nlist1995 = [[calculateMeanRating(genre, yearList[1]) for genre in genreList], \\\n           [calculateMovieCount(genre, yearList[1]) for genre in genreList], \\\n           [calculateMeanBoxOffice(genre, yearList[1]) for genre in genreList]]\n\nlist2000 = [[calculateMeanRating(genre, yearList[2]) for genre in genreList], \\\n           [calculateMovieCount(genre, yearList[2]) for genre in genreList], \\\n           [calculateMeanBoxOffice(genre, yearList[2]) for genre in genreList]]\n\nlist2005 = [[calculateMeanRating(genre, yearList[3]) for genre in genreList], \\\n           [calculateMovieCount(genre, yearList[3]) for genre in genreList], \\\n           [calculateMeanBoxOffice(genre, yearList[3]) for genre in genreList]]\n\nlist2010 = [[calculateMeanRating(genre, yearList[4]) for genre in genreList], \\\n           [calculateMovieCount(genre, yearList[4]) for genre in genreList], \\\n           [calculateMeanBoxOffice(genre, yearList[4]) for genre in genreList]]\n\nlist2014 = [[calculateMeanRating(genre, yearList[5]) for genre in genreList], \\\n           [calculateMovieCount(genre, yearList[5]) for genre in genreList], \\\n           [calculateMeanBoxOffice(genre, yearList[5]) for genre in genreList]]\n",
                "true_label": "",
                "top5_preds": [
                    "sum all the numbers in a list",
                    "remove duplicates from a list",
                    "convert list to numpy array",
                    "add an item in a tuple",
                    "predicting a categorical response"
                ]
            },
            {
                "code": "standardRatingList = [calculateStandradRating(year) for year in yearList]",
                "true_label": "",
                "top5_preds": [
                    "integrating datetime tools with pandas for time series",
                    "sum all the numbers in a list",
                    "predicting a categorical response",
                    "formatting datetimes as strings",
                    "python data type list"
                ]
            },
            {
                "code": "randomColorList = ['rgb({},{},{})'.format(red, green, blue) \n    for red, green, blue in zip(random.sample(range(255), 20), random.sample(range(255), 20), random.sample(range(255), 20))]",
                "true_label": "",
                "top5_preds": [
                    "creating an rdd from a list",
                    "sum all the numbers in a list",
                    "multiply all the numbers in a list",
                    "create a list",
                    "remove duplicates from a list"
                ]
            },
            {
                "code": "def function_(xValue, yValue):\n    \n    return {\n        'x' : [-10000000] + xValue + [140000000],\n        'y' : 22 * [yValue],\n        'mode': 'lines',\n        'showlegend' : True,\n        'name': 'Standard Rating: ' + str(yValue),\n        'hoverinfo': 'text',\n        'text' : 'Standard Rating: ' + str(yValue)\n    }",
                "true_label": "",
                "top5_preds": [
                    "plot the function",
                    "plot the data",
                    "create a filter function point",
                    "read data point",
                    "create a line plot"
                ]
            },
            {
                "code": "def data_(rating, movieCount, boxoffice, genre, i):\n    \n    return {\n        'x' : [boxoffice],\n        'y' : [rating],\n        'name': genre,\n        'mode' : 'markers',\n        'marker': {\n            'size' : [movieCount],\n            'sizemode' : 'diameter',\n            'color' : randomColorList[i],\n            'line' : {\n                'width' : 1\n            } \n        },\n        'text' : 'Genre: ' + genre + \\\n                 '<br>Mean Rating: ' + str(rating) + \\\n                 '<br>Movie Count: ' + str(movieCount) + \\\n                 '<br>Mean Box Office: ' + str(round(boxoffice/1000000, 2)) + 'M',\n        'hoverinfo': 'text'\n    }",
                "true_label": "",
                "top5_preds": [
                    "get the data",
                    "create a data dictionary",
                    "create a dictionary with the data",
                    "read the dataset point",
                    "data given as a dictionary"
                ]
            },
            {
                "code": "figure = {\n    'data' : [], \n    'layout' : {},\n    'frames' : []\n}",
                "true_label": "",
                "top5_preds": [
                    "matplotlib",
                    "plot using matplotlib",
                    "using interact for animation with data",
                    "using a dataframe and matplotlib commands",
                    "how to change the size of a plot"
                ]
            },
            {
                "code": "figure['layout']['xaxis'] = {'title' : ' Mean Adj. Box Office',\n                             'titlefont' : {\n                                 'size' : 20, 'family' : 'Droid Sans'\n                             },\n                            'showline' : True,\n                            'zeroline' : False,\n                            'range' : [-10000000, 140000000],\n                            'gridcolor' : '#FFFFFF',\n                            'ticks' : 'outside',\n                            'tickwidth' : 2}\n\nfigure['layout']['yaxis'] = {'title' : 'Mean Rating',\n                            'titlefont' : {\n                                'size' : 20, 'family' : 'Droid Sans'\n                            },\n                            'showline' : True,\n                            'range' : [3.5,9],\n                            'gridcolor' : '#FFFFFF',\n                            'ticks' : 'outside',\n                            'tickwidth' : 2}\n\nfigure['layout']['title'] = 'Movie Analysis'\n\nfigure['layout']['titlefont'] = {'size' : 28, 'family' : 'Times New Roman'}\n\nfigure['layout']['plot_bgcolor'] = 'rgb(223,232,243)'\n\nfigure['layout']['updatemenus'] = [\n    {\n        'type': 'buttons',\n        'buttons' : [{\n            'label' : 'Play',\n            'method' : 'animate',\n            'args' : [None, {'frame' : {'duration' : 500, 'redraw': False},'fromcurrent': True,\n                             'transistion' : {'duration': 300, 'easing': 'quadratic-in-out'}}]\n        },\n        {\n            'label' :'Pause',\n            'method' : 'animate',\n            'args' : [[None], {'frame' : {'duration' : 0, 'redraw' : False}, 'mode': 'immediate',\n                                'transistion': {'duration': 0}}]\n        }],\n        'direction' : 'left',\n        'pad': {'r': 10, 't': 87},\n        'showactive' : False,\n        'x': 0.1,\n        'y': 0,\n        'xanchor': 'right',\n        'yanchor': 'top'\n    }\n]\n\nfigure['layout']['legend'] = { 'font': { 'family' : 'Droid Sans',  \n                                        'size' : 16 }}",
                "true_label": "",
                "top5_preds": [
                    "pandas plotting",
                    "matplotlib",
                    "on single figure",
                    "create box plots",
                    "plot using matplotlib"
                ]
            },
            {
                "code": "for i in range(len(genreList)):\n    figure['data'].append(data_(list1990[0][i], list1990[1][i], list1990[2][i], genreList[i], i))\n    \nfigure['data'].append(function_(list1990[2], standardRatingList[0]))",
                "true_label": "",
                "top5_preds": [
                    "plot using matplotlib",
                    "plotting in python",
                    "line plot with a dataframe",
                    "add string to list using append",
                    "using a dataframe and matplotlib commands"
                ]
            },
            {
                "code": "sliders_dict = {\n    'active': 0,\n    'yanchor': 'top',\n    'xanchor': 'left',\n    'currentvalue': {\n        'font': {'size': 20}, \n        'prefix': 'Year:',\n        'visible': True,\n        'xanchor': 'right'\n    },\n    'transition': {'duration': 300, 'easing': 'cubic-in-out'},\n    'pad': {'b': 10, 't': 50},\n    'len': 0.9,\n    'x': 0.1,\n    'y': 0,\n    'steps': []\n}",
                "true_label": "",
                "top5_preds": [
                    "graph",
                    "data given as a dictionary",
                    "error plots",
                    "get a positive integer from a user",
                    "on single figure"
                ]
            },
            {
                "code": "for year in yearList:\n    frame = {'data' : [], 'name': year}\n      \n    for i in range(len(genreList)):\n        if year == 1990:\n            frame['data'].append(data_(list1990[0][i], list1990[1][i], list1990[2][i], genreList[i], i))\n        elif year == 1995:\n            frame['data'].append(data_(list1995[0][i], list1995[1][i], list1995[2][i], genreList[i], i))\n        elif year == 2000:\n            frame['data'].append(data_(list2000[0][i], list2000[1][i], list2000[2][i], genreList[i], i))\n        elif year == 2005:\n            frame['data'].append(data_(list2005[0][i], list2005[1][i], list2005[2][i], genreList[i], i))\n        elif year == 2010:\n            frame['data'].append(data_(list2010[0][i], list2010[1][i], list2010[2][i], genreList[i], i))\n        else:\n            frame['data'].append(data_(list2014[0][i], list2014[1][i], list2014[2][i], genreList[i], i))\n         \n    if year == 1990:\n        frame['data'].append(function_(list1990[2], standardRatingList[0]))\n    elif year == 1995: \n        frame['data'].append(function_(list1995[2], standardRatingList[1]))\n    elif year == 2000:\n        frame['data'].append(function_(list2000[2], standardRatingList[2]))\n    elif year == 2005:\n        frame['data'].append(function_(list2005[2], standardRatingList[3]))\n    elif year == 2010:\n        frame['data'].append(function_(list2010[2], standardRatingList[4]))\n    else:\n        frame['data'].append(function_(list2014[2], standardRatingList[5]))\n        \n    figure['frames'].append(frame)\n        \n    slider_step = {'args': [\n        [year],\n        {'frame': {'duration': 300, 'redraw': True},\n         'mode': 'immediate',\n       'transition': {'duration': 300}}\n     ],\n     'label': year,\n     'method': 'animate'}\n    sliders_dict['steps'].append(slider_step)\n\n    \nfigure['layout']['sliders'] = [sliders_dict]",
                "true_label": "",
                "top5_preds": [
                    "create a data dictionary",
                    "get the data",
                    "create a dictionary with the data",
                    "create a list of retweet count and status tuples",
                    "getting the dataset"
                ]
            },
            {
                "code": "plot(figure)\n# iplot(figure)",
                "true_label": "",
                "top5_preds": [
                    "plot using matplotlib",
                    "matplotlib",
                    "plotting in python",
                    "create an array of linearly spaced points",
                    "matplotlib introduction"
                ]
            }
        ],
        [
            {
                "code": "import math\nimport numpy as np\nimport pandas as pd\n\nimport datashader as ds\nimport datashader.transfer_functions as tf\nfrom datashader.layout import random_layout, circular_layout, forceatlas2_layout\nfrom datashader.bundling import connect_edges, hammer_bundle\n\nfrom itertools import chain",
                "true_label": "",
                "top5_preds": [
                    "equally spaced numbers on a grid",
                    "add edges in graph",
                    "counting triangles in a social network",
                    "create an array of linearly spaced points",
                    "tensorflow + keras"
                ]
            },
            {
                "code": "np.random.seed(0)\nn=100\nm=20000\n\nnodes = pd.DataFrame([\"node\"+str(i) for i in range(n)], columns=['name'])\nnodes.tail()",
                "true_label": "",
                "top5_preds": [
                    "create a one column dataframe with the values of a series",
                    "load table in pandas",
                    "predicting a categorical response",
                    "line plot with a dataframe",
                    "dataframe methods"
                ]
            },
            {
                "code": "edges = pd.DataFrame(np.random.randint(0,len(nodes), size=(m, 2)),\n                     columns=['source', 'target'])\nedges.tail()",
                "true_label": "",
                "top5_preds": [
                    "relationships between dataframes",
                    "ridge regression with one predictor on a grid",
                    "join two dataframes along rows",
                    "line plot with a dataframe",
                    "add edges in graph"
                ]
            },
            {
                "code": "circular  = circular_layout(nodes, uniform=False)\nrandomloc = random_layout(nodes)\nrandomloc.tail()",
                "true_label": "",
                "top5_preds": [
                    "create an array of linearly spaced points",
                    "equally spaced numbers on a grid",
                    "ridge regression with one predictor on a grid",
                    "counting triangles in a social network",
                    "ridge regression with polynomial features on a grid"
                ]
            },
            {
                "code": "cvsopts = dict(plot_height=400, plot_width=400)\n\ndef nodesplot(nodes, name=None, canvas=None, cat=None):\n    canvas = ds.Canvas(**cvsopts) if canvas is None else canvas\n    aggregator=None if cat is None else ds.count_cat(cat)\n    agg=canvas.points(nodes,'x','y',aggregator)\n    return tf.spread(tf.shade(agg, cmap=[\"#FF3333\"]), px=3, name=name)\n\ntf.Images(nodesplot(randomloc,\"Random layout\"),\n          nodesplot(circular, \"Circular layout\"))",
                "true_label": "",
                "top5_preds": [
                    "plot the data",
                    "create a graph",
                    "plot the cdf",
                    "graph",
                    "plot the function"
                ]
            },
            {
                "code": "def edgesplot(edges, name=None, canvas=None):\n    canvas = ds.Canvas(**cvsopts) if canvas is None else canvas\n    return tf.shade(canvas.line(edges, 'x','y', agg=ds.count()), name=name)\n    \ndef graphplot(nodes, edges, name=\"\", canvas=None, cat=None):\n    if canvas is None:\n        xr = nodes.x.min(), nodes.x.max()\n        yr = nodes.y.min(), nodes.y.max()\n        canvas = ds.Canvas(x_range=xr, y_range=yr, **cvsopts)\n        \n    np = nodesplot(nodes, name + \" nodes\", canvas, cat)\n    ep = edgesplot(edges, name + \" edges\", canvas)\n    return tf.stack(ep, np, how=\"over\", name=name)",
                "true_label": "",
                "top5_preds": [
                    "create a graph",
                    "graph",
                    "plot the data",
                    "create a visualization",
                    "plot the function"
                ]
            },
            {
                "code": "cd = circular\nfd = forcedirected\n\n%time cd_d = graphplot(cd, connect_edges(cd,edges), \"Circular layout\")\n%time fd_d = graphplot(fd, connect_edges(fd,edges), \"Force-directed\") \n%time cd_b = graphplot(cd, hammer_bundle(cd,edges), \"Circular layout, bundled\")\n%time fd_b = graphplot(fd, hammer_bundle(fd,edges), \"Force-directed, bundled\") \n\ntf.Images(cd_d,fd_d,cd_b,fd_b).cols(2)",
                "true_label": "",
                "top5_preds": [
                    "add edges in graph",
                    "equally spaced numbers on a grid",
                    "plotting in python",
                    "trend lines in pyplot",
                    "matplotlib"
                ]
            },
            {
                "code": "n = 75\nnp.random.seed(0)\nx = np.random.random(n)\n\nsnodes = pd.DataFrame(np.stack((np.cos(2*math.pi*x),\n                               np.sin(2*math.pi*x))).T, columns=['x','y'])\nsnodes.iloc[0] = (0.0,0.0)\nsedges = pd.DataFrame(list(zip((range(1,n)),[0]*n)),columns=['source', 'target'])\nstar = snodes,sedges",
                "true_label": "",
                "top5_preds": [
                    "create an array of linearly spaced points",
                    "predicting a categorical response",
                    "equally spaced numbers on a grid",
                    "ridge regression with one predictor on a grid",
                    "line plot with a dataframe"
                ]
            },
            {
                "code": "tf.Images(graphplot(snodes, connect_edges(*star),\"Star\"),\n          graphplot(snodes, hammer_bundle(*star),\"Star bundled\"))",
                "true_label": "",
                "top5_preds": [
                    "create a graph",
                    "graph",
                    "draw flights graph",
                    "create flights graph",
                    "create a scatter plot"
                ]
            },
            {
                "code": "%time grid = \\\n  [graphplot(snodes, hammer_bundle(*star, iterations=5, \\\n                                   decay=decay, initial_bandwidth=bw), \\\n             \"d={:0.2f}, bw={:0.2f}\".format(decay, bw)) \\\n    for decay in [0.1, 0.25, 0.5, 0.9] \\\n    for bw    in [0.1, 0.2, 0.5, 1]]\n    \ntf.Images(*grid).cols(4)",
                "true_label": "",
                "top5_preds": [
                    "plot the function",
                    "heatmap with time",
                    "create a graph",
                    "create an array of linearly spaced points",
                    "create a bar chart"
                ]
            },
            {
                "code": "np.random.seed(1)\ncats,n,m = 4,80,1000\n\ncnodes = pd.concat([\n           pd.DataFrame.from_records([(\"node\"+str(i+100*c),\"c\"+str(c)) for i in range(n)], \n                        columns=['name','cat']) \n             for c in range(cats)], ignore_index=True)\ncnodes.cat=cnodes.cat.astype('category')\n\ncedges = pd.concat([\n           pd.DataFrame(np.random.randint(n*c,n*(c+1), size=(m, 2)), \n                        columns=['source', 'target'])\n         for c in range(cats)], ignore_index=True)",
                "true_label": "",
                "top5_preds": [
                    "predicting a categorical response",
                    "transform categorical data into binary features",
                    "convert categorical variables",
                    "list of categories",
                    "line plot with a dataframe"
                ]
            },
            {
                "code": "rd = random_layout(     cnodes, cedges)\nfd = forceatlas2_layout(cnodes, cedges)\n\n%time rd_d = graphplot(rd, connect_edges(rd,cedges), \"Random layout\",          cat=\"cat\")\n%time fd_d = graphplot(fd, connect_edges(fd,cedges), \"Force-directed\",         cat=\"cat\") \n%time rd_b = graphplot(rd, hammer_bundle(rd,cedges), \"Random layout, bundled\", cat=\"cat\")\n%time fd_b = graphplot(fd, hammer_bundle(fd,cedges), \"Force-directed, bundled\",cat=\"cat\") \n\ntf.Images(rd_d,fd_d,rd_b,fd_b).cols(2)",
                "true_label": "",
                "top5_preds": [
                    "create an array of linearly spaced points",
                    "equally spaced numbers on a grid",
                    "line plot with a dataframe",
                    "pandas plotting",
                    "heatmap with time"
                ]
            },
            {
                "code": "import networkx as nx\n\ndef ng(graph,name):\n    graph.name = name\n    return graph\n\ndef nx_layout(graph):\n    layout = nx.circular_layout(graph)\n    data = [[node, *layout[node]] for node in graph.nodes]\n\n    nodes = pd.DataFrame(data, columns=['id', 'x', 'y'])\n    nodes.set_index('id', inplace=True)\n\n    edges = pd.DataFrame(list(graph.edges), columns=['source', 'target'])\n    return nodes, edges\n\ndef nx_plot(graph, name=\"\"):\n    print(graph.name, len(graph.edges))\n    nodes, edges = nx_layout(graph)\n    \n    direct = connect_edges(nodes, edges)\n    bundled_bw005 = hammer_bundle(nodes, edges)\n    bundled_bw030 = hammer_bundle(nodes, edges, initial_bandwidth=0.30)\n\n    return [graphplot(nodes, direct,         graph.name),\n            graphplot(nodes, bundled_bw005, \"Bundled bw=0.05\"),\n            graphplot(nodes, bundled_bw030, \"Bundled bw=0.30\")]",
                "true_label": "",
                "top5_preds": [
                    "create a graph",
                    "graph",
                    "add edges in graph",
                    "create an array of linearly spaced points",
                    "graph analysis"
                ]
            },
            {
                "code": "n=50\nplots = [nx_plot(g) for g in\n           [ng(nx.complete_graph(n),        name=\"Complete\"), \n            ng(nx.lollipop_graph(n, 5),     name=\"Lollipop\"),     \n            ng(nx.barbell_graph(n,2),       name=\"Barbell\"),\n            ng(nx.ladder_graph(n),          name=\"Ladder\"),   \n            ng(nx.circular_ladder_graph(n), name=\"Circular Ladder\"), \n            ng(nx.star_graph(n),            name=\"Star\"),\n            ng(nx.cycle_graph(n),           name=\"Cycle\")]]\n\ntf.Images(*chain.from_iterable(plots)).cols(3)",
                "true_label": "",
                "top5_preds": [
                    "create a graph",
                    "graph",
                    "graph analysis",
                    "add edges in graph",
                    "create an array of linearly spaced points"
                ]
            },
            {
                "code": "import holoviews.operation.datashader as hd\nimport holoviews as hv\nhv.extension(\"bokeh\")\nopts=dict()\n\ncircle = hv.Graph(edges, label='Bokeh edges').opts(style=dict(node_size=5))\nhnodes = circle.nodes.opts(style=dict(size=5))\ndscirc = (hd.dynspread(hd.datashade(circle))*hnodes).relabel(\"Datashader edges\")\n\ncircle + dscirc",
                "true_label": "",
                "top5_preds": [
                    "plot using matplotlib",
                    "counting triangles in a social network",
                    "ploting out data with box plots",
                    "matplotlib",
                    "add edges in graph"
                ]
            }
        ],
        [
            {
                "code": "#save this notebook to S3\ns3.Bucket('migrationmodeldigitalproto').upload_file('/home/ubuntu/code/amway/silver_gold/Example_Raytune.ipynb','silvergold/code/notebooks/Example_Raytune.ipynb')\n",
                "true_label": "",
                "top5_preds": [
                    "convert a tuple to a string",
                    "reading and writing binary files",
                    "running a local postgres database",
                    "importing data with numpy",
                    "import polynomial features from sklearn"
                ]
            },
            {
                "code": "import s3fs\nimport boto3\n\ns3_client = boto3.client('s3')\ns3 = boto3.resource('s3')\nfs = s3fs.S3FileSystem(anon=False)\n\nimport joblib\nfrom joblib import Parallel, delayed\nfrom catboost import *\nimport shap\n\nshap.initjs()\n\nimport statsmodels as sm\n\nfrom pdpbox import pdp, get_dataset, info_plots\nfrom catboost import CatBoostClassifier, Pool,cv\n\nfrom IPython.display import clear_output\n\nfrom io import BytesIO\nfrom sklearn.feature_selection import mutual_info_classif\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.linear_model import LogisticRegression,LogisticRegressionCV\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier,ExtraTreesClassifier,GradientBoostingClassifier\nfrom mlxtend.classifier import StackingCVClassifier\nfrom sklearn.model_selection import StratifiedKFold, GridSearchCV, RandomizedSearchCV\nfrom sklearn.feature_selection import RFECV, RFE\nfrom sklearn.preprocessing import OneHotEncoder,LabelBinarizer\n\nimport ray\nfrom ray.tune import run_experiments, register_trainable\nfrom ray.tune.suggest import HyperOptSearch \n\n\n\n\n\n\n\n\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.externals.six import StringIO  \nfrom IPython.display import Image  \nfrom sklearn.tree import export_graphviz\nimport pydotplus\n\n\n\nfrom ipywidgets import interact\n%matplotlib inline\n\n#from IPython.display import display\n\n\nimport xgboost as xgb\nimport pandas as pd\nimport numpy as np\nimport sys \nimport os\nimport matplotlib.pyplot as plt\nimport lightgbm as lgb\nimport xgbfir\npd.set_option('display.max_columns', 500)\npd.set_option('display.max_rows', 500)\npd.set_option('display.max_colwidth', 1500)\n\nimport time\nimport datetime\n\n\nsys.path.append(os.path.abspath(\"/home/ubuntu/code\"))\n\nfrom scipy.stats import randint as sp_randint\n\n\nimport eval_functions\nimport pdp\nfrom plot_1D_response import plot_1D_response\nimport freq_table\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import RandomizedSearchCV, train_test_split, cross_val_predict,KFold,cross_val_score\nfrom sklearn.feature_selection import SelectKBest, chi2,mutual_info_classif\n\n\nfrom sklearn.metrics import log_loss\n\nimport lime\nimport lime.lime_tabular\n\nfrom hyperopt import hp,fmin,tpe,Trials, STATUS_OK\nfrom hyperopt.mongoexp import MongoTrials\nfrom hyperopt.pyll import stochastic\n\nfrom xgboost import XGBClassifier\n\nos.environ['KERAS_BACKEND'] = 'tensorflow'\n\nfrom keras.models import Sequential, Model\nfrom keras.layers import LSTM, Dense,  Activation, Input, Masking,Dropout,concatenate #https://stackoverflow.com/questions/44720822/valueerror-with-concatenate-layer-keras-functional-api\nfrom keras.optimizers import Adam, RMSprop\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\nimport keras.backend as K\nfrom keras.wrappers.scikit_learn import KerasClassifier\n\n\ndef shap_table(shap_values,X,shap_vars,index,top_n,pos_neg = 'ALL',plot=True):\n    \n    df_shap=pd.DataFrame(list(zip(shap_values[index,:],shap_vars)), columns=['SHAP','Feature'])\n    \n        \n    if pos_neg == 'ALL':\n        df_shap['val_sort']=np.abs(df_shap['SHAP'].values)\n    else:\n        df_shap['val_sort']=df_shap['SHAP'].values\n    \n    if pos_neg == 'NEG':\n            ascending_sort = True\n    else:\n        ascending_sort = False\n    \n    df_shap=df_shap.sort_values ('val_sort',ascending=ascending_sort)\n    \n    df_shap =df_shap.iloc[0:top_n,0:2]\n    cols_returned=df_shap.Feature.tolist()\n    df=X.iloc[index,:][cols_returned]\n    df_shap['Actual_Value']=df.values.T    \n  \n    \n    df_shap['pos'] = df_shap['SHAP'] > 0\n    \n\n    \n    if plot:\n        plt.rcdefaults()\n        fig, ax = plt.subplots()\n        y_pos = np.arange(top_n)\n        ax.barh(y_pos, df_shap.SHAP.values, align='center',color=list(df_shap.pos.map({True: 'r', False: 'b'}).values))\n        ax.set_yticks(y_pos)\n        ax.set_yticklabels( df_shap.Feature.values)\n        ax.set_xlabel('Estimated Impact on Prediction (Change from Average Prediction)')\n        plt.axvline(x=0)\n        plt.gca().invert_yaxis()\n        plt.show()\n    return(df_shap.iloc[:,0:3])\n\n\n\n\n\nd1={24.0: 'INDONESIA',\n134.0: 'BULGARIA',\n60.0: 'BOTSWANA',\n61.0: 'BRUNEI',\n43.0: 'URUGUAY',\n37.0: 'SWEDEN',\n40.0: 'CHILE',\n49.0: 'EL SALVADOR',\n45.0: 'FINLAND',\n32.0: 'IRELAND',\n56.0: 'CROATIA',\n47.0: 'GREECE',\n73.0: 'VIETNAM',\n38.0: 'ARGENTINA',\n19.0: 'MEXICO',\n23.0: 'AUSTRIA',\n4.0: 'CANADA',\n17.0: 'POLAND',\n46.0: 'DENMARK',\n21.0: 'COLOMBIA',\n30.0: 'NORWAY',\n55.0: 'VENEZUELA',\n74.0: 'LATVIA',\n57.0: 'UKRAINE',\n29.0: 'PORTUGAL',\n51.0: 'SINGAPORE',\n41.0: 'RUSSIA',\n75.0: 'LITHUANIA',\n54.0: 'ROMANIA',\n3.0: 'UNITED STATES',\n33.0: 'BRAZIL',\n114.0: 'KAZAKHSTAN',\n35.0: 'PHILIPPINES',\n39.0: 'CZECH REPUBLIC',\n28.0: 'GUATEMALA',\n42.0: 'INDIA',\n18.0: 'ITALY',\n14.0: 'BELGIUM',\n20.0: 'KOREA',\n52.0: 'SOUTH AFRICA',\n48.0: 'SLOVAKIA',\n31.0: 'COSTA RICA',\n6.0: 'UK',\n11.0: 'NETHERLANDS',\n22.0: 'THAILAND',\n8.0: 'GERMANY',\n5.0: 'AUSTRALIA',\n44.0: 'TURKEY',\n25.0: 'PANAMA',\n50.0: 'HONDURAS',\n12.0: 'MALAYSIA',\n53.0: 'DOMINICAN REPUBLIC',\n34.0: 'HUNGARY',\n10.0: 'FRANCE',\n59.0: 'NAMIBIA',\n15.0: 'TAIWAN',\n16.0: 'SLOVENIA',\n26.0: 'NEW ZEALAND',\n9.0: 'JAPAN',\n27.0: 'SPAIN',\n76.0: 'ESTONIA',\n13.0: 'SWITZERLAND'}\n\n\nfrom OOFCallback import OOFCallback",
                "true_label": "",
                "top5_preds": [
                    "import polynomial features from sklearn",
                    "load table in pandas",
                    "importing data with numpy",
                    "importing functions",
                    "import stuff"
                ]
            },
            {
                "code": "X_train=pd.read_csv( 's3://migrationmodeldigitalproto/silvergold/data/outputs/X_train.csv')\nX_test=pd.read_csv('s3://migrationmodeldigitalproto/silvergold/data/outputs/X_test.csv')\ny_train=pd.read_csv('s3://migrationmodeldigitalproto/silvergold/data/outputs/y_train.csv',header=None)\ny_test=pd.read_csv('s3://migrationmodeldigitalproto/silvergold/data/outputs/y_test.csv',header=None)",
                "true_label": "",
                "top5_preds": [
                    "importing data with numpy",
                    "load table in pandas",
                    "from dictionary to dataframe",
                    "loading a csv into a dataframe",
                    "convert text data into vector"
                ]
            },
            {
                "code": "X_train['TIME_LEFT']=np.where(X_train.MONTH_SILVER > 8, 12-(X_train.MONTH_SILVER-8),8-X_train.MONTH_SILVER)\nX_train['STILL_TIME']=np.where(( (X_train.CUM_SILVER_FY < 6) & (X_train.TIME_LEFT >= (6-X_train.CUM_SILVER_FY))) | ((X_train.CUM_SILVER_FY >= 6) & (X_train.TIME_LEFT >= (12-X_train.CUM_SILVER_FY))) ,1,0)\n\ncntry_apps=pd.read_csv( 's3://migrationmodeldigitalproto/silvergold/data/inputs/country_apps.csv')\nadditional_imc_dat=pd.read_csv( 's3://migrationmodeldigitalproto/silvergold/data/inputs/additional_imc_dat.csv')\nprint(X_train.shape)\n#join to train\nX_train=pd.merge(X_train,cntry_apps, right_on=['MO_YR_KEY_NO', 'CNTRY_KEY_NO'],left_on=['MO_YR_KEY_NO', 'CNTRY_KEY_NO'],how=\"left\")\nprint(X_train.shape)\nX_train=pd.merge(X_train,additional_imc_dat, right_on=['MO_YR_KEY_NO', 'IMC_KEY_NO'],left_on=['MO_YR_KEY_NO', 'IMC_KEY_NO'],how=\"left\")\nprint(X_train.shape)\n\n\nX_train=X_train.fillna(0)\nX_train=X_train.replace(np.inf, 0)\n\n\nX_test['TIME_LEFT']=np.where(X_test.MONTH_SILVER > 8, 12-(X_test.MONTH_SILVER-8),8-X_test.MONTH_SILVER)\nX_test['STILL_TIME']=np.where(( (X_test.CUM_SILVER_FY < 6) & (X_test.TIME_LEFT >= (6-X_test.CUM_SILVER_FY))) | ((X_test.CUM_SILVER_FY >= 6) & (X_test.TIME_LEFT >= (12-X_test.CUM_SILVER_FY))) ,1,0)\n\n\nprint(X_test.shape)\n#join to train\nX_test=pd.merge(X_test,cntry_apps, right_on=['MO_YR_KEY_NO', 'CNTRY_KEY_NO'],left_on=['MO_YR_KEY_NO', 'CNTRY_KEY_NO'],how=\"left\")\nprint(X_test.shape)\nX_test=pd.merge(X_test,additional_imc_dat, right_on=['MO_YR_KEY_NO', 'IMC_KEY_NO'],left_on=['MO_YR_KEY_NO', 'IMC_KEY_NO'],how=\"left\")\nprint(X_test.shape)\n\n\n\nX_test=X_test.fillna(0)\nX_test=X_test.replace(np.inf, 0)",
                "true_label": "",
                "top5_preds": [
                    "integrating datetime tools with pandas for time series",
                    "create a one column dataframe with the values of a series",
                    "line plots show the trend of a numerical variable over time",
                    "using a dataframe and matplotlib commands",
                    "line plot with a dataframe"
                ]
            },
            {
                "code": "keep_vars2=['PRCNT_PV_CUST',\n#'TTL_IBO_DOWN',\n'DEPTH_WIDTH',\n'PRNCT_ENGAGED_FRONTLN',\n'PRNCT_RPT_BUYER',\n'NUMBER_LEGS_BONUS',      \n'PERS_TO_GRP_PV_RATIO',\n'BNS_DIF_TO_PERS',         \n'BNS_DIF_USD_AMT',\n'CNTRY_KEY_NO',        \n'TARGET_RATE_DIA',\n'MONTH_SILVER'  ,     \n'PERS_GRP_PV_RATIO_IBO_LEVEL_1',\n\n'PRIOR_SILVER_6',\n'PRIOR_BONUSAMT_12_CV',\n'PRCNT_PV_FROM_RPT_ABO',\n'PRCNT_PV_LEVEL_1',\n'LEGS_12_PLUS_BNS',\n'IMC_MONTHS_AFTER_SIGNUP',\n'PRIOR_PERS_GRP_PV_RT_6_CV',\n'RATIO_RPT_BUYERS_6MONTH',\n\n'RATIO_LEGS_6MONTH',\n'RATIO_GROUPPV_6MONTH',        \n'IMC_GROUP_PV',\n          \n'PRCNT_PVIBO_MB3',\n'IMC_QUAL_LEGS_QTY',\n'BNS_USD_AMT_IBO_LEVEL_4', \n'IMC_KEY_NO',\n'MO_YR_KEY_NO',\n\n    'STILL_TIME',\n    'RATIO_APPS_3_14',\n            \n       #'PROP_BL_OTHER_ORD_CNT_3', \n       #     'PROP_BL_DURABLES_ORD_CNT_3',\n       #'PROP_BL_HOMECARE_ORD_CNT_3', \n       'PROP_LAST_3DAY_PV_LC_AMT_3', \n        'PROP_RTURN_PV_LC_AMT_3',\n       'AVG_DMD_ORD_CNT_3',\n       #     'PROP_RTURN_PV_LC_AMT_0',\n            'APP_1_AGE',\n            'APP_2_POP', \n            'LPY_FLAGS', \n            'CONTRIBUTORS'\n           ]             ",
                "true_label": "",
                "top5_preds": [
                    "import polynomial features from sklearn",
                    "setup and re introduction to python",
                    "detect the number of local variables declared in a function",
                    "the mean of difference of variables",
                    "calculating the mean of a vector with nans"
                ]
            }
        ],
        [
            {
                "code": "import boto3\n\nimport rasterio\nimport numpy as np\n\nimport os\nimport sys\nimport threading",
                "true_label": "",
                "top5_preds": [
                    "timing, numpy, plotting",
                    "equally spaced numbers on a grid",
                    "matrix operations in python",
                    "heatmap with time",
                    "convert list to numpy array"
                ]
            },
            {
                "code": "# Local storage\nlocal_folder = \"/Users/nathansuberi/Desktop/WRI_Programming/RW_Data/\"\nrw_data_type = local_folder + \"Biodiversity/\"\n\nlocal_orig = rw_data_type + \"amphibians_all_threats.tif\"\nlocal_edit = local_orig[:-4] + \"_edit.tif\"\n\n# S3 storage\ns3_bucket = \"wri-public-data\"\ns3_folder = \"resourcewatch/bio_012_1_amphibian_species_under_threat/\"\n\ns3_key_orig = s3_folder + \"bio_012_1_amphibian_species_under_threat.tif\"\ns3_key_edit = s3_key_orig[0:-4] + \"_edit.tif\"\n\n# S3 services\ns3_download = boto3.resource(\"s3\")\ns3_upload = boto3.client(\"s3\")\n\n# Helper function to view upload progress\nclass ProgressPercentage(object):\n        def __init__(self, filename):\n            self._filename = filename\n            self._size = float(os.path.getsize(filename))\n            self._seen_so_far = 0\n            self._lock = threading.Lock()\n\n        def __call__(self, bytes_amount):\n            # To simplify we'll assume this is hooked up\n            # to a single filename.\n            with self._lock:\n                self._seen_so_far += bytes_amount\n                percentage = (self._seen_so_far / self._size) * 100\n                sys.stdout.write(\n                    \"\\r%s  %s / %s  (%.2f%%)\" % (\n                        self._filename, self._seen_so_far, self._size,\n                        percentage))\n                sys.stdout.flush()",
                "true_label": "",
                "top5_preds": [
                    "reading and writing binary files",
                    "extracting zip files",
                    "running a local postgres database",
                    "accessing databases via web apis",
                    "convert a tuple to a string"
                ]
            },
            {
                "code": "s3_download.meta.client.download_file(s3_bucket, s3_key_orig, local_orig)",
                "true_label": "",
                "top5_preds": [
                    "getting data from the internet",
                    "reading and writing binary files",
                    "download and inspect the twitter samples dataset",
                    "twitter api access",
                    "find maximum and the minimum value in a set"
                ]
            },
            {
                "code": "s3_upload.upload_file(local_orig, s3_bucket, s3_key_orig,\n                         Callback=ProgressPercentage(local_orig))",
                "true_label": "",
                "top5_preds": [
                    "download and inspect the twitter samples dataset",
                    "read images point",
                    "getting data from the internet",
                    "get a positive integer from a user",
                    "reading and writing binary files"
                ]
            },
            {
                "code": "# Adjust kwargs\n\nwith rasterio.open(local_orig) as src:\n    kwargs = src.profile\n\nprint(kwargs)\n\nnodata_val = 0\ndata_type = rasterio.int32\nt_crs = 'EPSG:4326'\n\nkwargs.update(\n    old_nodata = kwargs[\"nodata\"],\n    driver='GTiff',\n    dtype=data_type,  #rasterio.int16, rasterio.int32, rasterio.uint8,rasterio.uint16, rasterio.uint32, rasterio.float32, rasterio.float64\n    count=1,\n    compress='lzw',\n    nodata=nodata_val,\n    bigtiff='NO',\n    crs = t_crs,\n    tiled = False\n)\n\nkwargs.pop(\"blockxsize\", None)\nkwargs.pop(\"blockysize\", None)\n\nprint(kwargs)",
                "true_label": "",
                "top5_preds": [
                    "optimal value of k for dataset",
                    "helpers to read in dataset",
                    "numpy point",
                    "resampling and frequency conversion",
                    "create an array of linearly spaced points"
                ]
            }
        ],
        [
            {
                "code": "method_parameters_combinations = {\n              'blast+' : {'p-evalue': [0.001],\n                          'p-maxaccepts': [1, 10],\n                          'p-perc-identity': [0.80, 0.97, 0.99],\n                          'p-min-consensus': [0.51, 0.75, 0.99]}\n             }\n\ncommand_template = (\"mkdir -p {0}; \"\n                    \"qiime feature-classifier classify-consensus-blast --i-query {1} --o-classification \"\n                    \"{0}/rep_seqs_tax_assignments.qza --i-reference-reads {2} --i-reference-taxonomy {3} {5}; \"\n                    \"qiime tools export {0}/rep_seqs_tax_assignments.qza --output-dir {0}; \"\n                    \"mv {0}/taxonomy.tsv {0}/query_tax_assignments.txt\")\n        \n(dataset_reference_combinations, reference_dbs) = recall_novel_taxa_dirs(\\\n    data_dir, databases, iterations, ref_seqs='ref_seqs.qza',\n    ref_taxa='ref_taxa.qza', max_level=6, min_level=5, multilevel=False)\n\ncommands = parameter_sweep(data_dir, results_dir, reference_dbs,\n                           dataset_reference_combinations,\n                           method_parameters_combinations, command_template,\n                           infile='query.qza', output_name='rep_seqs_tax_assignments.qza')",
                "true_label": "",
                "top5_preds": [
                    "function fit_and_predict",
                    "fit a polynomial",
                    "sampling, simulation",
                    "setup and re introduction to python",
                    "one class svm fitting and estimates"
                ]
            },
            {
                "code": "print(len(commands))\nprint(commands[0])",
                "true_label": "",
                "top5_preds": [
                    "convert list to numpy array",
                    "sum all the numbers in a list",
                    "getting data from the internet",
                    "multiply all the numbers in a list",
                    "get a positive integer from a user"
                ]
            },
            {
                "code": "Parallel(n_jobs=23)(delayed(system)(command) for command in commands);",
                "true_label": "",
                "top5_preds": [
                    "building a mini lsst broker for data management and discovery",
                    "matrix operations in python",
                    "linear regression of many variables",
                    "equally spaced numbers on a grid",
                    "getting data from the internet"
                ]
            },
            {
                "code": "method_parameters_combinations = {\n              'vsearch' : {'p-maxaccepts': [1, 10],\n                           'p-perc-identity': [0.80, 0.90, 0.97, 0.99],\n                           'p-min-consensus': [0.51, 0.99]}\n             }\n\ncommand_template = (\"mkdir -p {0}; \"\n                    \"qiime feature-classifier classify-consensus-vsearch --i-query {1} --o-classification \"\n                    \"{0}/rep_seqs_tax_assignments.qza --i-reference-reads {2} --i-reference-taxonomy {3} {5}; \"\n                    \"qiime tools export {0}/rep_seqs_tax_assignments.qza --output-dir {0}; \"\n                    \"mv {0}/taxonomy.tsv {0}/query_tax_assignments.txt\")\n        \ncommands = parameter_sweep(data_dir, results_dir, reference_dbs,\n                           dataset_reference_combinations,\n                           method_parameters_combinations, command_template,\n                           infile='query.qza', output_name='rep_seqs_tax_assignments.qza')",
                "true_label": "",
                "top5_preds": [
                    "function fit_and_predict",
                    "one class svm fitting and estimates",
                    "fit a polynomial",
                    "creating polynomial features",
                    "shortcut principal component analysis in scikit learn"
                ]
            },
            {
                "code": "p_feat_ext__ngram_range = [\n    '[6,6]', '[8,8]', '[12,12]', '[16,16]'\n]\n\n# ['[4,4]', '[6,6]', '[8,8]', '[16,16]', '[32,32]',\n# '[7,7]', '[9,9]', '[10,10]', '[11,11]', \n# '[12,12]', '[14,14]', '[18,18]'],\n\nmethod_parameters_combinations = {\n    'naive-bayes' : {'p-feat-ext--ngram-range': p_feat_ext__ngram_range,\n                     'p-classify--alpha': [0.001]},\n    'naive-bayes-bespoke' : {'p-feat-ext--ngram-range': p_feat_ext__ngram_range,\n                             'p-classify--alpha': [0.001],\n                             'p-classify--fit-prior': ['']}\n}\n\ncommand_template = ('mkdir -p \"{0}\"; '\n                    'qiime feature-classifier fit-classifier-naive-bayes --o-classifier '\n                    '\"{0}/classifier.qza\" --i-reference-reads {2} --i-reference-taxonomy {3} {5}; ')\n\nconfidences = [0.5, 0.7, 0.9, 0.96, 0.99]\n\n# [0.0, 0.5, 0.7, 0.9, 0.92, 0.94,\n#  0.96, 0.98, 0.99]\n\ncommand_template += ''.join(\n    'mkdir -p \"{0}:' + str(c) + '\"; '\n    'qiime feature-classifier classify-sklearn '\n    '--o-classification \"{0}:' + str(c) + '/rep_seqs_tax_assignments.qza\" '\n    '--i-classifier \"{0}/classifier.qza\" '\n    '--i-reads {1} --p-confidence ' + str(c) + '; '\n    'qiime tools export \"{0}:' + str(c) + '/rep_seqs_tax_assignments.qza\" --output-dir \"{0}:' + str(c) + '\"; '\n    'mv \"{0}:' + str(c) + '/taxonomy.tsv\" \"{0}:' + str(c) + '/query_tax_assignments.txt\"; 'for c in confidences)\n\ncommand_template += 'rm \"{0}/classifier.qza\"; rmdir \"{0}\"'\n\n(dataset_reference_combinations, reference_dbs) = recall_novel_taxa_dirs(\\\n    data_dir, databases, iterations, ref_seqs='ref_seqs.qza',\n    ref_taxa='ref_taxa.qza', max_level=6, min_level=5, multilevel=False)\n\ncommands = parameter_sweep(data_dir, results_dir, reference_dbs,\n                           dataset_reference_combinations,\n                           method_parameters_combinations, command_template,\n                           infile='query.qza', output_name='rep_seqs_tax_assignments.qza')",
                "true_label": "",
                "top5_preds": [
                    "range of feature",
                    "import polynomial features from sklearn",
                    "creating polynomial features",
                    "implementing bag of words in scikit learn",
                    "what is scikit learn?"
                ]
            },
            {
                "code": "print(len(commands), 'commands')\nprint('\\n\\n'.join(commands[0].split(';')))",
                "true_label": "",
                "top5_preds": [
                    "formatting datetimes as strings",
                    "python data type list",
                    "convert a tuple to a string",
                    "add string to list using append",
                    "find hashtags using list comprehensions"
                ]
            },
            {
                "code": "# this filepath needs to point to the directory in which the SEPP wrapper can be found\nfp_wrapper_script = '../../../q2-fragment-insertion/tax-credit/'\n\nmethod_parameters_combinations = {\n    'sepp-paths': {'method': ['path'], 'reference_name': ['gg138']},\n    'sepp-otus': {'method': ['otus'], 'reference_name': ['gg138']}\n}\n\ncommand_template = \"%s/wrapper_sepp.py {1} {0}/query_tax_assignments.txt {5} --cross_validate\" % (\n    fp_wrapper_script)\n\n\ncommands = parameter_sweep(data_dir, results_dir, reference_dbs,\n                           dataset_reference_combinations,\n                           method_parameters_combinations, command_template,\n                           infile='query.qza', output_name='rep_seqs_tax_assignments.qza')",
                "true_label": "",
                "top5_preds": [
                    "setup and re introduction to python",
                    "postgres sql lab",
                    "scipy",
                    "import polynomial features from sklearn",
                    "running a local postgres database"
                ]
            }
        ],
        [
            {
                "code": "import diagonalizer_trivial_topology\nfrom diagonalizer_trivial_topology import SimpleNamespace, diagonalize, pSweep, \\\n                                            spectrum_plot, density_plot, FinalizedSystem_trivial\nimport numpy as np\nfrom copy import copy\nfrom numpy import pi, cos, sin\n\nSitesCount_Default = 200\nfsysDefault = FinalizedSystem_trivial(SitesCount_Default)\n\n#The parameters are taken from the Qi-Zhang RevModPhys for Bi2Se3\nParametersDefault = SimpleNamespace( Gap = 1.0, \\\n                     FermiEnergy = 0.0, lBinv2=0., x_shift= (SitesCount_Default - 1.)/2., \\\n                     EigenvectorsCount = 50, EnergyPrecision = 10**(-5), WavefunctionComponents = 2, \\\n                     py = 0.) #, pz = 0. )",
                "true_label": "",
                "top5_preds": [
                    "import polynomial features from sklearn",
                    "equally spaced numbers on a grid",
                    "ridge regression with polynomial features on a grid",
                    "creating polynomial features",
                    "optimal value of k for dataset"
                ]
            },
            {
                "code": "params = copy(ParametersDefault)\nparams.Rescale_onsite_0 = 0.3\nevals, evecs = pSweep(fsysDefault, params, -pi, pi, 20, 'pySweep')\nspectrum_plot(evals, -pi, pi, 20)\n\ndensity_plot(fsysDefault, params, evecs[10])",
                "true_label": "",
                "top5_preds": [
                    "create an array of linearly spaced points",
                    "line plots show the trend of a numerical variable over time",
                    "fit a polynomial",
                    "optimal value of k for dataset",
                    "hypothesis testing with slopes"
                ]
            }
        ],
        [
            {
                "code": "# Dependencies and setup\nimport requests\nimport pysb\nfrom IPython.display import display\nfrom IPython.core.display import HTML\n\n_habitatMapRoot = \"527d0a83e4b0850ea0518326\"",
                "true_label": "",
                "top5_preds": [
                    "ipython / jupyter environment",
                    "using python, ipython,",
                    "trend lines in pyplot",
                    "setup and re introduction to python",
                    "ipython"
                ]
            },
            {
                "code": "sb = pysb.SbSession()\nusername = input(\"Username: \")\nsb.loginc(str(username))",
                "true_label": "",
                "top5_preds": [
                    "get a positive integer from a user",
                    "postgres sql lab",
                    "running a local postgres database",
                    "connect to a remote database",
                    "getting data from the internet"
                ]
            },
            {
                "code": "# Retrieve the habitat map root item from ScienceBase\nhabitatMapRootItem = sb.get_item(_habitatMapRoot,{'fields':'title,body,purpose,contacts'})\n_shortReport = \"<h3>\"+habitatMapRootItem[\"title\"]+\"</h3>\"\n_shortReport = _shortReport+\"<h4>Abstract</h4><p>\"+habitatMapRootItem[\"body\"]+\"</p>\"\n_shortReport = _shortReport+\"<h4>Purpose</h4><p>\"+habitatMapRootItem[\"purpose\"]+\"</p>\"\n_shortReport = _shortReport+\"<h4>Contacts</h4>\"\nfor contact in habitatMapRootItem[\"contacts\"]:\n    _shortReport = _shortReport+\"<div>\"\n    _shortReport = _shortReport+contact[\"name\"]+\" (\"+contact[\"type\"]+\")\"\n    _shortReport = _shortReport+\"</div>\"\n    \n\nHTML(_shortReport)",
                "true_label": "",
                "top5_preds": [
                    "accessing databases via web apis",
                    "retrieving data from html page",
                    "getting data from the internet",
                    "load table in pandas",
                    "working with doi lists"
                ]
            }
        ],
        [
            {
                "code": "import pandas as pd\nimport numpy as np\nfrom datetime import datetime\nimport matplotlib.pyplot as plt\nimport seaborn as sns; sns.set()\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "formatting datetimes as strings",
                    "plotting time series with pandas",
                    "equally spaced numbers on a grid",
                    "create an array of linearly spaced points"
                ]
            },
            {
                "code": "players = players[['Season', 'Game_ID', 'Game_Date', 'Team', 'Person_ID', 'Name', 'ASG_Team', 'Active_Status']]\n\n#Split data by year\nviewers_2017 = viewers[viewers['Season'] == \"2016-17\"]\nviewers_2018 = viewers[viewers['Season'] == \"2017-18\"]\nplayers_2017 = players[players['Game_ID'] < 21700000]\nplayers_2018 = players[players['Game_ID'] > 21700000]\n\n#Covert 'Game_ID' to a string variable\nplayers_2017['Game_ID'] = players_2017['Game_ID'].apply(lambda x:str(int(x)))\nplayers_2018['Game_ID'] = players_2018['Game_ID'].apply(lambda x:str(int(x)))\n\nplayers_2017.head()",
                "true_label": "",
                "top5_preds": [
                    "ploting out data with box plots",
                    "importing data with pandas",
                    "find maximum and the minimum value in a set",
                    "importing data with numpy",
                    "line plot with a dataframe"
                ]
            },
            {
                "code": "def ASG(team):\n    \"\"\"Return 1 if player was an all-star\"\"\"\n    if team != \"None\":\n        return 1\n    else:\n        return 0\n\ndef to_int(num):\n    if isinstance(num,str):\n        return int(num.replace(',',''))\n    else:\n        return int(num)\n\nplayers_2017['AS'] = players_2017['ASG_Team'].apply(ASG)\nplayers_2018['AS'] = players_2018['ASG_Team'].apply(ASG)\n\nplayers_2017 = players_2017.merge(ASVotes_2017,on = 'Name', how = 'left')\nplayers_2017['Votes'] = players_2017['Votes'].fillna(value = 0).apply(to_int)\nplayers_2018 = players_2018.merge(ASVotes_2018, on = 'Name', how = 'left')\nplayers_2018['Votes'] = players_2018['Votes'].fillna(value = 0).apply(to_int)\n\nplayers_2017.head()",
                "true_label": "",
                "top5_preds": [
                    "get a positive integer from a user",
                    "convert integer or float data",
                    "calculate the mean yellow cards given per team",
                    "test whether a number is positive",
                    "convert strings to numbers"
                ]
            },
            {
                "code": "#Calculate total number of all-stars and votes for each game\np17 = players_2017.groupby('Game_ID', as_index = False).agg(np.sum).drop('Person_ID', axis = 1)\np18 = players_2018.groupby('Game_ID', as_index = False).agg(np.sum).drop('Person_ID', axis = 1)\n\np17.head()",
                "true_label": "",
                "top5_preds": [
                    "predicting a categorical response",
                    "create a dataframe by joining series by column",
                    "line plot with a dataframe",
                    "load table in pandas",
                    "join two dataframes along rows"
                ]
            },
            {
                "code": "viewers_2017 = viewers_2017.merge(p17, on = 'Game_ID')\nviewers_2018 = viewers_2018.merge(p18, on = 'Game_ID')\n\nviewers_2017.head()",
                "true_label": "",
                "top5_preds": [
                    "create a dataframe by joining series by column",
                    "join two dataframes along rows",
                    "join two dataframes along columns",
                    "combine two dataframes into one",
                    "from dictionary to dataframe"
                ]
            },
            {
                "code": "viewers_2017.plot.scatter(x = 'Votes', y = 'Total_Viewers', title = \"All Star Votes vs Total Viewers\")",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "plotting time series with pandas",
                    "ploting out data with box plots",
                    "line plots show the trend of a numerical variable over time",
                    "plot using pandas plotting"
                ]
            },
            {
                "code": "viewers_2017.boxplot(column='Total_Viewers', by='AS', figsize=(10,7))",
                "true_label": "",
                "top5_preds": [
                    "ploting out data with box plots",
                    "line plot with a dataframe",
                    "pandas plotting",
                    "plotting time series with pandas",
                    "using a dataframe and matplotlib commands"
                ]
            },
            {
                "code": "viewers_2017[viewers_2017['AS'] == 6]",
                "true_label": "",
                "top5_preds": [
                    "select every row after a specific row",
                    "find maximum and the minimum value in a set",
                    "load table in pandas",
                    "find all by term in field in case insensitive way",
                    "using pandas"
                ]
            },
            {
                "code": "viewers_2017.corr()['Total_Viewers']",
                "true_label": "",
                "top5_preds": [
                    "predicting a categorical response",
                    "line plots show the trend of a numerical variable over time",
                    "load table in pandas",
                    "transform year column",
                    "working with pandas series indexed by datetime"
                ]
            },
            {
                "code": "def by_team(viewers):\n    \"\"\"Return a DataFrame with each team's average viewership and average number of AS votes\"\"\"\n    by_team = pd.DataFrame(columns = ['Team', 'Avg_Viewers', 'Votes'])\n    for team in viewers['Away_Team'].unique():\n        a = viewers['Away_Team'] == team\n        b = viewers['Home_Team'] == team\n        avg_viewers = pd.concat([viewers[a], viewers[b]])['Total_Viewers'].mean()\n        avg_votes = pd.concat([viewers[a], viewers[b]])['Votes'].mean()\n    \n        row = pd.DataFrame([[team, avg_viewers, avg_votes], ], columns = ['Team', 'Avg_Viewers', 'Votes'])\n        by_team = by_team.append(row)\n    return by_team\n\nby_team17 = by_team(viewers_2017)\nby_team18 = by_team(viewers_2018)",
                "true_label": "",
                "top5_preds": [
                    "queries about movies",
                    "calculate the mean yellow cards given per team",
                    "get averages",
                    "read the dataset point",
                    "get the data"
                ]
            },
            {
                "code": "by_team17 = by_team17.sort_values('Avg_Viewers', ascending=False)\nby_team17",
                "true_label": "",
                "top5_preds": [
                    "sorting data",
                    "order by",
                    "remove duplicates from a list",
                    "sorting",
                    "groupby"
                ]
            },
            {
                "code": "#Read standings data\nstandings17 = pd.read_csv('data/NBA_Standings17.csv')\nstandings18 = pd.read_csv('data/NBA_Standings18.csv')\n\nby_team17 = by_team17.merge(standings17, on = 'Team')",
                "true_label": "",
                "top5_preds": [
                    "importing data with pandas",
                    "join two dataframes along rows",
                    "join two dataframes along columns",
                    "importing data with numpy",
                    "from dictionary to dataframe"
                ]
            },
            {
                "code": "#Calculate the median win percentage for the 2016-2017 season\nmedian_perc = np.median(by_team17['Percentage'])\nmedian_perc",
                "true_label": "",
                "top5_preds": [
                    "predicting a categorical response",
                    "calculate average by group",
                    "line plots show the trend of a numerical variable over time",
                    "calculating the mean of a vector with nans",
                    "the mean"
                ]
            },
            {
                "code": "#Choose the color coding for the bar chart. Above average teams are in orange, and below average teams in blue\ndef choose_color(perc):\n    if perc > 0.5:\n        return sns.xkcd_rgb[\"orange\"]\n    else:\n        return sns.xkcd_rgb[\"denim blue\"]\ncolors = np.array(by_team17['Percentage'].apply(choose_color))",
                "true_label": "",
                "top5_preds": [
                    "calculate the mean yellow cards given per team",
                    "predicting a categorical response",
                    "create a bar chart",
                    "visualize the hardest and easiest digits",
                    "get a positive integer from a user"
                ]
            },
            {
                "code": "plt.rcParams['figure.figsize'] = (10,7)\nplt.title('Avg Viewerss by Team 2017')\nplt.xlabel('Average Viewers')\nplt.barh(y = by_team17['Team'], width = by_team17['Avg_Viewers'], color = colors)",
                "true_label": "",
                "top5_preds": [
                    "create a bar chart",
                    "use pandas to make a bar chart",
                    "bar charts",
                    "bar chart",
                    "line plot with a dataframe"
                ]
            },
            {
                "code": "by_team17.plot.scatter(x = 'Percentage', y = 'Avg_Viewers', title = 'Win Percentage vs Average Team Viewership')",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "plotting time series with pandas",
                    "ploting out data with box plots",
                    "line plots show the trend of a numerical variable over time",
                    "pandas plotting"
                ]
            },
            {
                "code": "#Read necessary data sets\nviewers = pd.read_csv(\"data/training_set.csv\")\nplayers = pd.read_csv(\"data/player_data.csv\")\nplayers = players.where(players['Active_Status'] == 'Active').dropna()\n\nASVotes_2017 = pd.read_csv(\"data/2017_ASG.csv\")\nASVotes_2018 = pd.read_csv(\"data/2018_ASG.csv\")",
                "true_label": "",
                "top5_preds": [
                    "importing data with pandas",
                    "loading a csv into a dataframe",
                    "load table in pandas",
                    "using pandas",
                    "importing data with numpy"
                ]
            },
            {
                "code": "viewers.head()",
                "true_label": "",
                "top5_preds": [
                    "formatting datetimes as strings",
                    "find maximum and the minimum value in a set",
                    "getting data from the internet",
                    "load table in pandas",
                    "twitter api access"
                ]
            },
            {
                "code": "players.head()",
                "true_label": "",
                "top5_preds": [
                    "find maximum and the minimum value in a set",
                    "load table in pandas",
                    "tensorflow + keras",
                    "getting data from the internet",
                    "counting triangles in a social network"
                ]
            },
            {
                "code": "#Sum all of the viewers for each game throughout every country\nviewers = viewers.groupby(['Season', 'Game_ID', 'Game_Date', 'Away_Team', 'Home_Team'], as_index = False).agg(np.sum)\nviewers = viewers.rename(columns = {'Rounded_Viewers':'Total_Viewers'})\nviewers.head()",
                "true_label": "",
                "top5_preds": [
                    "create a dataframe by joining series by column",
                    "from dictionary to dataframe",
                    "load table in pandas",
                    "line plot with a dataframe",
                    "join two dataframes along rows"
                ]
            },
            {
                "code": "#Convert 'Game_ID' to a string variable\nviewers['Game_ID'] = viewers['Game_ID'].apply(str)\n\n#Get month and day by both name and number. October is 1 because it's when the NBA season starts\nviewers['Month'] = viewers['Game_Date'].apply(lambda x: datetime.strptime(x,\"%m/%d/%Y\").strftime(\"%B\"))\nviewers['Weekday'] = viewers['Game_Date'].apply(lambda x: datetime.strptime(x,\"%m/%d/%Y\").strftime(\"%A\"))\nviewers['Day_Num'] = viewers['Game_Date'].apply(lambda x: datetime.strptime(x,\"%m/%d/%Y\").weekday())\nmonth_num = {'October':1,'November':2,'December':3,'January':4,'February':5,'March':6,'April':7}\nviewers['Month_Num'] = viewers['Month'].map(month_num)\n\nviewers.head()",
                "true_label": "",
                "top5_preds": [
                    "convert date to datetime format",
                    "convert integer or float data",
                    "convert data from string to float",
                    "formatting datetimes as strings",
                    "load table in pandas"
                ]
            },
            {
                "code": "#Calculate average monthly and daily viewership\nmonthly_viewers = viewers.groupby('Month',as_index=False).agg(np.mean).sort_values('Month_Num').drop(['Month_Num','Day_Num'],axis=1).rename(columns={'Total_Viewers':'Avg_Monthly_Viewers'})\ndaily_viewers = viewers.groupby('Weekday',as_index=False).agg(np.mean).sort_values('Day_Num').drop(['Month_Num','Day_Num'],axis=1).rename(columns={'Total_Viewers':'Avg_Daily_Viewers'})",
                "true_label": "",
                "top5_preds": [
                    "working with pandas series indexed by datetime",
                    "join two dataframes along rows",
                    "join two dataframes along columns",
                    "integrating datetime tools with pandas for time series",
                    "line plot with a dataframe"
                ]
            },
            {
                "code": "monthly_viewers",
                "true_label": "",
                "top5_preds": [
                    "get a positive integer from a user",
                    "formatting datetimes as strings",
                    "convert date to datetime format",
                    "load table in pandas",
                    "get the names of all the tables in the database"
                ]
            },
            {
                "code": "monthly_viewers.plot(x = 'Month', y = 'Avg_Monthly_Viewers', xticks = range(0, 7))",
                "true_label": "",
                "top5_preds": [
                    "plotting time series with pandas",
                    "line plots show the trend of a numerical variable over time",
                    "line plot with a dataframe",
                    "plot using pandas plotting",
                    "ploting out data with box plots"
                ]
            },
            {
                "code": "daily_viewers",
                "true_label": "",
                "top5_preds": [
                    "formatting datetimes as strings",
                    "convert date to datetime format",
                    "get the names of all the tables in the database",
                    "get a positive integer from a user",
                    "load table in pandas"
                ]
            },
            {
                "code": "daily_viewers.plot(x = 'Weekday',y = 'Avg_Daily_Viewers', xticks = range(0,7))",
                "true_label": "",
                "top5_preds": [
                    "plotting time series with pandas",
                    "line plots show the trend of a numerical variable over time",
                    "line plot with a dataframe",
                    "ploting out data with box plots",
                    "using a dataframe and matplotlib commands"
                ]
            },
            {
                "code": "by_team17.plot.scatter(x = 'Percentage', y = 'Avg_Viewers', title = 'Win Percentage vs Average Team Viewership')",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "plotting time series with pandas",
                    "ploting out data with box plots",
                    "line plots show the trend of a numerical variable over time",
                    "pandas plotting"
                ]
            }
        ],
        [
            {
                "code": "model = make_pipeline(CountVectorizer(stop_words='english'),\n                      RandomForestClassifier())\nmodel.fit(X_train, y_train)\ny_pred = model.predict(X_test)\nprint accuracy_score(y_test, y_pred)\nprint \"Number of features:\", len(model.steps[0][1].get_feature_names())",
                "true_label": "",
                "top5_preds": [
                    "import polynomial features from sklearn",
                    "test the model for accuracy",
                    "polynomial regression with sklearn",
                    "check accuracy / score for a logistic classifier",
                    "build a vector of prediction from the trained model"
                ]
            },
            {
                "code": "X = X_words\ny = jobs.salarylevel.values\n\nskb_f = SelectKBest(f_classif, k=5)\nskb_chi2 = SelectKBest(chi2, k=5)\n\nskb_f.fit(X, y)\nskb_chi2.fit(X, y)\n\nkbest = pd.DataFrame([list(X.columns), list(skb_f.scores_), list(skb_chi2.scores_)], \n                     index=['feature','f_classif','chi2 score']).T.sort_values('chi2 score', ascending=False)\nkbest.head(20)",
                "true_label": "",
                "top5_preds": [
                    "what is scikit learn?",
                    "scikit learn",
                    "import polynomial features from sklearn",
                    "polynomial regression with sklearn",
                    "fit a polynomial"
                ]
            },
            {
                "code": "def ifds(x):\n    if 'data sci' in x.lower():\n        return 1\n    else:\n        return 0\njobs['ifds'] = jobs.title.map(ifds)\n\ndef rmdigit(x):\n    result = ''.join([i for i in x if not i.isdigit()])\n    return result\ndescrip = jobs.stemDesc.map(rmdigit)\n\nstop_words = text.ENGLISH_STOP_WORDS.union(['perm','bi'])\n\ncvec = CountVectorizer(stop_words=stop_words)\ncvec.fit(descrip)\n\nwords = pd.DataFrame(cvec.transform(jobs.title).todense(), columns=cvec.get_feature_names())\nwords = words.rename(columns = {'fit': 'fit_feature'})",
                "true_label": "",
                "top5_preds": [
                    "convert strings to numbers",
                    "convert integer or float data",
                    "get a positive integer from a user",
                    "transforming text into numbers",
                    "convert data from string to float"
                ]
            },
            {
                "code": "X = words\ny = jobs.ifds.values\n\nXtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.2, random_state=4)\nprint 'baseline', 1- float(y.sum())/len(y)\n\nfrom sklearn.ensemble import RandomForestClassifier\nclf = RandomForestClassifier(max_depth=2, random_state=0)\n\nclf.fit(Xtrain, ytrain)\nyhat = clf.predict(Xtest)\nprint 'RandomForest: ', accuracy_score(ytest, yhat)\n\nlogr = LogisticRegression()\nlogr.fit(Xtrain, ytrain)\nyhat2 = logr.predict(Xtest)\nprint 'Logistic Reg: ', accuracy_score(ytest, yhat2)\n\nskb_f = SelectKBest(f_classif, k=5)\nskb_chi2 = SelectKBest(chi2, k=5)\n\nskb_f.fit(X, y)\nskb_chi2.fit(X, y)\n\nkbest = pd.DataFrame([list(X.columns), list(skb_f.scores_), list(skb_chi2.scores_)], \n                     index=['feature','f_classif','chi2 score']).T.sort_values('f_classif', ascending=False)\nkbest.head(10)",
                "true_label": "",
                "top5_preds": [
                    "what is scikit learn?",
                    "scikit learn",
                    "import polynomial features from sklearn",
                    "sentiment classification & how",
                    "predicting a categorical response"
                ]
            },
            {
                "code": "X = words\ny = jobs.ifSenior.values\n\nXtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.2, random_state=3)\nprint 'baseline', 1- float(y.sum())/len(y)\n\nclf = RandomForestClassifier(max_depth=2, random_state=0)\n\nclf.fit(Xtrain, ytrain)\nyhat = clf.predict(Xtest)\nprint 'RandomForest: ', accuracy_score(ytest, yhat)\n\nlogr = LogisticRegression()\nlogr.fit(Xtrain, ytrain)\nyhat2 = logr.predict(Xtest)\nprint 'Logistic Reg: ', accuracy_score(ytest, yhat2)\n\nskb_f = SelectKBest(f_classif, k=5)\nskb_chi2 = SelectKBest(chi2, k=5)\n\nskb_f.fit(X, y)\nskb_chi2.fit(X, y)\n\nkbest = pd.DataFrame([list(X.columns), list(skb_f.scores_), list(skb_chi2.scores_)], \n                     index=['feature','f_classif','chi2 score']).T.sort_values('f_classif', ascending=False)\nkbest.head(10)",
                "true_label": "",
                "top5_preds": [
                    "what is scikit learn?",
                    "import polynomial features from sklearn",
                    "scikit learn",
                    "predicting a categorical response",
                    "using the classify function"
                ]
            },
            {
                "code": "# Load data scraping from au.indeed.com (details in Scraping notebook)\njobs = pd.read_csv('jobs.csv')\njobs.drop('Unnamed: 0', axis=1, inplace=True)\nprint jobs.shape\njobs.drop_duplicates(inplace=True)\nprint jobs.shape\njobs.dropna(inplace=True)\nprint jobs.shape\njobs.columns = ['city', 'title', 'company', 'location', 'description', 'salarytype', 'salary']",
                "true_label": "",
                "top5_preds": [
                    "importing data with pandas",
                    "importing data with numpy",
                    "load table in pandas",
                    "import polynomial features from sklearn",
                    "loading a csv into a dataframe"
                ]
            },
            {
                "code": "jobs['state'] = jobs.location.map(lambda x: x.split()[-1])\njobs.drop('location', axis=1, inplace=True)\n\nstate_dummies = pd.get_dummies(jobs.state)\njobs = pd.concat([jobs, state_dummies], axis=1)\njobs.drop(['state', 'Australia'], axis=1, inplace=True)\n\n# city_dummies = pd.get_dummies(jobs.city)\n# jobs = pd.concat([jobs, city_dummies], axis=1)\n# jobs.drop(['city', 'Newcastle'], axis=1, inplace=True)\n\ntype_dummies = pd.get_dummies(jobs.salarytype)\njobs = pd.concat([jobs, type_dummies], axis=1)\njobs.drop(['salarytype', 'month'], axis=1, inplace=True)",
                "true_label": "",
                "top5_preds": [
                    "from dictionary to dataframe",
                    "load table in pandas",
                    "join two dataframes along rows",
                    "importing data with pandas",
                    "importing data with numpy"
                ]
            },
            {
                "code": "def f(x):\n    x = re.sub(r'\\([^)]*\\)', '', x)\n    return x\n\njobs.title = jobs.title.map(f)",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "pandas apply",
                    "strings as function arguments",
                    "retrieving data from html page",
                    "load table in pandas"
                ]
            },
            {
                "code": "def ifSenior(x):\n    if 'senior' in x.lower():\n        return 1\n    else:\n        return 0\n\njobs['ifSenior'] = jobs.title.map(ifSenior)",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "what is conditional probability good for?",
                    "find all by term in field in case insensitive way",
                    "get a positive integer from a user",
                    "pandas apply"
                ]
            },
            {
                "code": "def ifJunior(x):\n    if 'junior' in x.lower():\n        return 1\n    else:\n        return 0\n\njobs['ifJunior'] = jobs.title.map(ifJunior)",
                "true_label": "",
                "top5_preds": [
                    "what is conditional probability good for?",
                    "line plot with a dataframe",
                    "test whether a number is positive",
                    "capitalize both mjob and fjob",
                    "get a positive integer from a user"
                ]
            },
            {
                "code": "snow = SnowballStemmer('english')\nport = PorterStemmer()\nlanc = LancasterStemmer()\n\ndef stem(x):\n    line = re.sub(r'[-|,./$&\\'+]', ' ', x)\n    word = line.split()\n    new = ' '.join([snow.stem(i) for i in word])\n\n    return new\njobs['stemTitle'] = jobs.title.map(stem)",
                "true_label": "",
                "top5_preds": [
                    "convert text data into vector",
                    "create a list of all words",
                    "line plots show the trend of a numerical variable over time",
                    "read text file point",
                    "transforming text into numbers"
                ]
            },
            {
                "code": "def stemd(x):\n    line = re.sub(r'[-|,./$&\\'+\\[\\]]', ' ', x)\n    word = line.split()\n    new = ' '.join([lanc.stem(i) for i in word])\n    return new\n\njobs['stemDesc'] = jobs.description.map(stemd)",
                "true_label": "",
                "top5_preds": [
                    "converting symbols to identifiers",
                    "convert text data into vector",
                    "load table in pandas",
                    "read text file point",
                    "find the most common words"
                ]
            },
            {
                "code": "jobs.reset_index(inplace=True)\njobs.drop('index', axis=1, inplace=True)",
                "true_label": "",
                "top5_preds": [
                    "load table in pandas",
                    "from dictionary to dataframe",
                    "join two dataframes along rows",
                    "using pandas",
                    "plotting time series with pandas"
                ]
            },
            {
                "code": "def levelSalary(x):\n    if x < 90000:\n        return 0\n    else:\n        return 1\njobs['salarylevel'] = jobs.salary.map(levelSalary)",
                "true_label": "",
                "top5_preds": [
                    "pandas apply",
                    "get a positive integer from a user",
                    "convert integer or float data",
                    "assign to a variable",
                    "the mean of difference of variables"
                ]
            },
            {
                "code": "jobs.head()",
                "true_label": "",
                "top5_preds": [
                    "tensorflow + keras",
                    "formatting datetimes as strings",
                    "sqlalchemy, sqlite, and dates",
                    "building a mini lsst broker for data management and discovery",
                    "load table in pandas"
                ]
            },
            {
                "code": "from sklearn.feature_extraction.text import CountVectorizer\n\ncvec = CountVectorizer(stop_words='english')\ncvec.fit(jobs.title)\n\nX_words = pd.DataFrame(cvec.transform(jobs.title).todense(), columns=cvec.get_feature_names())\nX_words.shape",
                "true_label": "",
                "top5_preds": [
                    "import polynomial features from sklearn",
                    "what is scikit learn?",
                    "implementing bag of words in scikit learn",
                    "vectorize words in movie reviews",
                    "use sklearn kfold"
                ]
            },
            {
                "code": "jobs.iloc[:, 5:15].head()",
                "true_label": "",
                "top5_preds": [
                    "join two dataframes along rows",
                    "select every row after a specific row",
                    "line plot with a dataframe",
                    "select rows and last five columns by position",
                    "spark dataframes"
                ]
            },
            {
                "code": "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = .5, random_state=90)\n\nlr = LinearRegression()\nlr.fit(X_train, y_train)\nprint np.mean(cross_val_score(lr, X_test, y_test, cv=5))",
                "true_label": "",
                "top5_preds": [
                    "polynomial regression with sklearn",
                    "predicting a continuous response using linear regression",
                    "ridge regression with polynomial features on a grid",
                    "ridge regression with one predictor on a grid",
                    "what is scikit learn?"
                ]
            },
            {
                "code": "X2 = pd.concat([X, X_words], axis=1)\nX2_train, X2_test, y2_train, y2_test = train_test_split(X2, y, train_size = .5, random_state=90)\n\nlr2 = LinearRegression()\nlr2.fit(X2_train, y2_train)\nprint np.mean(cross_val_score(lr2, X2_test, y2_test, cv=5))",
                "true_label": "",
                "top5_preds": [
                    "what is scikit learn?",
                    "linear regression with statsmodels and scikit learn",
                    "fit a logistic regression model using statsmodels using logistic regression formula in patsy",
                    "import polynomial features from sklearn",
                    "polynomial regression with sklearn"
                ]
            },
            {
                "code": "y = jobs.salarylevel.values\nX = jobs.iloc[:, 5:15]\nX_train, X_test, y_train, y_test = train_test_split(X, y, train_size = .5, random_state=90)\n\nlr = LogisticRegression()\nlr.fit(X_train, y_train)\nprint np.mean(cross_val_score(lr, X_test, y_test, cv=5))",
                "true_label": "",
                "top5_preds": [
                    "fit a logistic regression model using statsmodels using logistic regression formula in patsy",
                    "linear regression with statsmodels and scikit learn",
                    "using logistic regression instead",
                    "what is scikit learn?",
                    "polynomial regression with sklearn"
                ]
            },
            {
                "code": "float(jobs[jobs.salarylevel == 1].shape[0]) / jobs.shape[0]",
                "true_label": "",
                "top5_preds": [
                    "predicting a categorical response",
                    "pandas apply",
                    "get the sum of all the columns in mat",
                    "working with pandas series indexed by datetime",
                    "the mean of difference of variables"
                ]
            },
            {
                "code": "X_train, X_test, y_train, y_test = train_test_split(jobs.title, jobs.salarylevel, train_size = .5, random_state=90)",
                "true_label": "",
                "top5_preds": [
                    "tensorflow + keras",
                    "fit on training",
                    "scikit learn",
                    "optimal value of k for dataset",
                    "what is scikit learn?"
                ]
            },
            {
                "code": "model = make_pipeline(TfidfVectorizer(stop_words='english',\n                                      sublinear_tf=True,\n                                      max_df=0.5,\n                                      max_features=1000),\n                      LogisticRegression())\n\n\nmodel.fit(X_train, y_train)\ny_pred = model.predict(X_test)\nprint accuracy_score(y_test, y_pred)\nprint \"Number of features:\", len(model.steps[0][1].get_feature_names())",
                "true_label": "",
                "top5_preds": [
                    "pipeline of tf idf",
                    "build a vector of prediction from the trained model",
                    "tensorflow + keras",
                    "logistic regression using tensorflow",
                    "create feedforward network model"
                ]
            },
            {
                "code": "model = make_pipeline(HashingVectorizer(stop_words='english',\n                                        non_negative=True,\n                                        n_features=2**16),\n                      LogisticRegression())\nmodel.fit(X_train, y_train)\ny_pred = model.predict(X_test)\nprint accuracy_score(y_test, y_pred)\nprint \"Number of features:\", 2**16",
                "true_label": "",
                "top5_preds": [
                    "build a vector of prediction from the trained model",
                    "pipeline of tf idf",
                    "tensorflow + keras",
                    "logistic regression using tensorflow",
                    "logistic regression no pipeline, no stop words"
                ]
            },
            {
                "code": "model = make_pipeline(CountVectorizer(stop_words='english'),\n                      LogisticRegression())\nmodel.fit(X_train, y_train)\ny_pred = model.predict(X_test)\nprint accuracy_score(y_test, y_pred)\nprint \"Number of features:\", len(model.steps[0][1].get_feature_names())",
                "true_label": "",
                "top5_preds": [
                    "check accuracy / score for a logistic classifier",
                    "import polynomial features from sklearn",
                    "test the model for accuracy",
                    "polynomial regression with sklearn",
                    "logistic regression using tensorflow"
                ]
            },
            {
                "code": "X = X_words\ny = jobs.salarylevel.values\n\nskb_f = SelectKBest(f_classif, k=5)\nskb_chi2 = SelectKBest(chi2, k=5)\n\nskb_f.fit(X, y)\nskb_chi2.fit(X, y)\n\nkbest = pd.DataFrame([list(X.columns), list(skb_f.scores_), list(skb_chi2.scores_)], \n                     index=['feature','f_classif','chi2 score']).T.sort_values('chi2 score', ascending=False)\nkbest.head(20)",
                "true_label": "",
                "top5_preds": [
                    "what is scikit learn?",
                    "scikit learn",
                    "import polynomial features from sklearn",
                    "polynomial regression with sklearn",
                    "fit a polynomial"
                ]
            }
        ],
        [
            {
                "code": "%%bash\necho '1,Hillary,Clinton,hclinton@hotmail.com,Female,7.247.200.34\n2,Donald,Trump,the_boss_man@trump.com,Male,212.79.109.69\n3,Ted,Cruz,cruzing_with_ted@yahoo.com,Female,150.106.140.235\n4,Bernie,Sanders,sanders@freenet.org,Male,175.21.69.76' >logs.txt",
                "true_label": "",
                "top5_preds": [
                    "formatting datetimes as strings",
                    "select every row after a specific row",
                    "connect to a remote database",
                    "convert date to datetime format",
                    "get a positive integer from a user"
                ]
            },
            {
                "code": "from pyspark import SparkContext\n\nlogFile = \"logs.txt\"  # Should be some file on your system\n\nsc = SparkContext(\"local\", \"Simple App\")\n\nlogData = sc.textFile(logFile).cache()\nmale_count = logData.filter(lambda s: 'Male' in s).count()\nprint(\"Number of 'Males': {}\").format(male_count)",
                "true_label": "",
                "top5_preds": [
                    "word count in spark",
                    "spark",
                    "import polynomial features from sklearn",
                    "load table in pandas",
                    "spark lab"
                ]
            },
            {
                "code": "%%bash\n\nbrew install apache-spark # Automtically builds the right version with pyspark!",
                "true_label": "",
                "top5_preds": [
                    "spark",
                    "running blast with apache spark",
                    "spark dataframes",
                    "spark lab",
                    "rdd resilient distributed dataset in spark"
                ]
            },
            {
                "code": "from pyspark import SparkContext\nsc = SparkContext()",
                "true_label": "",
                "top5_preds": [
                    "tensorflow + keras",
                    "spark",
                    "spark dataframes",
                    "what is scikit learn?",
                    "spark lab"
                ]
            },
            {
                "code": "sc #=> <pyspark.context.SparkContext at 0x10b477b10>",
                "true_label": "",
                "top5_preds": [
                    "tensorflow + keras",
                    "numpy point",
                    "spark",
                    "spark lab",
                    "scipy"
                ]
            },
            {
                "code": "import random\nflips = 1000000\nheads = (sc.parallelize(xrange(flips))\n         .map(lambda i: random.random())\n         .filter(lambda r: r < 0.51)\n         .count())\n\nratio = float(heads)/float(flips)\n\nprint(heads)\nprint(\"{:.0%}\".format(ratio))",
                "true_label": "",
                "top5_preds": [
                    "create an array of linearly spaced points",
                    "counting triangles in a social network",
                    "rdd resilient distributed dataset in spark",
                    "equally spaced numbers on a grid",
                    "predicting a categorical response"
                ]
            },
            {
                "code": "%%writefile sales.txt\n#ID    Date           Store   State  Product    Amount\n101    11/13/2014     100     WA     331        300.00\n104    11/18/2014     700     OR     329        450.00\n102    11/15/2014     203     CA     321        200.00\n106    11/19/2014     202     CA     331        330.00\n103    11/17/2014     101     WA     373        750.00\n105    11/19/2014     202     CA     321        200.00",
                "true_label": "",
                "top5_preds": [
                    "formatting datetimes as strings",
                    "convert date to datetime format",
                    "sum all the numbers in a list",
                    "convert integer or float data",
                    "convert data from string to float"
                ]
            },
            {
                "code": "sc.textFile('sales.txt')\\\n    .take(2)",
                "true_label": "",
                "top5_preds": [
                    "spark",
                    "tensorflow + keras",
                    "use sklearn kfold",
                    "what is scikit learn?",
                    "spark dataframes"
                ]
            },
            {
                "code": "sc.textFile('sales.txt')\\\n    .map(lambda x: x.split())\\\n    .take(2)",
                "true_label": "",
                "top5_preds": [
                    "convert text data into vector",
                    "spark",
                    "use sklearn kfold",
                    "equally spaced numbers on a grid",
                    "create an array of linearly spaced points"
                ]
            },
            {
                "code": "def is_prime(number):\n    \"Determine if a number is prime\"\n    factor_min = 2\n    factor_max = int(number**0.5)+1\n    for factor in xrange(factor_min,factor_max):\n        if number % factor == 0:\n            return False\n    return True",
                "true_label": "",
                "top5_preds": [
                    "test whether a number is positive",
                    "get a positive integer from a user",
                    "check out the type of the columns",
                    "pi by means of the arithmetic geometric mean",
                    "permutation test"
                ]
            },
            {
                "code": "numbers = xrange(2,100)\nprimes = sc.parallelize(numbers)\\\n            .filter(is_prime)\\\n            .collect()\n    \nprint(primes)",
                "true_label": "",
                "top5_preds": [
                    "get a positive integer from a user",
                    "numpy point",
                    "what is conditional probability good for?",
                    "test whether a number is positive",
                    "create a one column dataframe with the values of a series"
                ]
            },
            {
                "code": "sc.textFile('input.txt') \\\n    .map(lambda x: x.split()) \\\n    .collect()",
                "true_label": "",
                "top5_preds": [
                    "convert text data into vector",
                    "spark",
                    "read text file point",
                    "spark dataframes",
                    "tensorflow + keras"
                ]
            },
            {
                "code": "sc.parallelize([1,3,2,2,1]).sortBy(lambda x: x).collect()",
                "true_label": "",
                "top5_preds": [
                    "spark",
                    "find maximum and the minimum value in a set",
                    "formatting datetimes as strings",
                    "equally spaced numbers on a grid",
                    "rdd resilient distributed dataset in spark"
                ]
            },
            {
                "code": "%%writefile input.txt\nhello world\nanother line\nyet another line\nyet another another line",
                "true_label": "",
                "top5_preds": [
                    "reading and writing binary files",
                    "read text file point",
                    "reading and writing text files",
                    "formatting datetimes as strings",
                    "file io"
                ]
            },
            {
                "code": "sc.textFile('input.txt') \\\n    .map(lambda x: x.split()) \\\n    .count()",
                "true_label": "",
                "top5_preds": [
                    "word count in spark",
                    "convert text data into vector",
                    "reading featurecounts",
                    "read text file point",
                    "counting word frequency"
                ]
            },
            {
                "code": "sc.textFile('input.txt') \\\n    .flatMap(lambda x: x.split()) \\\n    .count()",
                "true_label": "",
                "top5_preds": [
                    "word count in spark",
                    "convert text data into vector",
                    "read text file point",
                    "reading featurecounts",
                    "counting word frequency"
                ]
            },
            {
                "code": "sc.textFile('sales.txt')\\\n    .map(lambda x: x.split())\\\n    .filter(lambda x: x[0].startswith('#'))\\\n    .take(2)",
                "true_label": "",
                "top5_preds": [
                    "download and inspect the twitter samples dataset",
                    "convert text data into vector",
                    "download the newsgroups dataset",
                    "getting data from the internet",
                    "tokenize the text"
                ]
            },
            {
                "code": "# Stop cluster\nsc.stop() ",
                "true_label": "",
                "top5_preds": [
                    "building a mini lsst broker for data management and discovery",
                    "using pipelines with gridsearchcv",
                    "spark",
                    "create an array of linearly spaced points",
                    "equally spaced numbers on a grid"
                ]
            },
            {
                "code": "sc.textFile('sales.txt')\\\n    .map(lambda x: x.split())\\\n    .filter(lambda x: not x[0].startswith('#'))\\\n    .take(2)",
                "true_label": "",
                "top5_preds": [
                    "download and inspect the twitter samples dataset",
                    "convert text data into vector",
                    "download the newsgroups dataset",
                    "getting data from the internet",
                    "tokenize the text"
                ]
            },
            {
                "code": "sc.textFile('sales.txt')\\\n    .map(lambda x: x.split())\\\n    .filter(lambda x: not x[0].startswith('#'))\\\n    .map(lambda x: x[-1])\\\n    .take(2)",
                "true_label": "",
                "top5_preds": [
                    "convert text data into vector",
                    "download and inspect the twitter samples dataset",
                    "getting data from the internet",
                    "download the newsgroups dataset",
                    "tokenize the text"
                ]
            },
            {
                "code": "sc.textFile('sales.txt')\\\n    .map(lambda x: x.split())\\\n    .filter(lambda x: not x[0].startswith('#'))\\\n    .map(lambda x: float(x[-1]))\\\n    .sum()",
                "true_label": "",
                "top5_preds": [
                    "download and inspect the twitter samples dataset",
                    "convert text data into vector",
                    "download the newsgroups dataset",
                    "getting data from the internet",
                    "text data"
                ]
            },
            {
                "code": "sc.textFile('sales.txt')\\\n    .map(lambda x: x.split())\\\n    .filter(lambda x: not x[0].startswith('#'))\\\n    .map(lambda x: (x[-3],float(x[-1])))\\\n    .collect()",
                "true_label": "",
                "top5_preds": [
                    "download and inspect the twitter samples dataset",
                    "convert text data into vector",
                    "download the newsgroups dataset",
                    "getting data from the internet",
                    "read images point"
                ]
            },
            {
                "code": "sc.parallelize([1,3,2,2,1]).distinct().collect()",
                "true_label": "",
                "top5_preds": [
                    "rdd resilient distributed dataset in spark",
                    "spark",
                    "spark dataframes",
                    "tensorflow + keras",
                    "building a mini lsst broker for data management and discovery"
                ]
            },
            {
                "code": "sc.textFile('sales.txt')\\\n    .map(lambda x: x.split())\\\n    .filter(lambda x: not x[0].startswith('#'))\\\n    .map(lambda x: (x[-3],float(x[-1])))\\\n    .reduceByKey(lambda amount1,amount2: amount1+amount2)\\\n    .collect()",
                "true_label": "",
                "top5_preds": [
                    "convert text data into vector",
                    "download and inspect the twitter samples dataset",
                    "convert data from string to float",
                    "transforming text into numbers",
                    "download the newsgroups dataset"
                ]
            },
            {
                "code": "sc.textFile('sales.txt')\\\n    .map(lambda x: x.split())\\\n    .filter(lambda x: not x[0].startswith('#'))\\\n    .map(lambda x: x[-1])\\\n    .take(2)",
                "true_label": "",
                "top5_preds": [
                    "convert text data into vector",
                    "download and inspect the twitter samples dataset",
                    "getting data from the internet",
                    "download the newsgroups dataset",
                    "tokenize the text"
                ]
            }
        ],
        [
            {
                "code": "import numpy as np\nimport pandas as pd\npd.options.display.float_format = '{:.3f}'.format\npd.set_option('display.max_colwidth', -1)\npd.options.display.max_columns = 20",
                "true_label": "",
                "top5_preds": [
                    "formatting datetimes as strings",
                    "equally spaced numbers on a grid",
                    "line plot with a dataframe",
                    "pandas plotting",
                    "convert data from string to float"
                ]
            },
            {
                "code": "import matplotlib.pyplot as plt\nimport seaborn as sns",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "plotting time series with pandas",
                    "equally spaced numbers on a grid",
                    "plot using matplotlib",
                    "formatting datetimes as strings"
                ]
            },
            {
                "code": "loan_file_path=\"./loan/loan.csv\"\ndata_dict_file_path = \"./loan/Data_Dictionary.xlsx\"",
                "true_label": "",
                "top5_preds": [
                    "data given as a dictionary",
                    "load table in pandas",
                    "reading in the files",
                    "loading json in python",
                    "importing data with numpy"
                ]
            },
            {
                "code": "pd.options.display.max_columns = 20\nloan = pd.read_csv(loan_file_path, encoding=\"utf8\", low_memory=False)\nloan.head()",
                "true_label": "",
                "top5_preds": [
                    "load table in pandas",
                    "loading a csv into a dataframe",
                    "read text file point",
                    "convert text data into vector",
                    "importing data with pandas"
                ]
            },
            {
                "code": "print('The loan dataset set has %d rows and %d columns' % (loan.shape[0], loan.shape[1]))",
                "true_label": "",
                "top5_preds": [
                    "equally spaced numbers on a grid",
                    "scikit learn",
                    "what is scikit learn?",
                    "import polynomial features from sklearn",
                    "relationships between dataframes"
                ]
            },
            {
                "code": "loans_frame.loc[loans_frame['loan_status'] == 'Fully Paid','revol_bal'].describe()",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "load table in pandas",
                    "predicting a categorical response",
                    "line plots show the trend of a numerical variable over time",
                    "working with pandas series indexed by datetime"
                ]
            },
            {
                "code": "plt.figure(figsize=(6,10))\nlow, high = loans_frame.revol_bal.quantile([0.05, 0.95])\nax = sns.boxplot(x=\"loan_status\", y=\"revol_bal\", data=loans_frame[loans_frame.revol_bal.between(low,high)])\nplt.show()",
                "true_label": "",
                "top5_preds": [
                    "ploting out data with box plots",
                    "line plot with a dataframe",
                    "using a dataframe and matplotlib commands",
                    "plot using pandas plotting",
                    "plotting time series with pandas"
                ]
            },
            {
                "code": "loans_frame.loc[loans_frame['loan_status'] == 'Charged Off','dti'].describe()",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "load table in pandas",
                    "from dictionary to dataframe",
                    "convert text data into vector",
                    "working with pandas series indexed by datetime"
                ]
            },
            {
                "code": "loans_frame.loc[loans_frame['loan_status'] == 'Fully Paid','dti'].describe()",
                "true_label": "",
                "top5_preds": [
                    "load table in pandas",
                    "line plot with a dataframe",
                    "from dictionary to dataframe",
                    "convert text data into vector",
                    "working with pandas series indexed by datetime"
                ]
            },
            {
                "code": "plt.figure(figsize=(6,10))\nlow, high = loans_frame.dti.quantile([0.05, 0.95])\nax = sns.boxplot(x=\"loan_status\", y=\"dti\", data=loans_frame[loans_frame.dti.between(low,high)])\nplt.show()",
                "true_label": "",
                "top5_preds": [
                    "ploting out data with box plots",
                    "line plot with a dataframe",
                    "using a dataframe and matplotlib commands",
                    "plotting time series with pandas",
                    "box plot"
                ]
            },
            {
                "code": "loans_frame['open_closed_ratio'] = loans_frame['open_acc'] / (loans_frame['total_acc'] - loans_frame['open_acc'])\nloans_frame['open_closed_ratio'].head()",
                "true_label": "",
                "top5_preds": [
                    "create a one column dataframe with the values of a series",
                    "using pandas",
                    "line plot with a dataframe",
                    "using a dataframe and matplotlib commands",
                    "predicting a categorical response"
                ]
            },
            {
                "code": "plt.figure(figsize=(6,10))\nlow, high = loans_frame.open_closed_ratio.quantile([0.05, 0.95])\nax = sns.boxplot(x=\"loan_status\", y=\"open_closed_ratio\", data=loans_frame[loans_frame.open_closed_ratio.between(low,high)])\nplt.show()",
                "true_label": "",
                "top5_preds": [
                    "ploting out data with box plots",
                    "line plot with a dataframe",
                    "using a dataframe and matplotlib commands",
                    "plot using pandas plotting",
                    "plotting time series with pandas"
                ]
            },
            {
                "code": "def dateformat(earliest_cr_line_date):\n    date_split = earliest_cr_line_date.split('-')\n    if int(date_split[1]) > 18:\n        date_split[1] = '19' +  date_split[1]\n    else:\n        date_split[1] = '20' +  date_split[1]\n    return '-'.join(date_split)\nloans_frame['earliest_cr_line_mod'] = loans_frame['earliest_cr_line'].apply(dateformat)",
                "true_label": "",
                "top5_preds": [
                    "convert date to datetime format",
                    "transform the date column as a datetime type",
                    "formatting datetimes as strings",
                    "date ranges and frequencies",
                    "replace the first columns by a proper datetime index"
                ]
            },
            {
                "code": "loans_frame['credit_history'] = round((pd.to_datetime(loans_frame['issue_d'], format='%b-%y') - \\\n                                pd.to_datetime(loans_frame['earliest_cr_line_mod'], format='%b-%Y')) / np.timedelta64(1, 'M'))\nloans_frame['credit_history'].head()",
                "true_label": "",
                "top5_preds": [
                    "convert date to datetime format",
                    "formatting datetimes as strings",
                    "transform the date column as a datetime type",
                    "integrating datetime tools with pandas for time series",
                    "line plots show the trend of a numerical variable over time"
                ]
            },
            {
                "code": "loans_frame.loc[loans_frame['loan_status'] == 'Charged Off','credit_history'].describe()",
                "true_label": "",
                "top5_preds": [
                    "line plots show the trend of a numerical variable over time",
                    "line plot with a dataframe",
                    "load table in pandas",
                    "from dictionary to dataframe",
                    "formatting datetimes as strings"
                ]
            },
            {
                "code": "loans_frame.loc[loans_frame['loan_status'] == 'Fully Paid','credit_history'].describe()",
                "true_label": "",
                "top5_preds": [
                    "line plots show the trend of a numerical variable over time",
                    "load table in pandas",
                    "line plot with a dataframe",
                    "predicting a categorical response",
                    "from dictionary to dataframe"
                ]
            },
            {
                "code": "plt.figure(figsize=(6,10))\nlow, high = loans_frame.credit_history.quantile([0.05, 0.95])\nax = sns.boxplot(x=\"loan_status\", y=\"credit_history\", data=loans_frame[loans_frame.credit_history.between(low,high)])\nplt.show()",
                "true_label": "",
                "top5_preds": [
                    "ploting out data with box plots",
                    "line plot with a dataframe",
                    "using a dataframe and matplotlib commands",
                    "plot using matplotlib",
                    "plot using pandas plotting"
                ]
            },
            {
                "code": "loans_frame.loc[:,['annual_inc','installment','revol_bal']]\nloans_frame['new_debt_annual_inc_ratio'] = (loans_frame['installment'] * 12 + loans_frame['revol_bal']) /\\\n                                            loans_frame['annual_inc']\nloans_frame['new_debt_annual_inc_ratio'].head()",
                "true_label": "",
                "top5_preds": [
                    "create a one column dataframe with the values of a series",
                    "using a dataframe and matplotlib commands",
                    "create dataframe with given values",
                    "convert data from string to float",
                    "line plot with a dataframe"
                ]
            },
            {
                "code": "loans_frame.loc[loans_frame['loan_status'] == 'Charged Off','new_debt_annual_inc_ratio'].describe()",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "line plots show the trend of a numerical variable over time",
                    "create a one column dataframe with the values of a series",
                    "predicting a categorical response",
                    "using pandas"
                ]
            },
            {
                "code": "loans_frame.loc[loans_frame['loan_status'] == 'Fully Paid','new_debt_annual_inc_ratio'].describe()",
                "true_label": "",
                "top5_preds": [
                    "line plots show the trend of a numerical variable over time",
                    "line plot with a dataframe",
                    "predicting a categorical response",
                    "create a one column dataframe with the values of a series",
                    "using pandas"
                ]
            },
            {
                "code": "plt.figure(figsize=(6,10))\nlow, high = loans_frame.new_debt_annual_inc_ratio.quantile([0.05, 0.95])\nax = sns.boxplot(x=\"loan_status\", y=\"new_debt_annual_inc_ratio\", \\\n                 data=loans_frame[loans_frame.new_debt_annual_inc_ratio.between(low,high)])\nplt.show()",
                "true_label": "",
                "top5_preds": [
                    "ploting out data with box plots",
                    "line plot with a dataframe",
                    "using a dataframe and matplotlib commands",
                    "plot using pandas plotting",
                    "plot using matplotlib"
                ]
            },
            {
                "code": "column_desc.loc[~column_desc['LoanStatNew'].isin(columns_to_remove), ['LoanStatNew', 'Description']]",
                "true_label": "",
                "top5_preds": [
                    "delete column by name",
                    "load table in pandas",
                    "drop the rows with nan values",
                    "select every row after a specific row",
                    "relationships between dataframes"
                ]
            },
            {
                "code": "def category_univariate_analysis(column_name):\n    df = loans_frame.groupby('loan_status')[column_name].value_counts(ascending=False)\\\n                            .unstack(level=0).reset_index()\n    df['Charged Off'].fillna(value=0, inplace=True)\n    df['Total'] = df['Charged Off'] + df['Fully Paid']\n    df['Charged_Off_Percent'] = df['Charged Off'] * 100 /df['Total']\n    df['Fully_Paid_Percent'] = df['Fully Paid'] * 100 /df['Total']\n    return df.sort_values(by='Charged_Off_Percent', ascending=False)",
                "true_label": "",
                "top5_preds": [
                    "find data type of each column",
                    "function to compute principal component analysis",
                    "return a dataframe",
                    "analysis of stock prices using principal component analysis",
                    "an advanced preview introducing dirchilet distribution for multi level categorical analysis"
                ]
            },
            {
                "code": "def power_law_df(df, column_name):\n    s1 = np.log(df['Charged Off'].rank(axis=0, ascending=False)).to_frame(name='Rank_Log')\n    s2 = np.log(df['Charged Off']).to_frame(name='Count_Log')\n    s3 = df[column_name].to_frame(name=column_name)\n\n    power_law_1 = pd.concat([s1, s2, s3], axis=1)\n    power_law_1['status'] = 'Charged Off'\n\n    s1 = np.log(df['Fully Paid'].rank(axis=0, ascending=False)).to_frame(name='Rank_Log')\n    s2 = np.log(df['Fully Paid']).to_frame(name='Count_Log')\n\n    power_law_2 = pd.concat([s1, s2, s3], axis=1)\n    power_law_2['status'] = 'Fully Paid'\n\n    power_law = pd.concat([power_law_1, power_law_2], ignore_index=True)\n    return power_law",
                "true_label": "",
                "top5_preds": [
                    "find data type of each column",
                    "remove redundant columns vol sold gal and county no",
                    "return a dataframe",
                    "dataframe methods",
                    "plot the df dataframe using pandas + matplotlib"
                ]
            },
            {
                "code": "loans_frame['verification_status'].value_counts(normalize=True)",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "from dictionary to dataframe",
                    "relationships between dataframes",
                    "predicting a categorical response",
                    "find data type of each column"
                ]
            },
            {
                "code": "verification_status_analysis = category_univariate_analysis('verification_status')\nverification_status_analysis",
                "true_label": "",
                "top5_preds": [
                    "predicting a categorical response",
                    "find data type of each column",
                    "integrating datetime tools with pandas for time series",
                    "what is scikit learn?",
                    "shortcut principal component analysis in scikit learn"
                ]
            },
            {
                "code": "df_p = power_law_df(verification_status_analysis, 'verification_status')\ndf_p.sort_values(by='Rank_Log')",
                "true_label": "",
                "top5_preds": [
                    "relationships between dataframes",
                    "find data type of each column",
                    "predicting a categorical response",
                    "line plot with a dataframe",
                    "sorting data"
                ]
            },
            {
                "code": "plt.figure(figsize=(15,4))\nsns.pointplot(x=\"Rank_Log\", y=\"Count_Log\", hue=\"status\", data=df_p.loc[:,['Rank_Log', 'Count_Log', 'status']])\nplt.show()",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "line plots show the trend of a numerical variable over time",
                    "pandas plotting",
                    "plot using pandas plotting",
                    "pandas plotting documentation"
                ]
            },
            {
                "code": "plt.figure(figsize=(15,4))\nsns.barplot(x=\"verification_status\", y=\"Charged_Off_Percent\", data=verification_status_analysis)\\\n    .set(ylabel='Charged Off(%)', xlabel='Verification Status')\nplt.show()",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "create a bar chart",
                    "use pandas to make a bar chart",
                    "equally spaced numbers on a grid",
                    "matplotlib"
                ]
            },
            {
                "code": "plt.figure(figsize=(15,4))\ng = sns.pointplot(x=\"Revol_Util_Percentage_Range\", y=\"Percentage_Group\", hue='status', data=chart_df)\\\n.set(ylabel='Percentage of Loan Status', xlabel='Revoling Line Utilization Rate (% range)')\nplt.show()",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "plot using pandas plotting",
                    "line plots show the trend of a numerical variable over time",
                    "plotting time series with pandas",
                    "pandas plotting"
                ]
            },
            {
                "code": "plt.figure(figsize=(6,10))\nlow, high = loans_frame.revol_util.quantile([0.05, 0.95])\nax = sns.boxplot(x=\"loan_status\", y=\"revol_util\", data=loans_frame[loans_frame.revol_util.between(low,high)])\nplt.show()",
                "true_label": "",
                "top5_preds": [
                    "ploting out data with box plots",
                    "line plot with a dataframe",
                    "using a dataframe and matplotlib commands",
                    "plot using pandas plotting",
                    "plotting time series with pandas"
                ]
            },
            {
                "code": "revol_bal_co = loans_frame.loc[loans_frame['loan_status'] == 'Charged Off','revol_bal'].describe()\nrevol_bal_co",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "predicting a categorical response",
                    "load table in pandas",
                    "convert data from string to float",
                    "what is pandas?"
                ]
            },
            {
                "code": "loans_frame['purpose'].value_counts(normalize=True)",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "from dictionary to dataframe",
                    "convert text data into vector",
                    "relationships between dataframes",
                    "create a one column dataframe with the values of a series"
                ]
            },
            {
                "code": "purpose_analysis = category_univariate_analysis('purpose')\npurpose_analysis",
                "true_label": "",
                "top5_preds": [
                    "convert categorical variables",
                    "predicting a categorical response",
                    "what is scikit learn?",
                    "find data type of each column",
                    "shortcut principal component analysis in scikit learn"
                ]
            },
            {
                "code": "df_pr = power_law_df(purpose_analysis, 'purpose')\ndf_pr.sort_values(by='Rank_Log').head()",
                "true_label": "",
                "top5_preds": [
                    "relationships between dataframes",
                    "find data type of each column",
                    "line plot with a dataframe",
                    "statistics with pandas",
                    "line plots show the trend of a numerical variable over time"
                ]
            },
            {
                "code": "plt.figure(figsize=(15,4))\nsns.pointplot(x=\"Rank_Log\", y=\"Count_Log\", hue=\"status\", data=df_pr.loc[:,['Rank_Log', 'Count_Log', 'status']])\nlocs, labels = plt.xticks()\nplt.setp(labels, rotation=45)\nplt.show()",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "ploting out data with box plots",
                    "line plots show the trend of a numerical variable over time",
                    "plot using pandas plotting",
                    "pandas plotting documentation"
                ]
            },
            {
                "code": "plt.figure(figsize=(15,4))\ng = sns.barplot(x=\"purpose\", y=\"Charged_Off_Percent\", data=purpose_analysis)\\\n    .set(ylabel='Charged Off(%)', xlabel='Purpose')\nlocs, labels = plt.xticks()\nplt.setp(labels, rotation=45)\nplt.show()",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "ploting out data with box plots",
                    "equally spaced numbers on a grid",
                    "plot using matplotlib",
                    "matplotlib"
                ]
            },
            {
                "code": "loans_frame['grade'].value_counts(normalize=True)",
                "true_label": "",
                "top5_preds": [
                    "predicting a categorical response",
                    "line plot with a dataframe",
                    "line plots show the trend of a numerical variable over time",
                    "relationships between dataframes",
                    "calculating the mean of a vector with nans"
                ]
            },
            {
                "code": "grade_analysis = category_univariate_analysis('grade')\ngrade_analysis",
                "true_label": "",
                "top5_preds": [
                    "predicting a categorical response",
                    "convert categorical variables",
                    "import polynomial features from sklearn",
                    "integrating datetime tools with pandas for time series",
                    "what is scikit learn?"
                ]
            },
            {
                "code": "plt.figure(figsize=(15,12))\nplt.subplot(3, 1, 1)\ng = sns.barplot(x=\"grade\", y=\"Charged_Off_Percent\", data=grade_analysis.sort_values(by='grade'))\\\n    .set(ylabel='Charged Off(%)', xlabel='Grade')\n    \nplt.subplot(3, 1, 2)\nsns.barplot(x=\"grade\", y=\"Charged Off\", data=grade_analysis.sort_values(by='grade'))\\\n    .set(ylabel='Charged Off(Count)', xlabel='Grade')\n\nplt.subplot(3, 1, 3)\nsns.barplot(x=\"grade\", y=\"Fully Paid\", data=grade_analysis.sort_values(by='grade'))\\\n    .set(ylabel='Fully Paid(Count)', xlabel='Grade')\nplt.show()",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "create a bar chart",
                    "equally spaced numbers on a grid",
                    "use pandas to make a bar chart",
                    "line plots show the trend of a numerical variable over time"
                ]
            },
            {
                "code": "category_univariate_analysis('sub_grade').head()",
                "true_label": "",
                "top5_preds": [
                    "line plots show the trend of a numerical variable over time",
                    "predicting a categorical response",
                    "integrating datetime tools with pandas for time series",
                    "create a one column dataframe with the values of a series",
                    "line plot with a dataframe"
                ]
            },
            {
                "code": "loans_frame['emp_length'].value_counts(normalize=True)",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "create a one column dataframe with the values of a series",
                    "load table in pandas",
                    "from dictionary to dataframe",
                    "relationships between dataframes"
                ]
            },
            {
                "code": "emp_length_analysis = category_univariate_analysis('emp_length')\nemp_length_analysis",
                "true_label": "",
                "top5_preds": [
                    "shortcut principal component analysis in scikit learn",
                    "what is scikit learn?",
                    "import polynomial features from sklearn",
                    "predicting a categorical response",
                    "create a one column dataframe with the values of a series"
                ]
            },
            {
                "code": "plt.figure(figsize=(15,12))\nplt.subplot(3, 1, 1)\nsns.barplot(x=\"emp_length\", y=\"Charged_Off_Percent\", data=emp_length_analysis.sort_values(by='emp_length'))\\\n    .set(ylabel='Charged Off(%)', xlabel='Employee work experience')\n    \nplt.subplot(3, 1, 2)\nsns.barplot(x=\"emp_length\", y=\"Charged Off\", data=emp_length_analysis.sort_values(by='emp_length'))\\\n    .set(ylabel='Charged Off(Count)', xlabel='Employee work experience')\n\nplt.subplot(3, 1, 3)\nsns.barplot(x=\"emp_length\", y=\"Fully Paid\", data=emp_length_analysis.sort_values(by='emp_length'))\\\n    .set(ylabel='Fully Paid(Count)', xlabel='Employee work experience')\nlocs, labels = plt.xticks()\nplt.setp(labels, rotation=45)\nplt.show()",
                "true_label": "",
                "top5_preds": [
                    "create a bar chart",
                    "use pandas to make a bar chart",
                    "line plot with a dataframe",
                    "equally spaced numbers on a grid",
                    "line plots show the trend of a numerical variable over time"
                ]
            },
            {
                "code": "loans_frame['term'].value_counts(normalize=True)",
                "true_label": "",
                "top5_preds": [
                    "relationships between dataframes",
                    "line plot with a dataframe",
                    "convert text data into vector",
                    "create a one column dataframe with the values of a series",
                    "load table in pandas"
                ]
            },
            {
                "code": "term_analysis = category_univariate_analysis('term')\nterm_analysis",
                "true_label": "",
                "top5_preds": [
                    "predicting a categorical response",
                    "import polynomial features from sklearn",
                    "shortcut principal component analysis in scikit learn",
                    "what is scikit learn?",
                    "convert categorical variables"
                ]
            },
            {
                "code": "plt.figure(figsize=(15,4))\ng = sns.barplot(x=\"term\", y=\"Charged_Off_Percent\", data=term_analysis)\\\n    .set(ylabel='Charged Off(%)', xlabel='Term')\nplt.show()",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "line plots show the trend of a numerical variable over time",
                    "use pandas to make a bar chart",
                    "create a bar chart",
                    "matplotlib"
                ]
            },
            {
                "code": "loans_frame['addr_state'].value_counts(normalize=True).head()",
                "true_label": "",
                "top5_preds": [
                    "from dictionary to dataframe",
                    "convert text data into vector",
                    "line plot with a dataframe",
                    "relationships between dataframes",
                    "line plots show the trend of a numerical variable over time"
                ]
            },
            {
                "code": "addr_state_analysis = category_univariate_analysis('addr_state')\naddr_state_analysis.head()",
                "true_label": "",
                "top5_preds": [
                    "import polynomial features from sklearn",
                    "what is scikit learn?",
                    "predicting a categorical response",
                    "transform categorical data into binary features",
                    "create a one column dataframe with the values of a series"
                ]
            },
            {
                "code": "plt.figure(figsize=(15,4))\ng = sns.barplot(x=\"addr_state\", y=\"Charged_Off_Percent\", data=addr_state_analysis)\\\n    .set(ylabel='Charged Off(%)', xlabel='Address State')\nplt.show()",
                "true_label": "",
                "top5_preds": [
                    "equally spaced numbers on a grid",
                    "line plot with a dataframe",
                    "matplotlib",
                    "line plots show the trend of a numerical variable over time",
                    "pandas plotting"
                ]
            },
            {
                "code": "loans_frame['revol_util'] = loans_frame['revol_util'].astype('str')\nloans_frame['revol_util'] = loans_frame['revol_util'].map(lambda x : x.rstrip('%'))\nloans_frame['revol_util'] = loans_frame['revol_util'].astype('float')\nbins=[0,10,20,30,40,50,60,70,80,90,100]\nrevol_util_series = pd.cut(loans_frame.loc[loans_frame['loan_status'] == 'Charged Off','revol_util'], \\\n                       bins=bins).value_counts(normalize=True)",
                "true_label": "",
                "top5_preds": [
                    "convert data from string to float",
                    "convert categorical variables",
                    "create dataframe with given values",
                    "convert integer or float data",
                    "using a dataframe and matplotlib commands"
                ]
            },
            {
                "code": "loans_frame['revol_util'] = loans_frame['revol_util'].astype('str')\nloans_frame['revol_util'] = loans_frame['revol_util'].map(lambda x : x.rstrip('%'))\nloans_frame['revol_util'] = loans_frame['revol_util'].astype('float')\nbins=[0,10,20,30,40,50,60,70,80,90,100]\nrevol_util_fp_series = pd.cut(loans_frame.loc[loans_frame['loan_status'] == 'Fully Paid','revol_util'], \\\n                              bins=bins).value_counts(normalize=True)",
                "true_label": "",
                "top5_preds": [
                    "convert data from string to float",
                    "convert categorical variables",
                    "create dataframe with given values",
                    "convert integer or float data",
                    "using a dataframe and matplotlib commands"
                ]
            },
            {
                "code": "s1 = revol_util_series.to_frame('Charged_Off_Percentage')\ns2 = revol_util_fp_series.to_frame('Fully_Paid_Percentage')\ndf_u = pd.concat([s1, s2], axis=1)\ndf_u.reset_index(inplace=True)\ndf_u.rename(columns={'index': 'Revol_Util_Percentage_Range'}, inplace=True)\ndf_u['Charged_Off_Percentage'] = df_u['Charged_Off_Percentage'] * 100\ndf_u['Fully_Paid_Percentage'] = df_u['Fully_Paid_Percentage'] * 100\ndf_u",
                "true_label": "",
                "top5_preds": [
                    "create a one column dataframe with the values of a series",
                    "create a dataframe by joining series by column",
                    "from dictionary to dataframe",
                    "create dataframe with given values",
                    "join two dataframes along rows"
                ]
            },
            {
                "code": "nan_count_df = loan.isnull().sum().to_frame('nan_count')\nnum_col_with_all_nan = nan_count_df.loc[nan_count_df['nan_count']  == loan.shape[0], :].shape[0]\nprint('Number of columns with all NaN values are %d.' % (num_col_with_all_nan))",
                "true_label": "",
                "top5_preds": [
                    "computing the covariance when there are nan s",
                    "drop the rows with nan values",
                    "find data type of each column",
                    "what is the number of columns in the dataset?",
                    "return a dataframe"
                ]
            },
            {
                "code": "# Removing columns which have all values as NaN\nloans_frame = loan.dropna(axis=1, how=\"all\")\nprint('The loan dataset set has now %d rows and %d columns' % (loans_frame.shape[0], loans_frame.shape[1]))",
                "true_label": "",
                "top5_preds": [
                    "drop the rows with nan values",
                    "relationships between dataframes",
                    "line plot with a dataframe",
                    "drop data points with missing data",
                    "create dataframe with given values"
                ]
            },
            {
                "code": "data_dict = pd.read_excel(data_dict_file_path, sheet_name=\"LoanStats\")\ndata_dict.head()",
                "true_label": "",
                "top5_preds": [
                    "loading a csv into a dataframe",
                    "load table in pandas",
                    "data given as a dictionary",
                    "from dictionary to dataframe",
                    "importing data with pandas"
                ]
            },
            {
                "code": "filtered_data_dict = data_dict.loc[data_dict['LoanStatNew'].isin(loans_frame.columns), :]",
                "true_label": "",
                "top5_preds": [
                    "from dictionary to dataframe",
                    "line plot with a dataframe",
                    "load table in pandas",
                    "relationships between dataframes",
                    "using a dataframe and matplotlib commands"
                ]
            },
            {
                "code": "loans_frame = loans_frame.loc[loans_frame['loan_status'].isin(['Fully Paid', 'Charged Off']), :]\nloans_frame.head()",
                "true_label": "",
                "top5_preds": [
                    "importing data with pandas",
                    "load table in pandas",
                    "select every row after a specific row",
                    "line plot with a dataframe",
                    "relationships between dataframes"
                ]
            },
            {
                "code": "# Shape of the 'Charged Off' records i.e. number of records and columns\nloans_frame.shape",
                "true_label": "",
                "top5_preds": [
                    "what is the number of columns in the dataset?",
                    "import polynomial features from sklearn",
                    "selecting specific columns in a dataframe",
                    "find data type of each column",
                    "equally spaced numbers on a grid"
                ]
            },
            {
                "code": "clean_loan_df = loans_frame.isnull().sum().sort_index().to_frame('nan_count').reset_index()",
                "true_label": "",
                "top5_preds": [
                    "relationships between dataframes",
                    "line plot with a dataframe",
                    "drop the rows with nan values",
                    "create dataframe with given values",
                    "dataframe methods"
                ]
            },
            {
                "code": "# Creating a dataframe by merging the data dictional the clean_loan dataframe to get a better understanding\ncolumn_desc = pd.merge(filtered_data_dict, clean_loan_df, how=\"inner\", left_on=\"LoanStatNew\", right_on=\"index\")\ncolumn_desc.loc[:,['LoanStatNew','Description','nan_count']]",
                "true_label": "",
                "top5_preds": [
                    "from dictionary to dataframe",
                    "relationships between dataframes",
                    "line plot with a dataframe",
                    "create a dataframe by joining series by column",
                    "using a dataframe and matplotlib commands"
                ]
            },
            {
                "code": "column_desc.loc[column_desc['nan_count'] > 0,['LoanStatNew','Description','nan_count']]",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "create dataframe with given values",
                    "using pandas",
                    "in pandas",
                    "delete column by name"
                ]
            },
            {
                "code": "#### Removing columns  mths_since_last_delinq, mths_since_last_record, next_pymnt_d, emp_title, desc\ncolumns_to_remove = ['emp_title', 'desc', 'url', 'title']\ncolumns_under_process = column_desc.loc[~column_desc['LoanStatNew'].isin(columns_to_remove), 'LoanStatNew'].values\nloans_frame = loans_frame.loc[:,columns_under_process]\n\n# Validate will take 50% percent as cutoff and will keep below that\nmax_allowed_nan = len(loans_frame)/2\nprint(max_allowed_nan)\nloans_frame = loans_frame.loc[:,(nan_count_df['nan_count'] < max_allowed_nan)]\nprint(loans_frame.isnull().sum()) ",
                "true_label": "",
                "top5_preds": [
                    "remove redundant columns vol sold gal and county no",
                    "remove null values from county, category, and category name",
                    "delete column by name",
                    "load table in pandas",
                    "drop data points with missing data"
                ]
            },
            {
                "code": "loans_frame.shape",
                "true_label": "",
                "top5_preds": [
                    "import polynomial features from sklearn",
                    "what is scikit learn?",
                    "tensorflow + keras",
                    "plot multidimensional data in two dimensions",
                    "numpy"
                ]
            },
            {
                "code": "print(\"Total number of unique member in the data set is %d\" % loans_frame['member_id'].nunique())",
                "true_label": "",
                "top5_preds": [
                    "find data type of each column",
                    "load table in pandas",
                    "line plot with a dataframe",
                    "create a dataframe by joining series by column",
                    "from dictionary to dataframe"
                ]
            },
            {
                "code": "pd.options.display.max_columns = 100 # To see all columns\nloans_frame.describe()",
                "true_label": "",
                "top5_preds": [
                    "load table in pandas",
                    "line plot with a dataframe",
                    "pandas plotting",
                    "loading a csv into a dataframe",
                    "dataframe methods"
                ]
            },
            {
                "code": "# Validate all values in column is same by checking unique values in clumn\nuniques = loans_frame.apply(lambda x:x.nunique())\nprint(uniques)",
                "true_label": "",
                "top5_preds": [
                    "find data type of each column",
                    "line plot with a dataframe",
                    "change type of column",
                    "from dictionary to dataframe",
                    "create a dataframe by joining series by column"
                ]
            },
            {
                "code": "# Remove columns where unique values are 1 as it illustrates that all values are same in column\nloans_frame = loans_frame.drop(uniques[uniques <= 1].index, axis = 1)\nprint(loans_frame.shape)\nloans_frame.head()",
                "true_label": "",
                "top5_preds": [
                    "find data type of each column",
                    "load table in pandas",
                    "line plot with a dataframe",
                    "create a one column dataframe with the values of a series",
                    "create dataframe with given values"
                ]
            },
            {
                "code": "charged_off_df = df_u.loc[:, ['Revol_Util_Percentage_Range', 'Charged_Off_Percentage']]\ncharged_off_df['status'] = 'Charged Off'\ncharged_off_df.rename(columns={'Charged_Off_Percentage': 'Percentage_Group'}, inplace=True)\n\nfully_paid_df = df_u.loc[:, ['Revol_Util_Percentage_Range', 'Fully_Paid_Percentage']]\nfully_paid_df['status'] = 'Fully Paid'\nfully_paid_df.rename(columns={'Fully_Paid_Percentage': 'Percentage_Group'}, inplace=True)\nfully_paid_df\n\nchart_df = pd.concat([charged_off_df, fully_paid_df], ignore_index=True);",
                "true_label": "",
                "top5_preds": [
                    "create a dataframe by joining series by column",
                    "create a one column dataframe with the values of a series",
                    "create dataframe with given values",
                    "line plot with a dataframe",
                    "from dictionary to dataframe"
                ]
            },
            {
                "code": "home_ownership_analysis = category_univariate_analysis('home_ownership')\nhome_ownership_analysis",
                "true_label": "",
                "top5_preds": [
                    "predicting a categorical response",
                    "dataframe methods",
                    "create a one column dataframe with the values of a series",
                    "shortcut principal component analysis in scikit learn",
                    "relationships between dataframes"
                ]
            },
            {
                "code": "df_h = power_law_df(home_ownership_analysis.loc[home_ownership_analysis['Charged Off'] != 0, :], 'home_ownership')\ndf_h.sort_values(by='Rank_Log')",
                "true_label": "",
                "top5_preds": [
                    "relationships between dataframes",
                    "sorting data",
                    "line plot with a dataframe",
                    "dataframe methods",
                    "split a dataframe into a testing"
                ]
            },
            {
                "code": "plt.figure(figsize=(15,4))\nsns.pointplot(x=\"Rank_Log\", y=\"Count_Log\", hue=\"status\", data=df_h.loc[:,['Rank_Log', 'Count_Log', 'status']])\nlocs, labels = plt.xticks()\nplt.setp(labels, rotation=45)\nplt.show()",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "ploting out data with box plots",
                    "line plots show the trend of a numerical variable over time",
                    "plot using pandas plotting",
                    "pandas plotting documentation"
                ]
            },
            {
                "code": "plt.figure(figsize=(15,4))\nsns.barplot(x=\"home_ownership\", y=\"Charged_Off_Percent\", data=home_ownership_analysis)\\\n    .set(ylabel='Charged Off(%)', xlabel='Home Ownership')\nplt.show()",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "use pandas to make a bar chart",
                    "create a bar chart",
                    "equally spaced numbers on a grid",
                    "line plots show the trend of a numerical variable over time"
                ]
            },
            {
                "code": "df_p = power_law_df(verification_status_analysis, 'verification_status')\ndf_p.sort_values(by='Rank_Log')",
                "true_label": "",
                "top5_preds": [
                    "relationships between dataframes",
                    "find data type of each column",
                    "predicting a categorical response",
                    "line plot with a dataframe",
                    "sorting data"
                ]
            }
        ],
        [
            {
                "code": "%matplotlib inline\nimport matplotlib\nimport matplotlib.pylab as plt\nimport numpy as np\nimport pickle\nfrom keras import layers\nfrom keras import models\nfrom keras import optimizers\nfrom keras.utils import to_categorical\nfrom keras.datasets import mnist\nfrom keras.preprocessing import image\nfrom sklearn.utils import shuffle\nfrom sklearn.model_selection import train_test_split\nfrom skimage import exposure\nfrom skimage.morphology import disk\nfrom skimage.filters import rank\nfrom skimage import img_as_ubyte",
                "true_label": "",
                "top5_preds": [
                    "what is scikit learn?",
                    "polynomial regression with sklearn",
                    "import polynomial features from sklearn",
                    "plot using matplotlib",
                    "timing, numpy, plotting"
                ]
            },
            {
                "code": "img_generator = image.ImageDataGenerator(\n                    rotation_range     = 40,\n                    width_shift_range  = 0.15,\n                    height_shift_range = 0.15,\n                    shear_range        = 10,\n                    zoom_range         = 0.3,\n                    horizontal_flip    = False,\n                    vertical_flip      = False )",
                "true_label": "",
                "top5_preds": [
                    "read images point",
                    "create an array of linearly spaced points",
                    "read the dataset",
                    "getting data from the internet",
                    "getting the dataset"
                ]
            },
            {
                "code": "i = 0\nimage_list = []\nfor x in img_generator.flow(digit, batch_size=1):\n    image_list.append(x.reshape(28,28))\n    i += 1\n    if i%9 ==0:\n        break\n        \nfig, axes = plt.subplots(nrows=3, ncols=3, figsize=(8,8),\n                             sharex=True, sharey=True)\nax = axes.ravel()                      \nfor i in range(0, len(image_list)):\n    ax[i].imshow(image_list[i], cmap=plt.cm.binary)\nplt.tight_layout()\nplt.show()",
                "true_label": "",
                "top5_preds": [
                    "create an array of linearly spaced points",
                    "equally spaced numbers on a grid",
                    "create an array of integers",
                    "plotting in python",
                    "ploting out data with box plots"
                ]
            },
            {
                "code": "def PercentileAutoLevel(image):\n    '''\n    This function demos several image enhancement methods provided by the skimage library.\n    '''\n    selem = disk(3.5)\n    percent = 0.20\n\n    output = []\n    count = 0\n    for x in image:\n        x = rank.autolevel_percentile(x.reshape(28,28), selem=selem, p0=percent, p1=(1.0-percent))/255.0\n        count += 1\n        output.append(x)\n        if count%1000 == 0:\n            print('batch {} processed.'.format(count))\n    return np.array(output).reshape(image.shape)",
                "true_label": "",
                "top5_preds": [
                    "read images point",
                    "threshold the image point",
                    "perform gradient ascent point",
                    "create a filter function point",
                    "download and inspect the twitter samples dataset"
                ]
            },
            {
                "code": "x_train_autoleveled = PercentileAutoLevel(x_train)",
                "true_label": "",
                "top5_preds": [
                    "predicting a categorical response",
                    "import polynomial features from sklearn",
                    "polynomial regression with sklearn",
                    "what is scikit learn?",
                    "tensorflow + keras"
                ]
            },
            {
                "code": "img_generator.fit(x_train_autoleveled)",
                "true_label": "",
                "top5_preds": [
                    "tensorflow + keras",
                    "logistic regression using tensorflow",
                    "polynomial regression with sklearn",
                    "import polynomial features from sklearn",
                    "what is scikit learn?"
                ]
            },
            {
                "code": "train_generator = img_generator.flow(x_train_autoleveled, y_train, batch_size=64)",
                "true_label": "",
                "top5_preds": [
                    "tensorflow + keras",
                    "logistic regression using tensorflow",
                    "simple convolutional neural network",
                    "tensorflow",
                    "what is scikit learn?"
                ]
            },
            {
                "code": "model.load_weights('mnist_CNN_initial_weights.h5')",
                "true_label": "",
                "top5_preds": [
                    "tensorflow + keras",
                    "import polynomial features from sklearn",
                    "what is scikit learn?",
                    "scikit learn",
                    "logistic regression using tensorflow"
                ]
            },
            {
                "code": "steps = len(x_train_autoleveled) // 64\nprint('  Training steps per epoch:', steps)\n\nhistory2 = model.fit_generator( train_generator,\n                                steps_per_epoch = steps,\n                                epochs = 40,\n                                validation_data = (x_val, y_val) )\n\nmodel.save('mnist_CNN_model_2.h5')\n\nwith open('mnist_CNN_history_2.pickle', 'wb') as history_file:\n    pickle.dump(history2, history_file)",
                "true_label": "",
                "top5_preds": [
                    "tensorflow + keras",
                    "logistic regression using tensorflow",
                    "training a sequential model",
                    "step by step guide of machine learning in python",
                    "build a vector of prediction from the trained model"
                ]
            },
            {
                "code": "wrong, ans, pred = get_wrong_predictions(x_val, y_val, y_pred)",
                "true_label": "",
                "top5_preds": [
                    "predicting a categorical response",
                    "check accuracy / score for a logistic classifier",
                    "ridge regression with polynomial features on a grid",
                    "fit a polynomial",
                    "predicting on sample validation data"
                ]
            },
            {
                "code": "plot_predictions(1, x_val, y_val, y_pred, 10, 10)",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "predicting a categorical response",
                    "plot using matplotlib",
                    "plot predictions for every x",
                    "making predictions"
                ]
            },
            {
                "code": "plot_predictions(0, x_val, y_val, y_pred, 10, 10)",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "predicting a categorical response",
                    "plot using matplotlib",
                    "timing, numpy, plotting",
                    "plot predictions for every x"
                ]
            },
            {
                "code": "id = 67\nprint('\\n   prediction:', pred[id])\nprint(' ground truth:', ans[id], '\\n')\nimage_enhancement(wrong[id])",
                "true_label": "",
                "top5_preds": [
                    "check accuracy / score for a logistic classifier",
                    "classification with a cnn",
                    "using the classify function",
                    "predicting a categorical response",
                    "visualizing uncertainty"
                ]
            },
            {
                "code": "id = 91\ndigit = x_val[id]\nplt.imshow(digit.reshape(28,28), cmap=matplotlib.cm.binary)\nplt.axis('off')\nplt.show()\nprint('shape:', digit.shape)",
                "true_label": "",
                "top5_preds": [
                    "plot using matplotlib",
                    "numpy point",
                    "convert binary to hexadecimal",
                    "numpy",
                    "plotting in python"
                ]
            },
            {
                "code": "digit = digit.reshape((1, ) + digit.shape)\ndigit.shape",
                "true_label": "",
                "top5_preds": [
                    "numpy point",
                    "integer multiplication",
                    "pi by means of the arithmetic geometric mean",
                    "convert binary to hexadecimal",
                    "numpy"
                ]
            },
            {
                "code": "learning_rate = 5e-4\n\nmodel = models.Sequential()\nmodel.add(layers.Conv2D(32, 3, activation='relu', padding='same', input_shape=(28,28,1)))\nmodel.add(layers.MaxPool2D(2))\nmodel.add(layers.Conv2D(64, 3, activation='relu', padding='same'))\nmodel.add(layers.MaxPool2D(2))\nmodel.add(layers.Flatten())\nmodel.add(layers.Dropout(0.5))\nmodel.add(layers.Dense(64, activation='relu'))\nmodel.add(layers.Dense(10, activation='softmax'))\n\nmodel.summary()\n\nmodel.compile(optimizer = optimizers.RMSprop(lr=learning_rate), \n              loss = 'categorical_crossentropy',\n              metrics = ['accuracy'])\n\nmodel.save_weights('mnist_CNN_initial_weights.h5')",
                "true_label": "",
                "top5_preds": [
                    "tensorflow + keras",
                    "logistic regression using tensorflow",
                    "training a sequential model",
                    "scikit learn 4 step modeling pattern",
                    "tensorflow"
                ]
            },
            {
                "code": "history = model.fit(x_train, \n                    y_train,\n                    batch_size = 64,\n                    epochs = 40,\n                    validation_data = (x_val, y_val))\n\nmodel.save('mnist_CNN_model.h5')\n\nwith open('mnist_CNN_history.pickle', 'wb') as history_file:\n    pickle.dump(history, history_file)",
                "true_label": "",
                "top5_preds": [
                    "build a vector of prediction from the trained model",
                    "test the model for accuracy",
                    "using the model for prediction",
                    "logistic regression using tensorflow",
                    "fit a logistic regression model using statsmodels using logistic regression formula in patsy"
                ]
            },
            {
                "code": "h = pickle.load( open('mnist_CNN_history.pickle', 'rb'))\nplot_history(h, ymin=0.9)",
                "true_label": "",
                "top5_preds": [
                    "plot using matplotlib",
                    "what is scikit learn?",
                    "plot using pandas plotting",
                    "plot past data",
                    "timing, numpy, plotting"
                ]
            },
            {
                "code": "test_loss, test_acc = model.evaluate(x_test, y_test)\nprint(' test accuracy:', test_acc)",
                "true_label": "",
                "top5_preds": [
                    "test the model for accuracy",
                    "check accuracy / score for a logistic classifier",
                    "logistic regression using tensorflow",
                    "what is scikit learn?",
                    "using the classify function"
                ]
            },
            {
                "code": "m = models.load_model('mnist_CNN_model.h5')",
                "true_label": "",
                "top5_preds": [
                    "import polynomial features from sklearn",
                    "load table in pandas",
                    "what is scikit learn?",
                    "polynomial regression with sklearn",
                    "scikit learn"
                ]
            },
            {
                "code": "h2 = pickle.load( open('mnist_CNN_history_2.pickle', 'rb'))\nplot_history(h2, ymin=0.5)",
                "true_label": "",
                "top5_preds": [
                    "plot using matplotlib",
                    "plot using pandas plotting",
                    "timing, numpy, plotting",
                    "line plots show the trend of a numerical variable over time",
                    "trend lines in pyplot"
                ]
            },
            {
                "code": "test_loss, test_acc = model.evaluate(x_test, y_test)\nprint(' test accuracy:',test_acc)",
                "true_label": "",
                "top5_preds": [
                    "test the model for accuracy",
                    "check accuracy / score for a logistic classifier",
                    "logistic regression using tensorflow",
                    "what is scikit learn?",
                    "tensorflow + keras"
                ]
            },
            {
                "code": "from keras import backend as K",
                "true_label": "",
                "top5_preds": [
                    "tensorflow + keras",
                    "what is scikit learn?",
                    "import polynomial features from sklearn",
                    "scikit learn",
                    "polynomial regression with sklearn"
                ]
            },
            {
                "code": "# Credit: F. Chollet\ndef layer_filter(model, layer_name, filter_index, size=28):\n    layer_output = model.get_layer(layer_name).output\n    loss = K.mean(layer_output[:,:,:,filter_index])    \n    grads = K.gradients(loss, model.input)[0]\n    grads /= (K.sqrt(K.mean(K.square(grads))) + 1e-5)\n    iterate = K.function([model.input], [loss, grads])\n    input_img_data = np.random.random( (1, size, size, 1))*20 + 128.    \n    \n    step = 1.0\n    for i in range(40):\n        loss_value, grads_value = iterate([input_img_data])\n        input_img_data += grads_value * step\n    img = input_img_data[0]\n    \n    img -= img.mean()\n    img /= (img.std() + 1e-5)\n    img *= 0.1\n    img += 0.5\n    img = np.clip(img, 0, 1)\n    \n    return img\n\ndef ConvnetFilters(model, layer_name, filter_size, margin, nrows, ncols, figsize=(20,20)):\n    results = np.zeros((nrows*filter_size+(nrows-1)*margin, ncols*filter_size+(ncols-1)*margin, 1))\n    for i in range(nrows):\n        for j in range(ncols):\n            filter_img = layer_filter(model, layer_name, i+(j*nrows), size=filter_size)        \n            h_start = i*filter_size + i*margin\n            h_end = h_start + filter_size\n            v_start = j*filter_size + j*margin\n            v_end = v_start + filter_size\n            results[h_start:h_end, v_start:v_end,:] = filter_img\n\n    plt.figure(figsize=figsize)\n    h, w = results.shape[0], results.shape[1]\n    plt.title('Filter patterns for layer: {}'.format(layer_name), fontsize=24)\n    plt.imshow(results.reshape(h,w))\n    plt.show()",
                "true_label": "",
                "top5_preds": [
                    "build a vector of prediction from the trained model",
                    "create a filter function point",
                    "squared loss layer",
                    "simple convolutional neural network",
                    "one hidden layer neural network pipeline"
                ]
            },
            {
                "code": "m3 = models.load_model('mnist_CNN_model.h5')\nm3.summary()",
                "true_label": "",
                "top5_preds": [
                    "load table in pandas",
                    "import polynomial features from sklearn",
                    "what is scikit learn?",
                    "polynomial regression with sklearn",
                    "running a multivariate regression in python"
                ]
            },
            {
                "code": "(train_images, train_labels), (x_test, y_test) = mnist.load_data()\ntrain_images.shape, x_test.shape",
                "true_label": "",
                "top5_preds": [
                    "import polynomial features from sklearn",
                    "classification with a cnn",
                    "logistic regression using tensorflow",
                    "numpy",
                    "what is scikit learn?"
                ]
            },
            {
                "code": "h, b = np.histogram(train_labels, bins=10, range=(0,10))\nsigma = h.std()/np.sqrt(10.0)\n\nplt.figure(figsize=(9,6))\nplt.bar(b[:-1], h, width=0.5, fc='r', alpha=0.5)\nplt.hlines(h.mean(), -1, 10, colors='b', linestyle='dashed', label='Average')\nplt.hlines(h.mean(), -1, 10, colors='b', linewidth=sigma, alpha=0.15)\nplt.xlim([-0.7, 9.7])\nplt.ylim([0,8500])\nplt.xlabel('Digit', fontsize=15)\nplt.ylabel('Occurance', fontsize=15)\nplt.xticks([0,1,2,3,4,5,6,7,8,9], fontsize=13)\nplt.yticks(fontsize=13)\nplt.legend(fontsize=13)\nplt.show()",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "line plots show the trend of a numerical variable over time",
                    "ploting out data with box plots",
                    "plot histogram",
                    "trend lines in pyplot"
                ]
            },
            {
                "code": "def plot_digit(x, y):\n    '''\n    Thus function plots the image of x and, optionally, prints its label if provided.\n    Input:\n        x: Grey scale image of the digit, i.e. we are assuming there is only one channel. \n           The dimension could be (28, 28) or (28, 28, 1). \n        y: A list of category probabilities. The label is the category that has the \n           maximum probability.\n    '''\n    plt.imshow(x.reshape(28,28), cmap = matplotlib.cm.binary)\n    plt.axis('off')\n    print('label:', np.argmax(y))    \n    plt.show()\n\n\n\n# -------------------------------------------------------------------------------\ndef preprocess(x):\n    '''\n    The function preprocesses the dataset x.\n    '''\n    norm = 255.0    \n    x = x.reshape(x.shape + (1,))\n    x = x.astype('float32') / norm\n    \n    return x\n\n\n# -------------------------------------------------------------------------------\ndef plot_history(history, ymin=0.9, ymax=1.0):\n    '''\n    Simple function that plots metrics in the Keras history class.\n    '''\n    acc = history.history['acc']\n    loss = history.history['loss']\n    val_acc = history.history['val_acc']\n    val_loss = history.history['val_loss']\n    \n    epochs = range(1, len(acc)+1)\n    \n    plt.figure(figsize=(8,10))\n    plt.subplots_adjust(hspace=0.2)\n    \n    plt.subplot(211)\n    plt.plot(epochs, acc,     'bo-', markersize=3, label='Training acc')\n    plt.plot(epochs, val_acc, 'ro-', markersize=3, label='Validation acc')\n    plt.ylim(ymin, ymax)\n    plt.xlim(0, len(acc)+1)\n    plt.xlabel('epoch', fontsize=14)\n    plt.ylabel('Accuracy', fontsize=14)\n    plt.legend()\n    \n    plt.subplot(212)\n    plt.plot(epochs, loss,     'bo-', markersize=3, label='Training loss')\n    plt.plot(epochs, val_loss, 'ro-', markersize=3, label='Validation loss')\n    plt.xlim(0, len(acc)+1)\n    plt.xlabel('epoch', fontsize=14)\n    plt.ylabel('Loss', fontsize=14)\n    plt.legend()\n    \n    plt.show()\n    \n    \n    \n# -------------------------------------------------------------------------------\ndef plot_predictions(flag, x, y, y_pred, nrows, ncols, verbose=False):\n    '''\n    For inspection, this function visualizes correctly or wrongly predicted labels depending on the flag.\n    Inputs --\n         flag: 0 -> show wrong predictions\n               1 -> show correction predictions\n            x: target digit images of shape (batch, height, width, channel)\n            y: target digit labels, assumes the probability form.\n       y_pred: label predictions, assumes the probability form.\n        nrows: number of rows in the final plot\n        ncols: number of columns in the final plot\n      verbose: optional.\n    '''\n    assert flag <= 1, 'The first argument has to be 0 or 1'\n    height = 28\n    width = 28\n    header = 10\n    \n    pred = np.argmax(y_pred, axis=1)\n    ans = np.argmax(y, axis=1)\n    fltr = ( np.array(pred) == np.array(ans) )\n    if verbose:\n        print(' number of correct predictions:', len(x[fltr]))\n        print('   number of wrong predictions:', len(x[~fltr]))\n    if flag == 0:\n        digits = x[~fltr]\n        labels_pred = np.array(pred)[~fltr]\n        labels_ans = np.array(ans)[~fltr]\n    elif flag == 1:\n        digits = x[fltr]\n        labels_pred = np.array(pred)[fltr]\n        labels_ans = np.array(ans)[fltr]\n        \n    # Reshape the images for plotting    \n    digits = digits.reshape(len(digits), 28, 28)\n          \n    # Prepare the figure  \n    d = np.zeros(((height+header)*nrows, width*ncols))\n    fig, ax = plt.subplots(figsize=(14,14), sharex=True, sharey=True)\n    ax.axis('off')\n\n    for i in range(nrows):\n        for j in range(ncols):\n            idx= i*ncols + j            \n            d[i*(height+header)+header:(i+1)*(height+header), j*width:(j+1)*width] = digits[idx]\n            idx = j*ncols + i\n            if flag == 0:\n                ax.text(i*width+9,j*(height+header)+9,labels_pred[idx], \n                        ha=\"center\", va=\"center\", color=\"b\", fontsize=18)\n                ax.text(i*width+19,j*(height+header)+9,labels_ans[idx], \n                        ha=\"center\", va=\"center\", color=\"r\", fontsize=18)        \n            elif flag == 1:\n                ax.text(i*width+14,j*(height+header)+9,labels_pred[idx], \n                        ha=\"center\", va=\"center\", color=\"b\", fontsize=18)                \n    ax.imshow(d, cmap=matplotlib.cm.binary)\n    if flag == 0:\n        plt.title('blue: predictions       red: ground truth ', fontsize=20)\n        plt.suptitle('Samples of wrong predictions', y=0.94, fontsize=24)\n    elif flag == 1:\n        plt.suptitle('Samples of correct predictions', y=0.91, fontsize=24)\n    plt.show()    \n\n    \n    \n# -------------------------------------------------------------------------------\ndef get_wrong_predictions(x, y, y_pred):\n    '''\n    This functions returns digits that are wrongly predicted.\n    Corresponding prediction and ground truth are also returned.\n    '''\n    pred = np.argmax(y_pred, axis=1)\n    ans = np.argmax(y, axis=1)\n    fltr = ( np.array(pred) == np.array(ans) )\n    print(' number of correct predictions:', len(x[fltr]))\n    print('   number of wrong predictions:', len(x[~fltr]))\n\n    digits = x[~fltr]\n    labels_pred = np.array(pred)[~fltr]\n    labels_ans = np.array(ans)[~fltr]\n    \n    return digits.reshape(len(digits), 28,28), labels_ans, labels_pred\n\n\n\n# -------------------------------------------------------------------------------\ndef image_enhancement(image):\n    '''\n    This function demos several image enhancement methods provided by the skimage library.\n    '''\n    selem = disk(3.5)\n    cmap = matplotlib.cm.binary\n    p2, p98 = np.percentile(image, (2, 98))\n    percent = 0.20\n\n    image_rescale = exposure.rescale_intensity(image, in_range=(p2, p98))\n    image_adapteq = exposure.equalize_adapthist(img_as_ubyte(image), clip_limit=0.02)\n    image_eq = exposure.equalize_hist(image)\n    image_al = rank.autolevel(image, selem=selem)\n    image_alp = rank.autolevel_percentile(image, selem=selem, p0=percent, p1=(1.0-percent))\n    image_ec = rank.enhance_contrast(image, disk(2))\n    image_ecp = rank.enhance_contrast_percentile(image, disk(2), p0=percent, p1=(1.0-percent))\n    image_otsu = rank.otsu(image, disk(1))\n\n    fig, axes = plt.subplots(nrows=3, ncols=3, figsize=(8,8),\n                             sharex=True, sharey=True)\n    ax = axes.ravel()\n\n    title_list = ['original',  'contrast streching',\n                  'auto_level','auto-level {0:3.1f}%'.format(percent*100),\n                  'histogram equalizer','adaptive histogram equalizer',\n                  'enhance contrast', 'enhance contrast {0:3.1f}%'.format(percent*100),\n                  'Otsu threshold']\n    image_list = [image, image_rescale,              \n                  image_al, image_alp,\n                  image_eq, image_adapteq,\n                  image_ec, image_ecp,\n                  image_otsu]\n\n    for i in range(0, len(image_list)):\n        ax[i].imshow(image_list[i], cmap=cmap)\n        ax[i].set_title(title_list[i])\n        ax[i].axis('off')\n\n    plt.tight_layout()\n    plt.show()    ",
                "true_label": "",
                "top5_preds": [
                    "plot the data",
                    "plot the function",
                    "plot the training",
                    "visualize the scatterplot of x",
                    "create a scatter plot"
                ]
            },
            {
                "code": "test_size = 20000\nx_train, x_val, y_train, y_val = train_test_split(train_images, \n                                                  train_labels, \n                                                  test_size=test_size, \n                                                  random_state=42)\nx_train = preprocess(x_train)\nx_val   = preprocess(x_val)\nx_test  = preprocess(x_test)\n\ny_train = to_categorical(y_train)\ny_val   = to_categorical(y_val)\ny_test  = to_categorical(y_test)\n\nprint('   training tensor shape:',x_train.shape)\nprint(' validation tensor shape:',x_val.shape)\nprint('       test tensor shape:',x_test.shape)",
                "true_label": "",
                "top5_preds": [
                    "perform a train test split on the data",
                    "train, validation, test sets",
                    "train validation split",
                    "use train_test_split to divide dataset into a training and test set",
                    "create training and validation data split"
                ]
            },
            {
                "code": "idx = 3722\nprint('maximum element of the input image array:', np.amax(x_train[idx]))\nprint('minimum element of the input image array:', np.amin(x_train[idx]))\nplot_digit(x_train[idx], y=y_train[idx])",
                "true_label": "",
                "top5_preds": [
                    "numpy",
                    "line plots show the trend of a numerical variable over time",
                    "ridge regression with one predictor on a grid",
                    "predicting a categorical response",
                    "numpy point"
                ]
            },
            {
                "code": "y_pred = m.predict(x_val, verbose=1)",
                "true_label": "",
                "top5_preds": [
                    "polynomial regression with sklearn",
                    "import polynomial features from sklearn",
                    "logistic regression using tensorflow",
                    "using logistic regression with categorical features",
                    "predicting a categorical response"
                ]
            },
            {
                "code": "ConvnetFilters(m3, 'conv2d_1', filter_size=28, margin=1, nrows=4, ncols=8, figsize=(16,16))",
                "true_label": "",
                "top5_preds": [
                    "simple convolutional neural network",
                    "polynomial regression with sklearn",
                    "scikit learn",
                    "creating polynomial features",
                    "import polynomial features from sklearn"
                ]
            },
            {
                "code": "ConvnetFilters(m3, 'conv2d_2', filter_size=28, margin=1, nrows=8, ncols=8, figsize=(16,16))",
                "true_label": "",
                "top5_preds": [
                    "simple convolutional neural network",
                    "polynomial regression with sklearn",
                    "scikit learn",
                    "import polynomial features from sklearn",
                    "creating polynomial features"
                ]
            },
            {
                "code": "learning_rate=5e-4\nm5 = models.Sequential()\nm5.add(layers.Conv2D(32, 3, activation='relu', padding='same', input_shape=(28,28,1)))\nm5.add(layers.Conv2D(32, 3, activation='relu', padding='same'))\nm5.add(layers.BatchNormalization())\nm5.add(layers.MaxPool2D(2))\nm5.add(layers.Conv2D(64, 3, activation='relu', padding='same'))\nm5.add(layers.Conv2D(64, 3, activation='relu', padding='same'))\nm5.add(layers.BatchNormalization())\nm5.add(layers.MaxPool2D(2))\nm5.add(layers.Conv2D(128, 3, activation='relu', padding='same'))\nm5.add(layers.Conv2D(128, 3, activation='relu', padding='same'))\nm5.add(layers.BatchNormalization())\nm5.add(layers.Flatten())\nm5.add(layers.Dropout(0.5))\nm5.add(layers.Dense(128, activation='relu'))\nm5.add(layers.Dense(32, activation='relu'))\nm5.add(layers.BatchNormalization())\nm5.add(layers.Dense(10, activation='softmax'))\n\nm5.compile(optimizer = optimizers.RMSprop(lr=learning_rate), \n              loss = 'categorical_crossentropy',\n              metrics = ['accuracy'])\nm5.summary()",
                "true_label": "",
                "top5_preds": [
                    "tensorflow + keras",
                    "logistic regression using tensorflow",
                    "scikit learn 4 step modeling pattern",
                    "classification with a cnn",
                    "polynomial regression with sklearn"
                ]
            },
            {
                "code": "h5 = m5.fit_generator( train_generator,\n                  steps_per_epoch = steps,\n                  epochs = 40,\n                  validation_data = (x_val, y_val),\n                  verbose = 1 )\n\nm5.save('mnist_CNN_model_3.h5')\n\nwith open('mnist_CNN_history_3.pickle', 'wb') as history_file:\n    pickle.dump(h5, history_file)",
                "true_label": "",
                "top5_preds": [
                    "function fit_and_predict",
                    "test the model for accuracy",
                    "fit on training",
                    "build a vector of prediction from the trained model",
                    "tensorflow + keras"
                ]
            },
            {
                "code": "h5 = pickle.load( open('mnist_CNN_history_3.pickle', 'rb'))\nplot_history(h5, ymin=0.85)",
                "true_label": "",
                "top5_preds": [
                    "plot using matplotlib",
                    "plot using pandas plotting",
                    "plot past data",
                    "line plots show the trend of a numerical variable over time",
                    "what is scikit learn?"
                ]
            },
            {
                "code": "test_loss, test_acc = m5.evaluate(x_test, y_test)\nprint(' test accuracy:{0:8.4f}'.format(test_acc))",
                "true_label": "",
                "top5_preds": [
                    "check accuracy / score for a logistic classifier",
                    "test the model for accuracy",
                    "compute the mean absolute error of the predictions",
                    "scikit learn",
                    "polynomial regression with sklearn"
                ]
            },
            {
                "code": "id = 67\nprint('\\n   prediction:', pred[id])\nprint(' ground truth:', ans[id], '\\n')\nimage_enhancement(wrong[id])",
                "true_label": "",
                "top5_preds": [
                    "check accuracy / score for a logistic classifier",
                    "classification with a cnn",
                    "using the classify function",
                    "predicting a categorical response",
                    "visualizing uncertainty"
                ]
            }
        ],
        [
            {
                "code": "nam = pd.read_csv('data/morningstar_north_america.csv')\nuk = pd.read_csv('data/morningstar_uk_all_companies.csv')\neurope = pd.read_csv('data/morningstar_europe_ex_uk.csv')\njapan = pd.read_csv('data/morningstar_japan.csv')\nasia_pac = pd.read_csv('data/morningstar_asia_pacific_ex_japan.csv')\ngem = pd.read_csv('data/morningstar_global_emerging_markets.csv')\nchina = pd.read_csv('data/morningstar_china.csv')\nglobal1 = pd.read_csv('data/morningstar_global.csv')\nnam_small = pd.read_csv('data/morningstar_north_america_small_companies.csv')\nuk_small = pd.read_csv('data/morningstar_uk_small_companies.csv')\neurope_small = pd.read_csv('data/morningstar_europe_small_companies.csv')\njapan_small = pd.read_csv('data/morningstar_japan_small_companies.csv')",
                "true_label": "",
                "top5_preds": [
                    "importing data with pandas",
                    "loading a csv into a dataframe",
                    "importing data with numpy",
                    "load table in pandas",
                    "from dictionary to dataframe"
                ]
            },
            {
                "code": "data = pd.concat([nam, uk, europe, japan, asia_pac, gem, china, global1, nam_small, uk_small, europe_small, japan_small])",
                "true_label": "",
                "top5_preds": [
                    "importing data with numpy",
                    "read numbers until and print their mean and standard deviation without using a list",
                    "importing data with pandas",
                    "load table in pandas",
                    "convert date to datetime format"
                ]
            },
            {
                "code": "data.columns",
                "true_label": "",
                "top5_preds": [
                    "load table in pandas",
                    "find data type of each column",
                    "line plot with a dataframe",
                    "loading a csv into a dataframe",
                    "convert text data into vector"
                ]
            },
            {
                "code": "columns_to_drop = ['Morningstar Category',\n                   'Morningstar Rating',\n                   'Morningstar Analyst Rating',\n                   'YTD Return',\n                   'Curr',\n                   'Morningstar Risk (Rel to Category)',\n                   'YTD Return.1',\n                   '1 Year Return',\n                   '5 Year Annualised Return',\n                   '10 Year Annualised Return',\n                   'Bond Style Box',\n                   'Average Credit Quality',\n                   'Average Duration (Years)',\n                   'Max Initial Fee',\n                   'Deferred Fee']",
                "true_label": "",
                "top5_preds": [
                    "drop the rows with nan values",
                    "load table in pandas",
                    "drop data points with missing data",
                    "from dictionary to dataframe",
                    "delete column by name"
                ]
            },
            {
                "code": "data.drop(columns_to_drop, axis = 1, inplace = True)",
                "true_label": "",
                "top5_preds": [
                    "load table in pandas",
                    "drop the rows with nan values",
                    "from dictionary to dataframe",
                    "delete column by name",
                    "drop data points with missing data"
                ]
            },
            {
                "code": "data = data[data['3 Year Volatility'] != '-']",
                "true_label": "",
                "top5_preds": [
                    "convert data from string to float",
                    "retrieving data from html page",
                    "load table in pandas",
                    "loading a csv into a dataframe",
                    "using a dataframe and matplotlib commands"
                ]
            },
            {
                "code": "X = data.drop(['Name', '3 Year Annualised Return', 'Alpha', 'Outperform', 'Excess vol'], axis = 1)\nX = pd.get_dummies(X)\ny = data['3 Year Annualised Return']",
                "true_label": "",
                "top5_preds": [
                    "load table in pandas",
                    "transform categorical data into binary features",
                    "importing data with numpy",
                    "dataframe methods",
                    "loading a csv into a dataframe"
                ]
            },
            {
                "code": "print 'Results for Linear Regression'\nlr_reg = LinearRegression().fit(X, y)\npredictions_lr_reg = lr_reg.predict(X)\nprint 'Score {} --- MSE {}'.format(lr_reg.score(X, y).round(4), mean_squared_error(y, predictions_lr_reg).round(4))\nprint ''\n\nalpha_values = [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n\nprint 'Results for Linear Regression with Ridge Regularisation'\nlr_reg_ridge = RidgeCV(normalize = True, alphas = alpha_values).fit(X, y)\npredictions_lr_reg_ridge = lr_reg_ridge.predict(X)\nprint 'Score {} --- Alpha {} --- MSE {}'.format(lr_reg_ridge.score(X, y).round(4), lr_reg_ridge.alpha_, mean_squared_error(y, predictions_lr_reg_ridge).round(4))\nprint''\n\nprint 'Results for Linear Regression with Lasso Regularisation'\nlr_reg_lasso = LassoCV(alphas = alpha_values).fit(X, y)\npredictions_lr_reg_lasso = lr_reg_lasso.predict(X)\nprint 'Score {} --- Alpha {} --- MSE {}'.format(lr_reg_lasso.score(X, y).round(4), lr_reg_lasso.alpha_, mean_squared_error(y, predictions_lr_reg_lasso).round(4))",
                "true_label": "",
                "top5_preds": [
                    "predicting a continuous response using linear regression",
                    "polynomial regression with sklearn",
                    "ridge regression with polynomial features on a grid",
                    "linear regression of many variables",
                    "ridge regression with one predictor on a grid"
                ]
            },
            {
                "code": "X = data.drop(['Name', '3 Year Annualised Return', 'Alpha', 'Outperform', 'Excess vol'], axis = 1)\nX = pd.get_dummies(X)\ny = data['Outperform']",
                "true_label": "",
                "top5_preds": [
                    "transform categorical data into binary features",
                    "importing data with numpy",
                    "load table in pandas",
                    "dataframe methods",
                    "predicting a categorical response"
                ]
            },
            {
                "code": "print y.value_counts() / y.count()\nprint ''\nprint 'Baseline for the modelling is', 1 - round(y.mean(),2)",
                "true_label": "",
                "top5_preds": [
                    "predicting a categorical response",
                    "line plots show the trend of a numerical variable over time",
                    "line plot with a dataframe",
                    "likelihood of the binomial distribution",
                    "predicting on sample validation data"
                ]
            },
            {
                "code": "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state = 10, stratify = y)",
                "true_label": "",
                "top5_preds": [
                    "what is scikit learn?",
                    "fit on training set",
                    "sentiment classification & how",
                    "fit on training",
                    "ridge regression with one predictor on a grid"
                ]
            },
            {
                "code": "logreg = LogisticRegression()\nlogreg.fit(X_train, y_train)\ny_pred = logreg.predict(X_test)",
                "true_label": "",
                "top5_preds": [
                    "logistic regression using tensorflow",
                    "logistic regression using scikit learn",
                    "fit a logistic regression model using statsmodels using logistic regression formula in patsy",
                    "using logistic regression instead",
                    "using logistic regression with categorical features"
                ]
            },
            {
                "code": "print_classification_scores(y_test, y_pred)",
                "true_label": "",
                "top5_preds": [
                    "check accuracy / score for a logistic classifier",
                    "using the classify function",
                    "intro to classification with knn",
                    "predicting test data",
                    "import polynomial features from sklearn"
                ]
            },
            {
                "code": "def print_roc_curve(model):\n    plt.style.use('seaborn-white')\n    %matplotlib inline\n    # predictions\n    y_pred = model.decision_function(X_test)\n    # get rates\n    fpr, tpr, thr = roc_curve(y_test, y_pred)\n    roc_auc = auc(fpr, tpr)\n    # plot the chart\n    plt.figure(figsize=[8,6])\n    plt.plot(fpr, tpr, label = 'ROC curve (area = %0.2f)' % roc_auc, linewidth = 4)\n    plt.plot([0, 1], [0, 1], 'k--', linewidth = 4)\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.0])\n    plt.xlabel('False Positive Rate (1-Specificity)', fontsize = 12)\n    plt.ylabel('Recall or True Positive Rate (Sensitivity)', fontsize = 12)\n    plt.title('ROC curve', fontsize = 16)\n    plt.legend(loc = \"lower right\")\n    #plt.show()",
                "true_label": "",
                "top5_preds": [
                    "plot roc curve",
                    "plot the training",
                    "function fit_and_predict",
                    "predictive distribution",
                    "plot the function"
                ]
            },
            {
                "code": "def check_test_train():\n    print X_train.shape\n    print y_train.shape\n    print X_test.shape\n    print y_test.shape",
                "true_label": "",
                "top5_preds": [
                    "making predictions for the testing data",
                    "test the model for accuracy",
                    "train, validation, test sets",
                    "check accuracy / score for a logistic classifier",
                    "predict on test set"
                ]
            },
            {
                "code": "def print_cv_scores(model, cv):\n    print 'Cross val score of', cross_val_score(model, X, y, cv = cv).mean().round(4), 'from all data'\n    print 'Cross val score of', cross_val_score(model, X_train, y_train, cv = cv).mean().round(4), 'from train data'\n    print 'Cross val score of', cross_val_score(model, X_test, y_test, cv = cv).mean().round(4), 'from test data'",
                "true_label": "",
                "top5_preds": [
                    "check accuracy / score for a logistic classifier",
                    "making predictions for the testing data",
                    "build a vector of prediction from the trained model",
                    "predicting on sample validation data",
                    "one class svm fitting and estimates"
                ]
            },
            {
                "code": "# we need to add a constant in StatsModels (c.f. skLearn where this is not needed)\nX = sm.add_constant(X)\n\n# create train and test set\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33)\n\n# train the model and predict using the test set\nmodel = sm.OLS(y_train, X_train).fit()\npredictions = model.predict(X_test)\nmodel.summary()",
                "true_label": "",
                "top5_preds": [
                    "import polynomial features from sklearn",
                    "fit a logistic regression model using statsmodels using logistic regression formula in patsy",
                    "one class svm fitting and estimates",
                    "scipy",
                    "ridge regression with polynomial features on a grid"
                ]
            },
            {
                "code": "lr_features = pd.DataFrame(zip(X_train.columns, model.params),\n                           columns = ['Feature', 'Coefficient']).sort_values(by = 'Coefficient', ascending = False)",
                "true_label": "",
                "top5_preds": [
                    "supervised learning support vector machine",
                    "linear regression of many variables",
                    "import polynomial features from sklearn",
                    "calculate and store features in database",
                    "linear regression with statsmodels and scikit learn"
                ]
            },
            {
                "code": "data.loc[data['Total Assets (GBPm)'].isnull(),:] ",
                "true_label": "",
                "top5_preds": [
                    "load table in pandas",
                    "create dataframe with given values",
                    "remove null values from county, category, and category name",
                    "using pandas",
                    "loading a csv into a dataframe"
                ]
            },
            {
                "code": "data['Min Initial Purchase'] = data['Min Initial Purchase'].str.replace('1 Share', '1')\ndata['Min Initial Purchase'] = data['Min Initial Purchase'].str.replace('-', '1')\ndata['Min Initial Purchase'] = data['Min Initial Purchase'].str.replace(' GBP', '')\ndata['Min Initial Purchase'] = data['Min Initial Purchase'].str.replace(',', '')",
                "true_label": "",
                "top5_preds": [
                    "convert data from string to float",
                    "convert date to datetime format",
                    "convert integer or float data",
                    "convert strings to numbers",
                    "get a positive integer from a user"
                ]
            },
            {
                "code": "data.dtypes",
                "true_label": "",
                "top5_preds": [
                    "find data type of each column",
                    "convert text data into vector",
                    "numpy",
                    "convert data from string to float",
                    "convert integer or float data"
                ]
            },
            {
                "code": "data['3 Year Volatility'] = data['3 Year Volatility'].astype(float)\ndata['3 Year Annualised Return'] = data['3 Year Annualised Return'].astype(float)\ndata['Average Market Cap (GBPm)'] = data['Average Market Cap (GBPm)'].astype(int)\ndata['Total Assets (GBPm)'] = data['Total Assets (GBPm)'].astype(int)\ndata['Ongoing Charge'] = data['Ongoing Charge'].astype(float)\ndata['Manager Tenure (Years)'] = data['Manager Tenure (Years)'].astype(float)\ndata['Min Initial Purchase'] = data['Min Initial Purchase'].astype(int)",
                "true_label": "",
                "top5_preds": [
                    "convert data from string to float",
                    "convert integer or float data",
                    "convert date to datetime format",
                    "change type of column",
                    "using pandas"
                ]
            },
            {
                "code": "def print_classification_scores(y_test, y_pred):\n    print 'Accuracy score  ', accuracy_score(y_test, y_pred).round(4)\n    print 'Precision score ', precision_score(y_test, y_pred).round(4)\n    print 'Recall score    ', recall_score(y_test, y_pred).round(4)\n    print 'F1 score        ', f1_score(y_test, y_pred).round(4)\n    print 'ROC AuC score   ', roc_auc_score(y_test, y_pred).round(4)\n    print ''\n    print 'Classification report'\n    print classification_report(y_test, y_pred)\n    print ''\n    print 'Confusion matrix'\n    predicted_cols = ['Predicted ' + str(c) for c in y.unique()]\n    actual_rows = ['Actual ' + str(c) for c in y.unique()]\n    conf = confusion_matrix(y_test, y_pred)\n    print pd.DataFrame(conf, index = actual_rows, columns = predicted_cols)",
                "true_label": "",
                "top5_preds": [
                    "check accuracy / score for a logistic classifier",
                    "making predictions for the testing data",
                    "test the model for accuracy",
                    "predict on test set",
                    "get the sse by using the predictions for every x y_hats and the true y values"
                ]
            },
            {
                "code": "def prettify_confusion_matrix(cm, classes, title='Confusion matrix', cmap=plt.cm.Blues):\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=0)\n    plt.yticks(tick_marks, classes)\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    #plt.show()",
                "true_label": "",
                "top5_preds": [
                    "confusion matrix",
                    "using the classify function",
                    "visualize the scatterplot of x",
                    "compute covariance matrix",
                    "plot the cdf"
                ]
            },
            {
                "code": "print_roc_curve(logreg)",
                "true_label": "",
                "top5_preds": [
                    "fit a polynomial",
                    "ridge regression with polynomial features on a grid",
                    "line plots show the trend of a numerical variable over time",
                    "ridge regression with one predictor on a grid",
                    "plot roc curve"
                ]
            },
            {
                "code": "logreg_gs = LogisticRegression()\nC_vals = [0.0001, 0.001, 0.01, 0.1, 0.5, 0.75, 1.0, 2.5, 5.0, 10.0, 20.0, 100.0, 1000.0]\npenalties = ['l1','l2']\ngs = GridSearchCV(logreg_gs, {'penalty': penalties, 'C': C_vals}, verbose = True, cv = 5, scoring = 'accuracy')\ngs.fit(X_train, y_train)",
                "true_label": "",
                "top5_preds": [
                    "using logistic regression instead",
                    "ridge regression with polynomial features on a grid",
                    "linear regression of many variables",
                    "fit a logistic regression model using statsmodels using logistic regression formula in patsy",
                    "fit a logistic regression model"
                ]
            },
            {
                "code": "print 'Best parameters resulting from the Grid Search are', gs.best_params_",
                "true_label": "",
                "top5_preds": [
                    "equally spaced numbers on a grid",
                    "ridge regression with polynomial features on a grid",
                    "ridge regression with one predictor on a grid",
                    "predicting a continuous response using linear regression",
                    "fit a polynomial"
                ]
            },
            {
                "code": "gs_logreg = LogisticRegression(C = gs.best_params_['C'], penalty = gs.best_params_['penalty'], solver = 'liblinear')\ngs_logreg.fit(X_train, y_train)\ny_pred = gs_logreg.predict(X_test)",
                "true_label": "",
                "top5_preds": [
                    "fit a logistic regression model using statsmodels using logistic regression formula in patsy",
                    "logistic regression using scikit learn",
                    "using logistic regression instead",
                    "polynomial regression with sklearn",
                    "fit a logistic regression model"
                ]
            },
            {
                "code": "print_cv_scores(gs_logreg, 3)",
                "true_label": "",
                "top5_preds": [
                    "visualizing uncertainty",
                    "scipy",
                    "predicting a continuous response using linear regression",
                    "numpy",
                    "interpreting logistic regression coefficients"
                ]
            },
            {
                "code": "# another way to get the accuracy\nprint gs_logreg.score(X_test, y_test).round(4)",
                "true_label": "",
                "top5_preds": [
                    "check accuracy / score for a logistic classifier",
                    "predicting a categorical response",
                    "ridge regression with polynomial features on a grid",
                    "polynomial regression with sklearn",
                    "fit a logistic regression model using statsmodels using logistic regression formula in patsy"
                ]
            },
            {
                "code": "conmat_gs_logreg = confusion_matrix(y_test, y_pred, labels = gs_logreg.classes_)\nprettify_confusion_matrix(conmat_gs_logreg, classes = gs_logreg.classes_)",
                "true_label": "",
                "top5_preds": [
                    "check accuracy / score for a logistic classifier",
                    "interpreting logistic regression coefficients",
                    "import polynomial features from sklearn",
                    "using logistic regression with categorical features",
                    "polynomial regression with sklearn"
                ]
            },
            {
                "code": "print_roc_curve(gs_logreg)",
                "true_label": "",
                "top5_preds": [
                    "ridge regression with polynomial features on a grid",
                    "fit a polynomial",
                    "ridge regression with one predictor on a grid",
                    "using logistic regression instead",
                    "line plots show the trend of a numerical variable over time"
                ]
            },
            {
                "code": "plt.hist(data['Ongoing Charge'], bins = 12)\nplt.title('Histogram of annual fees charged by investment managers', fontsize = 12)\nplt.show()",
                "true_label": "",
                "top5_preds": [
                    "line plots show the trend of a numerical variable over time",
                    "line plot with a dataframe",
                    "plot histogram",
                    "ploting out data with box plots",
                    "plot using pandas plotting"
                ]
            },
            {
                "code": "print 'Average fee of a passive fund', round(data.loc[data['Passive'] == 1, 'Ongoing Charge'].mean(),2)\nprint 'Average fee of an active fund', round(data.loc[data['Passive'] == 0, 'Ongoing Charge'].mean(),2)",
                "true_label": "",
                "top5_preds": [
                    "predicting a categorical response",
                    "convert data from string to float",
                    "get a positive integer from a user",
                    "predicting on sample validation data",
                    "line plots show the trend of a numerical variable over time"
                ]
            },
            {
                "code": "passives = data[data['Passive'] == 1]\nactives = data[data['Passive'] == 0]",
                "true_label": "",
                "top5_preds": [
                    "predicting a categorical response",
                    "convert categorical variables",
                    "line plot with a dataframe",
                    "what is scikit learn?",
                    "importing data with numpy"
                ]
            },
            {
                "code": "plt.figure(figsize = (10,5))\nplt.scatter(actives['Excess vol'], actives['Alpha'], label = 'Active funds', c = 'b', marker = 'o')\nplt.scatter(passives['Excess vol'], passives['Alpha'], label = 'Passive funds', c = 'c', marker = 'o')\nplt.title('Excess returns vs excess risk over three years for all funds')\nplt.xlabel('Excess volatility')\nplt.ylabel('Excess return')\nplt.legend(loc = 'upper right')\nplt.axis([-10, 15, -20, 20])",
                "true_label": "",
                "top5_preds": [
                    "plot using matplotlib",
                    "line plot with a dataframe",
                    "line plots show the trend of a numerical variable over time",
                    "plotting in python",
                    "matplotlib"
                ]
            },
            {
                "code": "data.Outperform.value_counts()",
                "true_label": "",
                "top5_preds": [
                    "convert data from string to float",
                    "find data type of each column",
                    "convert text data into vector",
                    "predicting a categorical response",
                    "counting word frequency"
                ]
            },
            {
                "code": "print 'Baseline will be', round(617/(434+617), 2)",
                "true_label": "",
                "top5_preds": [
                    "reverse digits in a number",
                    "read numbers until and print their mean and standard deviation without using a list",
                    "equally spaced numbers on a grid",
                    "bytes to integer conversion",
                    "resampling and frequency conversion"
                ]
            },
            {
                "code": "data = data[data['Min Initial Purchase'] <= 10000]",
                "true_label": "",
                "top5_preds": [
                    "importing data with pandas",
                    "load table in pandas",
                    "find maximum and the minimum value in a set",
                    "importing data with numpy",
                    "selecting specific columns in a dataframe"
                ]
            },
            {
                "code": "round(np.percentile(data['Alpha'], 58.7), 2)",
                "true_label": "",
                "top5_preds": [
                    "predicting a categorical response",
                    "convert data from string to float",
                    "line plot with a dataframe",
                    "ploting out data with box plots",
                    "read numbers until and print their mean and standard deviation without using a list"
                ]
            },
            {
                "code": "print 'Mean 3 year excess return for active funds', round(actives['Alpha'].mean(), 2)\nprint 'Mean 3 year excess std dev for active funds', round(actives['Excess vol'].mean(), 2)\nprint ''\n\nprint 'Mean 3 year excess return for passive funds', round(passives['Alpha'].mean(), 2)\nprint 'Mean 3 year excess std dev for passive funds', round(passives['Excess vol'].mean(), 2)",
                "true_label": "",
                "top5_preds": [
                    "line plots show the trend of a numerical variable over time",
                    "predicting a categorical response",
                    "remove duplicates from a list",
                    "sum all the numbers in a list",
                    "formatting datetimes as strings"
                ]
            },
            {
                "code": "data = data[data['Total Assets (GBPm)'] != '-']\ndata['Total Assets (GBPm)'] = data['Total Assets (GBPm)'].str.replace(',', '')",
                "true_label": "",
                "top5_preds": [
                    "convert data from string to float",
                    "remove null values from county, category, and category name",
                    "convert integer or float data",
                    "convert text data into vector",
                    "convert date to datetime format"
                ]
            },
            {
                "code": "# data.loc[data['Total Assets (GBPm)'].isnull(),:]",
                "true_label": "",
                "top5_preds": [
                    "load table in pandas",
                    "remove null values from county, category, and category name",
                    "importing data with pandas",
                    "create dataframe with given values",
                    "using pandas"
                ]
            },
            {
                "code": "data['Total Assets (GBPm)'] = data['Total Assets (GBPm)'].fillna(fund_size)",
                "true_label": "",
                "top5_preds": [
                    "create dataframe with given values",
                    "create a one column dataframe with the values of a series",
                    "convert data from string to float",
                    "create a dataframe",
                    "create a dataframe by joining series by column"
                ]
            },
            {
                "code": "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, stratify = y)",
                "true_label": "",
                "top5_preds": [
                    "what is scikit learn?",
                    "sentiment classification & how",
                    "perform a train test split on the data",
                    "intro to classification with knn",
                    "fit on training set"
                ]
            },
            {
                "code": "dt = DecisionTreeClassifier(max_depth = 3)\ndt.fit(X_train, y_train)\ny_pred = dt.predict(X_test)\n\nprint_classification_scores(y_test, y_pred)",
                "true_label": "",
                "top5_preds": [
                    "check accuracy / score for a logistic classifier",
                    "using the classify function",
                    "import polynomial features from sklearn",
                    "logistic regression using tensorflow",
                    "what is scikit learn?"
                ]
            },
            {
                "code": "print_cv_scores(dt, 3)",
                "true_label": "",
                "top5_preds": [
                    "visualizing uncertainty",
                    "numpy point",
                    "using pipelines with gridsearchcv",
                    "predicting a categorical response",
                    "scikit image panorama"
                ]
            },
            {
                "code": "depth = []\nscores = []\nfor i in range(1,11):\n    dt = DecisionTreeClassifier(max_depth = i)\n    dt.fit(X,y)\n    mse = -cross_val_score(dt, X, y, scoring = 'neg_mean_squared_error', cv = 3)\n    depth.append(i)\n    scores.append(np.mean(np.sqrt(mse)))\nplt.plot(depth, scores)\nplt.title('Chart showing variation of RMSE with tree depth')\nplt.xlabel('Tree depth')\nplt.ylabel('RMSE')\nplt.grid(True)\nplt.show()",
                "true_label": "",
                "top5_preds": [
                    "check accuracy / score for a logistic classifier",
                    "predicting a categorical response",
                    "decision tree learning with sklearn",
                    "import polynomial features from sklearn",
                    "using the classify function"
                ]
            },
            {
                "code": "dt_gs = DecisionTreeClassifier()\n\nparameters = {'max_depth': [1,2,3,4,5],\n              'max_features': [1,2,3,4], \n              'max_leaf_nodes': [5,6,7,8],\n              'min_samples_leaf': [1,2,3,4],\n              'min_samples_split': [1,2,3,4]\n             }\n\nclf = GridSearchCV(dt_gs, parameters, scoring = 'accuracy', cv = 5)\nclf.fit(X_train, y_train)\n\nprint clf.best_estimator_\nprint''\nprint 'Best score', clf.best_score_.round(4), 'with parameters', clf.best_params_",
                "true_label": "",
                "top5_preds": [
                    "build a decision tree classifier",
                    "polynomial regression with sklearn",
                    "decision tree learning with sklearn",
                    "check accuracy / score for a logistic classifier",
                    "build a vector of prediction from the trained model"
                ]
            },
            {
                "code": "dt_gs = DecisionTreeClassifier(max_features = 3, max_leaf_nodes = 7, min_samples_split = 4,\n                               max_depth = 3, min_samples_leaf = 3)\n\ndt_gs.fit(X_train, y_train)\ny_pred = dt_gs.predict(X_test)\n\nprint_classification_scores(y_test, y_pred)",
                "true_label": "",
                "top5_preds": [
                    "decision tree learning with sklearn",
                    "polynomial regression with sklearn",
                    "import polynomial features from sklearn",
                    "logistic regression using tensorflow",
                    "what is scikit learn?"
                ]
            },
            {
                "code": "data['Outperform'] = data.Alpha.map(lambda x: 1 if x > 0 else 0)",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "convert data from string to float",
                    "convert integer or float data",
                    "predicting a categorical response",
                    "pandas apply"
                ]
            },
            {
                "code": "data.describe()",
                "true_label": "",
                "top5_preds": [
                    "formatting datetimes as strings",
                    "getting data from the internet",
                    "load table in pandas",
                    "predicting a categorical response",
                    "line plot with a dataframe"
                ]
            },
            {
                "code": "print pd.value_counts(data['IMA Sector'])\nprint ''\nprint 'There are', pd.value_counts(data['IMA Sector']).sum(), 'funds in total'",
                "true_label": "",
                "top5_preds": [
                    "read numbers until and print their mean and standard deviation without using a list",
                    "get a positive integer from a user",
                    "convert integer or float data",
                    "find data type of each column",
                    "convert data from string to float"
                ]
            },
            {
                "code": "regions = ['UK All Companies',\n'Global',\n'Europe Excluding UK',\n'Global Emerging Markets',\n'North America',\n'Asia Pacific Excluding Japan',\n'Japan',\n'UK Smaller Companies',\n'China/Greater China',\n'European Smaller Companies',\n'North American Smaller Companies',\n'Japanese Smaller Companies']\n\nreturns = []\nrisk = []\n\nfor region in regions:\n    returns.append(data[data['IMA Sector'] == region]['3 Year Annualised Return'].mean())\n    risk.append(data[data['IMA Sector'] == region]['3 Year Volatility'].mean())\n\nfig, ax = plt.subplots()\nax.scatter(risk, returns)\nplt.title('Return v risk plot for the various IA sectors', fontsize = 14)\nplt.xlabel('3 Year Annualised Volatility')\nplt.ylabel('3 Year Annualised Return')\nplt.grid(True)\n\nfor i, txt in enumerate(regions):\n    ax.annotate(txt, (risk[i], returns[i]))",
                "true_label": "",
                "top5_preds": [
                    "remove duplicates from a list",
                    "add an item in a tuple",
                    "sum all the numbers in a list",
                    "create a list of all words",
                    "formatting datetimes as strings"
                ]
            },
            {
                "code": "data = data[data['Ongoing Charge'] != '-']",
                "true_label": "",
                "top5_preds": [
                    "get a positive integer from a user",
                    "convert data from string to float",
                    "retrieving data from html page",
                    "importing data with numpy",
                    "importing data with pandas"
                ]
            },
            {
                "code": "data = data[data['Average Market Cap (GBPm)'] != '-']\ndata['Average Market Cap (GBPm)'] = data['Average Market Cap (GBPm)'].str.replace(',', '')",
                "true_label": "",
                "top5_preds": [
                    "convert data from string to float",
                    "remove null values from county, category, and category name",
                    "convert date to datetime format",
                    "convert integer or float data",
                    "convert text data into vector"
                ]
            },
            {
                "code": "data = data[data['Manager Tenure (Years)'] != '-']",
                "true_label": "",
                "top5_preds": [
                    "load table in pandas",
                    "convert data from string to float",
                    "loading a csv into a dataframe",
                    "convert text data into vector",
                    "retrieving data from html page"
                ]
            },
            {
                "code": "fund_size = data[(data['IMA Sector'] == 'North American Smaller Companies') | (data['IMA Sector'] == 'Japanese Smaller Companies')]['Total Assets (GBPm)'].median()\nprint 'The median fund size in the North American and Japanese Smaller Companies sectors is', fund_size, 'GBPm'",
                "true_label": "",
                "top5_preds": [
                    "convert data from string to float",
                    "find maximum and the minimum value in a set",
                    "get a positive integer from a user",
                    "read numbers until and print their mean and standard deviation without using a list",
                    "predicting a categorical response"
                ]
            },
            {
                "code": "data.reset_index(inplace = True, drop = True)",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "load table in pandas",
                    "using a dataframe and matplotlib commands",
                    "from dictionary to dataframe",
                    "line plots show the trend of a numerical variable over time"
                ]
            },
            {
                "code": "dot_data = StringIO()  \nexport_graphviz(dt, out_file = dot_data,  \n                feature_names = X.columns,  \n                filled = True, rounded = True,  \n                special_characters = True)  \ngraph = pydot.graph_from_dot_data(dot_data.getvalue())\nImage(graph[0].create_png())",
                "true_label": "",
                "top5_preds": [
                    "create a graph",
                    "data visualization",
                    "ploting out data with box plots",
                    "plot the data",
                    "visualize the distribution histogram of x using sns distplot"
                ]
            },
            {
                "code": "importance = pd.DataFrame({'Feature': X.columns, 'Importance': dt.feature_importances_}\n                         ).sort_values('Importance', ascending = False)\nimportance = importance[importance.Importance != 0]\nimportance",
                "true_label": "",
                "top5_preds": [
                    "import polynomial features from sklearn",
                    "importing data with numpy",
                    "importing data with pandas",
                    "relationships between dataframes",
                    "dataframe methods"
                ]
            },
            {
                "code": "bag = BaggingClassifier(dt, n_estimators = 100)\nbag.fit(X_train, y_train)\ny_pred = bag.predict(X_test)\n\nprint_classification_scores(y_test, y_pred)",
                "true_label": "",
                "top5_preds": [
                    "check accuracy / score for a logistic classifier",
                    "using the classify function",
                    "test the model for accuracy",
                    "implementing bag of words in scikit learn",
                    "import polynomial features from sklearn"
                ]
            },
            {
                "code": "print_cv_scores(bag, 3)",
                "true_label": "",
                "top5_preds": [
                    "scikit image panorama",
                    "visualizing uncertainty",
                    "predicting a categorical response",
                    "creating a simple numpy array",
                    "equally spaced numbers on a grid"
                ]
            },
            {
                "code": "# the first line of code here is to deconstruct the coefficients from a list-of-lists to a list\n# so I can use the zip function\n\nlog_reg_coeffs = [i for x in gs_logreg.coef_ for i in x]\nlog_reg_results = zip(X.columns, log_reg_coeffs)",
                "true_label": "",
                "top5_preds": [
                    "import polynomial features from sklearn",
                    "ridge regression with polynomial features on a grid",
                    "fit a polynomial",
                    "equally spaced numbers on a grid",
                    "interpreting logistic regression coefficients"
                ]
            },
            {
                "code": "log_reg_features = pd.DataFrame(log_reg_results, columns = ['Features', 'Coefficient']).sort_values(by = 'Coefficient', ascending = False)",
                "true_label": "",
                "top5_preds": [
                    "predicting a categorical response",
                    "using logistic regression with categorical features",
                    "using logistic regression instead",
                    "linear regression of many variables",
                    "import polynomial features from sklearn"
                ]
            },
            {
                "code": "log_reg_features.head(6)",
                "true_label": "",
                "top5_preds": [
                    "import polynomial features from sklearn",
                    "logistic regression using tensorflow",
                    "tensorflow + keras",
                    "what is scikit learn?",
                    "add intercept in logistic regression"
                ]
            },
            {
                "code": "log_reg_features.tail(6)",
                "true_label": "",
                "top5_preds": [
                    "add intercept in logistic regression",
                    "what is scikit learn?",
                    "logistic regression using scikit learn",
                    "logistic regression using tensorflow",
                    "predicting a continuous response using linear regression"
                ]
            },
            {
                "code": "# set the number of random trials\nNUM_TRIALS = 30\n\n# load the dataset\nX = data.drop(['Name', '3 Year Annualised Return', 'Alpha', 'Outperform', 'Excess vol'], axis = 1)\nX = pd.get_dummies(X)\ny = data['Outperform']\n\n# set up possible values of parameters to optimize over\np_grid = {\"C\": [1, 10, 100], \"penalty\": ['l1', 'l2']}\n\n# initialise the model\nmodel = LogisticRegression()\n\n# define arrays to store scores\nnon_nested_scores = np.zeros(NUM_TRIALS)\nnested_scores = np.zeros(NUM_TRIALS)\n\nfor i in range(NUM_TRIALS):\n\n    # Choose cross-validation techniques for the inner and outer loops independently of the dataset.\n    # e.g LabelKFold, LeaveOneOut or LeaveOneLabelOut\n    inner_cv = KFold(n_splits=4, shuffle=True, random_state=i)\n    outer_cv = KFold(n_splits=4, shuffle=True, random_state=i)\n\n    # non_nested parameter search and scoring\n    clf = GridSearchCV(model, param_grid = p_grid, cv = inner_cv)\n    clf.fit(X, y)\n    non_nested_scores[i] = clf.best_score_\n\n    # nested CV with parameter optimization\n    nested_score = cross_val_score(clf, X, y, cv = outer_cv)\n    nested_scores[i] = nested_score.mean()\n\nscore_difference = non_nested_scores - nested_scores\n\nprint(\"Average difference of {0:4f} with std dev of {1:4f}\".format(score_difference.mean(), score_difference.std()))",
                "true_label": "",
                "top5_preds": [
                    "ridge regression with polynomial features on a grid",
                    "ridge regression with one predictor on a grid",
                    "linear regression of many variables",
                    "optimal value of k for dataset",
                    "polynomial regression with sklearn"
                ]
            },
            {
                "code": "# plot scores from each trial for nested and non-nested CV\nplt.figure()\nplt.subplot(211)\nnon_nested_scores_line, = plt.plot(non_nested_scores, color='r')\nnested_line, = plt.plot(nested_scores, color='b')\nplt.ylabel(\"Score\", fontsize=\"14\")\nplt.legend([non_nested_scores_line, nested_line],\n           [\"Non-Nested CV\", \"Nested CV\"],\n           bbox_to_anchor=(0, 1.05, 1, 0))\nplt.title(\"Non-Nested and Nested Cross Validation\",\n          x=.5, y=1.1, fontsize=\"15\")\nplt.grid(True)\n\n# plot a bar chart of the difference.\nplt.subplot(212)\ndifference_plot = plt.bar(range(NUM_TRIALS), score_difference)\nplt.xlabel(\"Individual Trial #\")\nplt.legend([difference_plot],\n           [\"Non-Nested CV - Nested CV Score\"],\n           bbox_to_anchor=(0, 1.05, 1, 0))\nplt.ylabel(\"Score difference\", fontsize=\"14\")\nplt.grid(True)\nplt.show()",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "plot using matplotlib",
                    "create a scatter plot",
                    "matplotlib",
                    "line plots show the trend of a numerical variable over time"
                ]
            },
            {
                "code": "n = range(1,51)\n\nscores = []\n\nfor i in n:\n    knn = KNeighborsClassifier(n_neighbors = i)\n    knn.fit(X_train, y_train)\n    y_pred = knn.predict(X_test)\n    score = accuracy_score(y_test, y_pred)\n    scores.append(score)\n    \nplt.plot(n, scores)\nplt.grid(True)\nplt.title('Chart to show the optimum number of K nearest neighbours', fontsize = 12)\nplt.xlabel('Number of neighbours')\nplt.ylabel('Accuracy score')\nplt.show()",
                "true_label": "",
                "top5_preds": [
                    "check accuracy / score for a logistic classifier",
                    "intro to classification with knn",
                    "knn k nearest neighbors classification",
                    "creating a nearest neighbors classifier class",
                    "k nearest neighbors knn classification"
                ]
            },
            {
                "code": "X = data.drop(['Name', '3 Year Annualised Return', 'Alpha', 'Outperform', 'Excess vol'], axis = 1)\nX = pd.get_dummies(X)\nX = StandardScaler().fit_transform(X)\ny = data['Outperform']",
                "true_label": "",
                "top5_preds": [
                    "transform categorical data into binary features",
                    "what is scikit learn?",
                    "import polynomial features from sklearn",
                    "using logistic regression with categorical features",
                    "polynomial regression with sklearn"
                ]
            },
            {
                "code": "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state = 42, stratify = y)",
                "true_label": "",
                "top5_preds": [
                    "what is scikit learn?",
                    "fit on training set",
                    "fit on training",
                    "sentiment classification & how",
                    "ridge regression with one predictor on a grid"
                ]
            },
            {
                "code": "svm_model = SVC(kernel = 'rbf', C = 10)\nsvm_model.fit(X_train, y_train)\ny_pred = svm_model.predict(X_test)",
                "true_label": "",
                "top5_preds": [
                    "one class svm fitting and estimates",
                    "what is scikit learn?",
                    "import polynomial features from sklearn",
                    "logistic regression using tensorflow",
                    "polynomial regression with sklearn"
                ]
            },
            {
                "code": "nam_median_return = data[(data['IMA Sector'] == 'North America') & (data['Passive'] == 1)]['3 Year Annualised Return'].median()\n\nuk_median_return = data[(data['IMA Sector'] == 'UK All Companies') & (data['Passive'] == 1)]['3 Year Annualised Return'].median()\n\neurope_median_return = data[(data['IMA Sector'] == 'Europe Excluding UK') & (data['Passive'] == 1)]['3 Year Annualised Return'].median()\n\njapan_median_return = data[(data['IMA Sector'] == 'Japan') & (data['Passive'] == 1)]['3 Year Annualised Return'].median()\n\nasia_pac_median_return = data[(data['IMA Sector'] == 'Asia Pacific Excluding Japan') & (data['Passive'] == 1)]['3 Year Annualised Return'].median()\n\ngem_median_return = data[(data['IMA Sector'] == 'Global Emerging Markets') & (data['Passive'] == 1)]['3 Year Annualised Return'].median()\n\nglobal_median_return = data[(data['IMA Sector'] == 'Global') & (data['Passive'] == 1)]['3 Year Annualised Return'].median()",
                "true_label": "",
                "top5_preds": [
                    "predicting a categorical response",
                    "convert data from string to float",
                    "calculating the mean of a vector with nans",
                    "using pandas",
                    "find maximum and the minimum value in a set"
                ]
            },
            {
                "code": "print 'Median return of tracker funds'\nprint 'North America   ', nam_median_return\nprint 'UK              ', uk_median_return\nprint 'Europe          ', europe_median_return\nprint 'Japan           ', japan_median_return\nprint 'Asia Pacific    ', asia_pac_median_return\nprint 'Emerging Markets', gem_median_return\nprint 'Global          ', global_median_return",
                "true_label": "",
                "top5_preds": [
                    "formatting datetimes as strings",
                    "line plots show the trend of a numerical variable over time",
                    "convert date to datetime format",
                    "calculating the mean of a vector with nans",
                    "sum all the numbers in a list"
                ]
            },
            {
                "code": "data.groupby(['IMA Sector', 'Passive'])['3 Year Annualised Return'].median()",
                "true_label": "",
                "top5_preds": [
                    "line plots show the trend of a numerical variable over time",
                    "using pandas",
                    "dataframe methods",
                    "line plot with a dataframe",
                    "integrating datetime tools with pandas for time series"
                ]
            },
            {
                "code": "data.insert(11, 'Alpha', 0)",
                "true_label": "",
                "top5_preds": [
                    "add element to list using insert index",
                    "python data type list",
                    "convert text data into vector",
                    "convert integer or float data",
                    "get a positive integer from a user"
                ]
            },
            {
                "code": "# this will tidy up the following cell's output\n\npd.options.mode.chained_assignment = None",
                "true_label": "",
                "top5_preds": [
                    "pandas apply",
                    "load table in pandas",
                    "assign to a variable",
                    "create a dataframe by joining series by column",
                    "relationships between dataframes"
                ]
            },
            {
                "code": "data['Alpha'][data['IMA Sector'] == 'North America'] = data['3 Year Annualised Return'] - nam_median_return\n\ndata['Alpha'][data['IMA Sector'] == 'UK All Companies'] = data['3 Year Annualised Return'] - uk_median_return\n\ndata['Alpha'][data['IMA Sector'] == 'Europe Excluding UK'] = data['3 Year Annualised Return'] - europe_median_return\n\ndata['Alpha'][data['IMA Sector'] == 'Japan'] = data['3 Year Annualised Return'] - japan_median_return\n\ndata['Alpha'][data['IMA Sector'] == 'Asia Pacific Excluding Japan'] = data['3 Year Annualised Return'] - asia_pac_median_return\n\ndata['Alpha'][data['IMA Sector'] == 'Global Emerging Markets'] = data['3 Year Annualised Return'] - gem_median_return\n\ndata['Alpha'][data['IMA Sector'] == 'China/Greater China'] = data['3 Year Annualised Return'] - asia_pac_median_return\n\ndata['Alpha'][data['IMA Sector'] == 'Global'] = data['3 Year Annualised Return'] - global_median_return\n\ndata['Alpha'][data['IMA Sector'] == 'North American Smaller Companies'] = data['3 Year Annualised Return'] - nam_median_return\n\ndata['Alpha'][data['IMA Sector'] == 'UK Smaller Companies'] = data['3 Year Annualised Return'] - uk_median_return\n\ndata['Alpha'][data['IMA Sector'] == 'European Smaller Companies'] = data['3 Year Annualised Return'] - europe_median_return\n\ndata['Alpha'][data['IMA Sector'] == 'Japanese Smaller Companies'] = data['3 Year Annualised Return'] - japan_median_return",
                "true_label": "",
                "top5_preds": [
                    "convert data from string to float",
                    "using pandas",
                    "create a one column dataframe with the values of a series",
                    "importing data with pandas",
                    "importing data with numpy"
                ]
            },
            {
                "code": "nam_median_vol = data[(data['IMA Sector'] == 'North America') & (data['Passive'] == 1)]['3 Year Volatility'].median()\n\nuk_median_vol = data[(data['IMA Sector'] == 'UK All Companies') & (data['Passive'] == 1)]['3 Year Volatility'].median()\n\neurope_median_vol = data[(data['IMA Sector'] == 'Europe Excluding UK') & (data['Passive'] == 1)]['3 Year Volatility'].median()\n\njapan_median_vol = data[(data['IMA Sector'] == 'Japan') & (data['Passive'] == 1)]['3 Year Volatility'].median()\n\nasia_pac_median_vol = data[(data['IMA Sector'] == 'Asia Pacific Excluding Japan') & (data['Passive'] == 1)]['3 Year Volatility'].median()\n\ngem_median_vol = data[(data['IMA Sector'] == 'Global Emerging Markets') & (data['Passive'] == 1)]['3 Year Volatility'].median()\n\nglobal_median_vol = data[(data['IMA Sector'] == 'Global') & (data['Passive'] == 1)]['3 Year Volatility'].median()",
                "true_label": "",
                "top5_preds": [
                    "predicting a categorical response",
                    "using pandas",
                    "line plots show the trend of a numerical variable over time",
                    "calculating the mean of a vector with nans",
                    "line plot with a dataframe"
                ]
            },
            {
                "code": "print 'Median risk of tracker funds'\nprint 'North America   ', nam_median_vol\nprint 'UK              ', uk_median_vol\nprint 'Europe          ', europe_median_vol\nprint 'Japan           ', japan_median_vol\nprint 'Asia Pacific    ', asia_pac_median_vol\nprint 'Emerging Markets', gem_median_vol\nprint 'Global          ', global_median_vol",
                "true_label": "",
                "top5_preds": [
                    "line plots show the trend of a numerical variable over time",
                    "calculating the mean of a vector with nans",
                    "formatting datetimes as strings",
                    "read numbers until and print their mean and standard deviation without using a list",
                    "sum all the numbers in a list"
                ]
            },
            {
                "code": "cm = confusion_matrix(y_test, y_pred)\nprettify_confusion_matrix(cm, classes = logreg.classes_)",
                "true_label": "",
                "top5_preds": [
                    "check accuracy / score for a logistic classifier",
                    "using logistic regression with categorical features",
                    "interpreting logistic regression coefficients",
                    "polynomial regression with sklearn",
                    "import polynomial features from sklearn"
                ]
            },
            {
                "code": "sns.factorplot(data = data, x = 'Passive', y = 'Alpha', kind = 'box')",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "ploting out data with box plots",
                    "dataframe methods",
                    "using a dataframe and matplotlib commands",
                    "fit a polynomial"
                ]
            },
            {
                "code": "sns.factorplot(data = data, x = 'Passive', y = 'Ongoing Charge', kind = 'box')",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "ploting out data with box plots",
                    "using a dataframe and matplotlib commands",
                    "dataframe methods",
                    "pandas plotting"
                ]
            },
            {
                "code": "from __future__ import division\nimport numpy as np\nimport pandas as pd\n\nimport matplotlib\nfrom matplotlib import pyplot as plt\n% matplotlib inline\nplt.style.use('ggplot')\nimport seaborn as sns\nimport pylab\n\nimport statsmodels.api as sm\n\nfrom sklearn import linear_model, feature_selection, metrics, preprocessing\n\nfrom sklearn.linear_model import LinearRegression, LogisticRegression, RidgeCV, LassoCV\n\nfrom sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict, GridSearchCV, KFold\n\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc, roc_auc_score\nfrom sklearn.metrics import confusion_matrix, classification_report, silhouette_score\n\nfrom sklearn.feature_selection import SelectKBest\n\nimport itertools\n\nfrom sklearn.neighbors import KNeighborsClassifier\n\nfrom sklearn.svm import SVC\n\nfrom sklearn.feature_extraction.text import CountVectorizer\n\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\n\nfrom sklearn.tree import DecisionTreeClassifier\n# next four lines for the decision tree diagram\nfrom IPython.display import Image\nfrom sklearn.tree import export_graphviz\nfrom sklearn.externals.six import StringIO\nimport pydot\n\nfrom sklearn.ensemble import RandomForestClassifier, BaggingClassifier\n\nfrom sklearn.cluster import KMeans, DBSCAN\nfrom scipy.cluster.hierarchy import dendrogram, linkage, cophenet, fcluster\nfrom scipy.spatial.distance import pdist\n\nfrom sklearn.decomposition import PCA",
                "true_label": "",
                "top5_preds": [
                    "import polynomial features from sklearn",
                    "plot using matplotlib",
                    "line plots show the trend of a numerical variable over time",
                    "equally spaced numbers on a grid",
                    "timing, numpy, plotting"
                ]
            },
            {
                "code": "X = data[['IMA Sector', 'Equity Style Box']].copy()\ny = data['Outperform']",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "numpy",
                    "importing data with numpy",
                    "scipy",
                    "plot multidimensional data in two dimensions"
                ]
            },
            {
                "code": "X['Large'] = X['Equity Style Box'].str.lower().str.contains('large')\nX['Mid'] = X['Equity Style Box'].str.lower().str.contains('mid')\nX['Small'] = X['Equity Style Box'].str.lower().str.contains('small')\nX['Growth'] = X['Equity Style Box'].str.lower().str.contains('growth')\nX['Blend'] = X['Equity Style Box'].str.lower().str.contains('blend')\nX['Value'] = X['Equity Style Box'].str.lower().str.contains('value')\nX['America'] = X['IMA Sector'].str.lower().str.contains('america')\nX['UK'] = X['IMA Sector'].str.lower().str.contains('uk')\nX['Europe'] = X['IMA Sector'].str.lower().str.contains('europe')\nX['Japan'] = X['IMA Sector'].str.lower().str.contains('japan')\nX['Asia'] = X['IMA Sector'].str.lower().str.contains('asia')\nX['China'] = X['IMA Sector'].str.lower().str.contains('china')\nX['Global'] = X['IMA Sector'].str.lower().str.contains('global') & ~X['IMA Sector'].str.lower().str.contains('emerging')\nX['GEM'] = X['IMA Sector'].str.lower().str.contains('emerging')",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "convert categorical variables",
                    "pandas apply",
                    "find data type of each column",
                    "find all by term in field in case insensitive way"
                ]
            },
            {
                "code": "X = X[['Large', 'Mid', 'Small', 'Growth', 'Blend', 'Value', 'America', 'UK', 'Europe', 'Japan', 'Asia', \n       'China', 'Global', 'GEM']]",
                "true_label": "",
                "top5_preds": [
                    "importing data with numpy",
                    "load table in pandas",
                    "import polynomial features from sklearn",
                    "line plot with a dataframe",
                    "linear regression of many variables"
                ]
            },
            {
                "code": "model = LogisticRegression()\nmodel.fit(X_train, y_train)\ny_pred = model.predict(X_test)",
                "true_label": "",
                "top5_preds": [
                    "logistic regression using tensorflow",
                    "fit a logistic regression model using statsmodels using logistic regression formula in patsy",
                    "logistic regression using scikit learn",
                    "polynomial regression with sklearn",
                    "using logistic regression with categorical features"
                ]
            },
            {
                "code": "print 'Accuracy score  ', accuracy_score(y_test, y_pred).round(2)\nprint 'Precision score ', precision_score(y_test, y_pred).round(2)\nprint 'Recall score    ', recall_score(y_test, y_pred).round(2)\nprint 'F1 score        ', f1_score(y_test, y_pred).round(2)\nprint ''\nprint 'Classification report'\nprint classification_report(y_test, y_pred)",
                "true_label": "",
                "top5_preds": [
                    "check accuracy / score for a logistic classifier",
                    "predicting on sample validation data",
                    "predicting a categorical response",
                    "import polynomial features from sklearn",
                    "test whether a number is positive"
                ]
            },
            {
                "code": "data.insert(10, 'Passive', 0)",
                "true_label": "",
                "top5_preds": [
                    "get a positive integer from a user",
                    "convert integer or float data",
                    "python data type list",
                    "convert data from string to float",
                    "add element to list using insert index"
                ]
            },
            {
                "code": "data.loc[data['Name'].str.lower().str.contains('index|indx|idx|tracker|tkr'), 'Passive'] = 1",
                "true_label": "",
                "top5_preds": [
                    "find all by term in field in case insensitive way",
                    "line plot with a dataframe",
                    "sql LIKE operator",
                    "convert categorical variables",
                    "selecting specific columns in a dataframe"
                ]
            },
            {
                "code": "data['Passive'].value_counts()",
                "true_label": "",
                "top5_preds": [
                    "predicting a categorical response",
                    "line plot with a dataframe",
                    "find data type of each column",
                    "in pandas",
                    "working with pandas series indexed by datetime"
                ]
            },
            {
                "code": "data.groupby(['IMA Sector', 'Passive'])['3 Year Volatility'].median()",
                "true_label": "",
                "top5_preds": [
                    "line plots show the trend of a numerical variable over time",
                    "using pandas",
                    "line plot with a dataframe",
                    "dataframe methods",
                    "create a one column dataframe with the values of a series"
                ]
            },
            {
                "code": "data.insert(12, 'Excess vol', 0)",
                "true_label": "",
                "top5_preds": [
                    "how to change the style of individual lines",
                    "add element to list using insert index",
                    "python data type list",
                    "add an item in a tuple",
                    "convert integer or float data"
                ]
            },
            {
                "code": "data['Excess vol'][data['IMA Sector'] == 'North America'] = data['3 Year Volatility'] - nam_median_vol\n\ndata['Excess vol'][data['IMA Sector'] == 'UK All Companies'] = data['3 Year Volatility'] - uk_median_vol\n\ndata['Excess vol'][data['IMA Sector'] == 'Europe Excluding UK'] = data['3 Year Volatility'] - europe_median_vol\n\ndata['Excess vol'][data['IMA Sector'] == 'Japan'] = data['3 Year Volatility'] - japan_median_vol\n\ndata['Excess vol'][data['IMA Sector'] == 'Asia Pacific Excluding Japan'] = data['3 Year Volatility'] - asia_pac_median_vol\n\ndata['Excess vol'][data['IMA Sector'] == 'Global Emerging Markets'] = data['3 Year Volatility'] - gem_median_vol\n\ndata['Excess vol'][data['IMA Sector'] == 'China/Greater China'] = data['3 Year Volatility'] - asia_pac_median_vol\n\ndata['Excess vol'][data['IMA Sector'] == 'Global'] = data['3 Year Volatility'] - global_median_vol\n\ndata['Excess vol'][data['IMA Sector'] == 'North American Smaller Companies'] = data['3 Year Volatility'] - nam_median_vol\n\ndata['Excess vol'][data['IMA Sector'] == 'UK Smaller Companies'] = data['3 Year Volatility'] - uk_median_vol\n\ndata['Excess vol'][data['IMA Sector'] == 'European Smaller Companies'] = data['3 Year Volatility'] - europe_median_vol\n\ndata['Excess vol'][data['IMA Sector'] == 'Japanese Smaller Companies'] = data['3 Year Volatility'] - japan_median_vol",
                "true_label": "",
                "top5_preds": [
                    "using pandas",
                    "create a one column dataframe with the values of a series",
                    "in pandas",
                    "create dataframe with given values",
                    "using a dataframe and matplotlib commands"
                ]
            },
            {
                "code": "data = data[data['3 Year Annualised Return'] != '-']",
                "true_label": "",
                "top5_preds": [
                    "retrieving data from html page",
                    "convert data from string to float",
                    "importing data with pandas",
                    "load table in pandas",
                    "importing data with numpy"
                ]
            },
            {
                "code": "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33)\n\nlr = LinearRegression().fit(X, y)\ny_pred = lr.predict(X)\n\nprint 'Model score', lr.score(X, y).round(3)\nprint ''\nprint 'Model intercept', lr.intercept_.round(3)\nprint ''\nprint 'Coefficients'\nzip(X.columns, lr.coef_)",
                "true_label": "",
                "top5_preds": [
                    "polynomial regression with sklearn",
                    "ridge regression with polynomial features on a grid",
                    "ridge regression with one predictor on a grid",
                    "predicting a continuous response using linear regression",
                    "fit a logistic regression model using statsmodels using logistic regression formula in patsy"
                ]
            },
            {
                "code": "plt.figure(figsize = (8,5))\nplt.scatter(y, y_pred, s = 30)\nplt.title('Linear regression using SciKit Learn')\nplt.xlabel('Actual Returns')\nplt.ylabel('Predicted Returns')\nplt.grid(True)\nplt.show()\nprint 'Mean Squared Error', mean_squared_error(y, y_pred).round(2)",
                "true_label": "",
                "top5_preds": [
                    "predicting a continuous response using linear regression",
                    "ridge regression with polynomial features on a grid",
                    "line plot with a dataframe",
                    "polynomial regression with sklearn",
                    "scipy"
                ]
            },
            {
                "code": "def examine_coefficients(model, df):\n    df = pd.DataFrame({'Feature': df.columns, 'Coefficient': model.coef_[0]}).sort_values(by = 'Coefficient', ascending = False)\n    return df[df.Coefficient != 0]",
                "true_label": "",
                "top5_preds": [
                    "find data type of each column",
                    "co variance matrix",
                    "prepare the data for modelling indicator variables",
                    "dataframe methods",
                    "remove redundant columns vol sold gal and county no"
                ]
            },
            {
                "code": "examine_coefficients(model, X)",
                "true_label": "",
                "top5_preds": [
                    "fit a polynomial",
                    "ridge regression with polynomial features on a grid",
                    "import polynomial features from sklearn",
                    "polynomial regression with sklearn",
                    "ridge regression with one predictor on a grid"
                ]
            },
            {
                "code": "data.Outperform.value_counts()",
                "true_label": "",
                "top5_preds": [
                    "convert data from string to float",
                    "find data type of each column",
                    "convert text data into vector",
                    "predicting a categorical response",
                    "counting word frequency"
                ]
            }
        ],
        [
            {
                "code": "#tag name is div, class name is product-list-item",
                "true_label": "",
                "top5_preds": [
                    "add string to list using append",
                    "sum all the numbers in a list",
                    "convert list to numpy array",
                    "add an item in a tuple",
                    "how to change the style of individual lines"
                ]
            },
            {
                "code": "#tag name is span, class name is \"price\" and \"old-price\"",
                "true_label": "",
                "top5_preds": [
                    "add string to list using append",
                    "how to change the style of individual lines",
                    "how to change the size of a plot",
                    "integrating datetime tools with pandas for time series",
                    "what is scikit learn?"
                ]
            },
            {
                "code": "#tag name is \"a\", class name is \"product-url js-product-tracking\"",
                "true_label": "",
                "top5_preds": [
                    "add string to list using append",
                    "accessing twitter",
                    "social media twitter",
                    "import polynomial features from sklearn",
                    "tensorflow + keras"
                ]
            },
            {
                "code": "from bs4 import BeautifulSoup\nimport requests\nimport pandas as pd",
                "true_label": "",
                "top5_preds": [
                    "getting data from the internet",
                    "retrieving data from html page",
                    "load table in pandas",
                    "importing data with pandas",
                    "importing data with numpy"
                ]
            },
            {
                "code": "df = df.from_csv('HM_prices.csv')\ndf",
                "true_label": "",
                "top5_preds": [
                    "loading a csv into a dataframe",
                    "load table in pandas",
                    "from dictionary to dataframe",
                    "importing data with pandas",
                    "change type of column"
                ]
            },
            {
                "code": "df['New price'] = df['New price'].str.replace('$', '')\ndf['Old price'] = df['Old price'].str.replace('$', '')",
                "true_label": "",
                "top5_preds": [
                    "using a dataframe and matplotlib commands",
                    "convert data from string to float",
                    "pandas apply",
                    "using pandas",
                    "create dataframe with given values"
                ]
            },
            {
                "code": "%matplotlib inline\naverage_price = df['New price'].astype(float)\nprint(\"The average on-sale price is $\",round(average_price.mean(),2))\naverage_price.hist()",
                "true_label": "",
                "top5_preds": [
                    "line plots show the trend of a numerical variable over time",
                    "plotting time series with pandas",
                    "pandas plotting",
                    "plot using pandas plotting",
                    "line plot with a dataframe"
                ]
            },
            {
                "code": "discount_dollar = df['Old price'].astype(float)-average_price\nprint(\"The average discount is $\",round(discount_dollar.mean(),2))\ndiscount_dollar.hist()",
                "true_label": "",
                "top5_preds": [
                    "line plots show the trend of a numerical variable over time",
                    "predicting a categorical response",
                    "plotting time series with pandas",
                    "convert date to datetime format",
                    "sum all the numbers in a list"
                ]
            },
            {
                "code": "discount_percentage = discount_dollar/df['Old price'].astype(float)*100\nprint(\"The average discount is\",round(discount_percentage.mean(),2),\"per cent\")\ndiscount_percentage.hist()",
                "true_label": "",
                "top5_preds": [
                    "line plots show the trend of a numerical variable over time",
                    "predicting a categorical response",
                    "create a one column dataframe with the values of a series",
                    "plotting time series with pandas",
                    "convert data from string to float"
                ]
            },
            {
                "code": "print(df[discount_percentage>50]['Product code'].count(),\"items are over 50% off\")",
                "true_label": "",
                "top5_preds": [
                    "predicting a categorical response",
                    "line plot with a dataframe",
                    "sql LIKE operator",
                    "line plots show the trend of a numerical variable over time",
                    "credible interval vs confidence interval"
                ]
            },
            {
                "code": "articles = data['displayArticles']",
                "true_label": "",
                "top5_preds": [
                    "retrieving data from html page",
                    "get a positive integer from a user",
                    "loading json in python",
                    "data given as a dictionary",
                    "dealing with data"
                ]
            },
            {
                "code": "names = []\nfor article in articles:\n    name = article['name']\n    names.append(name)\nprint(names)\nprint(\"Number of displayed articles:\",len(names))",
                "true_label": "",
                "top5_preds": [
                    "sum all the numbers in a list",
                    "create a list of all words",
                    "find the most common words",
                    "remove duplicates from a list",
                    "add string to list using append"
                ]
            },
            {
                "code": "url_men = (\"http://api.hm.com/v2/us/en/products/\"+\\\n           \"display?categories=sale%2Fmen&concealCategories=true&pageSize=60&page=1&deviceType=DESKTOP\")",
                "true_label": "",
                "top5_preds": [
                    "constructing an api get request",
                    "twitter api access",
                    "getting data from the internet",
                    "sql LIKE operator",
                    "postgres sql lab"
                ]
            },
            {
                "code": "url_women = (\"http://api.hm.com/v2/us/en/products/\"+\\\n             \"display?categories=sale%2Fladies&concealCategories=true&pageSize=60&page=1&deviceType=DESKTOP\")",
                "true_label": "",
                "top5_preds": [
                    "constructing an api get request",
                    "sql LIKE operator",
                    "getting data from the internet",
                    "twitter api access",
                    "postgres sql lab"
                ]
            },
            {
                "code": "url_women_top = (\"http://api.hm.com/v2/us/en/products/display?\"+\\\n                 \"categories=sale%2Fladies%2Ftops&concealCategories=true&pageSize=60&page=1&deviceType=DESKTOP\")",
                "true_label": "",
                "top5_preds": [
                    "constructing an api get request",
                    "sql LIKE operator",
                    "getting data from the internet",
                    "twitter api access",
                    "load table in pandas"
                ]
            },
            {
                "code": "# the \"categories\" criterium",
                "true_label": "",
                "top5_preds": [
                    "list of categories",
                    "what is scikit learn?",
                    "import polynomial features from sklearn",
                    "implementing bag of words in scikit learn",
                    "obtaining metadata from crossref"
                ]
            },
            {
                "code": "response = requests.get(url_women_top)\ndata = response.json()",
                "true_label": "",
                "top5_preds": [
                    "loading json in python",
                    "getting data from the internet",
                    "twitter api access",
                    "download and inspect the twitter samples dataset",
                    "retrieving data from html page"
                ]
            },
            {
                "code": "articles = data['displayArticles']\nnames = []\nfor article in articles:\n    name = article['name']\n    names.append(name)\nprint(\"Number of found articles\",len(names))",
                "true_label": "",
                "top5_preds": [
                    "sum all the numbers in a list",
                    "find the most common words",
                    "remove duplicates from a list",
                    "predicting a categorical response",
                    "create a list of all words"
                ]
            },
            {
                "code": "#increase pageSize in the URL\nnames = []\npage_number = 1",
                "true_label": "",
                "top5_preds": [
                    "sum all the numbers in a list",
                    "add string to list using append",
                    "add an item in a tuple",
                    "getting data from the internet",
                    "get a positive integer from a user"
                ]
            },
            {
                "code": "while True:\n    url_women_top = (\"http://api.hm.com/v2/us/en/products/display?\"+\\\n                    \"categories=sale%2Fladies%2Ftops&concealCategories=true&pageSize=60&page=\"\\\n                    +str(page_number)+\"&deviceType=DESKTOP\")\n    response = requests.get(url_women_top)\n    data = response.json()\n    if data['displayArticles']:\n        articles = data['displayArticles']\n        for article in articles:\n            name = article['name']\n            names.append(name)\n            print(name)\n        page_number += 1\n    else:\n        break",
                "true_label": "",
                "top5_preds": [
                    "getting data from the internet",
                    "constructing an api get request",
                    "download and inspect the twitter samples dataset",
                    "retrieve and print local trends",
                    "getting online"
                ]
            },
            {
                "code": "len(names)",
                "true_label": "",
                "top5_preds": [
                    "sum all the numbers in a list",
                    "read numbers until and print their mean and standard deviation without using a list",
                    "create a list of all words",
                    "get the names of all the tables in the database",
                    "convert list to numpy array"
                ]
            },
            {
                "code": "products = []\npage_number = 1\n\nwhile True:\n    url_women_top = (\"http://api.hm.com/v2/us/en/products/display?\"+\\\n                    \"categories=sale%2Fladies%2Ftops&concealCategories=true&pageSize=60&page=\"\\\n                    +str(page_number)+\"&deviceType=DESKTOP\")\n    response = requests.get(url_women_top)\n    data = response.json()\n    if data['displayArticles']:\n        articles = data['displayArticles']\n        for article in articles:\n            current = {}\n            current['Name'] = article['name']\n            current['Product code'] = article['productNumber']\n            current['Old price'] = article['priceInfo']['formattedOldPrice']\n            current['New price'] = article['priceInfo']['formattedPrice']\n            current['URL'] = article['webUrl']\n            products.append(current)\n        page_number += 1\n    else:\n        break",
                "true_label": "",
                "top5_preds": [
                    "getting data from the internet",
                    "constructing an api get request",
                    "sum all the numbers in a list",
                    "select every row after a specific row",
                    "predicting a categorical response"
                ]
            },
            {
                "code": "df = pd.DataFrame(products)\ndf.to_csv('HM_prices.csv', index=False)",
                "true_label": "",
                "top5_preds": [
                    "reading and writing csv files",
                    "loading a csv into a dataframe",
                    "put ;y x ; in dataframe",
                    "from dictionary to dataframe",
                    "line plot with a dataframe"
                ]
            },
            {
                "code": "response = requests.get(\"http://api.hm.com/v2/us/en/products/display?categories=sale&concealCategories=true&pageSize=60&page=1&deviceType=DESKTOP\")\ndata = response.json()\ndata",
                "true_label": "",
                "top5_preds": [
                    "loading json in python",
                    "twitter api access",
                    "getting data from the internet",
                    "twitter application",
                    "download and inspect the twitter samples dataset"
                ]
            },
            {
                "code": "average_price = df['New price'].astype(float)\nprint(\"The average on-sale price is $\",round(average_price.mean(),2))\naverage_price.hist()",
                "true_label": "",
                "top5_preds": [
                    "line plots show the trend of a numerical variable over time",
                    "predicting a categorical response",
                    "convert data from string to float",
                    "plotting time series with pandas",
                    "sum all the numbers in a list"
                ]
            }
        ],
        [
            {
                "code": "import numpy as np\n\nimport pandas as pd\nfrom sklearn.linear_model import Lasso\nfrom sklearn.metrics import r2_score\nimport matplotlib\n\nimport matplotlib.pyplot as plt\nfrom scipy.stats import skew\nfrom scipy.stats.stats import pearsonr",
                "true_label": "",
                "top5_preds": [
                    "using logistic regression instead",
                    "import polynomial features from sklearn",
                    "polynomial regression with sklearn",
                    "scipy",
                    "ridge regression with polynomial features on a grid"
                ]
            },
            {
                "code": "#pandas is a powerful Python data analysis toolkit\n#fast, flexible, and expressive data structures designed to make \n#working with relational or labeled data\ntrain = pd.read_csv(\"data/train.csv\")\ntrain.head()",
                "true_label": "",
                "top5_preds": [
                    "load table in pandas",
                    "loading a csv into a dataframe",
                    "what is scikit learn?",
                    "helpers to read in dataset",
                    "import the dataset"
                ]
            },
            {
                "code": "train.shape",
                "true_label": "",
                "top5_preds": [
                    "numpy",
                    "tensorflow + keras",
                    "classification with a cnn",
                    "import polynomial features from sklearn",
                    "scipy"
                ]
            },
            {
                "code": "train.info()",
                "true_label": "",
                "top5_preds": [
                    "tensorflow + keras",
                    "what is scikit learn?",
                    "load table in pandas",
                    "import polynomial features from sklearn",
                    "training data"
                ]
            },
            {
                "code": "train.describe()",
                "true_label": "",
                "top5_preds": [
                    "tensorflow + keras",
                    "import polynomial features from sklearn",
                    "what is scikit learn?",
                    "load table in pandas",
                    "from dictionary to dataframe"
                ]
            },
            {
                "code": "corr = train.corr()[\"SalePrice\"]\ncorr[np.argsort(corr, axis=0)[::-1]]",
                "true_label": "",
                "top5_preds": [
                    "predicting a categorical response",
                    "shortcut principal component analysis in scikit learn",
                    "correlation analysis",
                    "computing the covariance matrix",
                    "transform categorical data into binary features"
                ]
            }
        ],
        [
            {
                "code": "print(\"ican\" in \"pelicans\")\nprint(\"\" in \"pelicans\") # the empty string is in everything\nprint(\"pelicans\" in \"pelicans\") # note: inclusive of the whole string!\nprint(\"icant\" in \"pelicans\")",
                "true_label": "",
                "top5_preds": [
                    "check a list is empty or not",
                    "test whether a number is positive",
                    "matching metacharacters literally",
                    "what is a string?",
                    "equally spaced numbers on a grid"
                ]
            },
            {
                "code": "sentence = \"The cat sat on the mat\"\n\nif \"cat\" in sentence:\n    print(\"Yes\")\nelse:\n    print(\"No\")",
                "true_label": "",
                "top5_preds": [
                    "get a positive integer from a user",
                    "what is a string?",
                    "test whether a number is positive",
                    "check a list is empty or not",
                    "formatting datetimes as strings"
                ]
            },
            {
                "code": "sentence =\"The fabrication of steel is expensive\"\n\nif \"cat\" in sentence:\n    print(\"Yes\")\nelse:\n    print(\"No\")",
                "true_label": "",
                "top5_preds": [
                    "get a positive integer from a user",
                    "what is a string?",
                    "test whether a number is positive",
                    "check a list is empty or not",
                    "formatting datetimes as strings"
                ]
            },
            {
                "code": "match_words(\"c.+t\")",
                "true_label": "",
                "top5_preds": [
                    "tokenization, stop words, punctuation",
                    "find the most common words",
                    "concordance: words that co-occur with a word of interest",
                    "the most famous quote in regex dom",
                    "create a list of all words"
                ]
            },
            {
                "code": "match_words(\"c.?t\")",
                "true_label": "",
                "top5_preds": [
                    "tokenization, stop words, punctuation",
                    "matching metacharacters literally",
                    "find the most common words",
                    "the most famous quote in regex dom",
                    "concordance: words that co-occur with a word of interest"
                ]
            },
            {
                "code": "match_words(\"^c.t\")",
                "true_label": "",
                "top5_preds": [
                    "tokenization, stop words, punctuation",
                    "matching metacharacters literally",
                    "concordance: words that co-occur with a word of interest",
                    "the most famous quote in regex dom",
                    "find the most common words"
                ]
            },
            {
                "code": "match_words(\"c.t$\")",
                "true_label": "",
                "top5_preds": [
                    "matching metacharacters literally",
                    "tokenization, stop words, punctuation",
                    "the most famous quote in regex dom",
                    "concordance: words that co-occur with a word of interest",
                    "find all by term in field in case insensitive way"
                ]
            },
            {
                "code": "match_words(\"^c.t$\")",
                "true_label": "",
                "top5_preds": [
                    "tokenization, stop words, punctuation",
                    "matching metacharacters literally",
                    "concordance: words that co-occur with a word of interest",
                    "find the most common words",
                    "the most famous quote in regex dom"
                ]
            },
            {
                "code": "match_words(\"p[nt][aeiou]\")",
                "true_label": "",
                "top5_preds": [
                    "tokenization, stop words, punctuation",
                    "matching metacharacters literally",
                    "the most famous quote in regex dom",
                    "matching special patterns",
                    "find the most common words"
                ]
            },
            {
                "code": "match_words(\"h[yui]z\")",
                "true_label": "",
                "top5_preds": [
                    "create a list of all words",
                    "tokenization, stop words, punctuation",
                    "implementing bag of words in scikit learn",
                    "matching metacharacters literally",
                    "find the most common words"
                ]
            },
            {
                "code": "# using a range of characters\nprint(re.match('[a-z].$', \"as\")) # match\nprint(re.match('[a-z].$', \"0s\")) # no match\n# note that it is case sensitive\nprint(re.match('[A-Z].$', \"AS\")) # no match",
                "true_label": "",
                "top5_preds": [
                    "matching metacharacters literally",
                    "matching special patterns",
                    "formatting datetimes as strings",
                    "equally spaced numbers on a grid",
                    "basic regular expression syntax"
                ]
            },
            {
                "code": "match_words(\"^c[ao]t$\")",
                "true_label": "",
                "top5_preds": [
                    "tokenization, stop words, punctuation",
                    "matching metacharacters literally",
                    "find the most common words",
                    "concordance: words that co-occur with a word of interest",
                    "create a list of all words"
                ]
            },
            {
                "code": "def match_words(pattern):\n    with open(\"words.txt\") as f:\n        for line in f:\n            word = line.strip() \n            if re.search(pattern, word):\n                print(word)",
                "true_label": "",
                "top5_preds": [
                    "find the most common words",
                    "most common words",
                    "tokenize the text",
                    "rewrite get _long _words using map and filter",
                    "concordance: words that co-occur with a word of interest"
                ]
            },
            {
                "code": "match_words(\"cat\")",
                "true_label": "",
                "top5_preds": [
                    "tokenization, stop words, punctuation",
                    "create a list of all words",
                    "matching metacharacters literally",
                    "find the most common words",
                    "the most famous quote in regex dom"
                ]
            },
            {
                "code": "match_words(\"c.t\")",
                "true_label": "",
                "top5_preds": [
                    "tokenization, stop words, punctuation",
                    "matching metacharacters literally",
                    "concordance: words that co-occur with a word of interest",
                    "the most famous quote in regex dom",
                    "implementing bag of words in scikit learn"
                ]
            },
            {
                "code": "# all words that begin fir and end with t\nmatch_words(\"fir.*t$\")",
                "true_label": "",
                "top5_preds": [
                    "matching metacharacters literally",
                    "tokenization, stop words, punctuation",
                    "exploring regex",
                    "matching special patterns",
                    "regex"
                ]
            },
            {
                "code": "# all words that have f<something>t<something>ha<something>\nmatch_words(\"f.*t.*ha.*\")",
                "true_label": "",
                "top5_preds": [
                    "find the most common words",
                    "tokenization, stop words, punctuation",
                    "create a list of all words",
                    "matching metacharacters literally",
                    "most common words"
                ]
            },
            {
                "code": "# match nec<zero or more vowels><one or more s><something>y\nmatch_words(\"nec[aeiou]*s+.*y\")",
                "true_label": "",
                "top5_preds": [
                    "tokenization, stop words, punctuation",
                    "matching metacharacters literally",
                    "regex",
                    "create a list of all words",
                    "implementing bag of words in scikit learn"
                ]
            },
            {
                "code": "match_words(\"c.*t\")",
                "true_label": "",
                "top5_preds": [
                    "tokenization, stop words, punctuation",
                    "matching metacharacters literally",
                    "find the most common words",
                    "the most famous quote in regex dom",
                    "exploring regex"
                ]
            },
            {
                "code": "sentence = \"The cat sat on the mat\"\nsentence2 =\"The fabrication of steel is expensive\"\n\nif \" cat \" in sentence:\n    print(\"Yes\")\nelse:\n    print(\"No\")\n    \nif \" cat \" in sentence2:\n    print(\"Yes2\")\nelse:\n    print(\"No2\")",
                "true_label": "",
                "top5_preds": [
                    "get a positive integer from a user",
                    "test whether a number is positive",
                    "tokenization, stop words, punctuation",
                    "create a list of all words",
                    "check accuracy / score for a logistic classifier"
                ]
            },
            {
                "code": "import re # import the Regular Expression module\nprint(re.findall(\"ican\", \"pelican\"))",
                "true_label": "",
                "top5_preds": [
                    "the re module in python",
                    "regex",
                    "the most famous quote in regex dom",
                    "matching metacharacters literally",
                    "basic regular expression syntax"
                ]
            },
            {
                "code": "match_words(\"^c[ao]*t$\")",
                "true_label": "",
                "top5_preds": [
                    "matching metacharacters literally",
                    "tokenization, stop words, punctuation",
                    "find the most common words",
                    "concordance: words that co-occur with a word of interest",
                    "create a list of all words"
                ]
            },
            {
                "code": "match_words(\"c[rhl][aeiou][nh]t\")",
                "true_label": "",
                "top5_preds": [
                    "tokenization, stop words, punctuation",
                    "create a list of all words",
                    "matching metacharacters literally",
                    "the most famous quote in regex dom",
                    "find the most common words"
                ]
            },
            {
                "code": "# does not match -- because the $ is taken to mean the anchor\nprint(re.match('200$', '200$'))\n\n# now we escape the $ and it behaves as the literal character $\n# it matches correctly\nprint(re.match('200\\$', '200$'))",
                "true_label": "",
                "top5_preds": [
                    "matching metacharacters literally",
                    "regex",
                    "formatting datetimes as strings",
                    "matching special patterns",
                    "basic regular expression syntax"
                ]
            },
            {
                "code": "# note the r: no chance the \\ does something unexpected\nprint(re.match(r'200\\$', '200$'))",
                "true_label": "",
                "top5_preds": [
                    "matching metacharacters literally",
                    "regex",
                    "the most famous quote in regex dom",
                    "matching special patterns",
                    "special characters"
                ]
            },
            {
                "code": "# a word beginning with f then three **non-vowels**\nmatch_words(\"f[^aeiou][^aeiou][^aeiou]\")",
                "true_label": "",
                "top5_preds": [
                    "matching metacharacters literally",
                    "tokenization, stop words, punctuation",
                    "concordance: words that co-occur with a word of interest",
                    "counting word frequency",
                    "create a list of all words"
                ]
            },
            {
                "code": "# same as the f followed by three non-vowels example\n# note the way the repeat character binds to the previous expression, \n# which might not be a single character in the pattern!\nmatch_words(\"f[^aeiou]{3}\")",
                "true_label": "",
                "top5_preds": [
                    "matching metacharacters literally",
                    "the re module in python",
                    "matching special patterns",
                    "tokenization, stop words, punctuation",
                    "the most famous quote in regex dom"
                ]
            },
            {
                "code": "# match a sequence of digits, possibly followed by one letter\n# Note that we can just jam in multiple ranges in the character class \n# inside the square brackets\noptions = [\"13131\", \"3133103b\", \"31hello\", \"o88\", \"7B\"]\n\nfor option in options:\n    print(option, re.match(\"[0-9]+[A-Za-z]?$\", option) is not None)",
                "true_label": "",
                "top5_preds": [
                    "sum all the numbers in a list",
                    "plotting in python",
                    "test whether a number is positive",
                    "plotting time series with pandas",
                    "get a positive integer from a user"
                ]
            },
            {
                "code": "tests = [\"flip\", \"fliplip\", \"flipliplip\", \"flipli\", \"flipl\", \"fliplipliplop\"]\n\n# match a pattern against a list of tests\ndef match_against(tests, pattern):\n    for st in tests:\n        print(st.ljust(20), re.match(pattern, st) is not None)\n        \nmatch_against(tests, \"f(lip)+$\")",
                "true_label": "",
                "top5_preds": [
                    "test whether a number is positive",
                    "write a function that counts the number of times a given pattern appears in a string, including overlap",
                    "test a function",
                    "predict on test set",
                    "normal test"
                ]
            },
            {
                "code": "names = [\"Mrs. Purple\", \"Miss. White\", \"Ms. Yellow\", \"Dr. Blue\", \"Mr. Red\"]\n\nmatch_against(names, \"(Mrs\\.)|(Miss\\.)|(Ms\\.)\")",
                "true_label": "",
                "top5_preds": [
                    "formatting datetimes as strings",
                    "write a function that counts the number of times a given pattern appears in a string, including overlap",
                    "regex",
                    "remove duplicates from a list",
                    "strings as function arguments"
                ]
            },
            {
                "code": "match_words(\"((b[aeiou]+k)|(d[aeiou]+t))$\")",
                "true_label": "",
                "top5_preds": [
                    "matching metacharacters literally",
                    "tokenization, stop words, punctuation",
                    "matching special patterns",
                    "find the most common words",
                    "concordance: words that co-occur with a word of interest"
                ]
            },
            {
                "code": "names = [\"Mrs. Purple\", \"Miss. White\", \"Dr. Blue\", \"Mr. Red\", \"Lord. Black\"]\n# simple matching\nmatch_against(names, \"(Mr|Mrs|Dr|Ms|Miss|Sir|Lord|Dame)\\. (\\w*)\")",
                "true_label": "",
                "top5_preds": [
                    "equally spaced numbers on a grid",
                    "remove duplicates from a list",
                    "formatting datetimes as strings",
                    "write a function that counts the number of times a given pattern appears in a string, including overlap",
                    "regex"
                ]
            },
            {
                "code": "def sub_list(tests, pattern, replacement):\n    for test in tests:\n        print(test.ljust(20), \"=>\", end=' ')\n        subst = re.sub(pattern,  replacement, test)\n        print(subst)\n# the \\1 refers to the title and the \\2 refers to the name\nsub_list(names, \"(Mr|Mrs|Dr|Ms|Miss|Sir|Lord|Dame)\\. (\\w*)\", \n         r\"{'title': '\\1', 'name': '\\2'}\")",
                "true_label": "",
                "top5_preds": [
                    "write a function that counts the number of times a given pattern appears in a string, including overlap",
                    "remove duplicates from a list",
                    "sum all the numbers in a list",
                    "setup and re introduction to python",
                    "get the sum of all the values in mat"
                ]
            },
            {
                "code": "# match everything that has a v, followed by two of the **same** vowel\nmatch_words(r\"v([aeiou])\\1\")",
                "true_label": "",
                "top5_preds": [
                    "matching metacharacters literally",
                    "regex",
                    "matching special patterns",
                    "tokenization, stop words, punctuation",
                    "the re module in python"
                ]
            },
            {
                "code": "# match a sequence of digits, possibly followed by one letter\n# Note that we can just jam in multiple ranges in the character class \n# inside the square brackets\noptions = [\"13131\", \"3133103b\", \"31hello\", \"o88\", \"7B\"]\n\nfor option in options:\n    print(option, re.match(\"[0-9]+[A-Za-z]?$\", option) is not None)",
                "true_label": "",
                "top5_preds": [
                    "sum all the numbers in a list",
                    "plotting in python",
                    "test whether a number is positive",
                    "plotting time series with pandas",
                    "get a positive integer from a user"
                ]
            }
        ],
        [
            {
                "code": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import Imputer\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.neighbors import KNeighborsClassifier\n#Missingno is a package to visualize missing data\nimport missingno as msno\n%matplotlib inline\n#Load data\ndf = pd.read_csv('nba_2016_2017_100.csv')",
                "true_label": "",
                "top5_preds": [
                    "import polynomial features from sklearn",
                    "what is scikit learn?",
                    "line plot with a dataframe",
                    "polynomial regression with sklearn",
                    "load table in pandas"
                ]
            },
            {
                "code": "display(df.head())\ndf.describe()",
                "true_label": "",
                "top5_preds": [
                    "plot the df dataframe using pandas + matplotlib",
                    "line plot with a dataframe",
                    "spark dataframes",
                    "load table in pandas",
                    "pandas plotting"
                ]
            },
            {
                "code": "msno.matrix(df)",
                "true_label": "",
                "top5_preds": [
                    "import polynomial features from sklearn",
                    "create a one column dataframe with the values of a series",
                    "load table in pandas",
                    "find data type of each column",
                    "dataframe methods"
                ]
            },
            {
                "code": "msno.bar(df, color=\"blue\", figsize=(30,18))",
                "true_label": "",
                "top5_preds": [
                    "use pandas to make a bar chart",
                    "line plot with a dataframe",
                    "using a dataframe and matplotlib commands",
                    "create a bar chart",
                    "load table in pandas"
                ]
            },
            {
                "code": "msno.heatmap(df, figsize=(5,5))",
                "true_label": "",
                "top5_preds": [
                    "heatmap with time",
                    "line plot with a dataframe",
                    "using a dataframe and matplotlib commands",
                    "heatmap",
                    "ploting out data with box plots"
                ]
            },
            {
                "code": "df_new = df.dropna()\ndisplay(df_new.describe())\ndisplay(df.describe())",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "create a one column dataframe with the values of a series",
                    "using a dataframe and matplotlib commands",
                    "displaying the data",
                    "create dataframe with given values"
                ]
            },
            {
                "code": "df['GP'].hist()\ndf_new['GP'].hist()\nplt.title('Games Played')\nplt.xlabel('Number of Games Played')\nplt.ylabel('Count')\nplt.show()",
                "true_label": "",
                "top5_preds": [
                    "line plots show the trend of a numerical variable over time",
                    "plot histogram",
                    "line plot with a dataframe",
                    "plotting time series with pandas",
                    "sum all the numbers in a list"
                ]
            },
            {
                "code": "impute = Imputer(missing_values='NaN', strategy='mean', axis=0, verbose=0, copy=True)\nsalary = df['SALARY_MILLIONS'].values\ngp = df['GP'].values\nsalary_mean = impute.fit_transform(salary.reshape(-1,1)).reshape(1,-1)[0]\nplt.scatter(gp,salary_mean,c='r')\nplt.scatter(gp,salary,c='b')\nplt.xlabel('Games Played')\nplt.ylabel('Salary ($ Millions)')\nplt.title('Imputation Using Mean')\nplt.show()",
                "true_label": "",
                "top5_preds": [
                    "import polynomial features from sklearn",
                    "line plot with a dataframe",
                    "fit a polynomial",
                    "scipy",
                    "fit on training set"
                ]
            },
            {
                "code": "linear_model = LinearRegression()\nresult = linear_model.fit(df_new['GP'].values.reshape(-1,1),df_new['SALARY_MILLIONS'].values)\nxvals = np.arange(0,90,5)\nmissing_salaries_GP = df[df['SALARY_MILLIONS'].isnull()]['GP'].values\nimputed_salaries = result.predict(missing_salaries_GP.reshape(-1,1))\nplt.plot(xvals,result.predict(xvals.reshape(-1,1)),'k--')\nplt.scatter(df['GP'].values,df['SALARY_MILLIONS'].values,c='b')\nplt.scatter(missing_salaries_GP,imputed_salaries,c='r')\nplt.xlabel('Games Played')\nplt.ylabel('Salary ($ Millions)')\nplt.title('Imputation using Regression')\nplt.show()",
                "true_label": "",
                "top5_preds": [
                    "linear regression of many variables",
                    "ridge regression with polynomial features on a grid",
                    "fit a polynomial",
                    "predicting a continuous response using linear regression",
                    "polynomial regression with sklearn"
                ]
            },
            {
                "code": "#Calculate residuals\nresiduals = df_new['SALARY_MILLIONS'].values-result.predict(df_new['GP'].values.reshape(-1,1))\nvar_fit = np.std(residuals)\n#Add noise\nimputed_salaries_noise = []\nfor item in imputed_salaries:\n    imputed_salaries_noise.append(max(0,np.random.normal(loc=item,scale=var_fit)))\nplt.plot(xvals,result.predict(xvals.reshape(-1,1)),'k--')\nplt.scatter(missing_salaries_GP,imputed_salaries_noise,c='r')\nplt.scatter(df['GP'].values,df['SALARY_MILLIONS'].values,c='b')\n#plt.scatter(missing_salaries_GP,imputed_salaries_noise,c='r')\nplt.xlabel('Games Played')\nplt.ylabel('Salary ($ Millions)')\nplt.title('Imputation using Regression')\nplt.show()",
                "true_label": "",
                "top5_preds": [
                    "predicting a categorical response",
                    "fit a polynomial",
                    "import polynomial features from sklearn",
                    "predicting a continuous response using linear regression",
                    "ridge regression with polynomial features on a grid"
                ]
            },
            {
                "code": "#Turn defensive ratings into class labels\ndf_class = df[['OFF_RATING','DEF_RATING','PTS']].dropna()\noffensive_rating = df_class['OFF_RATING'].values\ndefensive_rating = df_class['DEF_RATING'].values\npoints = df_class['PTS'].values\ndefensive_class = []\nfor i in range(len(offensive_rating)):\n    if defensive_rating[i] > 105:\n        defensive_class.append(1)\n    elif defensive_rating[i] <= 105:\n        defensive_class.append(0)\n\nclassifier = KNeighborsClassifier(n_neighbors=3)\nclass_result = classifier.fit(np.stack((offensive_rating,points),axis=1),defensive_class)\n#Find missing data\nmissing_def_rating = df[df['DEF_RATING'].isnull()][['OFF_RATING','PTS']].values\n#Predict\npredicted_def_rating = class_result.predict(missing_def_rating)\nplt.scatter(missing_def_rating[:,0],missing_def_rating[:,1],c=predicted_def_rating,marker='s')\nplt.scatter(offensive_rating,points,c=defensive_class)\nplt.title('Defensive Top Performers')\nplt.xlabel('Offensive Rating')\nplt.ylabel('Points')\nplt.show()",
                "true_label": "",
                "top5_preds": [
                    "predicting a categorical response",
                    "create a one column dataframe with the values of a series",
                    "line plot with a dataframe",
                    "separate data by class",
                    "create dataframe with given values"
                ]
            },
            {
                "code": "from statsmodels.imputation import mice\nimport statsmodels as sm\n#Create mice data instance\nimp = mice.MICEData(df[['GP','SALARY_MILLIONS']])\n#Linear model\nfml = 'SALARY_MILLIONS ~ GP'\n#Build MICE pipeline\nout = mice.MICE(fml, sm.regression.linear_model.OLS, imp)\n#Fit with burn in of 3 and 10 imputations\nresults = out.fit(3,10)\n#Output results\ndisplay(results.summary())\n#plot\nimp.plot_bivariate('GP','SALARY_MILLIONS')",
                "true_label": "",
                "top5_preds": [
                    "using logistic regression instead",
                    "polynomial regression with sklearn",
                    "import polynomial features from sklearn",
                    "linear regression of many variables",
                    "running a multivariate regression in python"
                ]
            }
        ],
        [
            {
                "code": "import pandas as pd",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "equally spaced numbers on a grid",
                    "load table in pandas",
                    "importing data with numpy",
                    "import polynomial features from sklearn"
                ]
            },
            {
                "code": "df_oz = pd.read_csv('D:\\\\TeachingMaterials\\\\BusinessAnalytics\\\\Visualization\\\\VizData\\\\ozone.csv')\ndf_con = pd.read_csv('D:\\\\TeachingMaterials\\\\BusinessAnalytics\\\\Visualization\\\\VizData\\\\construction.csv')\ndf_test = pd.read_csv('D:\\\\TeachingMaterials\\\\BusinessAnalytics\\\\Visualization\\\\VizData\\\\test.csv')",
                "true_label": "",
                "top5_preds": [
                    "loading a csv into a dataframe",
                    "load table in pandas",
                    "from dictionary to dataframe",
                    "importing data with pandas",
                    "importing data with numpy"
                ]
            },
            {
                "code": "df_con",
                "true_label": "",
                "top5_preds": [
                    "create a dataframe by joining series by column",
                    "line plot with a dataframe",
                    "from dictionary to dataframe",
                    "convert date to datetime format",
                    "create a one column dataframe with the values of a series"
                ]
            },
            {
                "code": "import matplotlib.pyplot as plt",
                "true_label": "",
                "top5_preds": [
                    "equally spaced numbers on a grid",
                    "line plot with a dataframe",
                    "trend lines in pyplot",
                    "plot using matplotlib",
                    "plotting in python"
                ]
            },
            {
                "code": "x = [1,2,3,4]\ny = [10000,20000, 30000, 25000]\nplt.plot(x,y,label='Sales Revenue')   # 'Sales Revenue' is the label for the y data\nplt.xlabel('Month')                   # Title for the horizontal axis\nplt.ylabel('Sales Revenue')           # Title for the vertical axis\nplt.axis([0,5,0,35000])               # sets the limits on the horizontal and vertical axes, respectively\nplt.show()",
                "true_label": "",
                "top5_preds": [
                    "plot using matplotlib",
                    "plotting time series with pandas",
                    "line plot with a dataframe",
                    "plotting in python",
                    "plot using pandas plotting"
                ]
            },
            {
                "code": "x = [1,2,3,4]\nx_labels = ['Jan','Feb','Mar','Apr']\ny = [10000,20000, 30000, 25000]\nplt.plot(x,y,label='Sales Revenue')   # 'Sales Revenue' is the label for the y data\nplt.xlabel('Month')                   # Title for the horizontal axis\nplt.ylabel('Sales Revenue')           # Title for the vertical axis\nplt.xticks(x,x_labels)\nplt.axis([0,5,0,35000])               # sets the limits on the horizontal and vertical axes, respectively\nplt.savefig('sales.png')\nplt.show()",
                "true_label": "",
                "top5_preds": [
                    "plotting time series with pandas",
                    "plot using matplotlib",
                    "line plot with a dataframe",
                    "plotting in python",
                    "plot using pandas plotting"
                ]
            },
            {
                "code": "df_con['Total Construction']",
                "true_label": "",
                "top5_preds": [
                    "create a one column dataframe with the values of a series",
                    "loading a csv into a dataframe",
                    "create a dataframe by joining series by column",
                    "convert date to datetime format",
                    "convert data from string to float"
                ]
            },
            {
                "code": "x = df_con.index\ny = df_con['Total Construction']\nplt.plot(x,y,label='Total Construction')   \nplt.xlabel('Month')                      # Title for the horizontal axis\nplt.ylabel('Construction Spending')      # Title for the vertical axis\nplt.axis([0,max(df_con['Month'])+1,0,max(df_con['Total Construction'])*1.05])    # Set ranges of axes\nplt.show()",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "plotting time series with pandas",
                    "plot using pandas plotting",
                    "plotting in python",
                    "plot using matplotlib"
                ]
            },
            {
                "code": "df_oz.columns.values",
                "true_label": "",
                "top5_preds": [
                    "from dictionary to dataframe",
                    "load table in pandas",
                    "find data type of each column",
                    "create a one column dataframe with the values of a series",
                    "dataframe methods"
                ]
            },
            {
                "code": "\"\"\" Format of the scatterplot method is as follows: plt.scatter(x-series, y-series) \"\"\"\nplt.scatter(df_oz['wind'], df_oz['ozone'], alpha=0.5)\n# alpha is a parameter that controls the transparency of the dots: 1 = solid, <1 = various transparency levels, 0 = no mark\nplt.title('Ozone vs. Wind Speed')\nplt.xlabel('Wind Speed')\nplt.ylabel('Ozone')\nplt.show()",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "plotting time series with pandas",
                    "create an array of linearly spaced points",
                    "equally spaced numbers on a grid",
                    "plot using matplotlib"
                ]
            },
            {
                "code": "\"\"\" Format of the scatterplot method is as follows: plt.scatter(x-series, y-series) \"\"\"\nplt.scatter(df_oz['radiation'], df_oz['ozone'], alpha=0.5)\n# alpha is a parameter that controls the transparency of the dots: 1 = solid, <1 = various transparency levels, 0 = no mark\nplt.title('Ozone vs. Radiation')\nplt.xlabel('Radiation (langleys)')\nplt.ylabel('Ozone (ppb)')\nplt.axis([0,400,0,200])\nplt.show()",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "plotting time series with pandas",
                    "create a scatter plot",
                    "plot using matplotlib",
                    "line plots show the trend of a numerical variable over time"
                ]
            },
            {
                "code": "df_test.columns.values",
                "true_label": "",
                "top5_preds": [
                    "find data type of each column",
                    "load table in pandas",
                    "from dictionary to dataframe",
                    "dataframe methods",
                    "what is the type of the columns?"
                ]
            },
            {
                "code": "df_test",
                "true_label": "",
                "top5_preds": [
                    "dataframe methods",
                    "line plot with a dataframe",
                    "create dataframe with given values",
                    "create a one column dataframe with the values of a series",
                    "in pandas"
                ]
            },
            {
                "code": "df_test1 = df_test.set_index('StudentIdentifier')",
                "true_label": "",
                "top5_preds": [
                    "create a dataframe by joining series by column",
                    "from dictionary to dataframe",
                    "create a one column dataframe with the values of a series",
                    "join two dataframes along rows",
                    "dataframe methods"
                ]
            },
            {
                "code": "df_test1",
                "true_label": "",
                "top5_preds": [
                    "create a one column dataframe with the values of a series",
                    "dataframe methods",
                    "create dataframe with given values",
                    "join two dataframes along rows",
                    "create a dataframe by joining series by column"
                ]
            },
            {
                "code": "df_test1['InstructorName'].unique()",
                "true_label": "",
                "top5_preds": [
                    "find all by term in field in case insensitive way",
                    "find data type of each column",
                    "load table in pandas",
                    "shortcut principal component analysis in scikit learn",
                    "dataframe methods"
                ]
            },
            {
                "code": "df_test1.loc[df_test1['InstructorName'] == 'Smith']",
                "true_label": "",
                "top5_preds": [
                    "find all by term in field in case insensitive way",
                    "select every row after a specific row",
                    "load table in pandas",
                    "using a dataframe and matplotlib commands",
                    "line plot with a dataframe"
                ]
            },
            {
                "code": "df_test1.loc[df_test1['InstructorName'] == 'Smith']['EndYearTestScore']",
                "true_label": "",
                "top5_preds": [
                    "find all by term in field in case insensitive way",
                    "select every row after a specific row",
                    "load table in pandas",
                    "loading a csv into a dataframe",
                    "using pandas"
                ]
            }
        ],
        [
            {
                "code": "from math import sqrt\n\ndef logistic_regression(feature_matrix, sentiment, initial_coefficients, step_size, max_iter):\n    coefficients = np.array(initial_coefficients) # make sure it's a numpy array\n    for itr in xrange(max_iter):\n\n        # Predict P(y_i = +1|x_i,w) using your predict_probability() function\n        predictions = predict_probability(feature_matrix, coefficients)\n        \n        # Compute indicator value for (y_i = +1)\n        indicator = (sentiment==+1)\n        \n        # Compute the errors as indicator - predictions\n        errors = indicator - predictions\n        for j in xrange(len(coefficients)): # loop over each coefficient\n            \n            # Recall that feature_matrix[:,j] is the feature column associated with coefficients[j].\n            # Compute the derivative for coefficients[j]. Save it in a variable called derivative\n            derivative = feature_derivative(errors, feature_matrix[:,j])\n            \n            # add the step size times the derivative to the current coefficient\n            coefficients[j] += step_size * derivative\n        \n        # Checking whether log likelihood is increasing\n        if itr <= 15 or (itr <= 100 and itr % 10 == 0) or (itr <= 1000 and itr % 100 == 0) \\\n        or (itr <= 10000 and itr % 1000 == 0) or itr % 10000 == 0:\n            lp = compute_log_likelihood(feature_matrix, sentiment, coefficients)\n            print 'iteration %*d: log likelihood of observed labels = %.8f' % \\\n                (int(np.ceil(np.log10(max_iter))), itr, lp)\n    return coefficients",
                "true_label": "",
                "top5_preds": [
                    "function fit_and_predict",
                    "likelihood of the binomial distribution",
                    "check accuracy / score for a logistic classifier",
                    "likelihood of the binomial",
                    "maximum likelihood estimate of the binomial"
                ]
            },
            {
                "code": "coefficients = logistic_regression(\n    feature_matrix,\n    sentiment,\n    initial_coefficients=np.zeros(194),\n    step_size=1e-7,\n    max_iter=301)",
                "true_label": "",
                "top5_preds": [
                    "using logistic regression instead",
                    "constructing the logistic regression",
                    "polynomial regression with sklearn",
                    "fit a logistic regression model using statsmodels using logistic regression formula in patsy",
                    "explore correlations in the dataset"
                ]
            },
            {
                "code": "# Compute the scores as a dot product between feature_matrix and coefficients.\nscores = np.dot(feature_matrix, coefficients)",
                "true_label": "",
                "top5_preds": [
                    "import polynomial features from sklearn",
                    "numpy",
                    "scipy",
                    "creating polynomial features",
                    "computing the covariance matrix"
                ]
            },
            {
                "code": "scores",
                "true_label": "",
                "top5_preds": [
                    "implementing bag of words in scikit learn",
                    "what is scikit learn?",
                    "equally spaced numbers on a grid",
                    "scikit learn",
                    "import polynomial features from sklearn"
                ]
            },
            {
                "code": "predictions = np.array(map(lambda x: 1 if x>=0 else -1, scores))",
                "true_label": "",
                "top5_preds": [
                    "predicting a categorical response",
                    "predicting a continuous response using linear regression",
                    "ridge regression with one predictor on a grid",
                    "ridge regression with polynomial features on a grid",
                    "interpreting logistic regression coefficients"
                ]
            },
            {
                "code": "sum(1 for prediction in predictions if prediction > 0)",
                "true_label": "",
                "top5_preds": [
                    "predicting a categorical response",
                    "check accuracy / score for a logistic classifier",
                    "sum all the numbers in a list",
                    "test whether a number is positive",
                    "predicting a continuous response using linear regression"
                ]
            },
            {
                "code": "num_mistakes = sum(predictions != sentiment)\naccuracy = sum(predictions == sentiment)/float(len(sentiment))\nprint \"-----------------------------------------------------\"\nprint '# Reviews   correctly classified =', len(products) - num_mistakes\nprint '# Reviews incorrectly classified =', num_mistakes\nprint '# Reviews total                  =', len(products)\nprint \"-----------------------------------------------------\"\nprint 'Accuracy = %.2f' % accuracy",
                "true_label": "",
                "top5_preds": [
                    "predicting a categorical response",
                    "check accuracy / score for a logistic classifier",
                    "test whether a number is positive",
                    "predicting test data",
                    "calculating the mean of a vector with nans"
                ]
            },
            {
                "code": "num_mistakes = sum(predictions != sentiment)\naccuracy = sum(predictions == sentiment)/float(len(sentiment))\n\naccuracy",
                "true_label": "",
                "top5_preds": [
                    "predicting a categorical response",
                    "check accuracy / score for a logistic classifier",
                    "calculating the mean of a vector with nans",
                    "test whether a number is positive",
                    "test the model for accuracy"
                ]
            }
        ],
        [
            {
                "code": "# !pip install boto3",
                "true_label": "",
                "top5_preds": [
                    "package installation",
                    "installing pytorch",
                    "get the names of all the tables in the database",
                    "import polynomial features from sklearn",
                    "download and inspect the twitter samples dataset"
                ]
            },
            {
                "code": "import boto3",
                "true_label": "",
                "top5_preds": [
                    "convert a tuple to a string",
                    "twitter api access",
                    "constructing an api get request",
                    "find maximum and the minimum value in a set",
                    "equally spaced numbers on a grid"
                ]
            },
            {
                "code": "import awskeys",
                "true_label": "",
                "top5_preds": [
                    "strings as function arguments",
                    "function get_keys",
                    "equally spaced numbers on a grid",
                    "formatting datetimes as strings",
                    "find maximum and the minimum value in a set"
                ]
            },
            {
                "code": "AWS_ACCESS_KEY = awskeys.AWS_ACCESS_KEY\nAWS_SECRET_KEY = awskeys.AWS_SECRET_KEY\nmy_phone =       awskeys.AWS_MY_PHONE_NUMBER ",
                "true_label": "",
                "top5_preds": [
                    "twitter api access",
                    "accessing twitter",
                    "get a positive integer from a user",
                    "formatting datetimes as strings",
                    "strings as function arguments"
                ]
            },
            {
                "code": "sms = boto3.client(\n    'sns',\n    'eu-west-1',\n    aws_access_key_id=AWS_ACCESS_KEY, \n    aws_secret_access_key=AWS_SECRET_KEY    )",
                "true_label": "",
                "top5_preds": [
                    "twitter api access",
                    "download and inspect the twitter samples dataset",
                    "constructing an api get request",
                    "accessing twitter",
                    "getting data from the internet"
                ]
            },
            {
                "code": "sms.get_sms_attributes()",
                "true_label": "",
                "top5_preds": [
                    "getting data from the internet",
                    "get a positive integer from a user",
                    "retrieving data from html page",
                    "accessing twitter",
                    "convert date to datetime format"
                ]
            },
            {
                "code": "sms.publish(\n    PhoneNumber = my_phone,\n    Message = '*Test*. This is an SMS from mstore. Your document is ready at http://mstore.cloud/edmdemo2',\n    MessageAttributes={\n        'AWS.SNS.SMS.SenderID': {\n          'DataType': 'String',\n          'StringValue': 'Arena'\n          }\n        }  \n    )",
                "true_label": "",
                "top5_preds": [
                    "social media email",
                    "receiving messages",
                    "twitter application",
                    "interacting with online services",
                    "getting data from the internet"
                ]
            }
        ],
        [
            {
                "code": "import os\nimport sys\nimport random\nimport time",
                "true_label": "",
                "top5_preds": [
                    "sum all the numbers in a list",
                    "pick a random integer using the random module",
                    "add edges in graph",
                    "multiply all the numbers in a list",
                    "formatting datetimes as strings"
                ]
            },
            {
                "code": "spark_home = os.getcwd()+'/spark-2.0.1-bin-hadoop2.7'\nos.environ['SPARK_HOME'] = spark_home\nsys.path.insert(0, os.path.join(spark_home, 'python'))\nsys.path.insert(0, os.path.join(spark_home, 'python\\lib\\py4j-0.10.3-src.zip'))",
                "true_label": "",
                "top5_preds": [
                    "import polynomial features from sklearn",
                    "postgres sql lab",
                    "running a local postgres database",
                    "load table in pandas",
                    "spark lab"
                ]
            },
            {
                "code": "from pyspark import SparkConf, SparkContext\nfrom pyspark.streaming import StreamingContext\n\nfrom operator import add\nfrom pyspark.sql import SparkSession\n\nconf = SparkConf()\n\n# In local mode, specify the number of CPU cores Spark can use in bracket, or use * to let Spark to detect\nconf.setMaster(\"local[*]\")\nconf.setAppName(\"Spark Tutorial\")\n\n# specify the memory Spark can use\nconf.set(\"spark.executor.memory\", \"1g\")    \nsc = SparkContext(conf = conf)",
                "true_label": "",
                "top5_preds": [
                    "rdd resilient distributed dataset in spark",
                    "spark",
                    "configure spark",
                    "spark lab",
                    "spark dataframes"
                ]
            },
            {
                "code": "# test if Spark is functioning, count the number words in LICENSE file\n\nspark = SparkSession.builder.appName(\"Spark Tutorial\").getOrCreate()\nlines = spark.read.text(spark_home+'LICENSE').rdd.map(lambda r: r[0])\ncounts = lines.flatMap(lambda x: x.split(' ')).map(lambda x: 1).reduce(add)\nprint counts",
                "true_label": "",
                "top5_preds": [
                    "word count in spark",
                    "rdd resilient distributed dataset in spark",
                    "spark",
                    "spark dataframes",
                    "spark lab"
                ]
            },
            {
                "code": "# create RDD from a list, (parallelizing an existing collection), then find the max value\ntest_list = [random.randint(1, sys.maxint) for i in range(10000)]\ndistData = sc.parallelize(test_list)\nmax_val = distData.reduce(lambda a, b: a if a>b else b)\nprint max_val == max(test_list)",
                "true_label": "",
                "top5_preds": [
                    "find maximum and the minimum value in a set",
                    "rdd resilient distributed dataset in spark",
                    "optimal value of k for dataset",
                    "predicting a categorical response",
                    "using k nearest neighbor for imputing missing data"
                ]
            },
            {
                "code": "# create RDD from existing data file\n\n# Count number of appearance of each word in LICENSE file\ntest_file = sc.textFile(spark_home+'LICENSE')  # reads it as a collection of lines\nword_counts = test_file.flatMap(lambda x: x.split(' ')).map(lambda x: (x, 1)).reduceByKey(add)\noutput = word_counts.collect()\nfor (word, count) in output:\n    print(\"%s: %i\" % (word, count))",
                "true_label": "",
                "top5_preds": [
                    "word count in spark",
                    "use sklearn kfold",
                    "rdd resilient distributed dataset in spark",
                    "spark dataframes",
                    "vectorize words in movie reviews"
                ]
            },
            {
                "code": "# make a larger file by repeating LICENSE 2000 times to make file reading time longer, result file size is around 34.5 MB\nfilenames = [spark_home+'LICENSE' for i in range(2000)]\nwith open(spark_home+'LARGE_LICENSE', 'w') as outfile:\n    for fname in filenames:\n        with open(fname) as infile:\n            outfile.write(infile.read())",
                "true_label": "",
                "top5_preds": [
                    "optimal value of k for dataset",
                    "use sklearn kfold",
                    "scikit learn",
                    "read numbers until and print their mean and standard deviation without using a list",
                    "vectorize words in movie reviews"
                ]
            },
            {
                "code": "line_len = sc.textFile(spark_home+'LARGE_LICENSE').map(lambda x: len(x))\nline_len.persist()    # persist to memory",
                "true_label": "",
                "top5_preds": [
                    "read text file point",
                    "tensorflow + keras",
                    "word count in spark",
                    "load table in pandas",
                    "read numbers until and print their mean and standard deviation without using a list"
                ]
            },
            {
                "code": "%%time\n\n# time with persisted line_len\nmax_len = line_len.reduce(lambda a,b : a if a>b else b)\nmin_len = line_len.reduce(lambda a,b : a if a<b else b)\ntotal_len = line_len.reduce(add)\n\nprint max_len, min_len, total_len",
                "true_label": "",
                "top5_preds": [
                    "formatting datetimes as strings",
                    "sum all the numbers in a list",
                    "read numbers until and print their mean and standard deviation without using a list",
                    "find maximum and the minimum value in a set",
                    "how to change the style of individual lines"
                ]
            },
            {
                "code": "line_len.unpersist()   # remove persisted RDD from memory, compare the time for the same operations",
                "true_label": "",
                "top5_preds": [
                    "obtaining metadata from crossref",
                    "formatting datetimes as strings",
                    "from dictionary to dataframe",
                    "sqlalchemy, sqlite, and dates",
                    "load table in pandas"
                ]
            },
            {
                "code": "%%time\n\n# time without persisted line_len\nmax_len = line_len.reduce(lambda a,b : a if a>b else b)\nmin_len = line_len.reduce(lambda a,b : a if a<b else b)\ntotal_len = line_len.reduce(add)\n\nprint max_len, min_len, total_len",
                "true_label": "",
                "top5_preds": [
                    "formatting datetimes as strings",
                    "sum all the numbers in a list",
                    "read numbers until and print their mean and standard deviation without using a list",
                    "find maximum and the minimum value in a set",
                    "equally spaced numbers on a grid"
                ]
            },
            {
                "code": "def complexMap(s):\n    '''\n    Get the individual words of current line\n    '''\n    words = s.strip().split(\" \")\n    \n    words_num = len(words)\n    \n    # only counts line with more than ten words, and the first word starts with an alphabetic character\n    if words_num>10 and words[0][0].isalpha():\n         return (words[0], words_len)\n    else:\n        return (None, 0)",
                "true_label": "",
                "top5_preds": [
                    "find the most common words",
                    "most common words",
                    "convert text data into vector",
                    "rewrite get _long _words using map and filter",
                    "tokenize the text"
                ]
            },
            {
                "code": "def complexReduce(a, b):\n    '''\n    conditional sum reduce\n    '''\n    if a[0] and b[0]:\n        return (\"Total\", a[1]+b[1])\n    \n    if a[0]:\n        return (\"Total\", a[1])\n    \n    if b[0]:\n        return (\"Total\", b[1])\n    \n    return (None, 0)",
                "true_label": "",
                "top5_preds": [
                    "to_tuple",
                    "remove duplicates from a list",
                    "integer addition",
                    "traffic sign classification with keras",
                    "function to_binary"
                ]
            },
            {
                "code": "sc.textFile(spark_home+'LICENSE').map(complexMap).reduce(complexReduce)",
                "true_label": "",
                "top5_preds": [
                    "spark dataframes",
                    "spark",
                    "spark lab",
                    "import polynomial features from sklearn",
                    "tensorflow + keras"
                ]
            },
            {
                "code": "ssc = StreamingContext(sc, 1)  # time interval is defined as 1 second",
                "true_label": "",
                "top5_preds": [
                    "building a mini lsst broker for data management and discovery",
                    "formatting datetimes as strings",
                    "getting data from the internet",
                    "create an array of linearly spaced points",
                    "interacting with online services"
                ]
            },
            {
                "code": "# install twitter package into Jupyter notebook\n!pip install twitter\nimport twitter",
                "true_label": "",
                "top5_preds": [
                    "ipython / jupyter environment",
                    "the ipython kernel",
                    "import polynomial features from sklearn",
                    "getting data from the internet",
                    "twitter application"
                ]
            },
            {
                "code": "def connect_twitter():\n    '''\n    Connect to Twitter with developer API keys, then call Twitter API on TwitterStream\n    '''\n    consumer_key = \"bm7qkiTCNPMzsBIkkSnwgnzVU\"\n    consumer_secret = \"fkID5ttsNogh4eQyWiKpgRg7P80yXbsglj9nAYA6peN4QGSNlX\"\n    access_token = \"794210841440686081-utUrhHReNXcUcD3KligzLb95MpyXv7c\"\n    access_secret = \"PDD7XWdAoJNYaMbwEzNHNfc1UueWNfepQIep4ABPoHHpq\"\n    auth = twitter.OAuth(token = access_token, token_secret = access_secret, consumer_key = consumer_key, consumer_secret = consumer_secret)\n    return twitter.TwitterStream(auth=auth)\n\ntwitter_stream = connect_twitter()",
                "true_label": "",
                "top5_preds": [
                    "download and inspect the twitter samples dataset",
                    "twitter api access",
                    "getting data from the internet",
                    "accessing twitter",
                    "twitter application"
                ]
            },
            {
                "code": "def get_tweet(content_generator):\n    '''\n    Get valid Twitter content from a generator returned by Twitter sample API\n    '''\n    while True:\n        tweet = content_generator.next()\n        if 'delete' in tweet:\n            continue\n\n        return tweet['text'].encode('utf-8')",
                "true_label": "",
                "top5_preds": [
                    "download and inspect the twitter samples dataset",
                    "getting data from the internet",
                    "create a list of retweet count and status tuples",
                    "twitter api access",
                    "twitter application"
                ]
            },
            {
                "code": "def gen_rdd_queue(twitter_stream, tweets_num=10, queue_len=10):\n    '''\n    Generate a RDD list out of the groups of tweets, this list will be transformed into data stream\n    '''\n    rddQueue = []\n    \n    # Get most recent tweets samples\n    content_generator = twitter_stream.statuses.sample(block=True)\n    \n    for q in range(queue_len):\n        contents = []\n        for i in range(tweets_num):\n            contents.append(get_tweet(content_generator))\n        \n        # Generate the distributed dataset from a group of tweets content\n        rdd = ssc.sparkContext.parallelize(contents, 5)\n        \n        rddQueue += [rdd]\n        \n    return rddQueue\n\nrddQueue = gen_rdd_queue(twitter_stream)",
                "true_label": "",
                "top5_preds": [
                    "download and inspect the twitter samples dataset",
                    "create a list of retweet count and status tuples",
                    "getting data from the internet",
                    "draw flights graph",
                    "create flights graph"
                ]
            },
            {
                "code": "def process_tweet(new_values, last_sum):\n    '''\n    Word count update function\n    '''\n    return sum(new_values) + (last_sum or 0)",
                "true_label": "",
                "top5_preds": [
                    "create a list of retweet count and status tuples",
                    "get a positive integer from a user",
                    "summarize the data",
                    "getting data from the internet",
                    "add an item in a tuple"
                ]
            }
        ],
        [
            {
                "code": "import pandas as pd\nimport numpy as np\n\nimport matplotlib.pyplot as plt\n%pylab inline\npylab.rcParams['figure.figsize'] = (12.0, 10.0)\n\npd.options.mode.chained_assignment = None\n\n# This last line of code is because Pandas can be a bit... overzealous with warnings, and some \n# of the exercises presented here raised \"chained assignment\" warnings unnecessarily.",
                "true_label": "",
                "top5_preds": [
                    "pandas plotting",
                    "plot using matplotlib",
                    "pandas plotting documentation",
                    "matplotlib",
                    "plot using pandas plotting"
                ]
            },
            {
                "code": "df = pd.read_csv('cleaning_data.csv')\ndf",
                "true_label": "",
                "top5_preds": [
                    "loading a csv into a dataframe",
                    "load table in pandas",
                    "from dictionary to dataframe",
                    "importing data with pandas",
                    "line plot with a dataframe"
                ]
            },
            {
                "code": "df = pd.read_csv('cleaning_data.csv', index_col=0)\ndf",
                "true_label": "",
                "top5_preds": [
                    "loading a csv into a dataframe",
                    "load table in pandas",
                    "from dictionary to dataframe",
                    "importing data with pandas",
                    "make a pandas data frame from csv"
                ]
            },
            {
                "code": "dfc = dfc.set_index('c')\ndfc.index.names=[None]\ndfc",
                "true_label": "",
                "top5_preds": [
                    "create dataframe with given values",
                    "create a one column dataframe with the values of a series",
                    "dataframe methods",
                    "from dictionary to dataframe",
                    "create a dataframe by joining series by column"
                ]
            },
            {
                "code": "dfc['Dates'] = ['20160504','20160505','20160506','20160507']\ndfc",
                "true_label": "",
                "top5_preds": [
                    "convert date to datetime format",
                    "working with pandas series indexed by datetime",
                    "integrating datetime tools with pandas for time series",
                    "plotting time series with pandas",
                    "formatting datetimes as strings"
                ]
            },
            {
                "code": "dfc['Dates'] = pd.to_datetime(dfc['Dates'])\ndfc",
                "true_label": "",
                "top5_preds": [
                    "convert date to datetime format",
                    "from dictionary to dataframe",
                    "transform the date column as a datetime type",
                    "loading a csv into a dataframe",
                    "working with pandas series indexed by datetime"
                ]
            },
            {
                "code": "dfc = dfc.set_index('Dates')\ndfc.index.names = [None]\ndfc",
                "true_label": "",
                "top5_preds": [
                    "convert date to datetime format",
                    "replace the first columns by a proper datetime index",
                    "create a one column dataframe with the values of a series",
                    "working with pandas series indexed by datetime",
                    "create dataframe with given values"
                ]
            },
            {
                "code": "dft = pd.DataFrame({'Customers':[55,50,61,750,56,55],'Profit':[5455,5740,4430,6104,5650,np.NaN],\n                    'Employees':['7','8','7','10','11.5','7'],\n                    'Dates':['20160313','20160314','20160315','20160316','20160317','20160314']})",
                "true_label": "",
                "top5_preds": [
                    "find data type of each column",
                    "dataframe methods",
                    "create a dataframe",
                    "create dataframe with given values",
                    "line plots show the trend of a numerical variable over time"
                ]
            },
            {
                "code": "dft.info()",
                "true_label": "",
                "top5_preds": [
                    "getting data from the internet",
                    "convert date to datetime format",
                    "importing data with numpy",
                    "introduction to the python datetime tools",
                    "reading and writing binary files"
                ]
            },
            {
                "code": "##employee is and object it should be an integer\n\n##Date should be a date object\ndft.Dates = pd.to_datetime(dft.Dates)\n\n\n##NaN profit\ndft.fillna(value=0)\n",
                "true_label": "",
                "top5_preds": [
                    "transform the date column as a datetime type",
                    "convert date to datetime format",
                    "integrating datetime tools with pandas for time series",
                    "find data type of each column",
                    "working with pandas series indexed by datetime"
                ]
            },
            {
                "code": "ps = pd.read_csv('timeseries_1.csv',index_col=0,parse_dates=True)\nps.head()",
                "true_label": "",
                "top5_preds": [
                    "working with pandas series indexed by datetime",
                    "plotting time series with pandas",
                    "loading a csv into a dataframe",
                    "importing data with pandas",
                    "pandas stores timestamps using numpy s data type, which has nanoseond resolution"
                ]
            },
            {
                "code": "ps['Indicator'] = np.where(abs(ps['open']-ps['close'])>0.3,'Trend','Range')\nps",
                "true_label": "",
                "top5_preds": [
                    "using a dataframe and matplotlib commands",
                    "integrating datetime tools with pandas for time series",
                    "create a one column dataframe with the values of a series",
                    "line plots show the trend of a numerical variable over time",
                    "relationships between dataframes"
                ]
            },
            {
                "code": "tp = pd.DataFrame({'City':['Vancouver','Toronto','Harrogate','Chennai','Quito'],\n                  'Temp High':[21,32,12,37,17],'Avg Temp':[22,25,20,28,14]})\ntp",
                "true_label": "",
                "top5_preds": [
                    "create a one column dataframe with the values of a series",
                    "using pandas",
                    "create dataframe with given values",
                    "line plots show the trend of a numerical variable over time",
                    "from dictionary to dataframe"
                ]
            },
            {
                "code": "pcw = pd.DataFrame({'Totals':[1607, 1438, 2476, 2489, 1587, 1587, 1587, 1509, 1919, 1682, 1984,2270, 2270, 2275]},\n                   index=pd.date_range('2017-02-13',periods=14,freq='D'))\npcw",
                "true_label": "",
                "top5_preds": [
                    "line plots show the trend of a numerical variable over time",
                    "integrating datetime tools with pandas for time series",
                    "predicting a categorical response",
                    "likelihood of the binomial distribution",
                    "plotting time series with pandas"
                ]
            },
            {
                "code": "pcw[pcw.index.weekday<5]",
                "true_label": "",
                "top5_preds": [
                    "integrating datetime tools with pandas for time series",
                    "select every row after a specific row",
                    "working with pandas series indexed by datetime",
                    "convert date to datetime format",
                    "importing data with pandas"
                ]
            },
            {
                "code": "pcw[pcw.index.weekday != 0]\npcw[~pcw.index.weekday.isin([1,4])]",
                "true_label": "",
                "top5_preds": [
                    "select every row after a specific row",
                    "convert date to datetime format",
                    "integrating datetime tools with pandas for time series",
                    "date ranges and frequencies",
                    "drop the rows with nan values"
                ]
            },
            {
                "code": "ph = pd.DataFrame({'open':np.random.randint(2230,2295,size=49)},\n                   index = pd.date_range('2014-05-11 00:00:00','2014-05-13 00:00:00', freq='H'))\nph.head(10)",
                "true_label": "",
                "top5_preds": [
                    "plotting time series with pandas",
                    "line plots show the trend of a numerical variable over time",
                    "line plot with a dataframe",
                    "working with pandas series indexed by datetime",
                    "integrating datetime tools with pandas for time series"
                ]
            },
            {
                "code": "ph.between_time('10:00', '15:00')",
                "true_label": "",
                "top5_preds": [
                    "integrating datetime tools with pandas for time series",
                    "formatting datetimes as strings",
                    "compare variable with time",
                    "plotting time series with pandas",
                    "parsing time"
                ]
            },
            {
                "code": "dup = pd.DataFrame({'Total Hours':[12,np.NaN,8,14,9.5,11,12],'Weekly Shifts':[2,3,1,2,1,3,2],\n        'Overnight Shift':['N','N','Y','N','Y','Y','N']},index=['Siva','J.R.','Nick','Keisha','Wayne','Judy','Siva'])\ndup",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "create dataframe with given values",
                    "create a one column dataframe with the values of a series",
                    "dataframe methods",
                    "using pd concat, vertically concat the new dataframe, new_data,"
                ]
            },
            {
                "code": "dup.duplicated()",
                "true_label": "",
                "top5_preds": [
                    "remove duplicates from a list",
                    "find duplicate dates",
                    "find the repeated items of a tuple",
                    "how many different items appear in the dataset?",
                    "add an item in a tuple"
                ]
            },
            {
                "code": "dup[dup.duplicated()]",
                "true_label": "",
                "top5_preds": [
                    "remove duplicates from a list",
                    "find the repeated items of a tuple",
                    "add an item in a tuple",
                    "find duplicate dates",
                    "how many different items appear in the dataset?"
                ]
            },
            {
                "code": "dup.drop_duplicates(keep='first')",
                "true_label": "",
                "top5_preds": [
                    "remove duplicates from a list",
                    "find duplicate dates",
                    "from dictionary to dataframe",
                    "formatting datetimes as strings",
                    "line plot with a dataframe"
                ]
            },
            {
                "code": "dup2.drop_duplicates(subset='b')",
                "true_label": "",
                "top5_preds": [
                    "remove duplicates from a list",
                    "join two dataframes along rows",
                    "create a one column dataframe with the values of a series",
                    "join two dataframes along columns",
                    "create a dataframe by joining series by column"
                ]
            },
            {
                "code": "dup2.index = [0,1,2,2]\ndup2",
                "true_label": "",
                "top5_preds": [
                    "add element to list using insert index",
                    "create a one column dataframe with the values of a series",
                    "add an item in a tuple",
                    "remove duplicates from a list",
                    "create a tuple with different data types"
                ]
            },
            {
                "code": "dup2.index.get_duplicates()",
                "true_label": "",
                "top5_preds": [
                    "remove duplicates from a list",
                    "find duplicate dates",
                    "create a one column dataframe with the values of a series",
                    "from dictionary to dataframe",
                    "how many different items appear in the dataset?"
                ]
            },
            {
                "code": "dup2[~dup2.index.duplicated(keep='first')]",
                "true_label": "",
                "top5_preds": [
                    "find duplicate dates",
                    "remove duplicates from a list",
                    "join two dataframes along rows",
                    "find the repeated items of a tuple",
                    "join two dataframes along columns"
                ]
            },
            {
                "code": "dup2.index.duplicated(keep='first')",
                "true_label": "",
                "top5_preds": [
                    "find duplicate dates",
                    "remove duplicates from a list",
                    "find the repeated items of a tuple",
                    "join two dataframes along rows",
                    "line plot with a dataframe"
                ]
            },
            {
                "code": "~dup2.index.duplicated(keep='first')",
                "true_label": "",
                "top5_preds": [
                    "find duplicate dates",
                    "remove duplicates from a list",
                    "join two dataframes along rows",
                    "find the repeated items of a tuple",
                    "how many different items appear in the dataset?"
                ]
            },
            {
                "code": "pc[(pc['Close Price'] > 1.5*pc['Close Price'].shift(1)) & (1.5*pc['Close Price'] > 1.5*pc['Close Price'].shift(-1))]",
                "true_label": "",
                "top5_preds": [
                    "predicting a categorical response",
                    "predicting a continuous response using linear regression",
                    "numpy point",
                    "ridge regression with one predictor on a grid",
                    "find maximum and the minimum value in a set"
                ]
            },
            {
                "code": "pc[(pc['Close Price'] > 2*pc['Close Price'].shift(1)) & (2*pc['Close Price'] > 1.5*pc['Close Price'].shift(-1))]",
                "true_label": "",
                "top5_preds": [
                    "predicting a categorical response",
                    "find maximum and the minimum value in a set",
                    "predicting a continuous response using linear regression",
                    "ridge regression with one predictor on a grid",
                    "numpy point"
                ]
            },
            {
                "code": "dfm = pd.DataFrame({'Total Hours':[12,np.NaN,8,14,9.5,11],'Weekly Shifts':[2,3,1,2,1,3],\n                   'Overnight Shift':['N','N','Y','N','Y','Y',]},index=['Siva','J.R.','Nick','Keisha','Wayne','Judy'])\ndfm",
                "true_label": "",
                "top5_preds": [
                    "create dataframe with given values",
                    "dataframe methods",
                    "create a dataframe",
                    "create a one column dataframe with the values of a series",
                    "line plot with a dataframe"
                ]
            },
            {
                "code": "dfm.dropna()",
                "true_label": "",
                "top5_preds": [
                    "drop the rows with nan values",
                    "from dictionary to dataframe",
                    "line plot with a dataframe",
                    "create dataframe with given values",
                    "drop data points with missing data"
                ]
            },
            {
                "code": "nan = pd.DataFrame({'a':[1,5,2,4],'b':[3,np.NaN,0,np.NaN],'c':[np.NaN,np.NaN,np.NaN,np.NaN],'d':[np.NaN,8,2,3]})\nnan",
                "true_label": "",
                "top5_preds": [
                    "calculating the mean of a vector with nans",
                    "computing the covariance when there are nan s",
                    "create dataframe with given values",
                    "dataframe methods",
                    "predicting a categorical response"
                ]
            },
            {
                "code": "nan.dropna(axis=1,how='all')",
                "true_label": "",
                "top5_preds": [
                    "drop the rows with nan values",
                    "drop nan values",
                    "drop data points with missing data",
                    "computing the covariance when there are nan s",
                    "calculating the mean of a vector with nans"
                ]
            },
            {
                "code": "nan.dropna(axis=1,how='any')",
                "true_label": "",
                "top5_preds": [
                    "drop the rows with nan values",
                    "drop nan values",
                    "computing the covariance when there are nan s",
                    "drop data points with missing data",
                    "calculating the mean of a vector with nans"
                ]
            },
            {
                "code": "nan.dropna(axis=1,thresh=2)",
                "true_label": "",
                "top5_preds": [
                    "drop the rows with nan values",
                    "drop nan values",
                    "computing the covariance when there are nan s",
                    "find maximum and the minimum value in a set",
                    "drop data points with missing data"
                ]
            },
            {
                "code": "nan.dropna(axis=0,thresh=2)",
                "true_label": "",
                "top5_preds": [
                    "drop the rows with nan values",
                    "drop nan values",
                    "computing the covariance when there are nan s",
                    "find maximum and the minimum value in a set",
                    "drop data points with missing data"
                ]
            },
            {
                "code": "dup2.drop_duplicates(subset=index)",
                "true_label": "",
                "top5_preds": [
                    "remove duplicates from a list",
                    "create a one column dataframe with the values of a series",
                    "find duplicate dates",
                    "join two dataframes along rows",
                    "from dictionary to dataframe"
                ]
            },
            {
                "code": "dfc1 = pd.DataFrame({'a':[0,2],'b':['q','q']})\ndfc2 = pd.DataFrame({'a':[3,0],'b':['r','s']})\ndfc = pd.concat([dfc1,dfc2])\ndfc",
                "true_label": "",
                "top5_preds": [
                    "join two dataframes along columns",
                    "join two dataframes along rows",
                    "create a dataframe by joining series by column",
                    "create a one column dataframe with the values of a series",
                    "combine two dataframes into one"
                ]
            },
            {
                "code": "dfc.reset_index(drop=True)",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "from dictionary to dataframe",
                    "create a dataframe by joining series by column",
                    "create a one column dataframe with the values of a series",
                    "loading a csv into a dataframe"
                ]
            },
            {
                "code": "dfc.reset_index()",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "loading a csv into a dataframe",
                    "from dictionary to dataframe",
                    "create a dataframe by joining series by column",
                    "create a one column dataframe with the values of a series"
                ]
            },
            {
                "code": "dfc['c'] = ['A','B','C','D']\ndfc",
                "true_label": "",
                "top5_preds": [
                    "create a one column dataframe with the values of a series",
                    "create a dataframe by joining series by column",
                    "create dataframe with given values",
                    "dataframe methods",
                    "loading a csv into a dataframe"
                ]
            },
            {
                "code": "dfc.set_index('c')",
                "true_label": "",
                "top5_preds": [
                    "create a one column dataframe with the values of a series",
                    "line plot with a dataframe",
                    "create a dataframe by joining series by column",
                    "create dataframe with given values",
                    "relationships between dataframes"
                ]
            },
            {
                "code": "df['Debt']",
                "true_label": "",
                "top5_preds": [
                    "create a one column dataframe with the values of a series",
                    "convert date to datetime format",
                    "convert data from string to float",
                    "in pandas",
                    "working with pandas series indexed by datetime"
                ]
            },
            {
                "code": "df['Debt'].str[1:]",
                "true_label": "",
                "top5_preds": [
                    "convert date to datetime format",
                    "convert data from string to float",
                    "select every row after a specific row",
                    "formatting datetimes as strings",
                    "find all by term in field in case insensitive way"
                ]
            },
            {
                "code": "df['Debt'] = df['Debt'].str[1:]\ndf",
                "true_label": "",
                "top5_preds": [
                    "convert date to datetime format",
                    "convert data from string to float",
                    "sql LIKE operator",
                    "formatting datetimes as strings",
                    "convert categorical variables"
                ]
            },
            {
                "code": "df['Debt'] = pd.to_numeric(df['Debt'])\ndf",
                "true_label": "",
                "top5_preds": [
                    "convert data from string to float",
                    "convert integer or float data",
                    "get a positive integer from a user",
                    "convert date to datetime format",
                    "using pandas"
                ]
            },
            {
                "code": "temps = pd.read_csv('temperature_cleaning.csv',index_col=0,parse_dates=True)\ntemps.head()",
                "true_label": "",
                "top5_preds": [
                    "convert date to datetime format",
                    "loading a csv into a dataframe",
                    "importing data with pandas",
                    "working with pandas series indexed by datetime",
                    "load table in pandas"
                ]
            },
            {
                "code": "temps.describe()",
                "true_label": "",
                "top5_preds": [
                    "formatting datetimes as strings",
                    "get the names of all the tables in the database",
                    "load table in pandas",
                    "retrieving data from html page",
                    "accessing databases via web apis"
                ]
            },
            {
                "code": "temps[temps['Avg Daily Temp']>40]",
                "true_label": "",
                "top5_preds": [
                    "selecting specific columns in a dataframe",
                    "find all by term in field in case insensitive way",
                    "in pandas",
                    "exclude entries by condition",
                    "filtering with boolean arrays"
                ]
            },
            {
                "code": "temps['2017-05-09':'2017-05-13']",
                "true_label": "",
                "top5_preds": [
                    "convert date to datetime format",
                    "formatting datetimes as strings",
                    "plotting time series with pandas",
                    "integrating datetime tools with pandas for time series",
                    "working with pandas series indexed by datetime"
                ]
            },
            {
                "code": "temps.plot();",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "plot using matplotlib",
                    "plotting in python",
                    "plotting time series with pandas",
                    "matplotlib"
                ]
            },
            {
                "code": "t2 = temps.copy() # We'll make a copy so we can address another method.\ntemps.loc['2017-05-11','Avg Daily Temp'] = 24\ntemps['2017-05-09':'2017-05-13']",
                "true_label": "",
                "top5_preds": [
                    "convert date to datetime format",
                    "working with pandas series indexed by datetime",
                    "formatting datetimes as strings",
                    "create a one column dataframe with the values of a series",
                    "integrating datetime tools with pandas for time series"
                ]
            },
            {
                "code": "nan.dropna(thresh=3)",
                "true_label": "",
                "top5_preds": [
                    "drop the rows with nan values",
                    "drop nan values",
                    "computing the covariance when there are nan s",
                    "find maximum and the minimum value in a set",
                    "drop data points with missing data"
                ]
            },
            {
                "code": "times = pd.date_range('2017-05-01 09:30:00','2017-05-01 09:45:00',freq='min')\npc = pd.DataFrame({'Price':[54,55,52,np.NaN,57,55,54,59,51,np.NaN,np.NaN,55,52,56,60,61]}, index=times)\npc",
                "true_label": "",
                "top5_preds": [
                    "integrating datetime tools with pandas for time series",
                    "plotting time series with pandas",
                    "working with pandas series indexed by datetime",
                    "create a one column dataframe with the values of a series",
                    "line plots show the trend of a numerical variable over time"
                ]
            },
            {
                "code": "# we'll make a few copies to show different methods\npc2 = pc.copy()\npc3 = pc.copy()",
                "true_label": "",
                "top5_preds": [
                    "numpy point",
                    "pi by means of the arithmetic geometric mean",
                    "the mean of difference of variables",
                    "linear interpolation with vectorised functions",
                    "detect the number of local variables declared in a function"
                ]
            },
            {
                "code": "pc.fillna(method='ffill')",
                "true_label": "",
                "top5_preds": [
                    "predicting a continuous response using linear regression",
                    "ridge regression with polynomial features on a grid",
                    "line plots show the trend of a numerical variable over time",
                    "ridge regression with one predictor on a grid",
                    "line plot with a dataframe"
                ]
            },
            {
                "code": "pc2.fillna(method='bfill')",
                "true_label": "",
                "top5_preds": [
                    "line plots show the trend of a numerical variable over time",
                    "ridge regression with polynomial features on a grid",
                    "integrating datetime tools with pandas for time series",
                    "line plot with a dataframe",
                    "predicting a categorical response"
                ]
            },
            {
                "code": "pc2.fillna(value='')",
                "true_label": "",
                "top5_preds": [
                    "relationships between dataframes",
                    "create a dataframe by joining series by column",
                    "join two dataframes along rows",
                    "join two dataframes along columns",
                    "create a one column dataframe with the values of a series"
                ]
            },
            {
                "code": "df.index.names = [None]\ndf",
                "true_label": "",
                "top5_preds": [
                    "create dataframe with given values",
                    "load table in pandas",
                    "create a one column dataframe with the values of a series",
                    "create a dataframe by joining series by column",
                    "from dictionary to dataframe"
                ]
            },
            {
                "code": "df.columns",
                "true_label": "",
                "top5_preds": [
                    "load table in pandas",
                    "find data type of each column",
                    "from dictionary to dataframe",
                    "dataframe methods",
                    "what is the type of the columns?"
                ]
            },
            {
                "code": "df.columns = ['Name', 'Age', 'Debt', ' ']\ndf",
                "true_label": "",
                "top5_preds": [
                    "create a dataframe by joining series by column",
                    "load table in pandas",
                    "loading a csv into a dataframe",
                    "from dictionary to dataframe",
                    "line plot with a dataframe"
                ]
            },
            {
                "code": "df = df[['Name','Age','Debt']]\ndf",
                "true_label": "",
                "top5_preds": [
                    "load table in pandas",
                    "loading a csv into a dataframe",
                    "from dictionary to dataframe",
                    "dataframe methods",
                    "convert date to datetime format"
                ]
            },
            {
                "code": "t2 = t2[t2['Avg Daily Temp']<40]\nt2",
                "true_label": "",
                "top5_preds": [
                    "add an item in a tuple",
                    "find the repeated items of a tuple",
                    "sql LIKE operator",
                    "load table in pandas",
                    "find all by term in field in case insensitive way"
                ]
            },
            {
                "code": "t2.plot();",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "line plots show the trend of a numerical variable over time",
                    "trend lines in pyplot",
                    "timing, numpy, plotting",
                    "plotting time series with pandas"
                ]
            },
            {
                "code": "pc = pd.DataFrame({'Close Price':[42, 39, 35, 31, 29, 24, 22, 28, 28, 24, 22, 43, 23, 26, 22, 26, 28, 26, 24, 22 ]},\n                  index=pd.date_range('2014-11-03',periods = 20,freq='D'))",
                "true_label": "",
                "top5_preds": [
                    "plotting time series with pandas",
                    "line plots show the trend of a numerical variable over time",
                    "working with pandas series indexed by datetime",
                    "create a one column dataframe with the values of a series",
                    "integrating datetime tools with pandas for time series"
                ]
            },
            {
                "code": "pc.describe()",
                "true_label": "",
                "top5_preds": [
                    "interacting with online services",
                    "getting data from the internet",
                    "predicting a categorical response",
                    "obtaining metadata from crossref",
                    "nltk to recognize a book"
                ]
            },
            {
                "code": "pc.plot()",
                "true_label": "",
                "top5_preds": [
                    "line plots show the trend of a numerical variable over time",
                    "equally spaced numbers on a grid",
                    "create an array of linearly spaced points",
                    "timing, numpy, plotting",
                    "ridge regression with polynomial features on a grid"
                ]
            },
            {
                "code": "pc[pc['Close Price']>40]",
                "true_label": "",
                "top5_preds": [
                    "predicting a categorical response",
                    "numpy point",
                    "ridge regression with one predictor on a grid",
                    "predicting a continuous response using linear regression",
                    "function to find dbZ given Pr radar equation"
                ]
            },
            {
                "code": "(pc['Close Price']/pc['Close Price'].shift(1)).mean()",
                "true_label": "",
                "top5_preds": [
                    "convert data from string to float",
                    "predicting a categorical response",
                    "line plots show the trend of a numerical variable over time",
                    "create a one column dataframe with the values of a series",
                    "calculating the mean of a vector with nans"
                ]
            },
            {
                "code": "dup2 = pd.DataFrame({'a':[0,2,3,0],'b':['q','q','r','s']})\ndup2",
                "true_label": "",
                "top5_preds": [
                    "create a one column dataframe with the values of a series",
                    "create dataframe with given values",
                    "create a dataframe by joining series by column",
                    "join two dataframes along rows",
                    "pandas apply"
                ]
            },
            {
                "code": "dup2.drop_duplicates(subset='a')",
                "true_label": "",
                "top5_preds": [
                    "remove duplicates from a list",
                    "join two dataframes along rows",
                    "create a one column dataframe with the values of a series",
                    "find duplicate dates",
                    "from dictionary to dataframe"
                ]
            },
            {
                "code": "dfc1 = pd.DataFrame({'a':[0,2],'b':['q','q']})\ndfc2 = pd.DataFrame({'a':[3,0],'b':['r','s']})\ndfc = pd.concat([dfc1,dfc2])\ndfc",
                "true_label": "",
                "top5_preds": [
                    "join two dataframes along columns",
                    "join two dataframes along rows",
                    "create a dataframe by joining series by column",
                    "create a one column dataframe with the values of a series",
                    "combine two dataframes into one"
                ]
            }
        ],
        [
            {
                "code": "my_list = [100,200,300,400,500,600]",
                "true_label": "",
                "top5_preds": [
                    "sum all the numbers in a list",
                    "multiply all the numbers in a list",
                    "remove duplicates from a list",
                    "convert list to numpy array",
                    "add string to list using append"
                ]
            },
            {
                "code": "my_tuple = (100,200,300,400,500,600)",
                "true_label": "",
                "top5_preds": [
                    "sum all the numbers in a list",
                    "add an item in a tuple",
                    "multiply all the numbers in a list",
                    "remove duplicates from a list",
                    "to_tuple"
                ]
            },
            {
                "code": "def add_together_strings(s):\n    \"\"\"\n    Arguments:\n        s: a list of strings\n    \n    Returns:\n        A single string with 'and' between each element of s\n    \"\"\"\n    return '%s'%(' and '.join(s))\n\nprint(add_together_strings(['carbon','nitrogen','oxygen'])) # works ok for a list of strings\nprint(add_together_strings('carbon')) # Doesn't work as we want for a single string!",
                "true_label": "",
                "top5_preds": [
                    "strings",
                    "convert a tuple to a string",
                    "concatenation",
                    "add an item in a tuple",
                    "formatting datetimes as strings"
                ]
            },
            {
                "code": "def add_together_strings(s):\n    \"\"\"\n    Arguments:\n        s: a list of strings\n    \n    Returns:\n        A single string with 'and' between each element of s\n    \"\"\"\n    if isinstance(s,str):\n        return s\n    else:\n        return '%s'%(' and '.join(s))\n\nprint(add_together_strings(['carbon','nitrogen','oxygen']))\nprint(add_together_strings('carbon'))\n            ",
                "true_label": "",
                "top5_preds": [
                    "strings",
                    "convert a tuple to a string",
                    "concatenation",
                    "create a dataframe by joining series by column",
                    "add an item in a tuple"
                ]
            },
            {
                "code": "morphologies = dict(ngc4849 = 'spiral', ngc550 = 'elliptical', ngc4994 = 'spiral', ngc2337 = 'irregular')",
                "true_label": "",
                "top5_preds": [
                    "import polynomial features from sklearn",
                    "implementing bag of words in scikit learn",
                    "what is scikit learn?",
                    "postgres sql lab",
                    "creating polynomial features"
                ]
            },
            {
                "code": "morphologies = {'ngc4849': 'spiral', 'ngc550': 'elliptical', 'ngc4994' : 'spiral', 'ngc2337' : 'irregular'}",
                "true_label": "",
                "top5_preds": [
                    "import polynomial features from sklearn",
                    "implementing bag of words in scikit learn",
                    "creating polynomial features",
                    "polynomial regression with sklearn",
                    "what is scikit learn?"
                ]
            },
            {
                "code": "my_list = [100,200,300,400,500,600]\nmy_list[1] = 999\nmy_list",
                "true_label": "",
                "top5_preds": [
                    "sum all the numbers in a list",
                    "convert list to numpy array",
                    "multiply all the numbers in a list",
                    "add string to list using append",
                    "check a list is empty or not"
                ]
            },
            {
                "code": "my_list = [100,200,300,400,500,600]\nmy_list + [1000] # Returns a new list, which we don't assign to anything\nmy_list # Original list wasn't changed",
                "true_label": "",
                "top5_preds": [
                    "sum all the numbers in a list",
                    "remove duplicates from a list",
                    "convert list to numpy array",
                    "add string to list using append",
                    "multiply all the numbers in a list"
                ]
            },
            {
                "code": "my_list = [100,200,300,400,500,600]\nmy_list.append(4) # Changes the list 'in place'\nmy_list",
                "true_label": "",
                "top5_preds": [
                    "sum all the numbers in a list",
                    "add string to list using append",
                    "convert list to numpy array",
                    "multiply all the numbers in a list",
                    "add element to list using insert index"
                ]
            },
            {
                "code": "empty_list = list() # initially empty\nempty_list.append(99)\nempty_list.append(100)\nempty_list # not empty anymore.",
                "true_label": "",
                "top5_preds": [
                    "sum all the numbers in a list",
                    "check a list is empty or not",
                    "convert list to numpy array",
                    "add string to list using append",
                    "create a list"
                ]
            },
            {
                "code": "my_tuple = (100,200,300,400,500,600)\nmy_tuple[1] = 100",
                "true_label": "",
                "top5_preds": [
                    "sum all the numbers in a list",
                    "add an item in a tuple",
                    "to_tuple",
                    "multiply all the numbers in a list",
                    "convert list to numpy array"
                ]
            },
            {
                "code": "my_tuple + (4,) # Returns a new tuple",
                "true_label": "",
                "top5_preds": [
                    "add an item in a tuple",
                    "to_tuple",
                    "create a tuple with different data types",
                    "convert a tuple to a string",
                    "python data types tuple"
                ]
            },
            {
                "code": "1, 2, 3, 4 # This makes a tuple",
                "true_label": "",
                "top5_preds": [
                    "to_tuple",
                    "add an item in a tuple",
                    "create a tuple with different data types",
                    "convert a tuple to a string",
                    "sum all the numbers in a list"
                ]
            },
            {
                "code": "my_function = lambda x: x\n['this', 1, None, True, my_function, 'is fine']",
                "true_label": "",
                "top5_preds": [
                    "strings as function arguments",
                    "convert a tuple to a string",
                    "fit a polynomial",
                    "detect the number of local variables declared in a function",
                    "linear interpolation with vectorised functions"
                ]
            },
            {
                "code": "for i in range(0,15):    \n    if i == 5 or (i > 8 and i <13):\n        print('Skipping this one ...')\n        continue\n    else:\n        print(i)\n    ",
                "true_label": "",
                "top5_preds": [
                    "range of feature",
                    "ranges",
                    "read numbers until",
                    "range test an integer",
                    "print the numbers from to backwards"
                ]
            },
            {
                "code": "'abcdefg'[2:5]",
                "true_label": "",
                "top5_preds": [
                    "fourth letters of a name",
                    "matching metacharacters literally",
                    "select every row after a specific row",
                    "convert binary to hexadecimal",
                    "formatting datetimes as strings"
                ]
            },
            {
                "code": "for i,x in enumerate('carbon dioxide'):\n    print('%3d : %s'%(i,x))",
                "true_label": "",
                "top5_preds": [
                    "formatting datetimes as strings",
                    "sum all the numbers in a list",
                    "remove duplicates from a list",
                    "print",
                    "read numbers until and print their mean and standard deviation without using a list"
                ]
            },
            {
                "code": "my_string = 'carbon dioxide'\nfor i,x in zip(range(0,len(my_string)), my_string):\n    print('%3d : %s'%(i,x))",
                "true_label": "",
                "top5_preds": [
                    "sum all the numbers in a list",
                    "equally spaced numbers on a grid",
                    "formatting datetimes as strings",
                    "read numbers until and print their mean and standard deviation without using a list",
                    "playing with condition numbers"
                ]
            },
            {
                "code": "def three_powers(x):\n    return x**2, x**3, x**4\n\ny = three_powers(4)\nprint('y is a tuple: %s'%(str(y)))",
                "true_label": "",
                "top5_preds": [
                    "multiply all the numbers in a list",
                    "multiplication",
                    "test whether a number is positive",
                    "integer multiplication",
                    "fit a polynomial"
                ]
            },
            {
                "code": "alpha, beta, gamma = three_powers(4)\nprint(alpha)\nprint(beta)\nprint(gamma)",
                "true_label": "",
                "top5_preds": [
                    "multiple independent variables",
                    "fit a polynomial",
                    "pi by means of the arithmetic geometric mean",
                    "multiply all the numbers in a list",
                    "multiplication"
                ]
            },
            {
                "code": "print('y is a tuple, the elements of which are: %s %s %s'%(y))",
                "true_label": "",
                "top5_preds": [
                    "sum all the numbers in a list",
                    "add an item in a tuple",
                    "multiply all the numbers in a list",
                    "test whether a number is positive",
                    "formatting datetimes as strings"
                ]
            },
            {
                "code": "for x in [1,2,3,4]:\n    print(x)",
                "true_label": "",
                "top5_preds": [
                    "sum all the numbers in a list",
                    "multiply all the numbers in a list",
                    "convert list to numpy array",
                    "remove duplicates from a list",
                    "add string to list using append"
                ]
            },
            {
                "code": "x = 0\ni = 0\nwhile i < 10:\n    x = x + i\n    i = i + 1\nprint(x)",
                "true_label": "",
                "top5_preds": [
                    "sum all the numbers in a list",
                    "get a positive integer from a user",
                    "integer addition",
                    "create an array of integers",
                    "multiply all the numbers in a list"
                ]
            },
            {
                "code": "x = 0\nfor i in range(0,10):\n    x = x+i\nprint(x)",
                "true_label": "",
                "top5_preds": [
                    "sum all the numbers in a list",
                    "integer addition",
                    "get a positive integer from a user",
                    "create an array of integers",
                    "bytes to integer conversion"
                ]
            },
            {
                "code": "range(0,20,2)",
                "true_label": "",
                "top5_preds": [
                    "convert binary to hexadecimal",
                    "sum all the numbers in a list",
                    "equally spaced numbers on a grid",
                    "create an array of integers",
                    "bytes to integer conversion"
                ]
            },
            {
                "code": "x = range(0,20,2)\nprint(x.start,x.stop,x.step)",
                "true_label": "",
                "top5_preds": [
                    "equally spaced numbers on a grid",
                    "sum all the numbers in a list",
                    "create an array of linearly spaced points",
                    "upsampling and interpolation",
                    "plotting time series with pandas"
                ]
            },
            {
                "code": "[i**2 for i in range(0,10)]",
                "true_label": "",
                "top5_preds": [
                    "equally spaced numbers on a grid",
                    "create an array of integers",
                    "multiply all the numbers in a list",
                    "create an array of linearly spaced points",
                    "sum all the numbers in a list"
                ]
            },
            {
                "code": "'a' in ['a','b','c']",
                "true_label": "",
                "top5_preds": [
                    "check a list is empty or not",
                    "test whether a number is positive",
                    "calculating the mean of a vector with nans",
                    "convert list to numpy array",
                    "equally spaced numbers on a grid"
                ]
            },
            {
                "code": "morphologies = {'ngc4849' : 'spiral',\n                'ngc550'  : 'elliptical', \n                'ngc4994' : 'spiral', \n                'ngc2337' : 'irregular'}",
                "true_label": "",
                "top5_preds": [
                    "import polynomial features from sklearn",
                    "creating polynomial features",
                    "polynomial regression with sklearn",
                    "creating basic geometries",
                    "fit a polynomial"
                ]
            },
            {
                "code": "morphologies['ngc550'] # get the value for a given key",
                "true_label": "",
                "top5_preds": [
                    "import polynomial features from sklearn",
                    "convert text data into vector",
                    "loading json in python",
                    "implementing bag of words in scikit learn",
                    "from dictionary to dataframe"
                ]
            },
            {
                "code": "x=0 ; print(sum([x+i for i in range(0,10)]))",
                "true_label": "",
                "top5_preds": [
                    "sum all the numbers in a list",
                    "integer addition",
                    "the sum product algorithm",
                    "get a positive integer from a user",
                    "multiply all the numbers in a list"
                ]
            },
            {
                "code": "for i in range(0,10):\n    if i > 5: break\n    print(i)",
                "true_label": "",
                "top5_preds": [
                    "playing with condition numbers",
                    "remove duplicates from a list",
                    "sum all the numbers in a list",
                    "select every row after a specific row",
                    "check a list is empty or not"
                ]
            },
            {
                "code": "print(morphologies.keys())\nprint(morphologies.values())",
                "true_label": "",
                "top5_preds": [
                    "create a list of all words",
                    "import polynomial features from sklearn",
                    "loading json in python",
                    "sum all the numbers in a list",
                    "convert text data into vector"
                ]
            },
            {
                "code": "my_list = [100,200,300,400,500,600] # create the list\n\nmy_list[0] # get the first element in the list",
                "true_label": "",
                "top5_preds": [
                    "sum all the numbers in a list",
                    "convert list to numpy array",
                    "multiply all the numbers in a list",
                    "python data type list",
                    "create a list"
                ]
            },
            {
                "code": "my_list[2]",
                "true_label": "",
                "top5_preds": [
                    "convert list to numpy array",
                    "sum all the numbers in a list",
                    "python data type list",
                    "add an item in a tuple",
                    "multiply all the numbers in a list"
                ]
            },
            {
                "code": "my_list[3]",
                "true_label": "",
                "top5_preds": [
                    "sum all the numbers in a list",
                    "convert list to numpy array",
                    "python data type list",
                    "add an item in a tuple",
                    "multiply all the numbers in a list"
                ]
            },
            {
                "code": "len(my_list)",
                "true_label": "",
                "top5_preds": [
                    "sum all the numbers in a list",
                    "check a list is empty or not",
                    "convert list to numpy array",
                    "find the length of a tuple",
                    "python data type list"
                ]
            },
            {
                "code": "my_list[0:3] # elements 0, 1 and 2, NOT INCLUDING element 3!",
                "true_label": "",
                "top5_preds": [
                    "sum all the numbers in a list",
                    "replace last value of tuples in a list",
                    "print the even numbers from a given list",
                    "find maximum and the minimum value in a set",
                    "remove duplicates from a list"
                ]
            },
            {
                "code": "my_list[1:] # This is a 'slice' of the list from the 2nd element to the last",
                "true_label": "",
                "top5_preds": [
                    "sum all the numbers in a list",
                    "convert list to numpy array",
                    "add an item in a tuple",
                    "indexing and slicing",
                    "multiply all the numbers in a list"
                ]
            },
            {
                "code": "my_list[-1] # Negative indices count backwards through the list",
                "true_label": "",
                "top5_preds": [
                    "convert list to numpy array",
                    "sum all the numbers in a list",
                    "replace last value of tuples in a list",
                    "multiply all the numbers in a list",
                    "equally spaced numbers on a grid"
                ]
            },
            {
                "code": "my_list[1:-1] # This is also a 'slice', here from the 2nd to the 2nd-last",
                "true_label": "",
                "top5_preds": [
                    "convert list to numpy array",
                    "sum all the numbers in a list",
                    "replace last value of tuples in a list",
                    "multiply all the numbers in a list",
                    "indexing and slicing"
                ]
            },
            {
                "code": "my_list[:-1]",
                "true_label": "",
                "top5_preds": [
                    "convert list to numpy array",
                    "sum all the numbers in a list",
                    "replace last value of tuples in a list",
                    "equally spaced numbers on a grid",
                    "print the even numbers from a given list"
                ]
            },
            {
                "code": "my_list[0:-1:2]",
                "true_label": "",
                "top5_preds": [
                    "convert list to numpy array",
                    "sum all the numbers in a list",
                    "print the even numbers from a given list",
                    "replace last value of tuples in a list",
                    "multiply all the numbers in a list"
                ]
            },
            {
                "code": "my_list[:-1:2]",
                "true_label": "",
                "top5_preds": [
                    "convert list to numpy array",
                    "sum all the numbers in a list",
                    "replace last value of tuples in a list",
                    "print the even numbers from a given list",
                    "multiply all the numbers in a list"
                ]
            },
            {
                "code": "my_list[::2]",
                "true_label": "",
                "top5_preds": [
                    "convert list to numpy array",
                    "sum all the numbers in a list",
                    "equally spaced numbers on a grid",
                    "print the even numbers from a given list",
                    "multiply all the numbers in a list"
                ]
            },
            {
                "code": "my_list[1::2]",
                "true_label": "",
                "top5_preds": [
                    "convert list to numpy array",
                    "sum all the numbers in a list",
                    "multiply all the numbers in a list",
                    "equally spaced numbers on a grid",
                    "print the even numbers from a given list"
                ]
            },
            {
                "code": "my_list[::-1]",
                "true_label": "",
                "top5_preds": [
                    "convert list to numpy array",
                    "sum all the numbers in a list",
                    "equally spaced numbers on a grid",
                    "multiply all the numbers in a list",
                    "print the even numbers from a given list"
                ]
            },
            {
                "code": "my_list.reverse()\nprint(my_list)\nmy_list.reverse()\nprint(my_list)",
                "true_label": "",
                "top5_preds": [
                    "reverse digits in a number",
                    "remove duplicates from a list",
                    "convert list to numpy array",
                    "sum all the numbers in a list",
                    "multiply all the numbers in a list"
                ]
            },
            {
                "code": "empty_list_a = []\nempty_list_b = list()",
                "true_label": "",
                "top5_preds": [
                    "convert list to numpy array",
                    "sum all the numbers in a list",
                    "add string to list using append",
                    "multiply all the numbers in a list",
                    "create a list"
                ]
            },
            {
                "code": "print([(1,2),(100,200),('alpha','beta','gamma')])",
                "true_label": "",
                "top5_preds": [
                    "equally spaced numbers on a grid",
                    "remove duplicates from a list",
                    "formatting datetimes as strings",
                    "linear interpolation with vectorised functions",
                    "tensorflow + keras"
                ]
            },
            {
                "code": "alpha, beta, gamma = three_powers(4)\nprint(alpha)\nprint(beta)\nprint(gamma)",
                "true_label": "",
                "top5_preds": [
                    "multiple independent variables",
                    "fit a polynomial",
                    "pi by means of the arithmetic geometric mean",
                    "multiply all the numbers in a list",
                    "multiplication"
                ]
            }
        ],
        [
            {
                "code": "\n#!pip install --user statsmodels\n#(for smote sampling if there is no package available, run this line by uncommenting)\n\n#!pip install --user imblearn\nimport sys\n#sys.path.append(\"./.local/lib/python3.5/site-packages\")\nimport csv\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn import metrics\nfrom sklearn.metrics import recall_score,accuracy_score\nfrom sklearn.metrics import confusion_matrix\nimport seaborn as sns\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import roc_curve\nfrom sklearn import metrics\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom scipy import stats\nimport numpy as np\nfrom collections import Counter\nplt.rcParams[\"figure.figsize\"] = (10,10)\n",
                "true_label": "",
                "top5_preds": [
                    "import polynomial features from sklearn",
                    "load table in pandas",
                    "importing data with numpy",
                    "what is scikit learn?",
                    "package installation"
                ]
            },
            {
                "code": "df = pd.read_csv('raw_data.csv') \ndata=df[['CASEID', 'AGECAT', 'SEX', 'RACE', 'CASETYPE','ALCOHOL']]\ndata=data[data.SEX!=-8] ##According to dataset's codebook \"-8\" are unknown values. Hence, removing it\ndata=data.rename(index=str, columns={\"CASEID\": \"id\", \"AGECAT\":\"age\", \"SEX\":\"gender\", \"RACE\":\"race\", \"CASETYPE\":\"suicide\", \n                                \"ALCOHOL\":\"alcohol_use\"})",
                "true_label": "",
                "top5_preds": [
                    "load table in pandas",
                    "loading a csv into a dataframe",
                    "importing data with pandas",
                    "remove null values from county, category, and category name",
                    "dataframe methods"
                ]
            },
            {
                "code": "print(data.isnull().sum())\n#drop race\ndata.drop(\"race\", axis=1, inplace=True)\n#replace non-suicide casetype with 0 i.e., from 2 to 8\ndata['suicide'].replace(to_replace=[1,2,3,4,5,6,7,8], value=[1,0,0,0,0,0,0,0], inplace=True)\nlen(data)\n#gender encoding (0=male, 1=female)\ndata['gender'].replace(to_replace=[1,2], value=[0,1], inplace=True)\ndata.head()",
                "true_label": "",
                "top5_preds": [
                    "create dataframe with given values",
                    "create a one column dataframe with the values of a series",
                    "line plot with a dataframe",
                    "in pandas",
                    "dataframe methods"
                ]
            },
            {
                "code": "#### Non dummied data\ndata1=data[['age','gender', 'alcohol_use', 'suicide']]\ndata_x=data1.iloc[:,0:3]\ndata_y=data1.iloc[:,-1]\n# splitting non dummied data to train and test samples\ndata_x_train, data_x_test, data_y_train, data_y_test = train_test_split(data_x, data_y, test_size=0.3, random_state=0)",
                "true_label": "",
                "top5_preds": [
                    "plot multidimensional data in two dimensions",
                    "line plot with a dataframe",
                    "importing data with numpy",
                    "join two dataframes along rows",
                    "what is scikit learn?"
                ]
            },
            {
                "code": "#dummies\nfinal_data=pd.get_dummies(data, columns=['age'])\nmodel_data=final_data[['gender', 'alcohol_use', 'age_3', 'age_4', 'age_5', 'age_6','age_7', 'age_8', 'age_9', 'age_10', 'age_11','suicide']]\n## Renaming age column names appropriately\nage_labels={'age_3':'age_12-17', 'age_4':'age_18-20', 'age_5':'age_21-24', 'age_6':'age_25-29', 'age_7':'age_30-34', \n                    'age_8':'age_35-44', 'age_9':'age_45-54', 'age_10':'age_55-64', 'age_11':'age_>65'}\nmodel_data=model_data.rename(index=str, columns=age_labels)\nmod_x=model_data.iloc[:, 0:11]\nmod_y=model_data.iloc[:, -1]\n#splitting the data in to train and test samples\nX_train,X_test, y_train,y_test = train_test_split(mod_x, mod_y, test_size=0.3, random_state=0)",
                "true_label": "",
                "top5_preds": [
                    "from dictionary to dataframe",
                    "dataframe methods",
                    "load table in pandas",
                    "transform categorical data into binary features",
                    "loading a csv into a dataframe"
                ]
            },
            {
                "code": "#over sampled logistic regression after removing less weight features\ncolumns=['gender','alcohol_use','12-17','21-24', '25-29','35-44',\n        '55-64','>65']\nover_log_reg1=LogisticRegression()\nover_log_reg1.fit(X_train_mod8_1, y_train_mod8_1)\ncoefs1=over_log_reg1.coef_\ncoefs_with_columns1=sorted(zip(coefs1[0],columns), reverse=True)\nfeature_weights1=pd.DataFrame(coefs_with_columns1, columns=['weights','features'])\nprint(feature_weights1)\nover_pred_vals1=over_log_reg1.predict(X_test8_1)\nprint(classification_report(y_test, over_pred_vals1))",
                "true_label": "",
                "top5_preds": [
                    "polynomial regression with sklearn",
                    "ridge regression with polynomial features on a grid",
                    "using logistic regression with categorical features",
                    "import polynomial features from sklearn",
                    "using logistic regression instead"
                ]
            },
            {
                "code": "confusion_matrix_value = confusion_matrix(y_test,over_pred_vals1)\nsns.set(font_scale=1.4)\nprint(\"confusion matrix of oversampled data: \\n\", confusion_matrix_value)",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "predicting a categorical response",
                    "check accuracy / score for a logistic classifier",
                    "nltk to recognize a book",
                    "import polynomial features from sklearn"
                ]
            },
            {
                "code": "over_under_pred=pd.DataFrame({'log_under':log_under, 'log_under1':log_under1, 'log_under2':log_under2, 'log_over':over_pred_vals})",
                "true_label": "",
                "top5_preds": [
                    "add intercept in logistic regression",
                    "dataframe methods",
                    "relationships between dataframes",
                    "create dataframe with given values",
                    "import polynomial features from sklearn"
                ]
            },
            {
                "code": "labels=[\"undersampled_data1\",\"undersampled_data2\", \"undersampled_data3\", \"oversampled_data\"]\nfrom sklearn.metrics import roc_curve\nfor i in range(4):\n    Roc_auc = roc_auc_score(y_test, over_under_pred.iloc[:,i])\n    fpr, tpr, thresholds = roc_curve(y_test, over_under_pred.iloc[:,i])\n    plt.plot(fpr, tpr, label=labels[i]+'(area = %0.2f)' % Roc_auc)\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC curve')\nplt.legend(loc=\"lower right\")\nplt.savefig('ROC_curve')\nplt.show()",
                "true_label": "",
                "top5_preds": [
                    "import polynomial features from sklearn",
                    "predicting a categorical response",
                    "fit a polynomial",
                    "polynomial regression with sklearn",
                    "ridge regression with polynomial features on a grid"
                ]
            },
            {
                "code": "## Random Forest\nfrom sklearn.ensemble import RandomForestClassifier\nRF = RandomForestClassifier(n_estimators=20, class_weight=\"balanced\")\n\nRF1 = RandomForestClassifier(n_estimators=200, class_weight=\"balanced\")\n\nRF.fit(X_train,y_train)\nRF1.fit(X_up_train,y_up_train)\ndata_y_pred = RF.predict(X_test)\ndata_y_pred1 = RF1.predict(X_test)\n\nprint(\"Random forest with 20 estimators: \\n \",classification_report(y_test, data_y_pred))\nprint(\"Random forest with 200 estimators: \\n \", classification_report(y_test, data_y_pred1))\n",
                "true_label": "",
                "top5_preds": [
                    "what is scikit learn?",
                    "scikit learn",
                    "import polynomial features from sklearn",
                    "polynomial regression with sklearn",
                    "use sklearn kfold"
                ]
            },
            {
                "code": "##Non-linear SVM on upsampled data\nfrom sklearn import svm\nsvm_clf = svm.NuSVC()\nsvm_clf.fit(X_up_train, y_up_train)\nsvm_pred=svm_clf.predict(X_test)\nprint(classification_report(y_test, svm_pred))\n",
                "true_label": "",
                "top5_preds": [
                    "import polynomial features from sklearn",
                    "what is scikit learn?",
                    "polynomial regression with sklearn",
                    "using the classify function",
                    "one class svm fitting and estimates"
                ]
            },
            {
                "code": "#over sampled logistic regression\nover_log_reg=LogisticRegression()\nover_log_reg.fit(X_up_train, y_up_train)\nover_pred_vals=over_log_reg.predict(X_test)\nprint(\"Results of model on oversampled data: \\n\", classification_report(y_test, over_pred_vals))",
                "true_label": "",
                "top5_preds": [
                    "check accuracy / score for a logistic classifier",
                    "polynomial regression with sklearn",
                    "import polynomial features from sklearn",
                    "using logistic regression with categorical features",
                    "ridge regression with polynomial features on a grid"
                ]
            },
            {
                "code": "#over sampled logistic regression\ncolumns=['gender','alcohol_use','12-17','18-20','21-24', '25-29','30-34','35-44',\n        '45-54','55-64','>65']\nover_log_reg=LogisticRegression()\nover_log_reg.fit(X_up_train, y_up_train)\ncoefs=over_log_reg.coef_\ncoefs_with_columns=sorted(zip(coefs[0],columns), reverse=True)\nfeature_weights=pd.DataFrame(coefs_with_columns, columns=['weights','features'])\nprint(feature_weights)\nover_train_pred=over_log_reg.predict(X_up_train)\nover_pred_vals=over_log_reg.predict(X_test)\nprint(classification_report(y_test, over_pred_vals))\nconfusion_matrix_value = confusion_matrix(y_test,over_pred_vals)\nsns.set(font_scale=1.4)\nprint(\"confusion matrix of oversampled data: \\n\", confusion_matrix_value)",
                "true_label": "",
                "top5_preds": [
                    "using logistic regression with categorical features",
                    "ridge regression with polynomial features on a grid",
                    "polynomial regression with sklearn",
                    "fit a logistic regression model using statsmodels using logistic regression formula in patsy",
                    "import polynomial features from sklearn"
                ]
            },
            {
                "code": "###### Checking if feature removal might increase accuracy (feature engineering) \n##random upsampling using smote\n###smote upsampling minority class i.e., suicides\nfrom imblearn.over_sampling import SMOTE\nsmt = SMOTE()\nX_train8_1=X_train.iloc[:,[0,1,2,4,5,7,9,10]]\nX_test8_1=X_test.iloc[:,[0,1,2,4,5,7,9,10]]\nX_train_mod8_1, y_train_mod8_1 = smt.fit_sample(X_train8_1, y_train)",
                "true_label": "",
                "top5_preds": [
                    "import polynomial features from sklearn",
                    "shortcut principal component analysis in scikit learn",
                    "scikit learn",
                    "predicting a categorical response",
                    "polynomial regression with sklearn"
                ]
            },
            {
                "code": "#male vs female\nsuicide =[]\ni = 0\nfor i in range(0, len(data)):\n    if data['suicide'][i] == 0:\n        suicide.append(\"No Suicide\")\n    elif data['suicide'][i] == 1:\n        suicide.append(\"Suicide\")\n        \nD = Counter(suicide)\nbar_alcohol = plt.bar(range(len(D)), list(D.values()), align='center')\nbar_alcohol[0].set_color('orange')\nplt.xticks(range(len(D)), list(D.keys()))\nplt.title(\"Suicide Distribution in Dataset\")\nplt.show()\nprint(\"Plot shows that the dataset is higly imbalanced i.e, no-suicide cases around 96% compared to suicide cases i.e., 4%\")",
                "true_label": "",
                "top5_preds": [
                    "predicting a categorical response",
                    "counting triangles in a social network",
                    "convert list to numpy array",
                    "line plot with a dataframe",
                    "create a list of retweet count and status tuples"
                ]
            },
            {
                "code": "#alcolhol vs non-alcohol mentioned\nalcohol =[]\ni = 0\nfor i in range(0, len(data)):\n    if data['alcohol_use'][i] == 0:\n        alcohol.append(\"No Alcohol Mentioned\")\n    elif data['alcohol_use'][i] == 1:\n        alcohol.append(\"Alcohol Mentioned\")\n        \nD = Counter(alcohol)\nbar_alcohol = plt.bar(range(len(D)), list(D.values()), align='center')\nbar_alcohol[0].set_color('orange')\nplt.xticks(range(len(D)), list(D.keys()))\nplt.title(\"Alcohol vs Non-alcohol in Dataset\")\nplt.show()\nprint(\"Individuals with no-alcohol use are more i.e., around 86% compared to alcohol use individuals in the dataset\")",
                "true_label": "",
                "top5_preds": [
                    "sum all the numbers in a list",
                    "convert data from string to float",
                    "calculating the mean of a vector with nans",
                    "get a positive integer from a user",
                    "python data type list"
                ]
            },
            {
                "code": "#male vs female\ngender =[]\ni = 0\nfor i in range(0, len(data)):\n    if data['gender'][i] == 0:\n        gender.append(\"Male\")\n    elif data['gender'][i] == 1:\n        gender.append(\"Female\")\n        \nD = Counter(gender)\nbar_alcohol = plt.bar(range(len(D)), list(D.values()), align='center')\nbar_alcohol[0].set_color('orange')\nplt.xticks(range(len(D)), list(D.keys()))\nplt.title(\"Gender Distribution in Dataset\")\nplt.show()\nprint(\"Number of males are higher in the dataset\")",
                "true_label": "",
                "top5_preds": [
                    "find data type of each column",
                    "predicting a categorical response",
                    "create a data dictionary",
                    "convert text data into vector",
                    "line plot with a dataframe"
                ]
            },
            {
                "code": "#age distribution\nage=[]\n\nfor i in data['age']:    \n    if i == 3:\n        age.append(\"12-17\")\n        \n    elif i == 4:\n        age.append(\"18-20\")\n       \n    elif i == 5:\n        age.append(\"21-24\")\n       \n    elif i == 6:\n        age.append(\"25-29\")\n   \n    elif i == 7:\n        age.append(\"30-34\")\n  \n    elif i == 8:\n        age.append(\"35-44\")\n       \n    elif i == 9:\n        age.append(\"45-54\")\n        \n    elif i == 10:\n        age.append(\"55-64\")\n        \n    elif i == 11:\n        age.append(\">65\")\n        \nfrom collections import OrderedDict\nD = Counter(age)\nD1 = OrderedDict(sorted(D.items()))\nplt.bar(range(len(D1)), list(D1.values()), align='center')\nplt.xticks(range(len(D1)), list(D1.keys()))\nplt.title(\"Age Distribution\")\nplt.show()\nprint(\"The number of individuals in the age of 35-44 and 45-54 are higher than other age groups\")",
                "true_label": "",
                "top5_preds": [
                    "integrating datetime tools with pandas for time series",
                    "read numbers until and print their mean and standard deviation without using a list",
                    "line plots show the trend of a numerical variable over time",
                    "equally spaced numbers on a grid",
                    "predicting a categorical response"
                ]
            },
            {
                "code": "suicide =[]\ni = 0\nfor i in range(0, len(data)):\n    if data['alcohol_use'][i] == 0 and data['suicide'][i] == 1:\n        suicide.append(\"No Alcohol Mentioned\")\n    elif data['alcohol_use'][i] == 1 and data['suicide'][i] == 1:\n        suicide.append(\"Alcohol Mentioned\")\n        \nD = Counter(suicide)\nbar_alcohol = plt.bar(range(len(D)), list(D.values()), align='center')\nbar_alcohol[0].set_color('orange')\nplt.xticks(range(len(D)), list(D.keys()))\nplt.title(\"Alcohol Distribution in Suicide Cases\")\nplt.show()\nprint(\"Plot shows there are more suicide cases in the individuals with no alcohol use which is not true\")\nprint(\"Reason is, as seen above the non-alcohol individuals in dataset are more i.e., around 86% than alcohol use individuals\")",
                "true_label": "",
                "top5_preds": [
                    "get a positive integer from a user",
                    "predicting a categorical response",
                    "predicting test data",
                    "convert data from string to float",
                    "counting triangles in a social network"
                ]
            },
            {
                "code": "#gender category stats: 0 is male, 1 is female\n#print('mean: ', np.mean(data['gender']))\n#print('median: ', np.median(data['gender']))\n#print('variance: ', np.var(data['gender']))\n#print('standard deviation: ', np.std(data['gender']))\n\ngender_suicide =[]\ngender_nosuicide =[]\ni = 0\nwhile i < len(data):\n    if data['suicide'][i] == 1:\n        gender_suicide.append(data['gender'][i])\n        i +=1\n    else:\n        gender_nosuicide.append(data['gender'][i])\n        i += 1\ngender_suicide1 = []\nfor i in gender_suicide:\n    if i == 0:\n        gender_suicide1.append(\"Male\")\n    else: \n        gender_suicide1.append(\"Female\")\n        \nD = Counter(gender_suicide1)\nbar_alcohol = plt.bar(range(len(D)), list(D.values()), align='center')\nbar_alcohol[0].set_color('orange')\nplt.xticks(range(len(D)), list(D.keys()))\nplt.title(\"Gender Distribution in Suicide Cases\")\nplt.show()\nprint(\"The number of suicide cases are more among females\")",
                "true_label": "",
                "top5_preds": [
                    "predicting a categorical response",
                    "find data type of each column",
                    "line plots show the trend of a numerical variable over time",
                    "calculating the mean of a vector with nans",
                    "line plot with a dataframe"
                ]
            },
            {
                "code": "age_suicide =[]\ni = 0\nwhile i < len(data):\n    if data['suicide'][i] == 1:\n        age_suicide.append(data['age'][i])\n        i +=1\n    else:\n        i +=1\n        \nage_suicide1 =[]\nfor i in age_suicide:    \n    if i == 3:\n        age_suicide1.append(\"12-17\")\n        \n    elif i == 4:\n        age_suicide1.append(\"18-20\")\n       \n    elif i == 5:\n        age_suicide1.append(\"21-24\")\n       \n    elif i == 6:\n        age_suicide1.append(\"25-29\")\n   \n    elif i == 7:\n        age_suicide1.append(\"30-34\")\n  \n    elif i == 8:\n        age_suicide1.append(\"35-44\")\n       \n    elif i == 9:\n        age_suicide1.append(\"45-54\")\n        \n    elif i == 10:\n        age_suicide1.append(\"55-64\")\n        \n    elif i == 11:\n        age_suicide1.append(\">65\")\n        \nfrom collections import OrderedDict\nD = Counter(age_suicide1)\nD1 = OrderedDict(sorted(D.items()))\nplt.bar(range(len(D1)), list(D1.values()), align='center')\nplt.xticks(range(len(D1)), list(D1.keys()))\nplt.title(\"Age Distribution in Suicide Cases\")\nplt.show()\nprint(\"The number of individuals are high in age range of 35-54, so it appears there are more suicides whereas other age \\\ngroups also have more suicide rates except age 65\")",
                "true_label": "",
                "top5_preds": [
                    "predicting a categorical response",
                    "remove duplicates from a list",
                    "replace last value of tuples in a list",
                    "parse time and visibility from json",
                    "create a data dictionary"
                ]
            },
            {
                "code": "#correlation between variables of the dummied data\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set(style=\"white\")\nsns.set(style=\"whitegrid\", color_codes=True)\n\n#get correlations of each features in dataset\ncorrmat = model_data.corr()\ntop_corr_features = corrmat.index\nplt.figure(figsize=(15,10))\n#plot heat map\ng=sns.heatmap(model_data[top_corr_features].corr(),annot=True,cmap=\"RdYlGn\")\nprint(\"Heat map shows that there is a weak correlation between indepedant variables. Hence, no multicollinearity problem\")\nprint(\"But there is weak correlation between independant and target variable which might affect our logistic model\")",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "import polynomial features from sklearn",
                    "predicting a categorical response",
                    "using a dataframe and matplotlib commands",
                    "pandas plotting"
                ]
            },
            {
                "code": "###Manual Undersampled data first time\nimport numpy as np\n\nnp.random.seed(20)\nnumber_of_suicides = len(model_data[model_data['suicide'] == 1])\nnon_suicides = model_data[model_data.suicide == 0].index\nrandom_indices = np.random.choice(non_suicides,number_of_suicides, replace=False)\n\nsuicide_indices = model_data[model_data.suicide == 1].index\n\nunder_sample_indices = np.concatenate([suicide_indices,random_indices])\nunder_sample = model_data.loc[under_sample_indices]\nprint(len(under_sample[under_sample.suicide==0]))\n\n#####undersampled second time \nnp.random.seed(200)\nnumber_of_suicides1 = len(model_data[model_data['suicide'] == 1])\nnon_suicides1 = model_data[model_data.suicide == 0].index\nrandom_indices1 = np.random.choice(non_suicides1,number_of_suicides1, replace=False)\n\nsuicide_indices1 = model_data[model_data.suicide == 1].index\n\nunder_sample_indices1 = np.concatenate([suicide_indices1,random_indices1])\nunder_sample1 = model_data.loc[under_sample_indices1]\nprint(len(under_sample1[under_sample1.suicide==0]))\n\n\n####undersampled third time\nnp.random.seed(150)\nnumber_of_suicides2 = len(model_data[model_data['suicide'] == 1])\nnon_suicides2 = model_data[model_data.suicide == 0].index\nrandom_indices2 = np.random.choice(non_suicides2,number_of_suicides2, replace=False)\nsuicide_indices2 = model_data[model_data.suicide == 1].index\n\nunder_sample_indices2 = np.concatenate([suicide_indices2,random_indices2])\nunder_sample2 = model_data.loc[under_sample_indices2]\nprint(len(under_sample2[under_sample2.suicide==0]))",
                "true_label": "",
                "top5_preds": [
                    "predicting a categorical response",
                    "sampling, simulation",
                    "predicting a continuous response using linear regression",
                    "running a multivariate regression in python",
                    "predicting test data"
                ]
            },
            {
                "code": "####Splitting undersized sample\n#under sized sample1\nunder_sample_x = under_sample.iloc[:,0:11]  #independent columns\nunder_sample_y= under_sample.iloc[:,-1] #dependant column\n\n#under sized sample2\nunder_sample_x1 = under_sample1.iloc[:,0:11]  #independent columns\nunder_sample_y1= under_sample1.iloc[:,-1] #dependant column\n\n#under sized sample3\nunder_sample_x2 = under_sample2.iloc[:,0:11]  #independent columns\nunder_sample_y2= under_sample2.iloc[:,-1] #dependant column\n",
                "true_label": "",
                "top5_preds": [
                    "import polynomial features from sklearn",
                    "equally spaced numbers on a grid",
                    "from dictionary to dataframe",
                    "plot multidimensional data in two dimensions",
                    "split a dataframe into a testing"
                ]
            },
            {
                "code": "###### random UPSAMPLING OF THE UPSAMPLING OF MINORITY CLASS I.E., 'SUICIDES' \n\n#!pip install --user imblearn\nsys.path.append(\"/users/bhavani/appdata/roaming/python/python36/site-packages\")\nfrom imblearn.over_sampling import SMOTE\nsmt = SMOTE()\nX_up_train, y_up_train = smt.fit_sample(X_train, y_train)",
                "true_label": "",
                "top5_preds": [
                    "import polynomial features from sklearn",
                    "sentiment analysis with an rnn",
                    "setup and re introduction to python",
                    "sampling, simulation",
                    "bootstrapping random sampling"
                ]
            },
            {
                "code": "###Logistic Regression\n\nclass logistic_regression:\n    #training logistic regression model\n    def __init__(self,indepedent_variables, dependent_variables, split_size):\n        self.indepedent_variables=indepedent_variables\n        self.dependent_variables=dependent_variables\n        self.split_size=split_size\n        self.X_train8, self.X_test8, self.y_train8, self.y_test8 = train_test_split(self.indepedent_variables,\n                                                            self.dependent_variables, test_size=self.split_size, random_state=0)\n    def logregression(self):\n        logreg = LogisticRegression()\n        logreg.fit(self.X_train8, self.y_train8)\n        return logreg\n    def pred_log_reg(self):\n        lr = self.logregression()\n        self.y_balanced_pred =lr.predict(X_test)\n        print(\"recall score\", recall_score(y_test,self.y_balanced_pred))\n        print(\"accuracy score\", accuracy_score(y_test,self.y_balanced_pred))\n        print(classification_report(y_test, self.y_balanced_pred))\n        Roc_auc = roc_auc_score(y_test, self.y_balanced_pred)\n        fpr, tpr, thresholds = roc_curve(y_test, self.y_balanced_pred)\n        plt.plot(fpr, tpr, label='Logistic Regression (area = %0.2f)' % Roc_auc)\n        plt.plot([0, 1], [0, 1],'r--')\n        plt.xlim([0.0, 1.0])\n        plt.ylim([0.0, 1.05])\n        plt.xlabel('False Positive Rate')\n        plt.ylabel('True Positive Rate')\n        plt.title('ROC curve')\n        plt.legend(loc=\"lower right\")\n        plt.savefig('ROC_curve')\n        plt.show()\n        return self.y_balanced_pred\n    \n    #confusion matrix\n    def conf_mat(self):\n        confusion_matrix_value = confusion_matrix(y_test,self.y_balanced_pred)\n        sns.set(font_scale=1.4)\n        print(confusion_matrix_value)",
                "true_label": "",
                "top5_preds": [
                    "using logistic regression instead",
                    "constructing the logistic regression",
                    "polynomial regression with sklearn",
                    "fit a logistic regression model",
                    "fit a logistic regression model using statsmodels using logistic regression formula in patsy"
                ]
            },
            {
                "code": "# Fitting the data into the model\nlog_1=logistic_regression(mod_x, mod_y, 0.3)\nprint(\"Classification report for unbalanced data: \")\nlog_under=log_1.pred_log_reg()\n# Confusion matrix of the model\n\nprint(\"Confusion matrix for unbalanced data: \")\nlog_1.conf_mat()\nprint(\"Report shows that the model predicts only non-suicide cases i.e., '0' which is the majority class in the dataset\")",
                "true_label": "",
                "top5_preds": [
                    "check accuracy / score for a logistic classifier",
                    "using logistic regression instead",
                    "interpreting logistic regression coefficients",
                    "likelihood of the binomial distribution",
                    "likelihood of the binomial"
                ]
            },
            {
                "code": "# Running the logistic regression model on Undersampled data\nlog_r=logistic_regression(under_sample_x, under_sample_y, 0.3)\nlog_r1=logistic_regression(under_sample_x1, under_sample_y1, 0.3)\nlog_r2=logistic_regression(under_sample_x2, under_sample_y2, 0.3)\n",
                "true_label": "",
                "top5_preds": [
                    "ridge regression with polynomial features on a grid",
                    "polynomial regression with sklearn",
                    "ridge regression with one predictor on a grid",
                    "using logistic regression instead",
                    "fit a polynomial"
                ]
            },
            {
                "code": "print(\"Classification report for first under sampled data: \")\nlog_under=log_r.pred_log_reg()\nprint(\"\\n\")\nprint(\"Classification report for second under sampled data\")\nlog_under1=log_r1.pred_log_reg()\nprint(\"\\n\")\n\nprint(\"Classification report for third under sampled data\")\nlog_under2=log_r2.pred_log_reg()",
                "true_label": "",
                "top5_preds": [
                    "check accuracy / score for a logistic classifier",
                    "add intercept in logistic regression",
                    "using logistic regression instead",
                    "interpreting logistic regression coefficients",
                    "fit a polynomial"
                ]
            },
            {
                "code": "print(\"Confusion matrix for first under sampled data: \")\nlog_r.conf_mat()\nprint(\"\\n\")\nprint(\"Confusion matrix for second under sampled data\")\nlog_r1.conf_mat()\nprint(\"\\n\")\n\nprint(\"Confusion matrix for third under sampled data\")\nlog_r2.conf_mat()",
                "true_label": "",
                "top5_preds": [
                    "ridge regression with polynomial features on a grid",
                    "fit a polynomial",
                    "interpreting logistic regression coefficients",
                    "using logistic regression instead",
                    "likelihood of the binomial distribution"
                ]
            },
            {
                "code": "###### Checking if feature removal might increase accuracy (feature engineering) \n##random upsampling using smote\n###smote upsampling minority class i.e., suicides\nfrom imblearn.over_sampling import SMOTE\nsmt = SMOTE()\nX_train8_1=X_train.iloc[:,[0,1,2,4,5,7,9,10]]\nX_test8_1=X_test.iloc[:,[0,1,2,4,5,7,9,10]]\nX_train_mod8_1, y_train_mod8_1 = smt.fit_sample(X_train8_1, y_train)",
                "true_label": "",
                "top5_preds": [
                    "import polynomial features from sklearn",
                    "shortcut principal component analysis in scikit learn",
                    "scikit learn",
                    "predicting a categorical response",
                    "polynomial regression with sklearn"
                ]
            }
        ],
        [
            {
                "code": "import numpy as np\nfrom scipy.misc import factorial\nfrom scipy.optimize import curve_fit\nimport scipy.constants as cst",
                "true_label": "",
                "top5_preds": [
                    "fit a polynomial",
                    "scipy",
                    "ridge regression with polynomial features on a grid",
                    "polynomial regression with sklearn",
                    "ridge regression with one predictor on a grid"
                ]
            },
            {
                "code": "import matplotlib.pyplot as plt\n%matplotlib inline",
                "true_label": "",
                "top5_preds": [
                    "plot using matplotlib",
                    "matplotlib",
                    "plotting in python",
                    "trend lines in pyplot",
                    "equally spaced numbers on a grid"
                ]
            },
            {
                "code": "def slater_ns(r, n=3, z=11, ao=ao):\n    \"\"\" \n    Return values of the radial part of a slater type AO of an hydrogen like specie\n    \n    Args:\n        r : float or ndarray of float in the same unit as ao (A by default)\n        z (int) : atomic number\n        ao (float): Bohr radius (in A by default)\n    \"\"\"\n    fact = 1 / np.sqrt(factorial(2 * n)) * (2 * z / (n * ao))**(n + 0.5)\n    return fact * r**(n-1) * np.exp(- z * r / (n * ao))",
                "true_label": "",
                "top5_preds": [
                    "function to find dbZ given Pr radar equation",
                    "co variance matrix",
                    "calculate absolute time of the first arrivals at the station",
                    "create an array of linearly spaced points",
                    "pi by means of the arithmetic geometric mean"
                ]
            },
            {
                "code": "def smooth_3s(r, c=14, alpha=1.9, ao=ao):\n    \"\"\" \n    Return values of the radial part of a smooth AO without any oscillation closed to the nuclei.\n    \n    Args:\n        r : float or ndarray of float in the same unit as ao (A by default)\n        z (int) : atomic number\n        ao (float): Bohr radius (in A by default)\n    \"\"\"\n    return c * np.exp(- alpha * r / ao)",
                "true_label": "",
                "top5_preds": [
                    "area under the roc curve",
                    "plot roc curve",
                    "resampling and frequency conversion",
                    "co variance matrix",
                    "create an array of linearly spaced points"
                ]
            },
            {
                "code": "r = np.linspace(0, 1.4, 200)\nplt.plot(r, OA3s(r, z=11), \"b-\", label=\"OA 3s\", lw=2)\n#plt.plot(r, smooth_3s(r), \"m-\", label=\"3s smooth\", lw=2)\nymin, ymax = plt.ylim()\nplt.title(\"Atomic orbitals\")\nplt.xlabel(\"r   /   $\\AA$\")\nplt.ylabel(\"wavefunction\")\nplt.legend()\nplt.savefig(\"orbitals_1.pdf\")\nplt.plot(r, slater_ns(r, n=3, z=11), \"r-\", label=\"Slater 3s\", lw=2)\nplt.vlines(0.5, ymin, ymax, lw=2)\nplt.fill_between(x=[0, .5], y1=[ymin, ymin], y2=[ymax, ymax], color=\"k\", alpha=.15)\nplt.annotate(\"Core part\", xy=(0.25, 27), horizontalalignment=\"center\")\nplt.annotate(\"Valence part\", xy=(0.9, 27), horizontalalignment=\"center\")\nplt.savefig(\"orbitals_2.pdf\")",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "equally spaced numbers on a grid",
                    "plot using matplotlib",
                    "create an array of linearly spaced points",
                    "matplotlib"
                ]
            },
            {
                "code": "def pw_1D(x, u, box=1, phi=0):\n    \"\"\" \n    Compute the real part of a 1D plane wave at position x. The length of the box is assume to be a.\n    \n    Args:\n        x: float or array of float\n        u: coordinate of the wave vector in reciprocal space\n        box: length of the box\n        phi: phase\n    \"\"\"\n    return 1 / np.sqrt(box) * np.cos(2 * np.pi * u * x / box + phi)",
                "true_label": "",
                "top5_preds": [
                    "pi by means of the arithmetic geometric mean",
                    "likelihood of the binomial distribution",
                    "traffic sign classification with keras",
                    "perform gradient ascent point",
                    "create a box plot"
                ]
            },
            {
                "code": "ao = cst.physical_constants[\"Bohr radius\"][0] / cst.angstrom\nprint(\"a0 = {} A\".format(ao))",
                "true_label": "",
                "top5_preds": [
                    "convert date to datetime format",
                    "convert data from string to float",
                    "pi by means of the arithmetic geometric mean",
                    "formatting datetimes as strings",
                    "convert list to numpy array"
                ]
            },
            {
                "code": "def rms(y_th, y):\n    \"\"\" compute the root mean square between y and y_th values \"\"\"\n    return np.sqrt(((np.array(y) - np.array(y_th))**2).mean())",
                "true_label": "",
                "top5_preds": [
                    "get the sse by using the predictions for every x y_hats and the true y values",
                    "compute the mean absolute error of the predictions",
                    "build a linear regression model to predict mpi",
                    "pi by means of the arithmetic geometric mean",
                    "co variance matrix"
                ]
            },
            {
                "code": "def OA4s(r, z=19, ao=ao):\n    \"\"\" \n    Return values of the radial part of a 4s AO of an hydrogen like specie\n    \n    Args:\n        r : float or ndarray of float in the same unit as ao (A by default)\n        z (int) : atomic number\n        ao (float): Bohr radius (in A by default)\n    \"\"\"\n    poly = 24 - 18 * z * r / ao + 3 * z**2 * r**2 / ao**2 - z**3 * r**3 / (8 * ao**3)\n    return (z / ao)**(3/2) / 96 * poly * np.exp(- z * r / (4 * ao))",
                "true_label": "",
                "top5_preds": [
                    "area under the roc curve",
                    "function to find dbZ given Pr radar equation",
                    "plot roc curve",
                    "co variance matrix",
                    "pi by means of the arithmetic geometric mean"
                ]
            },
            {
                "code": "def e_kinet_pw(u, box=1):\n    \"\"\" \n    Return the kinetic energy of a plane wave in electron volt defined by its reciprocal space vectors G.\n    \n    Args:\n        u (int): plane waves index\n    \"\"\"\n    g = 2 * np.pi * u / (box * cst.angstrom)\n    return cst.hbar**2 * g**2 / (2 * cst.m_e) / cst.eV",
                "true_label": "",
                "top5_preds": [
                    "traffic sign classification with keras",
                    "find the angle of attack for a given lift coefficient",
                    "pi by means of the arithmetic geometric mean",
                    "plot densities",
                    "create a box plot"
                ]
            },
            {
                "code": "BOXLENGTH = 5\nr = np.linspace(0, BOXLENGTH, 200)\nspw = np.zeros(200)\nfor u in range(1, 9):\n    pw = pw_1D(r, u, box=BOXLENGTH)\n    spw += pw\n    if u in [1, 2, 4, 8]:\n        plt.plot(r, pw, label=\"{:5.1f} eV\".format(e_kinet_pw(u, box=BOXLENGTH)), lw=1)\n\nplt.plot(r, spw/7, label=\"sum\", lw=3)\nplt.title(\"Plane waves\")\nplt.xlabel(\"r   /   $\\AA$\")\nplt.ylabel(\"wavefunction\")\nplt.legend()\nplt.savefig(\"planewaves.pdf\")",
                "true_label": "",
                "top5_preds": [
                    "fit a polynomial",
                    "equally spaced numbers on a grid",
                    "create an array of linearly spaced points",
                    "numpy point",
                    "ridge regression with polynomial features on a grid"
                ]
            },
            {
                "code": "def OA3s(r, z=11, ao=ao):\n    \"\"\" \n    Return values of the radial part of a 3s AO of an hydrogen like specie\n    \n    Args:\n        r : float or ndarray of float in the same unit as ao (A by default)\n        z (int) : atomic number\n        ao (float): Bohr radius (in A by default)\n    \"\"\"\n    poly = 6 - 4 * z * r / ao + 4 * z**2 * r**2 / (9 * ao**2)\n    return (z / ao)**(3/2) / (9. * np.sqrt(3)) * poly * np.exp(-z * r / (3 * ao))",
                "true_label": "",
                "top5_preds": [
                    "function to find dbZ given Pr radar equation",
                    "area under the roc curve",
                    "plot roc curve",
                    "pi by means of the arithmetic geometric mean",
                    "co variance matrix"
                ]
            },
            {
                "code": "BOXLENGTH = 5\nrmax = 2\nr = np.linspace(0, rmax, 100)",
                "true_label": "",
                "top5_preds": [
                    "equally spaced numbers on a grid",
                    "ridge regression with polynomial features on a grid",
                    "fit a polynomial",
                    "ridge regression with one predictor on a grid",
                    "heatmap with time"
                ]
            },
            {
                "code": "def pw_vector(x, *args):\n    \"\"\" return the linear combination of plane waves \"\"\"\n    npar = len(args)\n    return np.sum([args[u] * pw_1D(x, u + 1, box=BOXLENGTH, phi=0) for u in range(npar)], axis=0)",
                "true_label": "",
                "top5_preds": [
                    "vector function",
                    "pi by means of the arithmetic geometric mean",
                    "find the angle of attack for a given lift coefficient",
                    "likelihood of the binomial distribution",
                    "function fit_and_predict"
                ]
            }
        ],
        [
            {
                "code": "import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport plotly.graph_objs as go\nfrom plotly.offline import init_notebook_mode,iplot\ninit_notebook_mode(connected=True)\nimport matplotlib.cm as cm\nimport re\nsns.set_style(\"darkgrid\")\nfrom sklearn import linear_model\nfrom sklearn.metrics import mean_squared_error, r2_score\nfrom sklearn.preprocessing import PolynomialFeatures\n\n",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "plot using matplotlib",
                    "trend lines in pyplot",
                    "equally spaced numbers on a grid",
                    "import polynomial features from sklearn"
                ]
            },
            {
                "code": "df = pd.read_csv('../input/CompleteDataset.csv')\ndf.columns",
                "true_label": "",
                "top5_preds": [
                    "loading a csv into a dataframe",
                    "load table in pandas",
                    "find data type of each column",
                    "from dictionary to dataframe",
                    "helpers to read in dataset"
                ]
            },
            {
                "code": "squad_352_strict = ['GK', 'LB|LWB', 'CB', 'RB|RWB', 'LM|W$', 'RM|W$', 'CM', 'CM|CAM|CDM', 'CM|CAM|CDM', 'W$|T$', 'W$|T$']\nsquad_442_strict = ['GK', 'LB|LWB', 'CB', 'CB', 'RB|RWB', 'LM|W$', 'RM|W$', 'CM', 'CM|CAM|CDM', 'W$|T$', 'W$|T$']\nsquad_433_strict = ['GK', 'LB|LWB', 'CB', 'CB', 'RB|RWB', 'CM|LM|W$', 'CM|RM|W$', 'CM|CAM|CDM', 'W$|T$', 'W$|T$', 'W$|T$']\nsquad_343_strict = ['GK', 'LB|LWB', 'CB', 'RB|RWB', 'LM|W$', 'RM|W$', 'CM|CAM|CDM', 'CM|CAM|CDM', 'W$|T$', 'W$|T$', 'W$|T$']\nsquad_532_strict = ['GK', 'LB|LWB', 'CB|LWB|RWB', 'CB|LWB|RWB', 'CB|LWB|RWB', 'RB|RWB', 'M$|W$', 'M$|W$', 'M$|W$', 'W$|T$', 'W$|T$']\n\n\nsquad_list = [squad_352_strict, squad_442_strict, squad_433_strict, squad_343_strict, squad_532_strict]\nsquad_name = ['3-5-2', '4-4-2', '4-3-3', '3-4-3', '5-3-2']",
                "true_label": "",
                "top5_preds": [
                    "equally spaced numbers on a grid",
                    "counting triangles in a social network",
                    "predicting a categorical response",
                    "predicting a continuous response using linear regression",
                    "ridge regression with polynomial features on a grid"
                ]
            },
            {
                "code": "rating_352_EN_Overall, best_list_352_EN_Overall = get_best_squad_n(squad_352_strict, 'England', 'Overall')\nrating_352_EN_Potential, best_list_352_EN_Potential = get_best_squad_n(squad_352_strict, 'England', 'Potential')\n\nprint('-Overall-')\nprint('Average rating: {:.1f}'.format(rating_352_EN_Overall))\nprint(best_list_352_EN_Overall)\n\nprint('-Potential-')\nprint('Average rating: {:.1f}'.format(rating_352_EN_Potential))\nprint(best_list_352_EN_Potential)",
                "true_label": "",
                "top5_preds": [
                    "predicting a categorical response",
                    "get a positive integer from a user",
                    "predicting a continuous response using linear regression",
                    "sum all the numbers in a list",
                    "line plots show the trend of a numerical variable over time"
                ]
            },
            {
                "code": "OP_df_n = pd.DataFrame(np.array(get_summary_n(squad_list, squad_name, ['England'])).reshape(-1,4), columns = ['Nationality', 'Squad', 'Overall', 'Potential'])\nOP_df_n.set_index('Nationality', inplace = True)\nOP_df_n[['Overall', 'Potential']] = OP_df_n[['Overall', 'Potential']].astype(float)\n\nprint (OP_df_n)",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "dataframe methods",
                    "using pandas",
                    "create dataframe with given values",
                    "selecting specific columns in a dataframe"
                ]
            },
            {
                "code": "fig, ax = plt.subplots()\n\n\nOP_df_n.plot(kind = 'barh', x = 'Squad', y = ['Overall', 'Potential'], edgecolor = 'black', color = ['white', 'lightgrey'], figsize = (15,10), title = 'Current and potential rating (Best 11) by squad (England)', ax = ax)\n\n\n#print (OP_df_n[OP_df_n['Overall'] == OP_df_n['Overall'].max()]['Squad'])\n\ndef get_text_y(look_for):\n    count = 0\n    for i in squad_name:\n        if i == look_for:\n            return count\n        else:\n            count += 1\n\nax.text(OP_df_n['Overall'].max()/2, get_text_y(OP_df_n[OP_df_n['Overall'] == OP_df_n['Overall'].max()]['Squad'].tolist()[0])-0.2, 'Highest Current Rating: {}'.format(OP_df_n['Overall'].max()))\nax.text(OP_df_n['Potential'].max()/2, get_text_y(OP_df_n[OP_df_n['Potential'] == OP_df_n['Potential'].max()]['Squad'].tolist()[0])+0.1, 'Highest Potential Rating: {}'.format(OP_df_n['Potential'].max()))\n\n",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "pandas plotting",
                    "plot using pandas plotting",
                    "pandas plotting documentation",
                    "ploting out data with box plots"
                ]
            },
            {
                "code": "Country_list = ['Spain','Germany','Brazil','Argentina','Italy']\n\nOP_df_n = pd.DataFrame(np.array(get_summary_n(squad_list, squad_name, Country_list)).reshape(-1,4), columns = ['Nationality', 'Squad', 'Overall', 'Potential'])\nOP_df_n.set_index('Nationality', inplace = True)\nOP_df_n[['Overall', 'Potential']] = OP_df_n[['Overall', 'Potential']].astype(float)\n\nfor i in Country_list:\n    OP_df_n_copy = OP_df_n.copy()\n    OP_df_n_copy = OP_df_n_copy[OP_df_n_copy.index == i]\n    fig, ax = plt.subplots()\n    OP_df_n_copy.plot(kind = 'barh', x = 'Squad', y = ['Overall', 'Potential'], edgecolor = 'black', color = ['white', 'lightgrey'], figsize = (15,10), title = 'Current and potential rating (Best 11) by squad ({})'.format(i), ax = ax)\n\n    ax.text(OP_df_n_copy['Overall'].max()/2, get_text_y(OP_df_n_copy[OP_df_n_copy['Overall'] == OP_df_n_copy['Overall'].max()]['Squad'].tolist()[0])-0.2, 'Highest Current Rating: {}'.format(OP_df_n_copy['Overall'].max()))\n    ax.text(OP_df_n_copy['Potential'].max()/2, get_text_y(OP_df_n_copy[OP_df_n_copy['Potential'] == OP_df_n_copy['Potential'].max()]['Squad'].tolist()[0])+0.1, 'Highest Potential Rating: {}'.format(OP_df_n_copy['Potential'].max()))",
                "true_label": "",
                "top5_preds": [
                    "predicting a categorical response",
                    "line plot with a dataframe",
                    "dataframe methods",
                    "selecting specific columns in a dataframe",
                    "create a dataframe"
                ]
            },
            {
                "code": "df_summary['Overall age trend factor'] = df_summary['Overall'] / df_summary['Overall'].iloc[0]\n\n# assume players retire at 40\ndf_summary_trend = df_summary['Overall age trend factor'].loc[16:40]\n\nexpand = pd.Series(0, index=range(41,100))\n\ndf_summary_trend = df_summary_trend.append(expand)\n\nprint(df_summary_trend.head())",
                "true_label": "",
                "top5_preds": [
                    "create a one column dataframe with the values of a series",
                    "line plots show the trend of a numerical variable over time",
                    "create dataframe with given values",
                    "in pandas",
                    "using a dataframe and matplotlib commands"
                ]
            },
            {
                "code": "def get_best_squad_n_n_yr_later(n, position, nationality):\n    df_copy = df.copy()\n    df_copy = df_copy[df_copy['Nationality'] == nationality]\n    df_copy['Overall_n_yr_later'] = round(df_copy['Age'].apply(lambda x: df_summary_trend.loc[x+n]/df_summary_trend.loc[x])*df_copy['Overall'],1)\n    store = []\n    for i in position:\n        store.append([df_copy.loc[[df_copy[df_copy['Preferred Position'].str.contains(i)]['Overall_n_yr_later'].idxmax()]]['Preferred Position'].to_string(index = False),df_copy.loc[[df_copy[df_copy['Preferred Position'].str.contains(i)]['Overall_n_yr_later'].idxmax()]]['Name'].to_string(index = False), df_copy[df_copy['Preferred Position'].str.contains(i)]['Overall_n_yr_later'].max()])\n        df_copy.drop(df_copy[df_copy['Preferred Position'].str.contains(i)]['Overall_n_yr_later'].idxmax(), inplace = True)\n    #return store\n    return np.mean([x[2] for x in store]).round(2), pd.DataFrame(np.array(store).reshape(11,3), columns = ['Position', 'Player', 'Overall_n_yr_later']).to_string(index = False)\n\n# get next 3 years England's best squad for 3-5-2 based on estimate\nfor n in range(0,4):\n    print('{} years later'.format(n))\n    rating_352_EN_Overall_later, best_list_352_EN_Overall_later = get_best_squad_n_n_yr_later(n, squad_352_strict, 'England')\n    print('Average rating: {:.1f}'.format(rating_352_EN_Overall_later))\n    print(best_list_352_EN_Overall_later)\n    \n    ",
                "true_label": "",
                "top5_preds": [
                    "download the newsgroups dataset",
                    "return a dataframe",
                    "predicting a categorical response",
                    "calculate absolute time of the first arrivals at the station",
                    "credible interval vs confidence interval"
                ]
            },
            {
                "code": "# get next 3 years Spain's best squad for 3-5-2 based on estimate\nfor n in range(0,4):\n    print('{} years later'.format(n))\n    rating_352_SP_Overall_later, best_list_352_SP_Overall_later = get_best_squad_n_n_yr_later(n, squad_352_strict, 'Spain')\n    print('Average rating: {:.1f}'.format(rating_352_SP_Overall_later))\n    print(best_list_352_SP_Overall_later)",
                "true_label": "",
                "top5_preds": [
                    "sum all the numbers in a list",
                    "line plots show the trend of a numerical variable over time",
                    "predicting a continuous response using linear regression",
                    "get a positive integer from a user",
                    "predicting a categorical response"
                ]
            },
            {
                "code": "fig, ax = plt.subplots()\nOP_df.plot(kind = 'scatter', x = 'Overall', y = 'Potential', c = 'Value of highest Potential squad', s = 50, figsize = (15,15), xlim = (70, 90), ylim = (70, 90), title = 'Current Rating vs Potential Rating by Club: 3-5-2', ax = ax)\n",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "ploting out data with box plots",
                    "pandas plotting",
                    "plot using pandas plotting",
                    "pandas plotting documentation"
                ]
            },
            {
                "code": "fig, ax = plt.subplots()\nOP_df.plot(kind = 'scatter', x = 'Overall', y = 'Potential', c = 'Value of highest Potential squad', s = 50, figsize = (15,15), xlim = (80, 90), ylim = (85, 90), title = 'Current Rating vs Potential Rating by Club: 3-5-2', ax = ax)\n\ndef label_point(x, y, val, ax):\n    a = pd.concat({'x': x, 'y': y, 'val': val}, axis=1)\n    for i, point in a.iterrows():\n        ax.text(point['x'], point['y'], str(point['val']))\n       \nOP_df['Club_label'] = OP_df.index\n\nOP_df_sub = OP_df[(OP_df['Potential']>=85) & (OP_df['Value of highest Potential squad']<=350)]\n\nlabel_point(OP_df_sub['Overall'], OP_df_sub['Potential'], OP_df_sub['Club_label'], ax)\n",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "ploting out data with box plots",
                    "pandas plotting",
                    "plot using pandas plotting",
                    "plot using matplotlib"
                ]
            },
            {
                "code": "squad_352_adj = ['GK', 'B$', 'B$', 'B$', 'M$|W$|T$', 'M$|W$|T$', 'M$|W$|T$', 'M$|W$|T$', 'M$|W$|T$', 'W$|T$|M$', 'W$|T$|M$']\n\nrating_352_TH_Overall, best_list_352_TH_Overall, value_352_TH_Overall = get_best_squad(squad_352_adj, 'Tottenham Hotspur', 'Overall')\nrating_352_TH_Potential, best_list_352_TH_Potential, value_352_TH_Potential  = get_best_squad(squad_352_adj, 'Tottenham Hotspur', 'Potential')\n\nprint('-Overall-')\nprint('Average rating: {:.1f}'.format(rating_352_TH_Overall))\nprint('Total Value (M): {:.1f}'.format(value_352_TH_Overall))\nprint(best_list_352_TH_Overall)\n\nprint('-Potential-')\nprint('Average rating: {:.1f}'.format(rating_352_TH_Potential))\nprint('Total Value (M): {:.1f}'.format(value_352_TH_Potential))\nprint(best_list_352_TH_Potential)\n",
                "true_label": "",
                "top5_preds": [
                    "counting triangles in a social network",
                    "line plots show the trend of a numerical variable over time",
                    "equally spaced numbers on a grid",
                    "predicting a continuous response using linear regression",
                    "fitting an nth degree polynomial"
                ]
            },
            {
                "code": "def get_best_squad_n(position, nationality, measurement = 'Overall'):\n    df_copy = df.copy()\n    df_copy = df_copy[df_copy['Nationality'] == nationality]\n    store = []\n    for i in position:\n        store.append([df_copy.loc[[df_copy[df_copy['Preferred Position'].str.contains(i)][measurement].idxmax()]]['Preferred Position'].to_string(index = False),df_copy.loc[[df_copy[df_copy['Preferred Position'].str.contains(i)][measurement].idxmax()]]['Name'].to_string(index = False), df_copy[df_copy['Preferred Position'].str.contains(i)][measurement].max()])\n        df_copy.drop(df_copy[df_copy['Preferred Position'].str.contains(i)][measurement].idxmax(), inplace = True)\n    #return store\n    return np.mean([x[2] for x in store]).round(2), pd.DataFrame(np.array(store).reshape(11,3), columns = ['Position', 'Player', measurement]).to_string(index = False)\n\ndef get_summary_n(squad_list, squad_name, nationality_list):\n    OP_n = []\n\n    for i in nationality_list:\n        count = 0\n        for j in squad_list:\n            # for overall rating\n            O_temp_rating, _  = get_best_squad_n(position = j, nationality = i, measurement = 'Overall')\n            # for potential rating & corresponding value\n            P_temp_rating, _ = get_best_squad_n(position = j, nationality = i, measurement = 'Potential')\n            OP_n.append([i, squad_name[count], O_temp_rating.round(2), P_temp_rating.round(2)])    \n            count += 1\n    return OP_n\n\n",
                "true_label": "",
                "top5_preds": [
                    "download and inspect the twitter samples dataset",
                    "visualize the hardest and easiest digits",
                    "calculate the mean windspeed for each month in the dataset",
                    "download the newsgroups dataset",
                    "find the minimum and maximum"
                ]
            },
            {
                "code": "# get remaining potential\ndf['Remaining Potential'] = df['Potential'] - df['Overall']\n\n\n# get only one preferred position (first only)\ndf['Preferred Position'] = df['Preferred Positions'].str.split().str[0]\n\n# convert K to M\ndf['Unit'] = df['Value'].str[-1]\ndf['Value (M)'] = np.where(df['Unit'] == '0', 0, df['Value'].str[1:-1].replace(r'[a-zA-Z]',''))\ndf['Value (M)'] = df['Value (M)'].astype(float)\ndf['Value (M)'] = np.where(df['Unit'] == 'M', df['Value (M)'], df['Value (M)']/1000)\ndf = df.drop('Unit', 1)\n\ndf.head(10)",
                "true_label": "",
                "top5_preds": [
                    "convert data from string to float",
                    "predicting a categorical response",
                    "find data type of each column",
                    "dataframe methods",
                    "create a one column dataframe with the values of a series"
                ]
            },
            {
                "code": " def plot_geo(by_column, measure, sort_column, chart_title, min_rating = 0):\n    df_g = df.copy()\n    df_g = df_g[df_g['Overall']>min_rating]\n    df_geo = df_g.groupby(['Nationality']).agg({by_column: measure})\n    df_geo = pd.DataFrame(data = df_geo)\n    df_geo = df_geo.rename(columns={by_column: 'Measurement'})\n    df_geo['text'] = ''\n\n    df_geo_player = df[['Nationality','Name', sort_column]].groupby(['Nationality']).head(3)\n    df_geo_player = df_geo_player.sort_values(['Nationality', sort_column], ascending=[True, False])\n    df_geo_player['Name_text'] = df_geo_player['Name'] + ' (' + df_geo_player[sort_column].map(str) + ')'\n\n    for index, row in df_geo.iterrows():\n        df_geo['text'].loc[index] = '<br>'.join(df_geo_player[df_geo_player['Nationality'] == index]['Name_text'].values)\n\n    df_geo.rename(index={'England': 'United Kingdom'}, inplace = True)\n\n    data = dict(type='choropleth',\n    locations = df_geo.index,\n    locationmode = 'country names', z = df_geo['Measurement'],\n    text = df_geo['text'], colorbar = {'title':'Scale'},\n    colorscale = [[0.0, 'rgb(242,240,247)'],[0.2, 'rgb(218,218,235)'],[0.4, 'rgb(188,189,220)'],\n                [0.6, 'rgb(158,154,200)'],[0.8, 'rgb(117,107,177)'],[1.0, 'rgb(84,39,143)']], \n    reversescale = False)\n\n    layout = dict(title = chart_title,\n    geo = dict(showframe = True, showcoastlines = False, projection={'type':'Mercator'}))\n\n    choromap = go.Figure(data = [data], layout = layout)\n    iplot(choromap, validate=False)\n\nplot_geo('Nationality', 'count', 'Overall', 'Total number of players per nationality')\nplot_geo('Overall', 'mean', 'Overall', 'Average rating per nationality')\nplot_geo('Overall', 'max','Overall',  'Maximum rating per nationality')\nplot_geo('Potential', 'max', 'Potential', 'Maximum potential per nationality')\nplot_geo('Age', 'mean', 'Age', 'Average age per nationality')\n",
                "true_label": "",
                "top5_preds": [
                    "plot the data",
                    "plot the function",
                    "create a visualization",
                    "download the newsgroups dataset",
                    "download and inspect the twitter samples dataset"
                ]
            },
            {
                "code": "# 'ST', 'RW', 'LW', 'GK', 'CDM', 'CB', 'RM', 'CM', 'LM', 'LB', 'CAM','RB', 'CF', 'RWB', 'LWB'\n\ndef get_best_squad(position):\n    df_copy = df.copy()\n    store = []\n    for i in position:\n        store.append([i,df_copy.loc[[df_copy[df_copy['Preferred Position'] == i]['Overall'].idxmax()]]['Name'].to_string(index = False), df_copy[df_copy['Preferred Position'] == i]['Overall'].max()])\n        df_copy.drop(df_copy[df_copy['Preferred Position'] == i]['Overall'].idxmax(), inplace = True)\n    #return store\n    return pd.DataFrame(np.array(store).reshape(11,3), columns = ['Position', 'Player', 'Overall']).to_string(index = False)\n\n# 4-3-3\nsquad_433 = ['GK', 'LB', 'CB', 'CB', 'RB', 'LM', 'CDM', 'RM', 'LW', 'ST', 'RW']\nprint ('4-3-3')\nprint (get_best_squad(squad_433))\n",
                "true_label": "",
                "top5_preds": [
                    "predicting a categorical response",
                    "function fit_and_predict",
                    "stitching images along a minimum cost path",
                    "function to find dbZ given Pr radar equation",
                    "find the most common words"
                ]
            },
            {
                "code": "# 3-5-2\nsquad_352 = ['GK', 'LWB', 'CB', 'RWB', 'LM', 'CDM', 'CAM', 'CM', 'RM', 'LW', 'RW']\nprint ('3-5-2')\nprint (get_best_squad(squad_352))",
                "true_label": "",
                "top5_preds": [
                    "find the max of three numbers",
                    "counting triangles in a social network",
                    "computing the mle solution via gradient ascent theory",
                    "fit a polynomial",
                    "find maximum and the minimum value in a set"
                ]
            },
            {
                "code": "df_p = df.groupby(['Age'])['Potential'].mean()\ndf_o = df.groupby(['Age'])['Overall'].mean()\n\ndf_summary = pd.concat([df_p, df_o], axis=1)\n\nax = df_summary.plot()\nax.set_ylabel('Rating')\nax.set_title('Average Rating by Age')",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "dataframe methods",
                    "using pandas",
                    "predicting a categorical response",
                    "pandas plotting"
                ]
            },
            {
                "code": "def get_best_squad(position, club = '*', measurement = 'Overall'):\n    df_copy = df.copy()\n    df_copy = df_copy[df_copy['Club'] == club]\n    store = []\n    for i in position:\n        store.append([df_copy.loc[[df_copy[df_copy['Preferred Position'].str.contains(i)][measurement].idxmax()]]['Preferred Position'].to_string(index = False),df_copy.loc[[df_copy[df_copy['Preferred Position'].str.contains(i)][measurement].idxmax()]]['Name'].to_string(index = False), df_copy[df_copy['Preferred Position'].str.contains(i)][measurement].max(), float(df_copy.loc[[df_copy[df_copy['Preferred Position'].str.contains(i)][measurement].idxmax()]]['Value (M)'].to_string(index = False))])\n        df_copy.drop(df_copy[df_copy['Preferred Position'].str.contains(i)][measurement].idxmax(), inplace = True)\n    #return store\n    return np.mean([x[2] for x in store]).round(1), pd.DataFrame(np.array(store).reshape(11,4), columns = ['Position', 'Player', measurement, 'Value (M)']).to_string(index = False), np.sum([x[3] for x in store]).round(1)\n\n# easier constraint\nsquad_433_adj = ['GK', 'B$', 'B$', 'B$', 'B$', 'M$', 'M$', 'M$', 'W$|T$', 'W$|T$', 'W$|T$']\n\n# Example Output for Chelsea\nrating_433_Chelsea_Overall, best_list_433_Chelsea_Overall, value_433_Chelsea_Overall = get_best_squad(squad_433_adj, 'Chelsea', 'Overall')\nrating_433_Chelsea_Potential, best_list_433_Chelsea_Potential, value_433_Chelsea_Potential  = get_best_squad(squad_433_adj, 'Chelsea', 'Potential')\n\nprint('-Overall-')\nprint('Average rating: {:.1f}'.format(rating_433_Chelsea_Overall))\nprint('Total Value (M): {:.1f}'.format(value_433_Chelsea_Overall))\nprint(best_list_433_Chelsea_Overall)\n\nprint('-Potential-')\nprint('Average rating: {:.1f}'.format(rating_433_Chelsea_Potential))\nprint('Total Value (M): {:.1f}'.format(value_433_Chelsea_Potential))\nprint(best_list_433_Chelsea_Potential)\n",
                "true_label": "",
                "top5_preds": [
                    "visualize the hardest and easiest digits",
                    "read the dataset point",
                    "survey data",
                    "find the most common words",
                    "calculate the mean yellow cards given per team"
                ]
            },
            {
                "code": "# very easy constraint since some club do not have strict squad\nsquad_352_adj = ['GK', 'B$', 'B$', 'B$', 'M$|W$|T$', 'M$|W$|T$', 'M$|W$|T$', 'M$|W$|T$', 'M$|W$|T$', 'W$|T$|M$', 'W$|T$|M$']\n\nBy_club = df.groupby(['Club'])['Overall'].mean()\n\ndef get_summary(squad):\n    OP = []\n    # only get top 100 clubs for shorter run-time\n    for i in By_club.sort_values(ascending = False).index[0:100]:\n        # for overall rating\n        O_temp_rating, _, _  = get_best_squad(squad, club = i, measurement = 'Overall')\n        # for potential rating & corresponding value\n        P_temp_rating, _, P_temp_value = get_best_squad(squad, club = i, measurement = 'Potential')\n        OP.append([i, O_temp_rating, P_temp_rating, P_temp_value])\n    return OP\n\nOP_df = pd.DataFrame(np.array(get_summary(squad_352_adj)).reshape(-1,4), columns = ['Club', 'Overall', 'Potential', 'Value of highest Potential squad'])\nOP_df.set_index('Club', inplace = True)\nOP_df = OP_df.astype(float)\n\n\nprint (OP_df.head(10))\n    ",
                "true_label": "",
                "top5_preds": [
                    "equally spaced numbers on a grid",
                    "counting triangles in a social network",
                    "add an item in a tuple",
                    "line plots show the trend of a numerical variable over time",
                    "trend lines in pyplot"
                ]
            },
            {
                "code": "OP_df_n = pd.DataFrame(np.array(get_summary_n(squad_list, squad_name, ['England'])).reshape(-1,4), columns = ['Nationality', 'Squad', 'Overall', 'Potential'])\nOP_df_n.set_index('Nationality', inplace = True)\nOP_df_n[['Overall', 'Potential']] = OP_df_n[['Overall', 'Potential']].astype(float)\n\nprint (OP_df_n)",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "dataframe methods",
                    "using pandas",
                    "create dataframe with given values",
                    "selecting specific columns in a dataframe"
                ]
            }
        ],
        [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Net(nn.Module):\n    def __init__(self, D_in, H, D_out):\n        super(Net, self).__init__()\n        self.linear1 = nn.Linear(D_in, H)\n        self.linear2 = nn.Linear(H, D_out)\n\n    def forward(self, x):\n        x = F.sigmoid(self.linear1(x))\n        x = F.sigmoid(self.linear2(x))\n        return x",
                "true_label": "",
                "top5_preds": [
                    "tensorflow + keras",
                    "import polynomial features from sklearn",
                    "polynomial regression with sklearn",
                    "simple convolutional neural network",
                    "classification with a cnn"
                ]
            },
            {
                "code": "model = torch.nn.Sequential(torch.nn.Linear(1,2),\n                            torch.nn.Sigmoid(),\n                            torch.nn.Linear(2,1),\n                            torch.nn.Sigmoid())",
                "true_label": "",
                "top5_preds": [
                    "build a vector of prediction from the trained model",
                    "logistic regression using tensorflow",
                    "tensorflow + keras",
                    "using the model for prediction",
                    "training a sequential model"
                ]
            },
            {
                "code": "model = Net(1, 2, 1)\ncriterion = nn.BCELoss()\ndataset = Data()\ntrain_loader = DataLoader(dataset=dataset, batch_size=1)\noptimizer = optim.SGD(model.parameters(), lr=0.01)\ntrain(dataset, model, criterion, train_loader, optimizer, epochs=1000)\nyhat = model(x)",
                "true_label": "",
                "top5_preds": [
                    "polynomial regression with sklearn",
                    "what is scikit learn?",
                    "tensorflow + keras",
                    "scikit learn",
                    "logistic regression using tensorflow"
                ]
            },
            {
                "code": "model = Net(2, 4, 1)",
                "true_label": "",
                "top5_preds": [
                    "tensorflow + keras",
                    "logistic regression using tensorflow",
                    "polynomial regression with sklearn",
                    "import polynomial features from sklearn",
                    "what is scikit learn?"
                ]
            },
            {
                "code": "model = Net(2, 4, 10)",
                "true_label": "",
                "top5_preds": [
                    "tensorflow + keras",
                    "logistic regression using tensorflow",
                    "polynomial regression with sklearn",
                    "import polynomial features from sklearn",
                    "what is scikit learn?"
                ]
            },
            {
                "code": "class Net(nn.Module):\n    def __init__(self, D_in, H, D_out):\n        super(Net, self).__init__()\n        self.linear1 = nn.Linear(D_in, H)\n        self.linear2 = nn.Linear(H, D_out)\n\n    def forward(self, x):\n        x = F.sigmoid(self.linear1(x))\n        x = self.linear2(x)\n        return x",
                "true_label": "",
                "top5_preds": [
                    "simple convolutional neural network",
                    "train the network",
                    "import polynomial features from sklearn",
                    "building the network",
                    "the scikit learn interface"
                ]
            },
            {
                "code": "model = torch.nn.Sequential(torch.nn.Linear(1,2),\n                            torch.nn.Sigmoid(),\n                            torch.nn.Linear(2,1))",
                "true_label": "",
                "top5_preds": [
                    "build a vector of prediction from the trained model",
                    "logistic regression using tensorflow",
                    "tensorflow + keras",
                    "using the model for prediction",
                    "training a sequential model"
                ]
            },
            {
                "code": "model = Net(2, 2, 1)\ncriterion = nn.MSELoss()",
                "true_label": "",
                "top5_preds": [
                    "polynomial regression with sklearn",
                    "logistic regression using tensorflow",
                    "tensorflow + keras",
                    "using logistic regression instead",
                    "what is scikit learn?"
                ]
            },
            {
                "code": "from matplotlib import pyplot as plt\nimport numpy as np\n\ndef sigmoid(X):\n    f = 1/(1+np.exp(-X))\n    df = f * (1 - f)\n    return f, df\n\nX = np.arange(-10, 10, 0.1)\ny, dy = sigmoid(X)\n\nplt.figure(figsize=(15,3))\nplt.subplot(1, 2, 1)\nplt.plot(X, y)\nplt.subplot(1, 2, 2)\nplt.plot(X, dy)\nplt.show()",
                "true_label": "",
                "top5_preds": [
                    "plot the function",
                    "plot using matplotlib",
                    "matplotlib",
                    "line plot with a dataframe",
                    "create an array of linearly spaced points"
                ]
            },
            {
                "code": "def tanh(X):\n    f = np.tanh(X)\n    df = 1.0 - f**2\n    return f, df\n\nX = np.arange(-10, 10, 0.1)\ny, dy = tanh(X)\n\nplt.figure(figsize=(15,3))\nplt.subplot(1, 2, 1)\nplt.plot(X, y)\nplt.subplot(1, 2, 2)\nplt.plot(X, dy)\nplt.show()",
                "true_label": "",
                "top5_preds": [
                    "plot the function",
                    "the dot",
                    "co variance matrix",
                    "create a scatter plot",
                    "create a line plot"
                ]
            }
        ],
        [
            {
                "code": "%matplotlib inline\n\nimport os\nimport sys\n\n# Useful imports\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\n\nfrom keras.layers.recurrent import LSTM, GRU\n\n# Local scripts\nimport model\nimport preprocessing\nimport read_data\nimport viz",
                "true_label": "",
                "top5_preds": [
                    "import polynomial features from sklearn",
                    "load table in pandas",
                    "what is scikit learn?",
                    "polynomial regression with sklearn",
                    "equally spaced numbers on a grid"
                ]
            },
            {
                "code": "READ_PRE_TRAINED_MODELS = False\nPRE_TRAINED_EPOCH = 9",
                "true_label": "",
                "top5_preds": [
                    "matching metacharacters literally",
                    "the re module in python",
                    "loading json in python",
                    "tokenization, stop words, punctuation",
                    "import polynomial features from sklearn"
                ]
            },
            {
                "code": "FEATURES_READ = [\n    'SymH',  # What we are trying to predict,\n    'Bz',\n    'By',  # Necessary for calculating the clock angle.\n    'DynamicPressure'\n]\nomni_data = read_data.read_omni_db(FEATURES_READ)",
                "true_label": "",
                "top5_preds": [
                    "getting data from the internet",
                    "calculate and store features in database",
                    "load table in pandas",
                    "read the dataset",
                    "reading in the data & exploratory analysis"
                ]
            },
            {
                "code": "omni_data.describe()",
                "true_label": "",
                "top5_preds": [
                    "getting data from the internet",
                    "import polynomial features from sklearn",
                    "what is scikit learn?",
                    "predicting a categorical response",
                    "importing data with numpy"
                ]
            },
            {
                "code": "missing_b_pct = np.isnan(omni_data['Bz']).sum() / float(len(omni_data))\nmissing_pressure_pct = np.isnan(omni_data['DynamicPressure']).sum() / float(len(omni_data))\nprint('Missing B percent: %s' % missing_b_pct)\nprint('Missing Dynamic Pressure percent: %s' % missing_pressure_pct)",
                "true_label": "",
                "top5_preds": [
                    "computing the covariance when there are nan s",
                    "compute how many non missing values there are in total",
                    "predicting a categorical response",
                    "skipping observations with missing values",
                    "drop data points with missing data"
                ]
            },
            {
                "code": "clock_angle = np.arctan2(omni_data.By, -omni_data.Bz)\nomni_data = omni_data.assign(clock_angle=clock_angle)\ndel clock_angle",
                "true_label": "",
                "top5_preds": [
                    "numpy",
                    "importing data with numpy",
                    "scipy",
                    "create an array of linearly spaced points",
                    "creating a simple numpy array"
                ]
            },
            {
                "code": "omni_data = omni_data[omni_data.index > pd.Timestamp('1995-08-01')]\nprint len(omni_data)\nmissing_b_pct = np.isnan(omni_data['Bz']).sum() / float(len(omni_data))\nmissing_pressure_pct = np.isnan(omni_data['DynamicPressure']).sum() / float(len(omni_data))\nprint('Missing B percent: %s' % missing_b_pct)\nprint('Missing Dynamic Pressure percent: %s' % missing_pressure_pct)",
                "true_label": "",
                "top5_preds": [
                    "drop data points with missing data",
                    "integrating datetime tools with pandas for time series",
                    "computing the covariance when there are nan s",
                    "predicting a categorical response",
                    "line plot with a dataframe"
                ]
            },
            {
                "code": "omni_lo_res = omni_data.resample('20T').mean()\nprint 'Old data size: {}, New data size: {}'.format(len(omni_data), len(omni_lo_res))",
                "true_label": "",
                "top5_preds": [
                    "integrating datetime tools with pandas for time series",
                    "predicting on sample validation data",
                    "resampling and frequency conversion",
                    "predicting a categorical response",
                    "numpy"
                ]
            },
            {
                "code": "FIELDS = ['Bz', 'clock_angle', 'DynamicPressure']\nFIELDS_PREDICT = ['SymH']\nLOOK_BEHIND_SPAN = 15  # dataset freq is 20min so 15 points is 5 hours.\nLOOK_AHEAD_SPAN = 3    # dataset freq is 20min so 3 points is 1 hour.\nx_train, y_train, x_test, y_test = preprocessing.train_test_split(\n    omni_lo_res,\n    FIELDS,\n    FIELDS_PREDICT,\n    n_points_behind=LOOK_BEHIND_SPAN,\n    n_points_ahead=LOOK_AHEAD_SPAN)\n\ninput_shape = (LOOK_BEHIND_SPAN, x_train.shape[2])",
                "true_label": "",
                "top5_preds": [
                    "line plots show the trend of a numerical variable over time",
                    "heatmap with time",
                    "equally spaced numbers on a grid",
                    "line plot with a dataframe",
                    "trend lines in pyplot"
                ]
            },
            {
                "code": "import itertools\nparams = itertools.product((LSTM, GRU), (.1, .3, .5))\nmodels = []\nfor rnn_type, dropout in params:\n    name = '%s-dropout-%s' % (rnn_type.__name__, dropout)\n    m = model.ModelWrapper(\n        model.build_model(input_shape, LOOK_AHEAD_SPAN, hidden=32, rnn_type=rnn_type, dropout=dropout),\n        name=name)\n    m.save_path = './model-checkpoints/'  # save in the model-checkpoints directory.\n    m.save_freq = 5  # When training, save every 5 epochs.    \n    model.compile_model(m)\n    models.append(m)\n",
                "true_label": "",
                "top5_preds": [
                    "tensorflow + keras",
                    "polynomial regression with sklearn",
                    "import polynomial features from sklearn",
                    "logistic regression using tensorflow",
                    "creating polynomial features"
                ]
            },
            {
                "code": "if READ_PRE_TRAINED_MODELS:\n    new_models = []\n    for m in models:\n        m = m.restore(os.path.join(m.save_path, m.name + '.%s.json' % PRE_TRAINED_EPOCH))\n        new_models.append(m)\n    models[:] = new_models\nelse:\n    for m in models:\n        # Hold out 20% of the dat a for validation.\n        # Splitting the dataset at a specific point minimizes the correlation\n        # between the input vectors and the validation vectors.\n        n_validate = int(len(x_train) * .2)\n        X = x_train[:-n_validate]\n        Y = y_train[:-n_validate]\n        x_validate = x_train[-n_validate:]\n        y_validate = y_train[-n_validate:]\n        m.fit(\n            X,\n            Y,\n            epochs=10,\n            batch_size=400,\n            validation_data=(x_validate, y_validate))\n",
                "true_label": "",
                "top5_preds": [
                    "reading in the files",
                    "read the dataset",
                    "load table in pandas",
                    "build a vector of prediction from the trained model",
                    "read images point"
                ]
            },
            {
                "code": "loss = pd.DataFrame({m.name: m.loss for m in models})\nval_loss = pd.DataFrame({m.name: m.val_loss for m in models})",
                "true_label": "",
                "top5_preds": [
                    "from dictionary to dataframe",
                    "create a dataframe by joining series by column",
                    "create a one column dataframe with the values of a series",
                    "dataframe methods",
                    "import polynomial features from sklearn"
                ]
            },
            {
                "code": "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(9, 6))\nloss.plot(ax=ax[0], title='loss vs. dropout')\nval_loss.plot(ax=ax[1], title='validation loss vs. dropout')",
                "true_label": "",
                "top5_preds": [
                    "matplotlib",
                    "plot using matplotlib",
                    "line plot with a dataframe",
                    "plotting squared loss",
                    "how to change the size of a plot"
                ]
            },
            {
                "code": "m = model.ModelWrapper(\n    model.build_model(input_shape, LOOK_AHEAD_SPAN, hidden=32, rnn_type=GRU, dropout=.1, stacks=3),\n    name='GRU-stacks-3-dropout-.1-hidden-32')\nm.save_path = './model-checkpoints/'\nmodel.compile_model(m)",
                "true_label": "",
                "top5_preds": [
                    "tensorflow + keras",
                    "logistic regression using tensorflow",
                    "polynomial regression with sklearn",
                    "import polynomial features from sklearn",
                    "test the model for accuracy"
                ]
            },
            {
                "code": "if READ_PRE_TRAINED_MODELS:\n    m = m.restore(os.path.join(m.save_path, m.name + '.%s.json' % PRE_TRAINED_EPOCH))\nelse:\n    n_validate = int(len(x_train) * .2)\n    X = x_train[:-n_validate]\n    Y = y_train[:-n_validate]\n    x_validate = x_train[-n_validate:]\n    y_validate = y_train[-n_validate:]\n    m.fit(\n        X,\n        Y,\n        epochs=10,\n        batch_size=400,\n        validation_data=(x_validate, y_validate))\n",
                "true_label": "",
                "top5_preds": [
                    "test the model for accuracy",
                    "fit on training",
                    "training data",
                    "fit on training set",
                    "making predictions for the testing data"
                ]
            },
            {
                "code": "import itertools\nstacked_model = m\n\nevaluate_vals = []\n\nfor m in itertools.chain([stacked_model], models):\n    evaluate_vals.append(m.evaluate(x_test, y_test))",
                "true_label": "",
                "top5_preds": [
                    "tensorflow + keras",
                    "import polynomial features from sklearn",
                    "logistic regression using tensorflow",
                    "what is scikit learn?",
                    "build a vector of prediction from the trained model"
                ]
            },
            {
                "code": "for e_val, m in sorted(zip(evaluate_vals, itertools.chain([stacked_model], models))):\n    print m.name, e_val, m.val_loss[-1]",
                "true_label": "",
                "top5_preds": [
                    "replace last value of tuples in a list",
                    "predicting a continuous response using linear regression",
                    "linear regression of many variables",
                    "using logistic regression instead",
                    "sum all the numbers in a list"
                ]
            },
            {
                "code": "viz.plot_event_predictions(\n        stacked_model,\n        omni_lo_res,\n        pd.Timestamp('2016-05-07'),\n        pd.Timestamp('2016-05-08T12:00:00'),\n        FIELDS,\n        FIELDS_PREDICT,\n        n_points_behind=15,\n        n_points_ahead=3)",
                "true_label": "",
                "top5_preds": [
                    "plot the data",
                    "plot the training",
                    "visualize the scatterplot of x",
                    "plot the distributions",
                    "data visualization"
                ]
            },
            {
                "code": "m = next(m for m in models if m.name == 'GRU-dropout-0.3')\nviz.plot_event_predictions(\n        m,\n        omni_lo_res,\n        pd.Timestamp('2016-05-07'),\n        pd.Timestamp('2016-05-08T12:00:00'),\n        FIELDS,\n        FIELDS_PREDICT,\n        n_points_behind=15,\n        n_points_ahead=3)",
                "true_label": "",
                "top5_preds": [
                    "ploting out data with box plots",
                    "line plot with a dataframe",
                    "plot the data",
                    "line plots show the trend of a numerical variable over time",
                    "plotting data"
                ]
            },
            {
                "code": "m = next(m for m in models if m.name == 'LSTM-dropout-0.3')\nviz.plot_event_predictions(\n        m,\n        omni_lo_res,\n        pd.Timestamp('2016-05-07'),\n        pd.Timestamp('2016-05-08T12:00:00'),\n        FIELDS,\n        FIELDS_PREDICT,\n        n_points_behind=15,\n        n_points_ahead=3)",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "ploting out data with box plots",
                    "plot the data",
                    "line plots show the trend of a numerical variable over time",
                    "plotting data"
                ]
            },
            {
                "code": "error_histogram = []\nfor m in recent_models:\n    dset = dsets['By'] if 'By' in name else dsets['clock_angle']\n    _, _, x_test, y_test = dset\n    plot_bins, error_counts = predict_accuracy_histogram(m, x_test, y_test)\n    sys.stdout.write('Predictions measured for %s\\n' % m.name)\n    sys.stdout.flush()\n    error_histogram.append((plot_bins, error_counts, m))",
                "true_label": "",
                "top5_preds": [
                    "predicting a categorical response",
                    "function fit_and_predict",
                    "using the predict functionality of statsmodels, predict the values for and",
                    "check accuracy / score for a logistic classifier",
                    "predictive distribution"
                ]
            },
            {
                "code": "for bins, error_counts, m in error_histogram[::2]:\n    legend_name = m.name.replace('fld-', '').replace('stacks-', '').replace('hidden-', '')\n    plt.plot(bins, error_counts, label=legend_name)\n\nax = plt.gca()\nax.set_xlim(-50, 50)\n\n# Shrink current axis by 20%\nbox = ax.get_position()\nax.set_position([box.x0, box.y0, box.width * 0.8, box.height])\nax.grid()\n# Put a legend to the right of the current axis\nax.legend(loc='center left', bbox_to_anchor=(1, 0.5))",
                "true_label": "",
                "top5_preds": [
                    "trend lines in pyplot",
                    "line plot with a dataframe",
                    "ploting out data with box plots",
                    "matplotlib",
                    "plot using matplotlib"
                ]
            },
            {
                "code": "for bins, error_counts, m in error_histogram[1::2]:\n    legend_name = m.name.replace('fld-', '').replace('stacks-', '').replace('hidden-', '')\n    plt.plot(bins, error_counts, label=legend_name)\n\nax = plt.gca()\nax.set_xlim(-50, 50)\n\n# Shrink current axis by 20%\nbox = ax.get_position()\nax.set_position([box.x0, box.y0, box.width * 0.8, box.height])\nax.grid()\n# Put a legend to the right of the current axis\nax.legend(loc='center left', bbox_to_anchor=(1, 0.5))",
                "true_label": "",
                "top5_preds": [
                    "trend lines in pyplot",
                    "line plot with a dataframe",
                    "ploting out data with box plots",
                    "plot using matplotlib",
                    "matplotlib"
                ]
            },
            {
                "code": "plot_model = recent_models[3]",
                "true_label": "",
                "top5_preds": [
                    "load table in pandas",
                    "trend lines in pyplot",
                    "linear regression of many variables",
                    "ridge regression with one predictor on a grid",
                    "fit a logistic regression model using statsmodels using logistic regression formula in patsy"
                ]
            },
            {
                "code": "viz.plot_event_predictions(\n        plot_model,\n        omni_lo_res,\n        pd.Timestamp('2016-05-07'),\n        pd.Timestamp('2016-05-08T12:00:00'),\n        FIELDS,\n        FIELDS_PREDICT,\n        n_points_behind=15,\n        n_points_ahead=3)",
                "true_label": "",
                "top5_preds": [
                    "plot the data",
                    "plot the training",
                    "plot the distributions",
                    "plot the function",
                    "visualize the scatterplot of x"
                ]
            },
            {
                "code": "viz.plot_event_predictions(\n        plot_model,\n        omni_lo_res,\n        pd.Timestamp('2015-10-06T12:00:00'),\n        pd.Timestamp('2015-10-08T00:00:00'),\n        FIELDS,\n        FIELDS_PREDICT,\n        n_points_behind=15,\n        n_points_ahead=3)",
                "true_label": "",
                "top5_preds": [
                    "plot the data",
                    "plot the training",
                    "plot the distributions",
                    "plot the function",
                    "visualize the scatterplot of x"
                ]
            },
            {
                "code": "viz.plot_event_predictions(\n        plot_model,\n        omni_lo_res,\n        pd.Timestamp('2015-09-11T00:00:00'),\n        pd.Timestamp('2015-09-12T00:00:00'),\n        FIELDS,\n        FIELDS_PREDICT,\n        n_points_behind=15,\n        n_points_ahead=3)",
                "true_label": "",
                "top5_preds": [
                    "plot the data",
                    "plot the training",
                    "plot the distributions",
                    "plot the function",
                    "visualize the scatterplot of x"
                ]
            },
            {
                "code": "plot_model = recent_models[1]",
                "true_label": "",
                "top5_preds": [
                    "load table in pandas",
                    "trend lines in pyplot",
                    "ridge regression with one predictor on a grid",
                    "fit a logistic regression model using statsmodels using logistic regression formula in patsy",
                    "linear regression of many variables"
                ]
            },
            {
                "code": "plot_model = recent_models[2]",
                "true_label": "",
                "top5_preds": [
                    "load table in pandas",
                    "trend lines in pyplot",
                    "linear regression of many variables",
                    "fit a logistic regression model using statsmodels using logistic regression formula in patsy",
                    "ridge regression with one predictor on a grid"
                ]
            },
            {
                "code": "_ = omni_data.fillna({col: omni_data[col].mean() for col in omni_data.columns}, inplace=True)",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "dataframe methods",
                    "from dictionary to dataframe",
                    "loading up data with missing values",
                    "calculating the mean of a vector with nans"
                ]
            },
            {
                "code": "_BIN_SIZE = 5  # 5 nT\n\ndef predict_accuracy_histogram(model, x_test, y_test, bin_size=_BIN_SIZE):\n    \"\"\"Make predictions with the model and bin the differences.\"\"\"\n    y_predict = model.predict(x_test)\n    differences = (y_test - y_predict).ravel()\n    diff_min = differences.min()\n    diff_max = differences.max()\n    half_bin = bin_size / 2.  # Shift the bins by half a binsize so that they are centered on 0.\n    b_min = int(np.floor(diff_min / bin_size)) * bin_size - half_bin\n    b_max = int(np.ceil(diff_max / bin_size)) * bin_size + half_bin + 1\n    h_vals, bins = np.histogram(differences, np.arange(b_min, b_max, bin_size), density=False)\n\n    plot_bins = (bins[:-1].astype(float) + bins[1:]) / 2\n    h_vals = h_vals.astype(float)\n    h_vals /= len(differences)  # Normalize to frequency-per-bin\n    return plot_bins, h_vals",
                "true_label": "",
                "top5_preds": [
                    "check accuracy / score for a logistic classifier",
                    "test the model for accuracy",
                    "making predictions for the testing data",
                    "compute the mean absolute error of the predictions",
                    "function fit_and_predict"
                ]
            },
            {
                "code": "dsets = {}\ndsets_validate = {}\ninput_shapes = {}\nfor xxx in 'By', 'clock_angle':\n    dsets[xxx] = preprocessing.train_test_split(\n        omni_lo_res,\n        ['Bz', xxx, 'DynamicPressure'],\n        FIELDS_PREDICT,\n        n_points_behind=LOOK_BEHIND_SPAN,\n        n_points_ahead=LOOK_AHEAD_SPAN)\n\n    x_train, y_train, x_test, y_test = dsets[xxx]\n    dsets_validate[xxx] = x_train[-n_validate:], y_train[-n_validate:]\n    input_shapes[xxx] = (LOOK_BEHIND_SPAN, x_train.shape[2])",
                "true_label": "",
                "top5_preds": [
                    "helpers to read in dataset",
                    "import polynomial features from sklearn",
                    "traffic sign classification with keras",
                    "fit on training set",
                    "making predictions for the testing data"
                ]
            },
            {
                "code": "error_histogram = []\nfor m in recent_models:\n    dset = dsets_validate['By'] if 'By' in name else dsets_validate['clock_angle']\n    x_validate, y_validate = dset\n    plot_bins, error_counts = predict_accuracy_histogram(m, x_validate, y_validate)\n    sys.stdout.write('Predictions measured for %s\\n' % m.name)\n    sys.stdout.flush()\n    error_histogram.append((plot_bins, error_counts, m))",
                "true_label": "",
                "top5_preds": [
                    "check accuracy / score for a logistic classifier",
                    "function fit_and_predict",
                    "test the model for accuracy",
                    "using the predict functionality of statsmodels, predict the values for and",
                    "making predictions for the testing data"
                ]
            },
            {
                "code": "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(12, 8))\nloss[names[1::2]].plot(ax=ax[0], title='loss (clock angle)')\nval_loss[names[1::2]].plot(ax=ax[1], title='validation loss (clock angle)')",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "plot using matplotlib",
                    "matplotlib",
                    "plot using pandas plotting",
                    "pandas plotting"
                ]
            },
            {
                "code": "fig, ax = plt.subplots(nrows=6, ncols=2, figsize=(12, 12))\nfor i in range(0, 12, 2):\n    kwargs = dict(title='loss') if not i else dict()\n    loss[names[i:i+2]].plot(ax=ax[i//2, 0], **kwargs)\n    kwargs = dict(title='validation loss') if not i else dict()\n    val_loss[names[i:i+2]].plot(ax=ax[i//2, 1], **kwargs)",
                "true_label": "",
                "top5_preds": [
                    "plot using matplotlib",
                    "line plot with a dataframe",
                    "matplotlib",
                    "plotting in python",
                    "plot using pandas plotting"
                ]
            },
            {
                "code": "error_histogram = []\nfor m in recent_models:\n    dset = dsets['By'] if 'By' in name else dsets['clock_angle']\n    _, _, x_test, y_test = dset\n    plot_bins, error_counts = predict_accuracy_histogram(m, x_test, y_test)\n    sys.stdout.write('Predictions measured for %s\\n' % m.name)\n    sys.stdout.flush()\n    error_histogram.append((plot_bins, error_counts, m))",
                "true_label": "",
                "top5_preds": [
                    "predicting a categorical response",
                    "function fit_and_predict",
                    "using the predict functionality of statsmodels, predict the values for and",
                    "check accuracy / score for a logistic classifier",
                    "predictive distribution"
                ]
            }
        ],
        [
            {
                "code": "%cd '/Users/danielfriedman/Desktop/'",
                "true_label": "",
                "top5_preds": [
                    "formatting datetimes as strings",
                    "convert date to datetime format",
                    "running a local postgres database",
                    "convert binary to hexadecimal",
                    "equally spaced numbers on a grid"
                ]
            },
            {
                "code": "import pandas as pd \nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport warnings; warnings.filterwarnings('ignore')\n\n# options\nsns.set_palette(sns.color_palette('PuBu')[::-1])\nmypalette = sns.color_palette('PuBu')[::-1]; mypalette.append((.95,.92,.95))\npd.options.display.max_rows = 10\npd.options.display.max_columns = 100\n",
                "true_label": "",
                "top5_preds": [
                    "plot using matplotlib",
                    "matplotlib",
                    "plotting time series with pandas",
                    "plot using pandas plotting",
                    "plotting in python"
                ]
            },
            {
                "code": "df = pd.read_csv('VOTER_Survey_December16_Release1.csv')\ndf.head(3)\n",
                "true_label": "",
                "top5_preds": [
                    "loading a csv into a dataframe",
                    "convert date to datetime format",
                    "load table in pandas",
                    "importing data with pandas",
                    "select every row after a specific row"
                ]
            },
            {
                "code": "label = LE()\ngeneral_labeled = label.fit_transform(dems['2016_vote']).reshape(-1,1)\n\nenc = OHE()\nenc.fit(general_labeled)\ngeneral_encoded = enc.transform(general_labeled).toarray() \n\ngeneral_df = pd.DataFrame(general_encoded, dtype = 'int')\ngeneral_df = rename_one_hot(dems, '2016_vote', general_df, 'general_')\ndems = pd.concat([dems, general_df], axis = 1)\ndems.drop(['2016_vote'], axis = 1, inplace = True)",
                "true_label": "",
                "top5_preds": [
                    "transform categorical data into binary features",
                    "import polynomial features from sklearn",
                    "using logistic regression with categorical features",
                    "predicting a continuous response using linear regression",
                    "polynomial regression with sklearn"
                ]
            },
            {
                "code": "dems['race'][(dems['race'] != 'White') & (dems['race'] != 'Black') & (dems['race'] != 'Hispanic') & (dems['race'] != 'Asian')] = 'Other'\n\nrace = pd.concat([dems[['race']],target], axis = 1)\nrace = race.groupby(by = 'race').mean()\nrace.reset_index(inplace = True)\nrace.rename({'donor':'donation_percent'}, axis=1, inplace=True)\nrace.sort_values('donation_percent', inplace = True, ascending = False)\n\nplt.figure(figsize = (10,3))\nsns.barplot(data = race, x = 'race', y = 'donation_percent', palette = mypalette) \n\n# not super significant differences, but interesting enough to keep",
                "true_label": "",
                "top5_preds": [
                    "predicting a categorical response",
                    "convert categorical variables",
                    "create a one column dataframe with the values of a series",
                    "using pandas",
                    "create dataframe with given values"
                ]
            },
            {
                "code": "label = LE()\nrace_labeled = label.fit_transform(dems['race']).reshape(-1,1)\n\nenc = OHE()\nenc.fit(race_labeled)\nrace_encoded = enc.transform(race_labeled).toarray() \n\nrace_df = pd.DataFrame(race_encoded, dtype = 'int')\nrace_df = rename_one_hot(dems, 'race', race_df, 'race_')\ndems = pd.concat([dems, race_df], axis = 1)\ndems.drop(['race'], axis = 1, inplace = True)",
                "true_label": "",
                "top5_preds": [
                    "using logistic regression with categorical features",
                    "logistic regression using tensorflow",
                    "polynomial regression with sklearn",
                    "predicting a continuous response using linear regression",
                    "add intercept in logistic regression"
                ]
            },
            {
                "code": "# empstat/student\n\nstudent_rep = {'Full-time student':1, 'Part-time student':1, 'Not a student':0, 'nan':0}\ndems['student'].replace(student_rep, inplace = True)\ndems['empstat'][dems['student']==1] = 'Student'\n\nempstat_rep = {'Full-time employed':'employed', 'Retired':'retired', 'Part-time employed':'employed', 'Student':'student', \\\n               'Unemployed or temporarily on layoff':'unemp','Permanently disabled':'unemp','Self-employed':'employed',\\\n               'Homemaker':'unemp', 'Other':'nan'}\ndems['empstat'].replace(empstat_rep, inplace = True)\n\nempstat = pd.concat([dems[['empstat']],target], axis = 1)\nempstat = empstat.groupby(by = 'empstat').mean()\nempstat.reset_index(inplace = True)\nempstat.rename({'donor':'donation_percent'}, axis=1, inplace=True)\nempstat.sort_values('donation_percent', inplace = True, ascending = False)\n\nplt.figure(figsize = (10,3))\nsns.barplot(data = empstat, x = 'empstat', y = 'donation_percent', palette = mypalette) \n\n# decent differences - keeping \n",
                "true_label": "",
                "top5_preds": [
                    "convert data from string to float",
                    "line plot with a dataframe",
                    "using pandas",
                    "create dataframe with given values",
                    "pandas apply"
                ]
            },
            {
                "code": "label = LE()\nemp_labeled = label.fit_transform(dems['empstat']).reshape(-1,1)\n\nenc = OHE()\nenc.fit(emp_labeled)\nemp_encoded = enc.transform(emp_labeled).toarray() \n\nemp_df = pd.DataFrame(emp_encoded, dtype = 'int')\nemp_df = rename_one_hot(dems, 'empstat', emp_df, 'empstat_')\ndems = pd.concat([dems, emp_df], axis = 1)\ndems.drop(['empstat','student'], axis = 1, inplace = True)",
                "true_label": "",
                "top5_preds": [
                    "import polynomial features from sklearn",
                    "what is scikit learn?",
                    "linear regression with statsmodels and scikit learn",
                    "add intercept in logistic regression",
                    "using logistic regression with categorical features"
                ]
            },
            {
                "code": "religion_rep = {'Protestant':'Christian', 'Roman Catholic':'Christian','Agnostic':'agnostic/atheist', 'Nothing in particular':'none', 'Atheist':'agnostic/atheist', 'Something else':'other', 'Jewish':'Jewish' }\ndems['religion'].replace(religion_rep, inplace = True)\ndems['religion'][(dems['religion'] != 'Christian') & (dems['religion'] != 'none') & (dems['religion'] != 'Jewish') & (dems['religion'] != 'agnostic/atheist')]='other'\n\nreligion = pd.concat([dems[['religion']],target], axis = 1)\nreligion = religion.groupby(by = 'religion').mean()\nreligion.reset_index(inplace = True)\nreligion.rename({'donor':'donation_percent'}, axis=1, inplace=True)\nreligion.sort_values('donation_percent', inplace = True, ascending = False)\n\nplt.figure(figsize = (10,3))\nsns.barplot(data = religion, x = 'religion', y = 'donation_percent', palette = mypalette) \n\n# high variety - keep \n",
                "true_label": "",
                "top5_preds": [
                    "from dictionary to dataframe",
                    "relationships between dataframes",
                    "create dataframe with given values",
                    "convert data from string to float",
                    "line plot with a dataframe"
                ]
            },
            {
                "code": "label = LE()\nreligion_labeled = label.fit_transform(dems['religion']).reshape(-1,1)\n\nenc = OHE()\nenc.fit(religion_labeled)\nreligion_encoded = enc.transform(religion_labeled).toarray() \n\nreligion_df = pd.DataFrame(religion_encoded, dtype = 'int')\nreligion_df = rename_one_hot(dems, 'religion', religion_df, 'religion_')\ndems = pd.concat([dems, religion_df], axis = 1)\ndems.drop(['religion'], axis = 1, inplace = True)",
                "true_label": "",
                "top5_preds": [
                    "import polynomial features from sklearn",
                    "polynomial regression with sklearn",
                    "transform categorical data into binary features",
                    "using logistic regression with categorical features",
                    "what is scikit learn?"
                ]
            },
            {
                "code": "new_agenda = transform('agenda', 6)\n\ndems.drop([col for col in dems.columns if col.startswith('agenda_')], axis = 1, inplace = True)\ndems = pd.concat([dems, new_agenda], axis = 1)",
                "true_label": "",
                "top5_preds": [
                    "from dictionary to dataframe",
                    "load table in pandas",
                    "relationships between dataframes",
                    "import polynomial features from sklearn",
                    "importing data with pandas"
                ]
            },
            {
                "code": "ncomp_threshold('fav', start = .6, stop = .9, by = .01, startswith=False) # going with 3 ",
                "true_label": "",
                "top5_preds": [
                    "optimal value of k for dataset",
                    "using k nearest neighbor for imputing missing data",
                    "use sklearn kfold",
                    "predicting a categorical response",
                    "how well does kmeans perform?"
                ]
            },
            {
                "code": "new_fav = transform(subset = 'fav', n_components= 3, startswith = False)\n\ndems.drop([col for col in dems.columns if col.endswith('fav')], axis = 1, inplace = True)\ndems = pd.concat([dems, new_fav], axis = 1)",
                "true_label": "",
                "top5_preds": [
                    "import polynomial features from sklearn",
                    "relationships between dataframes",
                    "create a dataframe by joining series by column",
                    "load table in pandas",
                    "line plot with a dataframe"
                ]
            },
            {
                "code": "ncomp_threshold('rs', start = .6, stop = .9, by = .01, startswith=True) # going with 3 ",
                "true_label": "",
                "top5_preds": [
                    "optimal value of k for dataset",
                    "using k nearest neighbor for imputing missing data",
                    "equally spaced numbers on a grid",
                    "find maximum and the minimum value in a set",
                    "fitting an nth degree polynomial"
                ]
            },
            {
                "code": "new_rs = transform(subset = 'rs', n_components= 3, startswith = True)\n\ndems.drop([col for col in dems.columns if col.startswith('rs')], axis = 1, inplace = True)\ndems = pd.concat([dems, new_rs], axis = 1)",
                "true_label": "",
                "top5_preds": [
                    "from dictionary to dataframe",
                    "import polynomial features from sklearn",
                    "drop the rows with nan values",
                    "find data type of each column",
                    "load table in pandas"
                ]
            },
            {
                "code": "ncomp_threshold('ii', start = .6, stop = .9, by = .01, startswith=True) ",
                "true_label": "",
                "top5_preds": [
                    "optimal value of k for dataset",
                    "using k nearest neighbor for imputing missing data",
                    "fitting an nth degree polynomial",
                    "equally spaced numbers on a grid",
                    "check accuracy / score for a logistic classifier"
                ]
            },
            {
                "code": "ncomp_graph(ncomp('ii', 4, 14)) # going with 10 - almost 80% of the variation ",
                "true_label": "",
                "top5_preds": [
                    "counting triangles in a social network",
                    "create a graph",
                    "graph analysis",
                    "graph",
                    "predicting a categorical response"
                ]
            },
            {
                "code": "new_ii = transform(subset = 'ii', n_components= 10, startswith = True)\n\ndems.drop([col for col in dems.columns if col.startswith('ii')], axis = 1, inplace = True)\ndems = pd.concat([dems, new_ii], axis = 1)",
                "true_label": "",
                "top5_preds": [
                    "import polynomial features from sklearn",
                    "from dictionary to dataframe",
                    "create a one column dataframe with the values of a series",
                    "transform categorical data into binary features",
                    "relationships between dataframes"
                ]
            },
            {
                "code": "df['pid7_baseline'].value_counts()",
                "true_label": "",
                "top5_preds": [
                    "create a one column dataframe with the values of a series",
                    "line plot with a dataframe",
                    "in pandas",
                    "line plots show the trend of a numerical variable over time",
                    "loading a csv into a dataframe"
                ]
            },
            {
                "code": "party_replacement_list = {'Strong Democrat':0, 'Not very strong Democrat':1, 'Lean Democrat':2, 'Independent':3, 'Not sure':3}\ndf['pid7_baseline'] = df[['pid7_baseline']].replace(party_replacement_list) # replace strings with integer codes",
                "true_label": "",
                "top5_preds": [
                    "create dataframe with given values",
                    "sql LIKE operator",
                    "line plot with a dataframe",
                    "using a dataframe and matplotlib commands",
                    "create a one column dataframe with the values of a series"
                ]
            },
            {
                "code": "is_dem = pd.Series([type(row) == int for row in df['pid7_baseline']]) # list of integers\ndems_full = df.loc[is_dem] # only keep integers (dems or independents)\ndems_full.reset_index(inplace = True, drop = True)\ndems_full.shape # 4820 dems/moderates remaining\n",
                "true_label": "",
                "top5_preds": [
                    "find data type of each column",
                    "predicting a categorical response",
                    "dataframe methods",
                    "in pandas",
                    "convert categorical variables"
                ]
            },
            {
                "code": "plot = sns.catplot(x = 'pid7_baseline', data = dems_full, kind = 'count',height = 4, aspect=2)\nplot.set(xlabel = '')\nplot.set_xticklabels(party_replacement_list.keys())\n",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "plot using matplotlib",
                    "pandas plotting documentation",
                    "ploting out data with box plots",
                    "plot using pandas plotting"
                ]
            },
            {
                "code": "target = pd.DataFrame(((dems_full['polcontr_1_baseline'] == 'Yes') | (dems_full['polcontr_4_baseline'] == 'Yes')).astype(int), columns=['donor'])\n    # 0 = non-donor, 1 = donor",
                "true_label": "",
                "top5_preds": [
                    "predicting a categorical response",
                    "creating polynomial features",
                    "convert categorical variables",
                    "predicting a continuous response using linear regression",
                    "line plot with a dataframe"
                ]
            },
            {
                "code": "plot = sns.catplot(x = 'polcontr_1_baseline', hue = 'pid7_baseline', data = dems_full, kind = 'count',height = 4, aspect=2)\nplot.set(title = 'Distribution of donors by Dem Level', xlabel = 'Donor?')\nplot._legend.set_title('Dem Level')",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "visualize the distribution histogram of x using sns distplot",
                    "ploting out data with box plots",
                    "line plots show the trend of a numerical variable over time",
                    "predicting a categorical response"
                ]
            },
            {
                "code": "data_dict = {\n    \n    # voting \n    'pp_primary16_2016':'primary_vote',\n    'pp_demprim16_2016':'dem_primary_vote',\n    'pp_repprim16_2016':'rep_primary_vote', # fill into primary_vote\n    'votereg2_2016':'registered', # y/n whether registered\n    'turnout16_2016':'2016_turnout', # y/n whether voted in 2016 presidential\n    'presvote16post_2016':'2016_vote', # actual vote\n    \n    # favorability \n    'fav_trump_2016':'trump_fav', \n    'fav_ryan_2016':'ryan_fav', # Paul Ryan \n    'fav_obama_2016':'obama_fav',\n    'fav_hrc_2016':'clinton_fav',\n    'fav_sanders_2016':'sanders_fav', # Bernie\n    \n    # dem party opinions - how much should the party focus on the following \n    'PARTY_AGENDAS_D1_2016':'agenda_reduce_gov', # reduce size of government \n    'PARTY_AGENDAS_D2_2016':'agenda_create_jobs',\n    'PARTY_AGENDAS_D3_2016':'agenda_trade_deals',\n    'PARTY_AGENDAS_D4_2016':'agenda_health_care_reform',\n    'PARTY_AGENDAS_D5_2016':'agenda_reduce_taxes',\n    'PARTY_AGENDAS_D6_2016':'agenda_climate_change',\n    'PARTY_AGENDAS_D7_2016':'agenda_reduce_poverty',\n    'PARTY_AGENDAS_D8_2016':'agenda_restrict_imm', # restrict immigration\n    'PARTY_AGENDAS_D9_2016':'agenda_reduce_debt',\n    'PARTY_AGENDAS_D10_2016':'agenda_racial_equality',\n    'PARTY_AGENDAS_D11_2016':'agenda_combat_terrorism',\n    'PARTY_AGENDAS_D12_2016':'agenda_reduce_pc', # reduce political correctness\n    \n    # rigged systems questions (rs)\n    'RIGGED_SYSTEM_1_2016':'rs_elections_ineffective', # believes 'elections today don't matter; things stay the same'\n    'RIGGED_SYSTEM_2_2016':'rs_american_opportunity', # believes anyone can make it \n    'RIGGED_SYSTEM_3_2016':'rs_econ_helps_rich', # believes economy helps the wealthiest few\n    'RIGGED_SYSTEM_4_2016':'rs_media_lies',\n    'RIGGED_SYSTEM_5_2016':'rs_no_say', # believes 'people like me have no say in gov't'\n    \n    # outlook questions (attitude toward society, etc.)\n    'prouddem_2016':'outlook_american_pride', \n\n    # issue importance (ii)\n    'imiss_a_2016':'ii_crime', # how important is crime\n    'imiss_b_2016':'ii_econ', # economy\n    'imiss_c_2016':'ii_imm', # immigration\n    'imiss_d_2016':'ii_envir', # environment\n    'imiss_e_2016':'ii_religion', # religious liberty\n    'imiss_f_2016':'ii_terrorism',\n    'imiss_g_2016':'ii_gay_rights',\n    'imiss_h_2016':'ii_edu',\n    'imiss_i_2016':'ii_paid_leave',\n    'imiss_j_2016':'ii_health_care',\n    'imiss_k_2016':'ii_money_in_pol', \n    'imiss_l_2016':'ii_climate_change',\n    'imiss_m_2016':'ii_social_sec',\n    'imiss_n_2016':'ii_infrastructure',\n    'imiss_o_2016':'ii_jobs',\n    'imiss_p_2016':'ii_deficit',\n    'imiss_q_2016':'ii_poverty',\n    'imiss_r_2016':'ii_taxes',\n    'imiss_s_2016':'ii_medicare',\n    'imiss_t_2016':'ii_abortion',\n    'imiss_u_2016':'ii_gov_size', # size of gov't\n    'imiss_x_2016':'ii_race', # racial equality\n    'imiss_y_2016':'ii_gender', # gender equality\n    \n    # demographics\n    'race_baseline':'race',\n    'healthdk_0_baseline':'health_insurance', # 1 = has health insurance, 2 = doesn't \n    'birthyr_baseline':'birthyear',\n    'gender_baseline':'gender',\n    'educ_baseline':'educ_level',\n    'marstat_baseline':'marstat', # marital status\n    'child18_baseline':'parent',\n    'student2_baseline':'student',\n    'employstat2_baseline':'empstat', # employment status # have to account for students\n    'faminc_baseline':'income', # family income\n    'religpew_2016':'religion',\n    \n    # organization membership (for liberal organization belonging)\n    'org_membership_12_baseline':'org_now', \n    'org_membership_15_baseline':'org_nature_conservancy',\n    'org_membership_16_baseline':'org_peta',\n    'org_membership_18_baseline':'org_sierra_club',  \n    \n    # news following \n    'newsint2_baseline':'news_interest',\n    'localnewspaper_baseline':'newspaper', # how many days a week do you read the newspaper\n    'localeve_baseline':'evening_news', \n    'polinterest_baseline':'pol_interest', \n    'pol_know_baseline':'pol_knowledge',\n    \n    # registration and stuff\n    'partyreg_baseline':'registered_party', \n    'reliablevoter_baseline':'vote_freq', # how often they vote (lower is more frequent)\n    'straighttic_baseline':'vote_freq_dem', # how often they vote for democrats (lower is more frequently)\n    \n    # volunteering\n    'volunteerorg2_13_baseline':'pol_vol', # political volunteering -- keep this on its own\n    # make these into 'other_vol' -- volunteers in other civic/do-good groups\n    'volunteerorg2_3_baseline':'volunteerorg2_3_baseline',\n    'volunteerorg2_4_baseline':'volunteerorg2_4_baseline',\n    'volunteerorg2_5_baseline':'volunteerorg2_5_baseline',\n    'volunteerorg2_7_baseline':'volunteerorg2_7_baseline',\n    'volunteerorg2_8_baseline':'volunteerorg2_8_baseline',\n    'volunteerorg2_9_baseline':'volunteerorg2_9_baseline',\n    'volunteerorg2_10_baseline':'volunteerorg2_10_baseline',\n    'volunteerorg2_11_baseline':'volunteerorg2_11_baseline',\n    'volunteerorg2_12_baseline':'volunteerorg2_12_baseline',\n    'volunteerorg2_14_baseline':'volunteerorg2_14_baseline',\n        \n    # self-labels \n    'selfdescr_ccap_2_baseline':'selfdesc_socialist',\n    'selfdescr_ccap_3_baseline':'selfdesc_green',\n    'selfdescr_ccap_4_baseline':'selfdesc_envi', # environmentalist\n    'selfdescr_ccap_5_baseline':'selfdesc_liberal',\n    'selfdescr_ccap_6_baseline':'selfdesc_moderate',\n    \n    \n    # political_knowledge (pk) \n    # use to calculate pk_score \n    'pk_ideo_baseline':'pk_ideo_baseline', # Rep is correct\n    'pk_house_baseline':'pk_house_baseline', # Rep is correct\n    'pk_senate_baseline':'pk_senate_baseline', # Dem is correct\n    'pk_HMinL_baseline':'pk_HMinL_baseline', # Representative is correct\n    'pk_Speaker_baseline':'pk_Speaker_baseline', # Representative is correct\n    'pk_HMajL_baseline':'pk_HMajL_baseline', # Representative is right\n    'pk_SMinL_baseline':'pk_SMinL_baseline', # Senator is right\n    'pk_SMajL_baseline':'pk_SMajL_baseline', # Senator is right\n    'pk_SCJ_baseline':'pk_SCJ_baseline' # Judge is right\n    }",
                "true_label": "",
                "top5_preds": [
                    "data given as a dictionary",
                    "create a data dictionary",
                    "create a dictionary with the data",
                    "from dictionary to dataframe",
                    "get a positive integer from a user"
                ]
            },
            {
                "code": "dems = pd.DataFrame(data = dems_full[list(data_dict.keys())])\ndems.columns = list(data_dict.values())\ndems.head(3)",
                "true_label": "",
                "top5_preds": [
                    "from dictionary to dataframe",
                    "load table in pandas",
                    "loading a csv into a dataframe",
                    "data given as a dictionary",
                    "find data type of each column"
                ]
            },
            {
                "code": "dems = dems.fillna('nan')",
                "true_label": "",
                "top5_preds": [
                    "integrating datetime tools with pandas for time series",
                    "import polynomial features from sklearn",
                    "computing the covariance when there are nan s",
                    "calculating the mean of a vector with nans",
                    "predicting a categorical response"
                ]
            },
            {
                "code": "replacements_template = {'Yes':1, 'No':0}\n\n# registered\nregistered_replacements = replacements_template.copy()\nregistered_replacements.update({\"Don't know\":0})\ndems['registered'].replace(registered_replacements, inplace = True)\n\n# 2016 turnout\nturnout_rep = replacements_template.copy()\nturnout_rep.update({'nan':0})\ndems['2016_turnout'].replace(turnout_rep, inplace = True)\n\n# favorability\nfav_columns = [col for col in dems.columns if col[-4:]=='_fav']\nfor col in fav_columns:\n    dems[col][(dems[col]=='Don\\'t know') | (dems[col]=='nan')]='none'\n\nfavorability_rep = {'Very unfavorable':1, 'Somewhat unfavorable':2, 'none':3, 'Somewhat favorable':4, 'Very favorable':5}\nfor col in fav_columns:\n    dems[col].replace(favorability_rep, inplace = True)\n\n# agenda\nagenda_columns = [col for col in dems.columns if col[:6]=='agenda']\nfor col in agenda_columns:\n    dems[col][dems[col]=='nan'] = 'About the same'\n\nagenda_rep = {'Much more':1, 'Somewhat more':2, 'About the same':3, 'Somewhat less':4, 'Much less':5}\nfor col in agenda_columns:\n    dems[col].replace(agenda_rep, inplace = True)\n    \n# rigged system\nrs_columns = [col for col in dems.columns if col[:2]=='rs']\nfor col in rs_columns:\n    dems[col][dems[col]=='nan'] = 'neither'\n\nrs_rep = {'Strongly agree':1, 'Agree':2, 'neither':3, 'Disagree':4, 'Strongly disagree':5}\nfor col in rs_columns:\n    dems[col].replace(rs_rep, inplace = True)\n\n# American pride\npride_rep = {'Very proud':1, 'Somewhat proud':2, 'Don\\'t know':3, 'nan':3, 'Not very proud':4, 'Not proud at all':5}\ndems['outlook_american_pride'].replace(pride_rep, inplace = True)\n\n## issue importance\nii_columns = [col for col in dems.columns if col[:2]=='ii']\n\nii_rep = {'Very important':1, 'Somewhat important':2, 'nan':3, 'Not very important':4, 'Unimportant':5}\nfor col in ii_columns:\n    dems[col].replace(ii_rep, inplace = True)\n\n# demographics\ndems['health_insurance'][dems['health_insurance']!='Yes'] = 0\ndems['health_insurance'][dems['health_insurance']=='Yes'] = 1\n\ndems['age'] = 2018-dems['birthyear']\ndems.drop('birthyear', axis = 1, inplace = True)\n\ndems['gender'] = dems['gender'].replace({'Male':1, 'Female':0})\ndems.rename({'gender':'male'}, axis = 1, inplace = True)\n\neduc_rep = {'No HS':1, 'High school graduate':2, 'Some college':3, '2-year':4, '4-year':5, 'Post-grad':6}\ndems['educ_level'] = dems['educ_level'].replace(educ_rep)\nmean_educ = int(dems['educ_level'][dems['educ_level'] != 'nan'].mean()) # intentionally rounding down \ndems['educ_level'][dems['educ_level']=='nan'] = mean_educ\n\ndems['ever_married'] = 0\ndems['ever_married'][(dems['marstat'] == 'Married') | (dems['marstat'] == 'Divorced') | (dems['marstat'] == 'Widowed')] = 1\ndems.drop('marstat', axis = 1, inplace = True)\n\nparent_rep = {'Yes':1, 'No':0, 'nan':0}\ndems['parent'].replace(parent_rep, inplace = True)\n\n# news interest \nnews_rep = {'Most of the time':1, 'Some of the time':2, 'Only now and then':3, 'Hardly at all':4, 'nan':4}\ndems['news_interest'].replace(news_rep, inplace = True)\n\n# newspaper frequency\nnewspaper_rep = {'none':0, 'one':1, 'two':2, 'three':3, 'four':4, 'five':5, 'six':6, 'everyday':7}\ndems['newspaper'].replace(newspaper_rep, inplace = True)\ndems['newspaper'][dems['newspaper'] == 'nan'] = dems['newspaper'][dems['newspaper']!='nan'].median()\n\n# evening news frequency\ndems['evening_news'].replace(newspaper_rep, inplace = True)\ndems['evening_news'][dems['evening_news']=='nan'] = dems['evening_news'][dems['evening_news']!='nan'].median()\n\n# political interest\npol_rep = {'Very much interested':1, 'Somewhat interested':2, 'Not much interested':3, 'Not sure':4, 'nan':4}\ndems['pol_interest'].replace(pol_rep, inplace = True)\n\n# registered democrat binary\ndems['registered_dem'] = 0\ndems['registered_dem'][dems['registered_party']=='Democrat'] = 1\ndems.drop('registered_party', axis = 1, inplace = True)\n\n# voting frequency\nvote_rep = {'Always':1, 'Nearly always':2, 'Part of the time':3, 'Seldom':4, 'nan':5}\ndems['vote_freq'].replace(vote_rep, inplace = True)\n\n# vote_freq_dem\nvote_dem_rep = {'Almost always vote for Democrats':1, 'Vote for both Democrats and Republicans':2, 'Almost always vote for Republicans':3, 'nan':2}\ndems['vote_freq_dem'].replace(vote_dem_rep, inplace = True)\n\n# political volunteering \ndems['pol_vol'].replace({'Yes':1, 'No':0}, inplace = True)\n\n# self descriptions\nselfdesclist = [col for col in dems.columns if col.startswith('selfdesc_')]\nfor var in selfdesclist:\n    dems[var].replace({'Yes':1, 'No':0}, inplace = True )",
                "true_label": "",
                "top5_preds": [
                    "from dictionary to dataframe",
                    "predicting a categorical response",
                    "get a positive integer from a user",
                    "remove null values from county, category, and category name",
                    "formatting datetimes as strings"
                ]
            },
            {
                "code": "from sklearn.preprocessing import OneHotEncoder as OHE, LabelEncoder as LE\n\ndef rename_one_hot(original_df, original_df_column, hot_df, preface):\n    col_list = []\n    col_names = list(original_df[original_df_column].unique())\n    col_names_indices = []\n    for name in col_names:\n        original_df_index = list(original_df[original_df_column]).index(name)\n        col_names_indices.append((name, original_df_index))\n\n    for candidate, row in col_names_indices:\n        col = list(hot_df.iloc[row,:]).index(1)\n        hot_df.rename({col:preface+candidate}, axis = 1, inplace = True)\n        \n    return(hot_df)",
                "true_label": "",
                "top5_preds": [
                    "from dictionary to dataframe",
                    "create a one column dataframe with the values of a series",
                    "line plot with a dataframe",
                    "use sklearn kfold",
                    "dataframe methods"
                ]
            },
            {
                "code": "answers = np.array('Republican Party; Republican Party; Democratic Party; Representative; Representative; Representative; Senator; Senator; Judge'.split('; '))\n\npk_score = []\nfor row in dems.index:\n    response = np.array(dems.loc[row, 'pk_ideo_baseline':'pk_SCJ_baseline'])\n    pk_score.append(sum(response==answers))\n\nold_pk_list = [col for col in dems.columns if col.startswith('pk_')]\ndems.drop(old_pk_list, axis = 1, inplace = True)\ndems.drop('pol_knowledge', axis =1, inplace = True)\n\ndems['pk_score'] = pk_score\n\n",
                "true_label": "",
                "top5_preds": [
                    "predicting a categorical response",
                    "find data type of each column",
                    "numpy",
                    "what is scikit learn?",
                    "line plot with a dataframe"
                ]
            },
            {
                "code": "vol_list = [col for col in dems.columns if col.startswith('volunteer')]\nvol_freq = []\nfor row in dems.index:\n    vol_freq.append(sum(dems[vol_list].loc[row,:]=='Yes'))\n\ndems['other_vol'] = vol_freq\ndems.drop(vol_list, axis = 1, inplace = True)\n",
                "true_label": "",
                "top5_preds": [
                    "create a one column dataframe with the values of a series",
                    "line plot with a dataframe",
                    "in pandas",
                    "find data type of each column",
                    "create dataframe with given values"
                ]
            },
            {
                "code": "orglist = [col for col in dems.columns if col[:4] == 'org_']\nliborg = []\nfor row in list(dems.index):\n    liborg.append(int(any(dems[orglist].loc[row] == 'Yes')))\n        \ndems['liborg'] = liborg\ndems.drop(orglist, axis = 1, inplace = True)\n",
                "true_label": "",
                "top5_preds": [
                    "find data type of each column",
                    "load table in pandas",
                    "importing data with numpy",
                    "importing data with pandas",
                    "import polynomial features from sklearn"
                ]
            },
            {
                "code": "# create train (those with known incomes) and test (those without)\n\nimpute_train = dems[dems['income'] != 'nan']\nimpute_train_y = dems['income'][dems['income'] != 'nan']\n\nimpute_vars = ['age', 'male','educ_level', 'ever_married','parent']+[col for col in impute_train.columns if col.startswith('religion')]+[col for col in impute_train.columns if col.startswith('empstat')]+[col for col in impute_train.columns if col.startswith('race')]\nimpute_train = impute_train[impute_vars]\n\n# training\nfrom sklearn.linear_model import LinearRegression as LR\nlm = LR()\nlm.fit(impute_train, impute_train_y)\n\n# predicting and filling into 'dems' \nimpute_df = dems[impute_vars]\ndems['income_pred'] = lm.predict(impute_df)\ndems['income'][dems['income'] == 'nan'] = dems['income_pred']\ndems.drop('income_pred', axis = 1, inplace = True)\ndems.head()\n",
                "true_label": "",
                "top5_preds": [
                    "import polynomial features from sklearn",
                    "what is scikit learn?",
                    "dataframe methods",
                    "convert categorical variables",
                    "load table in pandas"
                ]
            },
            {
                "code": "# For determining n_components\n\nfrom sklearn.decomposition import PCA\n\ndef ncomp(subset, nstart, nstop, startswith = True):\n    if (startswith == True):\n        cols = [col for col in dems.columns if col.startswith(subset)]\n    else:\n        cols = [col for col in dems.columns if col.endswith(subset)]    \n    df = dems[cols]\n    \n    l = []\n    for n in range(nstart, nstop+1):\n        pca = PCA(n_components = n)\n        pca.fit(df)\n        explained = sum(pca.explained_variance_ratio_)\n        l.append((n, explained))\n    \n    return(l)\n\ndef ncomp_graph(ncomp_results):\n    n = [i[0] for i in ncomp_results]\n    var = [i[1] for i in ncomp_results]\n    \n    sns.lineplot(n, var, palette='Blues').set(xlabel = 'n_components', ylabel = 'variance explained')\n    \ndef ncomp_threshold(subset, start, stop, by, startswith = True):\n    if (startswith == True):\n        cols = [col for col in dems.columns if col.startswith(subset)]\n    else:\n        cols = [col for col in dems.columns if col.endswith(subset)]\n    df = dems[cols]\n    \n    l = []\n    for percent in [round(i,2) for i in np.arange(start, stop, by)]:\n        pca = PCA(n_components=percent)\n        pca.fit(df)\n        n = len(pca.explained_variance_ratio_)\n        l.append((percent, n))\n        \n    df = pd.DataFrame(l, columns =['var_exp', 'n_comp']).T\n    \n    return(df)\n\n\n#####################################################################################################\n\n# For executing PCA\n\ndef transform(subset, n_components, startswith = True):\n    if (startswith == True):\n        cols = [col for col in dems.columns if col.startswith(subset)]\n    else:\n        cols = [col for col in dems.columns if col.endswith(subset)]\n    data = dems[cols]\n\n    pca = PCA(n_components=n_components)\n    df = pd.DataFrame(pca.fit_transform(data))\n    \n    df.columns = [subset+'_'+str(num) for num in range(1, n_components+1)]\n    return(df)\n",
                "true_label": "",
                "top5_preds": [
                    "import polynomial features from sklearn",
                    "shortcut principal component analysis in scikit learn",
                    "find data type of each column",
                    "function to compute principal component analysis",
                    "fit a polynomial"
                ]
            },
            {
                "code": "ncomp_graph(ncomp('agenda', 1, 10))",
                "true_label": "",
                "top5_preds": [
                    "tensorflow + keras",
                    "creating a tree diagram",
                    "counting triangles in a social network",
                    "what is scikit learn?",
                    "import polynomial features from sklearn"
                ]
            },
            {
                "code": "ncomp_threshold('agenda', start = .7, stop = .9, by = .01) # going with 6 ",
                "true_label": "",
                "top5_preds": [
                    "predicting a categorical response",
                    "using k nearest neighbor for imputing missing data",
                    "optimal value of k for dataset",
                    "use sklearn kfold",
                    "how well does kmeans perform?"
                ]
            },
            {
                "code": "ncomp_threshold('selfdesc', start = .6, stop = .9, by = .01, startswith=True)  # going with 3 again",
                "true_label": "",
                "top5_preds": [
                    "optimal value of k for dataset",
                    "using k nearest neighbor for imputing missing data",
                    "predicting a categorical response",
                    "check accuracy / score for a logistic classifier",
                    "shortcut principal component analysis in scikit learn"
                ]
            },
            {
                "code": "new_selfdesc = transform(subset = 'selfdesc', n_components= 3, startswith = True)\n\ndems.drop([col for col in dems.columns if col.startswith('selfdesc')], axis = 1, inplace = True)\ndems = pd.concat([dems, new_selfdesc], axis = 1)",
                "true_label": "",
                "top5_preds": [
                    "relationships between dataframes",
                    "import polynomial features from sklearn",
                    "from dictionary to dataframe",
                    "find data type of each column",
                    "load table in pandas"
                ]
            },
            {
                "code": "corr = pd.concat([dems, target], axis = 1).corr()[['donor']]\ncorr['abs'] = abs(np.array(corr['donor']))\ncorr.sort_values('abs', ascending = False, inplace=True)\ncorr.drop('abs', inplace = True, axis = 1)\ncorr = corr.iloc[1:,:]\ncorr.reset_index(inplace = True)\ncorr.rename({'donor':'corr','index':'var'}, axis = 1, inplace = 1)\n\nplt.figure(figsize=(18,3))\nsns.barplot(x = 'var', y = 'corr', data=corr[:10])",
                "true_label": "",
                "top5_preds": [
                    "predicting a categorical response",
                    "correlation analysis",
                    "shortcut principal component analysis in scikit learn",
                    "computing the covariance when there are nan s",
                    "relationships between dataframes"
                ]
            },
            {
                "code": "dems['income'][dems['income'] == 'Prefer not to say'] = 'nan'\ndems['income'][dems['income'] == 'Less than $10,000'] = '$0 - $9,999'\n\ninc = []\nfor item in dems['income']:\n    if item == 'nan':\n        inc.append(item)\n    else:\n        if len(item) == 17:\n            inc.append(int(str(item[1])))\n        else:\n            inc.append(int(str(item[1:3])))\n\ndems['income'] = inc",
                "true_label": "",
                "top5_preds": [
                    "predicting a categorical response",
                    "convert data from string to float",
                    "convert categorical variables",
                    "create a one column dataframe with the values of a series",
                    "create dataframe with given values"
                ]
            },
            {
                "code": "plt.figure(figsize=(18,3))\nsns.barplot(x = 'var', y = 'corr', data = corr[-10:])",
                "true_label": "",
                "top5_preds": [
                    "predicting a categorical response",
                    "plot using matplotlib",
                    "line plots show the trend of a numerical variable over time",
                    "matplotlib",
                    "using logistic regression instead"
                ]
            },
            {
                "code": "pd.crosstab(dems.outlook_american_pride, target.donor,  normalize = 'index') # random -- taking it out",
                "true_label": "",
                "top5_preds": [
                    "predicting a categorical response",
                    "line plots show the trend of a numerical variable over time",
                    "line plot with a dataframe",
                    "use numpy to generate an array of random numbers sampled from a standard normal distribution",
                    "ploting out data with box plots"
                ]
            },
            {
                "code": "pd.crosstab(dems.ever_married, target.donor,  normalize = 'index') # adds nothing -- taking it out",
                "true_label": "",
                "top5_preds": [
                    "relationships between dataframes",
                    "predicting a categorical response",
                    "line plots show the trend of a numerical variable over time",
                    "dataframe methods",
                    "line plot with a dataframe"
                ]
            },
            {
                "code": "pd.crosstab(dems.parent, target.donor,  normalize = 'index') # makes enough of a difference -- keeping it",
                "true_label": "",
                "top5_preds": [
                    "relationships between dataframes",
                    "predicting a categorical response",
                    "dataframe methods",
                    "line plots show the trend of a numerical variable over time",
                    "line plot with a dataframe"
                ]
            },
            {
                "code": "dems_remove = ['outlook_american_pride', 'ever_married']\ndems.drop(dems_remove, axis = 1, inplace = True)",
                "true_label": "",
                "top5_preds": [
                    "relationships between dataframes",
                    "from dictionary to dataframe",
                    "import polynomial features from sklearn",
                    "convert date to datetime format",
                    "load table in pandas"
                ]
            },
            {
                "code": "vol_list = [col for col in dems.columns if col.startswith('volunteer')]\nvol_freq = []\nfor row in dems.index:\n    vol_freq.append(sum(dems[vol_list].loc[row,:]=='Yes'))\n\ndems['other_vol'] = vol_freq\ndems.drop(vol_list, axis = 1, inplace = True)",
                "true_label": "",
                "top5_preds": [
                    "create a one column dataframe with the values of a series",
                    "line plot with a dataframe",
                    "in pandas",
                    "find data type of each column",
                    "create dataframe with given values"
                ]
            }
        ],
        [
            {
                "code": "import pandas as pd\nimport numpy as np\nfrom random import randint\nfrom datetime import datetime\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import neighbors\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.metrics import classification_report\nimport matplotlib.pyplot as plt",
                "true_label": "",
                "top5_preds": [
                    "import polynomial features from sklearn",
                    "polynomial regression with sklearn",
                    "what is scikit learn?",
                    "predicting a continuous response using linear regression",
                    "predicting a categorical response"
                ]
            },
            {
                "code": "def findNA(df):\n    df = df.replace(r'\\s+', np.nan, regex=True)\n    df = df.replace('-unknown-',np.nan, regex=False)\n    df = df.replace('Other/Unknown',np.nan, regex=False)\n    df = df.dropna(thresh=10) #Ignore the rows with majority Missing Value during Analysis\n    return df",
                "true_label": "",
                "top5_preds": [
                    "drop the rows with nan values",
                    "drop data points with missing data",
                    "drop nan values",
                    "find missing data",
                    "drop na values"
                ]
            },
            {
                "code": "def encodeDate(df):\n    df['date_account_created']=pd.to_datetime(df['date_account_created']).dt.dayofweek\n    df['date_first_booking']=pd.to_datetime(df['date_first_booking']).dt.dayofweek\n    return df",
                "true_label": "",
                "top5_preds": [
                    "transform the date column as a datetime type",
                    "convert date to datetime format",
                    "convert integer or float data",
                    "formatting datetimes as strings",
                    "convert columns"
                ]
            },
            {
                "code": "def weightedRandomImputation(df):\n    for col in df:\n        nan_count=df[col].isnull().sum()\n        #print(\"nan_count=:::\"+nan_count)\n        if col=='age':\n            df=handleOutlierAge(df)\n            \n        # For parameters other then age, compute their missing value using stratified methodology of missing value imputation    \n        if nan_count>0 and col!='age': \n            df_counts=df[col].value_counts() #Count columnwise repeated value\n            Total_minus_unknown = 0\n            Total_minus_unknown = len(df[col]) - len(df_counts) #Get unknown value count in a column\n            ratio_list=[]\n            for i in range(len(df_counts)):\n                ratio_list.append(float(df_counts[i])*100/float(Total_minus_unknown))  #Multiplying actual value with 100 and diviving it with unknown value count\n            min_ratio = min(ratio_list)  #Finding minimum value from ration_List\n            ratio_list = [int(x/min_ratio) for x in ratio_list] #Divide actual value with min_ratio\n            counts_list=df_counts.index.tolist() #Convert Weight to list\n            pairs = list(zip(ratio_list,counts_list)) #merge Weight with new min_ratio value\n            df[col]=df[col].apply(lambda x: weightedRandomHelper(pairs) if(pd.isnull(x)) else x)\n            # Creating bins for signup_flow parameter\n        if col=='signup_flow': \n            bins = [-1,5,10,15,20,28]\n            group_names = [0,1,2,3,4]\n            df['signup_flow_bins'] = pd.cut(df['signup_flow'], bins, labels=group_names)\n    return df",
                "true_label": "",
                "top5_preds": [
                    "dataframe methods",
                    "return a dataframe",
                    "find data type of each column",
                    "create a dataframe",
                    "summarize the dataframe"
                ]
            },
            {
                "code": "def weightedRandomHelper(pairs):  \n    total = sum(pair[0] for pair in pairs)\n    r = randint(1, total)\n    for (weight, value) in pairs:\n        r -= weight\n        if r <= 0: return value",
                "true_label": "",
                "top5_preds": [
                    "alternate uniform distribution",
                    "likelihood of the binomial distribution",
                    "pair plot",
                    "get a positive integer from a user",
                    "find maximum and the minimum value in a set"
                ]
            },
            {
                "code": "def handleOutlierAge(df):\n    df['age']=df['age'].apply(lambda x: datetime.now().year-x if x>1900 else x)\n    \n    #Valid age range between 14 to 90 as per data, otherwise check if its outlier or not\n    df['age']=df['age'].apply(lambda x: x if 14<=x<=90 else np.nan)     \n    mean = df['age'].mean()\n    mean = int(mean)\n    df['age']=df['age'].apply(lambda x: mean if np.isnan(x) else x) \n    return df",
                "true_label": "",
                "top5_preds": [
                    "removing outliers",
                    "drop data points with missing data",
                    "credible interval vs confidence interval",
                    "transform the date column as a datetime type",
                    "when arithmetic operations are performed between differently indexed time series pandas will automatically align on dates"
                ]
            },
            {
                "code": "df = pd.read_csv('train_users_2.csv')   #load data\n\nprint(\"Doing Preprocessing\")\nprint(\"Handling Missing Values\")\ndf = findNA(df)\noriginal_data  = df.copy()\noriginal_data=encodeDate(original_data)   #convert date to the day of the week with Monday=0, Sunday=6\noriginal_data=weightedRandomImputation(original_data) # Missing Value Imputation\n\ndf,df_test = train_test_split( df, test_size=0.3, stratify=df['country_destination'])\n\ndf=encodeDate(df)   #convert date to the day of the week with Monday=0, Sunday=6\ndf=weightedRandomImputation(df) # Missing Value Imputation\n\n#preprocess of test\ndf_test = encodeDate(df_test)\ndf_test = weightedRandomImputation(df_test)",
                "true_label": "",
                "top5_preds": [
                    "transform the date column as a datetime type",
                    "importing data with pandas",
                    "from dictionary to dataframe",
                    "integrating datetime tools with pandas for time series",
                    "in pandas"
                ]
            }
        ],
        [
            {
                "code": "import numpy as np\nimport pandas as pd\nimport os\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import confusion_matrix\n\nimport featuretools as ft\n\nimport utils as utils\n\n%matplotlib inline",
                "true_label": "",
                "top5_preds": [
                    "import polynomial features from sklearn",
                    "polynomial regression with sklearn",
                    "what is scikit learn?",
                    "scikit learn",
                    "use sklearn kfold"
                ]
            },
            {
                "code": "DATA_DIR = os.path.join(os.getcwd(),\"data/olympic_games_data\")\nes = utils.load_entityset(data_dir=DATA_DIR)\n\n# Load a pre-made labels table for supervised learning\nlabel_file = os.path.join(DATA_DIR, \"num_medals_by_country_labels.csv\")\nlabel_df = pd.read_csv(label_file,\n                       parse_dates=['Olympics Date'],\n                       encoding='utf-8',\n                       usecols=['Number of Medals', 'Olympics Date', 'Country'])\nlabel_df.sort_values(['Olympics Date', 'Country'], inplace=True)",
                "true_label": "",
                "top5_preds": [
                    "load table in pandas",
                    "import polynomial features from sklearn",
                    "import data",
                    "import the dataset",
                    "load in data sets for visualization examples"
                ]
            },
            {
                "code": "es.plot()",
                "true_label": "",
                "top5_preds": [
                    "create an array of linearly spaced points",
                    "line plot with a dataframe",
                    "equally spaced numbers on a grid",
                    "plotting time series with pandas",
                    "plot using matplotlib"
                ]
            },
            {
                "code": "# Make a new label for binary classification\ndates = label_df['Olympics Date']\nlabels = label_df['Number of Medals']\ny_binary = (labels >= 10).values",
                "true_label": "",
                "top5_preds": [
                    "predicting a categorical response",
                    "transform categorical data into binary features",
                    "using the classify function",
                    "using logistic regression with categorical features",
                    "integrating datetime tools with pandas for time series"
                ]
            },
            {
                "code": "cutoff_times = label_df[['Country', 'Olympics Date']].rename(columns={'Country': 'Code'})\ncutoff_times.tail()",
                "true_label": "",
                "top5_preds": [
                    "create a dataframe by joining series by column",
                    "load table in pandas",
                    "plotting time series with pandas",
                    "create a one column dataframe with the values of a series",
                    "select every row after a specific row"
                ]
            },
            {
                "code": "agg_primitives = ['Sum', 'Std', 'Max', 'Min', 'Mean', \n                  'Count', 'Percent_True', 'Num_Unique', \n                  'Mode', 'Trend', 'Skew']\n\nfeature_matrix, features = ft.dfs(\n    entityset=es,\n    target_entity=\"countries\",\n    trans_primitives=[],\n    agg_primitives=agg_primitives,\n    max_depth=3,\n    cutoff_time=cutoff_times,\n    verbose=True\n)\n\nprint(\"{} features generated\".format(len(features)))",
                "true_label": "",
                "top5_preds": [
                    "transform categorical data into binary features",
                    "import polynomial features from sklearn",
                    "find data type of each column",
                    "dataframe methods",
                    "calculate and store features in database"
                ]
            },
            {
                "code": "features[-10:]",
                "true_label": "",
                "top5_preds": [
                    "predicting a continuous response using linear regression",
                    "range of feature",
                    "equally spaced numbers on a grid",
                    "numpy",
                    "what is scikit learn?"
                ]
            },
            {
                "code": "feature_matrix_encoded, features_encoded = ft.encode_features(feature_matrix, features)\n\npipeline_preprocessing = [(\"imputer\",\n                           SimpleImputer()),\n                          (\"scaler\", RobustScaler(with_centering=True))]\nfeature_matrix_encoded.tail()",
                "true_label": "",
                "top5_preds": [
                    "import polynomial features from sklearn",
                    "calculate and store features in database",
                    "creating polynomial features",
                    "transform categorical data into binary features",
                    "classification with a cnn"
                ]
            },
            {
                "code": "splitter = utils.TimeSeriesSplitByDate(dates=dates, earliest_date=pd.Timestamp('1/1/1960'))\nX = feature_matrix_encoded.values\n\nrf_clf = RandomForestClassifier(n_estimators=1000, n_jobs=-1)\npipeline = Pipeline(pipeline_preprocessing + [('rf_clf', rf_clf)])\nbinary_scores = utils.fit_and_score(X, y_binary, splitter, pipeline, _type='classification')\n\"Average AUC score is {} with standard dev {}\".format(\n        round(binary_scores['roc_auc'].mean(), 3),\n        round(np.std(binary_scores['roc_auc']), 3)\n)",
                "true_label": "",
                "top5_preds": [
                    "polynomial regression with sklearn",
                    "import polynomial features from sklearn",
                    "transform categorical data into binary features",
                    "using logistic regression with categorical features",
                    "what is scikit learn?"
                ]
            },
            {
                "code": "binary_scores.set_index('Olympics Year')['roc_auc'].plot(title='AUC vs. Olympics Year')",
                "true_label": "",
                "top5_preds": [
                    "integrating datetime tools with pandas for time series",
                    "plotting time series with pandas",
                    "predicting a categorical response",
                    "create a one column dataframe with the values of a series",
                    "line plot with a dataframe"
                ]
            },
            {
                "code": "# 1984 = 5th split\nsplit, year = 5, '1984'\ntrain, test = splitter.split(X, y_binary)[split]\npipeline.fit(X[train], y_binary[train])\ny_pred = pipeline.predict(X[test])\ncm = confusion_matrix(y_binary[test], y_pred)\nutils.plot_confusion_matrix(cm, ['Won < 10 Medals', 'Won >= 10 Medals'], title=year)\n",
                "true_label": "",
                "top5_preds": [
                    "predicting a categorical response",
                    "using the classify function",
                    "sentiment classification & how",
                    "using logistic regression with categorical features",
                    "fit a polynomial"
                ]
            },
            {
                "code": "# 2004 = 10th split\nsplit, year = 10, '2004'\ntrain, test = splitter.split(X, y_binary)[split]\npipeline.fit(X[train], y_binary[train])\ny_pred = pipeline.predict(X[test])\ncm = confusion_matrix(y_binary[test], y_pred)\nutils.plot_confusion_matrix(cm, ['Won < 10 Medals', 'Won >= 10 Medals'], title=year)",
                "true_label": "",
                "top5_preds": [
                    "predicting a categorical response",
                    "using the classify function",
                    "sentiment classification & how",
                    "fit a polynomial",
                    "using logistic regression with categorical features"
                ]
            },
            {
                "code": "# Get feature importances for every year\nfeature_imp = utils.get_feature_importances(pipeline, \n                                            feature_matrix_encoded, \n                                            (labels >= 10), splitter)",
                "true_label": "",
                "top5_preds": [
                    "calculate and store features in database",
                    "download and inspect the twitter samples dataset",
                    "import the dataset",
                    "import polynomial features from sklearn",
                    "import data"
                ]
            },
            {
                "code": "# Show 10 most important features for 1984\ntest_date = pd.Timestamp('6/29/1984')\ndisplay(feature_imp[test_date].iloc[:5].reset_index(drop=True))",
                "true_label": "",
                "top5_preds": [
                    "integrating datetime tools with pandas for time series",
                    "plotting time series with pandas",
                    "line plots show the trend of a numerical variable over time",
                    "working with pandas series indexed by datetime",
                    "convert date to datetime format"
                ]
            },
            {
                "code": "# Save output files\n\nimport os\n\ntry:\n    os.mkdir(\"output\")\nexcept:\n    pass\n\nfeature_matrix_encoded.to_csv('output/feature_matrix_encoded.csv', encoding='utf-8')\ncutoff_times.to_csv('output/cutoff_times.csv', encoding='utf-8')",
                "true_label": "",
                "top5_preds": [
                    "reading and writing csv files",
                    "importing data with numpy",
                    "convert text data into vector",
                    "reading and writing binary files",
                    "convert list to numpy array"
                ]
            }
        ],
        [
            {
                "code": "import numpy as np\nimport pandas as pd",
                "true_label": "",
                "top5_preds": [
                    "equally spaced numbers on a grid",
                    "ridge regression with polynomial features on a grid",
                    "numpy",
                    "import polynomial features from sklearn",
                    "line plot with a dataframe"
                ]
            },
            {
                "code": "college = pd.read_csv(\"College.csv\")",
                "true_label": "",
                "top5_preds": [
                    "loading a csv into a dataframe",
                    "importing data with pandas",
                    "importing data with numpy",
                    "load table in pandas",
                    "from dictionary to dataframe"
                ]
            },
            {
                "code": "college[0:5]",
                "true_label": "",
                "top5_preds": [
                    "python data type list",
                    "select every row after a specific row",
                    "get a positive integer from a user",
                    "convert text data into vector",
                    "importing data with numpy"
                ]
            },
            {
                "code": "college = college.rename(columns={'Unnamed: 0': 'Name'})",
                "true_label": "",
                "top5_preds": [
                    "sqlalchemy, sqlite, and dates",
                    "from dictionary to dataframe",
                    "load table in pandas",
                    "relationships between dataframes",
                    "import polynomial features from sklearn"
                ]
            },
            {
                "code": "college = college.set_index('Name')\ncollege[0:5]",
                "true_label": "",
                "top5_preds": [
                    "select every row after a specific row",
                    "load table in pandas",
                    "working with pandas series indexed by datetime",
                    "importing data with pandas",
                    "loading a csv into a dataframe"
                ]
            },
            {
                "code": "college.describe()",
                "true_label": "",
                "top5_preds": [
                    "load table in pandas",
                    "accessing databases via web apis",
                    "import polynomial features from sklearn",
                    "formatting datetimes as strings",
                    "predicting a categorical response"
                ]
            },
            {
                "code": "%matplotlib inline\nimport seaborn as sb\n\nsb.pairplot(college[college.columns[0:10]], hue=\"Private\")",
                "true_label": "",
                "top5_preds": [
                    "pandas plotting",
                    "plotting time series with pandas",
                    "plot using matplotlib",
                    "plot using pandas plotting",
                    "using a dataframe and matplotlib commands"
                ]
            },
            {
                "code": "sb.boxplot(x=college['Private'], y=college['Outstate'], data=college, order=[\"No\", \"Yes\"])",
                "true_label": "",
                "top5_preds": [
                    "ploting out data with box plots",
                    "using a dataframe and matplotlib commands",
                    "plotting time series with pandas",
                    "ridge regression with one predictor on a grid",
                    "load table in pandas"
                ]
            },
            {
                "code": "college['Elite'] = pd.Series(\"No\", index=college.index)\n#Elite = [\"No\"] * college.shape[0]\n#e = college.loc[college['Top10perc'] > 50]\ncollege.loc[college['Top10perc'] > 50, 'Elite'] = 'Yes'\ncollege['Elite'] = college['Elite'].astype('category')\ncollege.describe()",
                "true_label": "",
                "top5_preds": [
                    "convert categorical variables",
                    "predicting a categorical response",
                    "find data type of each column",
                    "find all by term in field in case insensitive way",
                    "change type of column"
                ]
            },
            {
                "code": "sb.boxplot(x=college['Elite'], y=college['Outstate'], data=college, order=[\"No\", \"Yes\"])",
                "true_label": "",
                "top5_preds": [
                    "ploting out data with box plots",
                    "using a dataframe and matplotlib commands",
                    "plotting time series with pandas",
                    "ridge regression with one predictor on a grid",
                    "load table in pandas"
                ]
            },
            {
                "code": "import seaborn as sb\n\nsb.pairplot(college[college.columns[0:10]], hue=\"Private\")",
                "true_label": "",
                "top5_preds": [
                    "plotting time series with pandas",
                    "pandas plotting",
                    "use seaborn",
                    "line plot with a dataframe",
                    "plot using pandas plotting"
                ]
            }
        ],
        [
            {
                "code": "from __future__ import print_function\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\n\nfrom torch.autograd import Variable\n\nfrom torchvision import transforms, datasets\n\nimport numpy as np\n\nfrom tqdm import tqdm\n\nimport sys",
                "true_label": "",
                "top5_preds": [
                    "import polynomial features from sklearn",
                    "tensorflow + keras",
                    "polynomial regression with sklearn",
                    "what is scikit learn?",
                    "scipy"
                ]
            },
            {
                "code": "data_path = \"data/mnist/raw\"\nbatch_size = 128\n\ntransform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize([0.5], [1.0])\n])\n\ntrain_loader = torch.utils.data.DataLoader(\n    datasets.MNIST(data_path, train=True, download=True, transform=transform),\n    batch_size=batch_size, shuffle=True)\n\ntest_loader = torch.utils.data.DataLoader(\n    datasets.MNIST(data_path, train=False, download=True, transform=transform),\n    batch_size=batch_size, shuffle=True)",
                "true_label": "",
                "top5_preds": [
                    "tensorflow + keras",
                    "logistic regression using tensorflow",
                    "import polynomial features from sklearn",
                    "polynomial regression with sklearn",
                    "load table in pandas"
                ]
            },
            {
                "code": "class LeNet5(nn.Module):\n\n    def __init__(self):\n        super(LeNet5, self).__init__()\n        \n        self.conv = nn.Sequential(\n            nn.Conv2d(1, 6, 5, 1, 2),\n            nn.Tanh(),\n            nn.MaxPool2d(2),\n            nn.Conv2d(6, 16, 5, 1, 0),\n            nn.Tanh(),\n            nn.MaxPool2d(2)\n        )\n        \n        self.fc = nn.Sequential(\n            nn.Linear(16 * 5 * 5, 120),\n            nn.Tanh(),\n            nn.Linear(120, 84),\n            nn.Tanh(),\n            nn.Linear(84, 10),\n            nn.LogSoftmax(dim=1)\n        )\n\n    def forward(self, x):\n        x = self.conv(x)\n        x = x.view(-1, 16 * 5 * 5)\n        x = self.fc(x)\n        return x",
                "true_label": "",
                "top5_preds": [
                    "simple convolutional neural network",
                    "train the network",
                    "the scikit learn interface",
                    "training the network",
                    "classification with a cnn"
                ]
            },
            {
                "code": "def initialize_weights(m):\n    if isinstance(m, nn.Linear) or isinstance(m, nn.Conv2d):\n        nn.init.kaiming_uniform_(m.weight, a=0, mode=\"fan_in\")",
                "true_label": "",
                "top5_preds": [
                    "create the vectorizer",
                    "resampling with weights",
                    "train the network",
                    "the scikit learn interface",
                    "create median, unweighted mean stacks using a weighting function"
                ]
            }
        ],
        [
            {
                "code": "from __future__ import print_function\nimport numpy as np\nimport tensorflow as tf\nimport time\nimport os\nfrom six.moves import cPickle\nfrom simple_model import Model\nimport codecs\nimport collections\nimport argparse",
                "true_label": "",
                "top5_preds": [
                    "tensorflow + keras",
                    "logistic regression using tensorflow",
                    "polynomial regression with sklearn",
                    "what is scikit learn?",
                    "import polynomial features from sklearn"
                ]
            },
            {
                "code": "data_dir = '../author_data'\ninput_encoding = None \nlog_dir = 'logs'\nsave_dir = 'save' \nrnn_size = 256 \nnum_layers = 2 \nmodel = 'lstm' \nbatch_size = 50 \nseq_length = 25 \nnum_epochs = 2 \nsave_every = 1000 \ngrad_clip = 5. \nlearning_rate= 0.002\ndecay_rate = 0.97 \ngpu_mem = 0.666\ninit_from = None",
                "true_label": "",
                "top5_preds": [
                    "tensorflow + keras",
                    "import polynomial features from sklearn",
                    "optimal value of k for dataset",
                    "what is scikit learn?",
                    "logistic regression using tensorflow"
                ]
            },
            {
                "code": "input_file = os.path.join(data_dir, \"eap_train.txt\")\nvocab_file = os.path.join(data_dir, \"vocab.pkl\")\ntensor_file = os.path.join(data_dir, \"data.npy\")\nwith codecs.open(input_file, \"r\", encoding=None) as f:\n    data = f.read()\nx_text = data.split() #Split Sentences",
                "true_label": "",
                "top5_preds": [
                    "import polynomial features from sklearn",
                    "what is scikit learn?",
                    "numpy binary files npy, npz",
                    "load table in pandas",
                    "reading and writing binary files"
                ]
            },
            {
                "code": "# count the number of words\nword_counts = collections.Counter(x_text)\n\n# Mapping from index to word : that's the vocabulary\nvocabulary_inv = [x[0] for x in word_counts.most_common()]\nvocabulary_inv = list(sorted(vocabulary_inv))\n\n# Mapping from word to index\nvocab = {x: i for i, x in enumerate(vocabulary_inv)}\nwords = [x[0] for x in word_counts.most_common()]\nvocab_size = len(words)",
                "true_label": "",
                "top5_preds": [
                    "find the most common words",
                    "counting word frequency",
                    "create a list of all words",
                    "most common words",
                    "transforming text into numbers"
                ]
            },
            {
                "code": "with open(vocab_file, 'wb') as f:\n    cPickle.dump((words), f)",
                "true_label": "",
                "top5_preds": [
                    "implementing bag of words in scikit learn",
                    "create a list of all words",
                    "add string to list using append",
                    "what is scikit learn?",
                    "in a pickle"
                ]
            },
            {
                "code": "tensor = np.array(list(map(vocab.get, x_text)))\n\n# Save the data to data.npy\nnp.save(tensor_file, tensor)\n\nprint('tensor is:' + str(tensor))\nprint(\"It's shape: \" + str(np.shape(tensor)))",
                "true_label": "",
                "top5_preds": [
                    "convert text data into vector",
                    "numpy",
                    "what is scikit learn?",
                    "numpy binary files npy, npz",
                    "import polynomial features from sklearn"
                ]
            },
            {
                "code": "num_batches = int(tensor.size / (batch_size * seq_length))\nprint('Number of batches is: ' + str(num_batches))\ntensor = tensor[:num_batches * batch_size * seq_length]\nprint('The shape of the new tensor is: '+ str(np.shape(tensor)))\n\nxdata = tensor\nydata = np.copy(tensor)\nydata[:-1] = xdata[1:]\nydata[-1] = xdata[0]\nx_batches = np.split(xdata.reshape(batch_size, -1), num_batches, 1)\ny_batches = np.split(ydata.reshape(batch_size, -1), num_batches, 1)\n\npointer = 0",
                "true_label": "",
                "top5_preds": [
                    "tensorflow + keras",
                    "numpy",
                    "creating a simple numpy array",
                    "convert list to numpy array",
                    "polynomial regression with sklearn"
                ]
            },
            {
                "code": "with open(os.path.join(save_dir, 'words_vocab.pkl'), 'wb') as f:\n    cPickle.dump((words, vocab), f)",
                "true_label": "",
                "top5_preds": [
                    "implementing bag of words in scikit learn",
                    "in a pickle",
                    "what is scikit learn?",
                    "postgres sql lab",
                    "nltk to recognize a book"
                ]
            },
            {
                "code": "model = Model(data_dir,input_encoding,log_dir,save_dir,rnn_size,num_layers,model,batch_size,seq_length,num_epochs,save_every,grad_clip,learning_rate,decay_rate,gpu_mem,init_from, vocab_size)",
                "true_label": "",
                "top5_preds": [
                    "tensorflow + keras",
                    "logistic regression using tensorflow",
                    "training a sequential model",
                    "polynomial regression with sklearn",
                    "scikit learn 4 step modeling pattern"
                ]
            },
            {
                "code": "merged = tf.summary.merge_all()\ntrain_writer = tf.summary.FileWriter(log_dir)",
                "true_label": "",
                "top5_preds": [
                    "tensorflow + keras",
                    "tensorflow",
                    "logistic regression using tensorflow",
                    "what is scikit learn?",
                    "use sklearn kfold"
                ]
            },
            {
                "code": "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=gpu_mem)",
                "true_label": "",
                "top5_preds": [
                    "tensorflow + keras",
                    "cpu vs gpu",
                    "tensorflow",
                    "logistic regression using tensorflow",
                    "what is scikit learn?"
                ]
            }
        ],
        [
            {
                "code": "import pandas as pd\ncat_retained = pd.read_csv(\"/home/data/kaggle/csv_cat_cut1.csv\", nrows=100)",
                "true_label": "",
                "top5_preds": [
                    "optimal value of k for dataset",
                    "select every row after a specific row",
                    "predicting a categorical response",
                    "line plots show the trend of a numerical variable over time",
                    "what is scikit learn?"
                ]
            },
            {
                "code": "#cat_retained.drop('Id', axis=1, inplace=True)\ncat_retained.drop('Unnamed: 0', axis=1, inplace=True)\n\ncat_data_to_vectorize = cat_retained.fillna('Na')",
                "true_label": "",
                "top5_preds": [
                    "transform categorical data into binary features",
                    "from dictionary to dataframe",
                    "dataframe methods",
                    "drop data points with missing data",
                    "import polynomial features from sklearn"
                ]
            },
            {
                "code": "cat_retained.head()",
                "true_label": "",
                "top5_preds": [
                    "predicting a categorical response",
                    "predicting a continuous response using linear regression",
                    "join two dataframes along rows",
                    "import polynomial features from sklearn",
                    "create a dataframe by joining series by column"
                ]
            },
            {
                "code": "\ncat_data_to_vectorize = cat_data_to_vectorize.T.to_dict().values()",
                "true_label": "",
                "top5_preds": [
                    "from dictionary to dataframe",
                    "convert text data into vector",
                    "transform categorical data into binary features",
                    "import polynomial features from sklearn",
                    "numpy"
                ]
            }
        ],
        [
            {
                "code": "from utils import file_to_list\n\nromeo_juliet_raw = file_to_list(\"plays/romeo_and_juliet_entire_play.html\")\n\n# Showing the beggining\nfor line in romeo_juliet_raw[:10]:\n    print(line, end=\"\")",
                "true_label": "",
                "top5_preds": [
                    "read numbers until and print their mean and standard deviation without using a list",
                    "getting data from the internet",
                    "sum all the numbers in a list",
                    "retrieving data from html page",
                    "remove duplicates from a list"
                ]
            },
            {
                "code": "# Showing the middle portion\nfor line in romeo_juliet_raw[2992:3007]:\n    print(line, end=\"\")",
                "true_label": "",
                "top5_preds": [
                    "select every row after a specific row",
                    "read text file point",
                    "line plots show the trend of a numerical variable over time",
                    "formatting datetimes as strings",
                    "getting data from the internet"
                ]
            },
            {
                "code": "for line in romeo_juliet_raw[3315:3317]:\n    print(line, end=\"\")",
                "true_label": "",
                "top5_preds": [
                    "loading json in python",
                    "select every row after a specific row",
                    "formatting datetimes as strings",
                    "line plots show the trend of a numerical variable over time",
                    "convert date to datetime format"
                ]
            },
            {
                "code": "# in between dialogue\nfor line in romeo_juliet_raw[1778:1782]:\n    print(line, end=\"\")",
                "true_label": "",
                "top5_preds": [
                    "select every row after a specific row",
                    "formatting datetimes as strings",
                    "read text file point",
                    "convert date to datetime format",
                    "read numbers until and print their mean and standard deviation without using a list"
                ]
            },
            {
                "code": "# within a dialogue\nfor line in romeo_juliet_raw[3257:3273]:\n    print(line, end=\"\")",
                "true_label": "",
                "top5_preds": [
                    "select every row after a specific row",
                    "read text file point",
                    "loading json in python",
                    "formatting datetimes as strings",
                    "getting data from the internet"
                ]
            },
            {
                "code": "from mit_shakespeare_regex import matcher\n\nline1 = romeo_juliet_raw[1943]\nprint(line1)",
                "true_label": "",
                "top5_preds": [
                    "the re module in python",
                    "matching metacharacters literally",
                    "regex",
                    "formatting datetimes as strings",
                    "loading json in python"
                ]
            },
            {
                "code": "# Since line 1 is a piece of dialogue, matcher.dialogue should return an object when it searches the line\nmatcher.dialogue.search(line1)",
                "true_label": "",
                "top5_preds": [
                    "matching metacharacters literally",
                    "nltk to recognize a book",
                    "check accuracy / score for a logistic classifier",
                    "regex",
                    "polynomial regression with sklearn"
                ]
            },
            {
                "code": "# Since this line does not indicate which character is speaking, it should return None (so nothing)\nmatcher.character.search(line1)",
                "true_label": "",
                "top5_preds": [
                    "matching metacharacters literally",
                    "get a positive integer from a user",
                    "read text file point",
                    "getting data from the internet",
                    "exploring regex"
                ]
            },
            {
                "code": "# A line that matcher.character will match\nline2 = romeo_juliet_raw[1935]\nmatcher.character.search(line2)",
                "true_label": "",
                "top5_preds": [
                    "matching metacharacters literally",
                    "regex",
                    "exploring regex",
                    "formatting datetimes as strings",
                    "loading json in python"
                ]
            },
            {
                "code": "from utils import json_file_to_dict\n\ngender = json_file_to_dict(\"plays/romeo_and_juliet_entire_play_gender.json\")\nprint(gender)",
                "true_label": "",
                "top5_preds": [
                    "loading json in python",
                    "parse time and visibility from json",
                    "data given as a dictionary",
                    "convert a tuple to a dictionary",
                    "using json to find your location"
                ]
            },
            {
                "code": "from parse import get_speaking_characters\n\nspeaking = get_speaking_characters(romeo_juliet_raw, matcher.character)\nprint(speaking)",
                "true_label": "",
                "top5_preds": [
                    "matching metacharacters literally",
                    "the most famous quote in regex dom",
                    "get a positive integer from a user",
                    "loading json in python",
                    "what is a string?"
                ]
            },
            {
                "code": "from parse import parse_raw_text\n\nplay_lines = parse_raw_text(romeo_juliet_raw, speaking, matcher)\nfor line in play_lines[:20]:\n    print(line)",
                "true_label": "",
                "top5_preds": [
                    "sentiment analysis on movie review data",
                    "loading json in python",
                    "getting data from the internet",
                    "formatting datetimes as strings",
                    "read text file point"
                ]
            },
            {
                "code": "from process import process\n\nadj, act_scene_start_end = process(speaking, play_lines)\n\n# adj gives the line number where one character spoke in the precense of another. \n# Lets see all the times when romeo said something in the precense of Juliet.\nromeo_to_juliet = adj['ROMEO']['JULIET']\nprint(romeo_to_juliet)\nprint()\nprint(\"Number of times Romeo said something in the presence of Juliet :\", len(romeo_to_juliet))",
                "true_label": "",
                "top5_preds": [
                    "add edges in graph",
                    "using interact for animation with data",
                    "how to change the style of individual lines",
                    "get a positive integer from a user",
                    "importing code"
                ]
            },
            {
                "code": "# Exercise: Replace None with the correct numerical value\n\nprint(\"Number of times Juliet said something in the presence of Romeo :\", None)",
                "true_label": "",
                "top5_preds": [
                    "get a positive integer from a user",
                    "assign to a variable",
                    "check a list is empty or not",
                    "sum all the numbers in a list",
                    "detect the number of local variables declared in a function"
                ]
            },
            {
                "code": "# Gives the starting line and the ending line + 1 for each scene\nprint(act_scene_start_end)\nprint()\nprint(\"Number of scenes in Romeo and Juliet :\", len(act_scene_start_end))",
                "true_label": "",
                "top5_preds": [
                    "add edges in graph",
                    "sum all the numbers in a list",
                    "read numbers until and print their mean and standard deviation without using a list",
                    "line plots show the trend of a numerical variable over time",
                    "create a line plot"
                ]
            },
            {
                "code": "from analysis import create_graph\n\nadj_num = { speaker : { spoken : len(adj[speaker][spoken]) \n        for spoken in adj[speaker] } \n        for speaker in adj }\n# create_graph uses the network x library, which addition to doing network analysis, can also draw graphs.\ngraph = create_graph(adj_num)\n",
                "true_label": "",
                "top5_preds": [
                    "find the most common words",
                    "add edges in graph",
                    "graph analysis",
                    "counting triangles in a social network",
                    "import polynomial features from sklearn"
                ]
            },
            {
                "code": "from analysis import get_characters_by_importance\n\n# Important for page rank algorithmn\nreciprocal_graph = create_graph(adj_num, reciprocal=True)\n\ncharacters_by_importance = get_characters_by_importance(\n    play_lines, \n    speaking, \n    graph,\n    reciprocal_graph\n)\n\nprint(characters_by_importance)",
                "true_label": "",
                "top5_preds": [
                    "find the most common words",
                    "getting data from the internet",
                    "counting triangles in a social network",
                    "equally spaced numbers on a grid",
                    "import polynomial features from sklearn"
                ]
            },
            {
                "code": "# order of metrics [lines_by_character, out_degree, page_rank, betweenness]\nmetrics_weight = [0, 0, 1, 0] # Just using page rank\n\ncharacters_by_importance = get_characters_by_importance(\n    play_lines, \n    speaking, \n    graph,\n    reciprocal_graph,\n    metrics_weight=metrics_weight\n)\n\nprint(characters_by_importance)",
                "true_label": "",
                "top5_preds": [
                    "equally spaced numbers on a grid",
                    "find the most common words",
                    "predicting a categorical response",
                    "counting triangles in a social network",
                    "counting word frequency"
                ]
            },
            {
                "code": "from analysis import vocab_difference\n\ndiff = vocab_difference(play_lines, gender)\n\n# words frequented by gender 1\nprint(\"gender1\", diff[:25])\n\n# words frequented by gender 2\nprint(\"gender2\", diff[-25:])",
                "true_label": "",
                "top5_preds": [
                    "counting word frequency",
                    "find the most common words",
                    "read numbers until and print their mean and standard deviation without using a list",
                    "reverse digits in a number",
                    "remove duplicates from a list"
                ]
            },
            {
                "code": "from analysis import bechdel_test   \n\n# First we need to reset characters by importance\ncharacters_by_importance = get_characters_by_importance(\n    play_lines, \n    speaking, \n    graph,\n    reciprocal_graph\n)\n\nbechdel_scenes = bechdel_test(play_lines, characters_by_importance, adj,\n            gender, act_scene_start_end)\nprint(bechdel_scenes)\nprint(len(bechdel_scenes[0]))",
                "true_label": "",
                "top5_preds": [
                    "visualizing uncertainty",
                    "using interact for animation with data",
                    "line plots show the trend of a numerical variable over time",
                    "add edges in graph",
                    "plot past data"
                ]
            }
        ],
        [
            {
                "code": "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)",
                "true_label": "",
                "top5_preds": [
                    "what is scikit learn?",
                    "ridge regression with one predictor on a grid",
                    "fit on training",
                    "fit on training set",
                    "ridge regression with polynomial features on a grid"
                ]
            },
            {
                "code": "# some housekeeping\ninput_dim = X_train.shape[1]\noutput_dim = 1 # for regression",
                "true_label": "",
                "top5_preds": [
                    "tensorflow + keras",
                    "logistic regression using tensorflow",
                    "import polynomial features from sklearn",
                    "what is scikit learn?",
                    "classification with a cnn"
                ]
            },
            {
                "code": "learning_rate = 0.025\nnum_epochs = 100",
                "true_label": "",
                "top5_preds": [
                    "tensorflow + keras",
                    "logistic regression using tensorflow",
                    "what is scikit learn?",
                    "step by step guide of machine learning in python",
                    "polynomial regression with sklearn"
                ]
            },
            {
                "code": "model = Sequential()\n\nmodel.add(Dense(units = 32, input_dim = input_dim, activation = \"relu\") )\nmodel.add(Dense(units = 32, activation = \"relu\"))\nmodel.add(Dense(units = 32, activation = \"relu\")) \nmodel.add(Dense(units = output_dim, activation = \"relu\"))           ",
                "true_label": "",
                "top5_preds": [
                    "tensorflow + keras",
                    "logistic regression using tensorflow",
                    "import polynomial features from sklearn",
                    "tensorflow",
                    "build a vector of prediction from the trained model"
                ]
            },
            {
                "code": "model.compile(loss='mean_squared_error', optimizer=Adam(lr = learning_rate))",
                "true_label": "",
                "top5_preds": [
                    "tensorflow + keras",
                    "logistic regression using tensorflow",
                    "what is scikit learn?",
                    "linear regression with statsmodels and scikit learn",
                    "polynomial regression with sklearn"
                ]
            },
            {
                "code": "# number of parameters = num. features + bias\nmodel.summary()",
                "true_label": "",
                "top5_preds": [
                    "tensorflow + keras",
                    "what is scikit learn?",
                    "what is the number of observations in each dataset?",
                    "import polynomial features from sklearn",
                    "logistic regression using tensorflow"
                ]
            },
            {
                "code": "# we keep the losses in the history object, for later plotting\nhistory = model.fit(X_train, y_train, epochs = num_epochs, validation_split = 0.2, callbacks = [EarlyStopping(patience=2)])",
                "true_label": "",
                "top5_preds": [
                    "logistic regression using tensorflow",
                    "tensorflow + keras",
                    "fit a logistic regression model using statsmodels using logistic regression formula in patsy",
                    "fit on training",
                    "build a vector of prediction from the trained model"
                ]
            },
            {
                "code": "train_score = model.evaluate(X_train, y_train)\ntest_score = model.evaluate(X_test, y_test)\n\nprint(\"\\n\\nTraining cost: \", \"{:.4f}\".format(train_score))\nprint(\"\\nTest cost: \", \"{:.4f}\".format(test_score))",
                "true_label": "",
                "top5_preds": [
                    "test the model for accuracy",
                    "check accuracy / score for a logistic classifier",
                    "predicting on sample validation data",
                    "what is scikit learn?",
                    "fit a polynomial"
                ]
            },
            {
                "code": "plt.plot(history.history['loss'], 'c.')\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.show()",
                "true_label": "",
                "top5_preds": [
                    "plot using matplotlib",
                    "line plots show the trend of a numerical variable over time",
                    "using logistic regression instead",
                    "trend lines in pyplot",
                    "how to change the size of a plot"
                ]
            }
        ],
        [
            {
                "code": "%matplotlib inline\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style('whitegrid')\nsns.set_context('poster')\n\nimport sqlite3\nimport numpy as np\nfrom scipy.optimize import curve_fit",
                "true_label": "",
                "top5_preds": [
                    "plot using matplotlib",
                    "line plot with a dataframe",
                    "matplotlib",
                    "using a dataframe and matplotlib commands",
                    "fit a polynomial"
                ]
            },
            {
                "code": "connection = sqlite3.connect('shots.db')\ncursor = connection.cursor()\ncursor.execute(\"SELECT period FROM Shots WHERE period IS NOT NULL and \")\nperiods = cursor.fetchall()\ncursor.close()\nconnection.close()\n\nperiods = np.asarray(periods)\ngyration_frequency = 1. / periods\n\naxes = sns.distplot(gyration_frequency/1e3, axlabel=r'frequency [kHz]', color='purple', kde=False)\naxes.set_ylabel('shots')\nplt.show()",
                "true_label": "",
                "top5_preds": [
                    "formatting datetimes as strings",
                    "load table in pandas",
                    "reading in and sampling from the data",
                    "line plot with a dataframe",
                    "integrating datetime tools with pandas for time series"
                ]
            },
            {
                "code": "connection = sqlite3.connect('shots.db')\ncursor = connection.cursor()\ncursor.execute(\"SELECT fiducial_pre_crowbar_gyration_spectral_density FROM Shots WHERE fiducial_pre_crowbar_gyration_spectral_density IS NOT NULL\")\nspectral_density = cursor.fetchall()\ncursor.close()\nconnection.close()\n\nbins = np.logspace(-8, 0., 100)\n\nspectral_density = np.asarray(spectral_density)\nprint spectral_density.max()\nspectral_density = spectral_density / spectral_density.max() \n\naxes = sns.distplot(spectral_density, axlabel=r'normalized spectral density', color='purple', bins=bins, kde=False)\naxes.set_xscale('log')\naxes.set_ylabel('shots')\nplt.show()",
                "true_label": "",
                "top5_preds": [
                    "reading in and sampling from the data",
                    "postgres sql lab",
                    "running a local postgres database",
                    "load table in pandas",
                    "formatting datetimes as strings"
                ]
            },
            {
                "code": "def fit_func_gauss_poly(x, a0, a1, a2, a3, a4, a5):\n    z = (x - a1) / (np.sqrt(2)*a2)\n    y = a0 * np.exp(-z**2) + a3 + a4 * x + a5 * x**2\n    return y",
                "true_label": "",
                "top5_preds": [
                    "function fit_and_predict",
                    "fit a polynomial",
                    "fit",
                    "plot the function",
                    "fit the vectorizer and svd"
                ]
            },
            {
                "code": "def fit_func_pure_gauss(x, a0, a1, a2, a3):\n    z = (x - a1) / (np.sqrt(2)*a2)\n    y = a0 * np.exp(-z**2) + a3\n    return y",
                "true_label": "",
                "top5_preds": [
                    "function fit_and_predict",
                    "fit a polynomial",
                    "fit",
                    "solve equation for x",
                    "plot the function"
                ]
            },
            {
                "code": "bins=np.logspace(-8, 1, 10*8)",
                "true_label": "",
                "top5_preds": [
                    "likelihood of the binomial distribution",
                    "likelihood of the binomial",
                    "equally spaced numbers on a grid",
                    "create an array of linearly spaced points",
                    "line plots show the trend of a numerical variable over time"
                ]
            },
            {
                "code": "n, bins, patches = plt.hist(spectral_density, bins=np.logspace(-8, 1, 10*8))\naxes = plt.gca()\naxes.set_xscale('log')\nplt.xlim((1e-8, 1))\nplt.show()",
                "true_label": "",
                "top5_preds": [
                    "likelihood of the binomial distribution",
                    "likelihood of the binomial",
                    "log likelihood of the binomial",
                    "ploting out data with box plots",
                    "plot histogram"
                ]
            },
            {
                "code": "parameters, covariance = curve_fit(fit_func_pure_gauss, np.log(bins[:-1] + np.diff(bins)/2), n, p0=[250, -1, 1, 1e-3])",
                "true_label": "",
                "top5_preds": [
                    "fit a polynomial",
                    "ridge regression with one predictor on a grid",
                    "ridge regression with polynomial features on a grid",
                    "fitting an nth degree polynomial",
                    "likelihood of the binomial distribution"
                ]
            },
            {
                "code": "parameters",
                "true_label": "",
                "top5_preds": [
                    "strings as function arguments",
                    "fit a polynomial",
                    "equally spaced numbers on a grid",
                    "linear interpolation with vectorised functions",
                    "create an array of linearly spaced points"
                ]
            },
            {
                "code": "fit_func_pure_gauss(np.log(bins), *parameters)",
                "true_label": "",
                "top5_preds": [
                    "fit a polynomial",
                    "fit a logistic regression model using statsmodels using logistic regression formula in patsy",
                    "likelihood of the binomial distribution",
                    "using logistic regression instead",
                    "ridge regression with polynomial features on a grid"
                ]
            },
            {
                "code": "axes = sns.distplot(spectral_density, axlabel=r'normalized spectral power', color='purple', bins=bins, kde=False)\naxes.set_xscale('log')\naxes.set_xlabel(axes.get_xlabel(), fontsize=30)\naxes.set_ylabel('Shots', fontsize=30)\nplt.plot(bins, fit_func_pure_gauss(np.log(bins), *parameters), color='darkviolet')\nplt.tick_params(axis='both', which='major', labelsize=20)",
                "true_label": "",
                "top5_preds": [
                    "likelihood of the binomial distribution",
                    "ploting out data with box plots",
                    "visualize the distribution histogram of x using sns distplot",
                    "plot the distributions",
                    "line plot with a dataframe"
                ]
            },
            {
                "code": "connection = sqlite3.connect('shots.db')\ncursor = connection.cursor()\ncursor.execute(\"SELECT fiducial_pre_crowbar_gyration_spectral_density FROM Shots WHERE fiducial_pre_crowbar_gyration_spectral_density IS NOT NULL\")\nspectral_density = cursor.fetchall()\ncursor.close()\nconnection.close()\n\nbins = np.logspace(-8, 0., 100)\n\nspectral_density = np.asarray(spectral_density)\nspectral_density = spectral_density / spectral_density.max() \n\naxes = sns.distplot(spectral_density, axlabel=r'normalized spectral density', color='purple', bins=bins, kde=False)\naxes.set_xscale('log')\naxes.set_yscale('log')\naxes.set_ylabel('shots')\nplt.show()",
                "true_label": "",
                "top5_preds": [
                    "reading in and sampling from the data",
                    "postgres sql lab",
                    "running a local postgres database",
                    "load table in pandas",
                    "formatting datetimes as strings"
                ]
            },
            {
                "code": "connection = sqlite3.connect('shots.db')\ncursor = connection.cursor()\ncursor.execute(\"SELECT uncalibrated_integrated_fiducial_a_gyration_amplitude FROM Shots WHERE\" +\n\" (fiducial_pre_crowbar_gyration_spectral_density > 1.6e-7 and period IS NOT NULL)\")\namplitudes = cursor.fetchall()\ncursor.close()\nconnection.close()\n\namplitudes = np.asarray(amplitudes)\namplitudes = amplitudes / amplitudes.max()\n\naxes = sns.distplot(amplitudes, axlabel=r'normalized amplitudes', color='purple', kde=False)\nplt.tick_params(axis='both', which='major', labelsize=20)\naxes.set_xlabel(axes.get_xlabel(), fontsize=30)\naxes.set_ylabel('Shots', fontsize=30)",
                "true_label": "",
                "top5_preds": [
                    "reading in and sampling from the data",
                    "running a local postgres database",
                    "get a positive integer from a user",
                    "load table in pandas",
                    "formatting datetimes as strings"
                ]
            },
            {
                "code": "n, bins, patches = plt.hist(amplitudes, bins=60)",
                "true_label": "",
                "top5_preds": [
                    "ploting out data with box plots",
                    "plot histogram",
                    "trend lines in pyplot",
                    "likelihood of the binomial distribution",
                    "line plots show the trend of a numerical variable over time"
                ]
            },
            {
                "code": "from scipy.stats import truncnorm",
                "true_label": "",
                "top5_preds": [
                    "the norm of a vector",
                    "use numpy to generate an array of random numbers sampled from a standard normal distribution",
                    "equally spaced numbers on a grid",
                    "scipy",
                    "calculating the mean of a vector with nans"
                ]
            },
            {
                "code": "amplitudes.mean()",
                "true_label": "",
                "top5_preds": [
                    "calculating the mean of a vector with nans",
                    "create an array of linearly spaced points",
                    "numpy",
                    "importing data with numpy",
                    "use numpy to generate an array of random numbers sampled from a standard normal distribution"
                ]
            },
            {
                "code": "amplitudes.std()",
                "true_label": "",
                "top5_preds": [
                    "use numpy to generate an array of random numbers sampled from a standard normal distribution",
                    "numpy",
                    "create an array of linearly spaced points",
                    "line plots show the trend of a numerical variable over time",
                    "equally spaced numbers on a grid"
                ]
            },
            {
                "code": "parameters, covariance = curve_fit(fit_func_pure_gauss, bins[:-1] + np.diff(bins)/2, n, p0=[230, 0.2, 0.08, 0.1])",
                "true_label": "",
                "top5_preds": [
                    "fit a polynomial",
                    "ridge regression with one predictor on a grid",
                    "ridge regression with polynomial features on a grid",
                    "fitting an nth degree polynomial",
                    "fit"
                ]
            },
            {
                "code": "axes = sns.distplot(amplitudes, axlabel=r'normalized amplitudes', color='purple', kde=False)\nplt.tick_params(axis='both', which='major', labelsize=20)\naxes.set_xlabel(axes.get_xlabel(), fontsize=30)\naxes.set_ylabel('Shots', fontsize=30)\nplt.plot(bins, fit_func_pure_gauss(bins, *parameters), color='darkviolet')",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "equally spaced numbers on a grid",
                    "ploting out data with box plots",
                    "plot the distributions",
                    "pandas plotting"
                ]
            },
            {
                "code": "connection = sqlite3.connect('shots.db')\ncursor = connection.cursor()\ncursor.execute(\"SELECT bias_current_peak FROM Shots WHERE bias_current_peak IS NOT NULL\")\nbias_current_peak = cursor.fetchall()\ncursor.close()\nconnection.close()\n\nbias_current_peak = np.asarray(bias_current_peak)\n\naxes = sns.distplot(bias_current_peak*2e3, axlabel=r'Current [A]', color='green', kde=False)\naxes.set_ylabel('shots')\nplt.show()",
                "true_label": "",
                "top5_preds": [
                    "reading in and sampling from the data",
                    "running a local postgres database",
                    "load table in pandas",
                    "postgres sql lab",
                    "get the names of all the tables in the database"
                ]
            },
            {
                "code": "connection = sqlite3.connect('shots.db')\ncursor = connection.cursor()\ncursor.execute(\"SELECT bias_current_peak FROM Shots WHERE bias_current_peak IS NOT NULL\")\nbias_current_peak = cursor.fetchall()\ncursor.close()\nconnection.close()\n\nbias_current_peak = np.asarray(bias_current_peak)\n\naxes = sns.distplot(bias_current_peak*2e3, axlabel=r'Current [A]', color='green')\naxes.set_ylabel('probability density')\nplt.show()",
                "true_label": "",
                "top5_preds": [
                    "reading in and sampling from the data",
                    "running a local postgres database",
                    "load table in pandas",
                    "postgres sql lab",
                    "get the names of all the tables in the database"
                ]
            },
            {
                "code": "connection = sqlite3.connect('shots.db')\ncursor = connection.cursor()\ncursor.execute(\"SELECT bias_current_peak FROM Shots WHERE bias_current_peak IS NOT NULL AND bias_current_pre_ramp_std > 0.002\")\nbias_current_peak = cursor.fetchall()\ncursor.close()\nconnection.close()\n\nbias_current_peak = np.asarray(bias_current_peak)\n\nsns.distplot(bias_current_peak*2e3, axlabel=r'Current [A]', color='green', kde=False)\nplt.show()",
                "true_label": "",
                "top5_preds": [
                    "reading in and sampling from the data",
                    "read the dataset point",
                    "load table in pandas",
                    "postgres sql lab",
                    "getting data from the internet"
                ]
            },
            {
                "code": "connection = sqlite3.connect('shots.db')\ncursor = connection.cursor()\ncursor.execute(\"SELECT bias_current_crowbar_time FROM Shots WHERE bias_current_crowbar_time IS NOT NULL\")\nbias_current_crowbar_time = cursor.fetchall()\ncursor.close()\nconnection.close()\n\nbias_current_crowbar_time = np.asarray(bias_current_crowbar_time)\n\nsns.distplot(bias_current_crowbar_time*1e3, axlabel=r'Time [ms]', color='green', kde=False)\nplt.show()",
                "true_label": "",
                "top5_preds": [
                    "load table in pandas",
                    "reading in and sampling from the data",
                    "postgres sql lab",
                    "running a local postgres database",
                    "integrating datetime tools with pandas for time series"
                ]
            },
            {
                "code": "connection = sqlite3.connect('shots.db')\ncursor = connection.cursor()\ncursor.execute(\"SELECT bias_current_crowbar_time FROM Shots WHERE bias_current_crowbar_time IS NOT NULL\")\nbias_current_crowbar_time = cursor.fetchall()\ncursor.close()\nconnection.close()\n\nbias_current_crowbar_time = np.asarray(bias_current_crowbar_time)\n\nsns.distplot(bias_current_crowbar_time*1e3, axlabel=r'Time [ms]', color='green')\nplt.show()",
                "true_label": "",
                "top5_preds": [
                    "load table in pandas",
                    "reading in and sampling from the data",
                    "postgres sql lab",
                    "running a local postgres database",
                    "integrating datetime tools with pandas for time series"
                ]
            },
            {
                "code": "connection = sqlite3.connect('shots.db')\ncursor = connection.cursor()\ncursor.execute(\"SELECT ramp_time FROM Shots WHERE ramp_time IS NOT NULL\")\nramp_time = cursor.fetchall()\ncursor.close()\nconnection.close()\n\nramp_time = np.asarray(ramp_time)\n\nsns.distplot(ramp_time*1e3, axlabel=r'Time [ms]', color='green', kde=False)\nplt.show()",
                "true_label": "",
                "top5_preds": [
                    "reading in and sampling from the data",
                    "formatting datetimes as strings",
                    "read the dataset point",
                    "integrating datetime tools with pandas for time series",
                    "load table in pandas"
                ]
            },
            {
                "code": "connection = sqlite3.connect('shots.db')\ncursor = connection.cursor()\ncursor.execute(\"SELECT ramp_time FROM Shots WHERE ramp_time IS NOT NULL\")\nramp_time = cursor.fetchall()\ncursor.close()\nconnection.close()\n\nramp_time = np.asarray(ramp_time)\n\nsns.distplot(ramp_time*1e3, axlabel=r'Time [ms]', color='green')\nplt.show()",
                "true_label": "",
                "top5_preds": [
                    "reading in and sampling from the data",
                    "formatting datetimes as strings",
                    "read the dataset point",
                    "integrating datetime tools with pandas for time series",
                    "load table in pandas"
                ]
            },
            {
                "code": "connection = sqlite3.connect('shots.db')\ncursor = connection.cursor()\ncursor.execute(\"SELECT bias_current_pre_ramp_std FROM Shots WHERE bias_current_pre_ramp_std IS NOT NULL\")\nbias_current_pre_ramp_std = cursor.fetchall()\ncursor.close()\nconnection.close()\n\nbias_current_pre_ramp_std = np.asarray(bias_current_pre_ramp_std)\n\nsns.distplot(bias_current_pre_ramp_std*1e3, axlabel=r'standard deviation [mV]', color='green', kde=False)\nplt.show()",
                "true_label": "",
                "top5_preds": [
                    "reading in and sampling from the data",
                    "postgres sql lab",
                    "load table in pandas",
                    "get a positive integer from a user",
                    "exploring the database with sql"
                ]
            }
        ],
        [
            {
                "code": "import matplotlib.pyplot as plt\nimport numpy as np\nimport random\nfrom scipy.io import loadmat\nfrom sklearn.preprocessing import StandardScaler",
                "true_label": "",
                "top5_preds": [
                    "polynomial regression with sklearn",
                    "import polynomial features from sklearn",
                    "scikit learn",
                    "what is scikit learn?",
                    "ridge regression with polynomial features on a grid"
                ]
            },
            {
                "code": "datafile = loadmat('machine-learning-ex7/ex7/ex7data1.mat', struct_as_record=False)\nX = datafile['X']\nprint(\"The shape of X is: {}\".format(X.shape))",
                "true_label": "",
                "top5_preds": [
                    "importing data with numpy",
                    "convert text data into vector",
                    "import polynomial features from sklearn",
                    "load table in pandas",
                    "what is scikit learn?"
                ]
            },
            {
                "code": "plt.scatter(X[:, 0], X[:, 1])\nplt.xlabel(\"x1\")\nplt.ylabel(\"x2\")\nplt.show()",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "create a scatter plot",
                    "equally spaced numbers on a grid",
                    "visualize the scatterplot of x",
                    "using principal component analysis to plot in two dimensions"
                ]
            },
            {
                "code": "def covariance(X):\n    \"\"\"Returns covariance matrix of X. Note: X must be mean normalised.\"\"\"\n    c_matrix = np.dot(X.T, X) / X.shape[0]\n    return c_matrix\n\ndef eigenvectors(X):\n    return np.linalg.eig(X)",
                "true_label": "",
                "top5_preds": [
                    "compute covariance matrix",
                    "computing the covariance matrix",
                    "co variance matrix",
                    "covariance matrix",
                    "covariance"
                ]
            },
            {
                "code": "# scale and normalise our data prior to PCA\nscaler = StandardScaler()\nX_std = scaler.fit_transform(X)\n#X_norm = zero_mean(X_std)\nX_norm = X_std\n\n# find covariance matrix and eigenvalues, eigenvectors\nX_covariance = covariance(X_norm)\n\n# the columns eigvecs[:, i] correspond to the eigenvector for eigenvalue[i]\neigvalues, eigvecs = eigenvectors(X_covariance)\n\nprint(eigvalues)\nprint(eigvecs)",
                "true_label": "",
                "top5_preds": [
                    "likelihood of the binomial distribution",
                    "scipy",
                    "computing the mean together with the covariance",
                    "computing the covariance matrix",
                    "compute covariance matrix"
                ]
            },
            {
                "code": "# co-ordinates of mean on our 2D plot\nmean = np.mean(X, axis=0)\n\n# projection matrix using normalised X and eigenvectors\nprojected_data = np.dot(X_norm, eigvecs)\n# mean standard dev of projection matrix for vector length - used as a reasonable arrow length for our plot\nsigma = projected_data.std(axis=0).mean()\n\n# plot original data scatter\nfig, ax = plt.subplots()\nax.scatter(X[:, 0], X[:, 1])\n\n# colours for eigvec plots\ncolours = ['red', 'blue']\n\n# plot an arrow in the direction of each eigenvector\nfor i, axis in enumerate(eigvecs.T):\n    start, end = mean, mean + sigma*axis\n    ax.annotate('', xy=end, xycoords='data',\n               xytext=start, textcoords='data',\n               arrowprops=dict(facecolor=colours[i], width=2.0))\nax.set_aspect('equal')\nplt.show()",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "scipy",
                    "use numpy to generate an array of random numbers sampled from a standard normal distribution",
                    "equally spaced numbers on a grid",
                    "create an array of linearly spaced points"
                ]
            },
            {
                "code": "eigval_total = sum(eigvalues)\nvariance_ratio = [(i/eigval_total) for i in sorted(eigvalues, reverse=True)]\ncum_var_ratio = np.cumsum(variance_ratio)\n\nplt.bar(range(1, eigvalues.shape[0] + 1), variance_ratio, alpha=0.5, align='center', label='Explained Variance')\nplt.step(range(1, eigvalues.shape[0] + 1), cum_var_ratio, where='mid', label='Cumulative Explained Variance')\nplt.xlabel(\"Principle component index\")\nplt.ylabel(\"Explained variance ratio\")\nplt.legend(loc='best')\nplt.show()",
                "true_label": "",
                "top5_preds": [
                    "likelihood of the binomial distribution",
                    "likelihood of the binomial",
                    "predicting a categorical response",
                    "line plots show the trend of a numerical variable over time",
                    "use numpy to generate an array of random numbers sampled from a standard normal distribution"
                ]
            },
            {
                "code": "# choose only first k columns of U - k is 1 in this case\nU_reduce = eigvecs[:, :1]\nU_reduce",
                "true_label": "",
                "top5_preds": [
                    "singular vector decomposition",
                    "import polynomial features from sklearn",
                    "shortcut principal component analysis in scikit learn",
                    "sentiment classification & how",
                    "compute covariance matrix"
                ]
            },
            {
                "code": "print(U_reduce.shape)\nprint(X_norm.shape)\n\nreduced_X_norm = X_norm.dot(U_reduce)\nprint(\"X data after PCA is now of shape: {}\".format(reduced_X_norm.shape))",
                "true_label": "",
                "top5_preds": [
                    "numpy",
                    "projection onto the new feature space",
                    "import polynomial features from sklearn",
                    "computing the covariance matrix",
                    "transform categorical data into binary features"
                ]
            },
            {
                "code": "# undo the processes of mean normalisation and scaling of features\ntemp = np.column_stack((reduced_X_norm, np.zeros(reduced_X_norm.shape[0]).T))\nreduced_X = scaler.inverse_transform(temp)[:, 0]\nprint(reduced_X)",
                "true_label": "",
                "top5_preds": [
                    "import polynomial features from sklearn",
                    "numpy",
                    "ridge regression with polynomial features on a grid",
                    "transform categorical data into binary features",
                    "shortcut principal component analysis in scikit learn"
                ]
            },
            {
                "code": "plt.figure(figsize=(15,4))\nplt.hlines(1, np.floor(reduced_X.min()), np.ceil(reduced_X.max()))  # Draw a horizontal line\nplt.eventplot(reduced_X.flatten(), orientation='horizontal', colors='b', alpha=0.4)\nplt.show()",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "ploting out data with box plots",
                    "equally spaced numbers on a grid",
                    "visualize the scatterplot of x",
                    "plot using matplotlib"
                ]
            },
            {
                "code": "approx_X_norm = U_reduce*reduced_X_norm.T\napprox_X_norm = approx_X_norm.T\napprox_X_norm.shape",
                "true_label": "",
                "top5_preds": [
                    "numpy",
                    "predicting a continuous response using linear regression",
                    "import polynomial features from sklearn",
                    "projection onto the new feature space",
                    "scipy"
                ]
            },
            {
                "code": "# recover approximate X by undoing the scaling and mean normalisation\napprox_X = scaler.inverse_transform(approx_X_norm)",
                "true_label": "",
                "top5_preds": [
                    "import polynomial features from sklearn",
                    "predicting a continuous response using linear regression",
                    "resampling and frequency conversion",
                    "fit a polynomial",
                    "ridge regression with polynomial features on a grid"
                ]
            },
            {
                "code": "plt.scatter(approx_X[:, 0], approx_X[:, 1], color='r', label='reconstructed data')\nplt.scatter(X[:, 0], X[:, 1], color='b', label='original data')\nplt.xlabel(\"x1\")\nplt.ylabel(\"x2\")\nplt.title(\"Reconstruction of 2D data from PCA reduced data\")\nplt.legend(loc='best')\nplt.show()",
                "true_label": "",
                "top5_preds": [
                    "predicting a continuous response using linear regression",
                    "line plot with a dataframe",
                    "ridge regression with polynomial features on a grid",
                    "ridge regression with one predictor on a grid",
                    "visualize the scatterplot of x"
                ]
            },
            {
                "code": "face_data = loadmat('machine-learning-ex7/ex7/ex7faces.mat', struct_as_record=False)\nX = face_data['X']\nprint(\"The shape of X is: {}\".format(X.shape))",
                "true_label": "",
                "top5_preds": [
                    "convert text data into vector",
                    "import polynomial features from sklearn",
                    "line plot with a dataframe",
                    "importing data with numpy",
                    "load table in pandas"
                ]
            },
            {
                "code": "plt.imshow(X[1].reshape((32, 32)).T, cmap='gray')\nplt.show()",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "ridge regression with polynomial features on a grid",
                    "equally spaced numbers on a grid",
                    "visualize the scatterplot of x",
                    "polynomial regression with sklearn"
                ]
            },
            {
                "code": "fig, ax = plt.subplots(nrows = 6, ncols = 6, sharex = True, sharey = True)\nax = ax.flatten()\nfor i in range(36):\n    img_num = random.randint(1, X.shape[0])\n    ax[i].imshow(X[img_num].reshape((32, 32)).T, cmap='gray')\nax[0].set_xticks([])\nax[0].set_yticks([])\nplt.tight_layout()\nplt.show()",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "plot multidimensional data in two dimensions",
                    "create an array of linearly spaced points",
                    "equally spaced numbers on a grid",
                    "visualize the scatterplot of x"
                ]
            },
            {
                "code": "# mean normalise and standardise our image data features\nscaler = StandardScaler()\nX_norm = scaler.fit_transform(X)\n\n# find covariance matrix and eigenvalues, eigenvectors\nX_covariance = covariance(X_norm)\n\n# the columns eigvecs[:, i] correspond to the eigenvector for eigenvalue[i]\neigvalues, eigvecs = eigenvectors(X_covariance)\n\nprint(eigvalues.shape)\nprint(eigvecs.shape)\n\nprint(eigvalues[:5])",
                "true_label": "",
                "top5_preds": [
                    "likelihood of the binomial distribution",
                    "computing the covariance matrix",
                    "compute covariance matrix",
                    "scipy",
                    "computing the mean together with the covariance"
                ]
            },
            {
                "code": "# create pairs of eigenvalues, eigenvectors and sort in descending order\neig_pairs = [(np.abs(eigvalues[i]), eigvecs[:, i]) for i in range(eigvalues.shape[0])]\neig_pairs.sort(key=lambda x: x[0], reverse=True)\nprint(eig_pairs[:5])",
                "true_label": "",
                "top5_preds": [
                    "sorting eigenpairs",
                    "eigendecomposition computing eigenvectors and eigenvalues",
                    "remove duplicates from a list",
                    "equally spaced numbers on a grid",
                    "numpy"
                ]
            },
            {
                "code": "def zero_mean(X):\n    \"\"\"Apply mean normalisation to our data\"\"\"\n    normalised = X - np.mean(X, axis=0)\n    return normalised",
                "true_label": "",
                "top5_preds": [
                    "normalize the data point",
                    "the mean",
                    "compute the mean absolute error of the predictions",
                    "calculating the mean of a vector with nans",
                    "drop data points with missing data"
                ]
            },
            {
                "code": "k=100\n\nw_matrix = eig_pairs[0][1][:, np.newaxis]\n\nfor i in range(1, k):\n    w_matrix = np.hstack((w_matrix, eig_pairs[i][1][:, np.newaxis]))\n\nprint(w_matrix.shape)",
                "true_label": "",
                "top5_preds": [
                    "numpy",
                    "numpy arrays",
                    "computing the covariance matrix",
                    "convert list to numpy array",
                    "using the numpy array below"
                ]
            },
            {
                "code": "X_pca_norm = X_norm.dot(w_matrix)\nprint(X_pca_norm.shape)",
                "true_label": "",
                "top5_preds": [
                    "computing the covariance matrix",
                    "numpy",
                    "compute covariance matrix",
                    "scipy",
                    "projection onto the new feature space"
                ]
            },
            {
                "code": "# pad our dim reduced X with 924 empty cols to allow reverse of scaling / normalising\ntemp = np.column_stack((X_pca_norm, np.zeros((X_pca_norm.shape[0], 924))))\nX_pca = scaler.inverse_transform(temp)[:, :k]\nprint(X_pca.shape)",
                "true_label": "",
                "top5_preds": [
                    "shortcut principal component analysis in scikit learn",
                    "using principal component analysis to plot in two dimensions",
                    "numpy",
                    "using k nearest neighbor for imputing missing data",
                    "import polynomial features from sklearn"
                ]
            },
            {
                "code": "fig, ax = plt.subplots(nrows = 6, ncols = 6, sharex = True, sharey = True)\nax = ax.flatten()\nfor i in range(36):\n    img_num = random.randint(1, X_pca.shape[0])\n    ax[i].imshow(X_pca[img_num].reshape((10, 10)).T, cmap='gray')\nax[0].set_xticks([])\nax[0].set_yticks([])\nplt.tight_layout()\nplt.show()",
                "true_label": "",
                "top5_preds": [
                    "plot multidimensional data in two dimensions",
                    "line plot with a dataframe",
                    "create an array of linearly spaced points",
                    "equally spaced numbers on a grid",
                    "visualize the scatterplot of x"
                ]
            },
            {
                "code": "approx_X_norm = U_reduce*reduced_X_norm.T\napprox_X_norm = approx_X_norm.T\napprox_X_norm.shape",
                "true_label": "",
                "top5_preds": [
                    "numpy",
                    "predicting a continuous response using linear regression",
                    "import polynomial features from sklearn",
                    "projection onto the new feature space",
                    "scipy"
                ]
            }
        ],
        [
            {
                "code": "import pandas as pd\nimport json\nfrom pprint import pprint",
                "true_label": "",
                "top5_preds": [
                    "loading json in python",
                    "formatting datetimes as strings",
                    "equally spaced numbers on a grid",
                    "importing data with numpy",
                    "ipython notebook as json"
                ]
            },
            {
                "code": "df = pd.read_csv('data/merged4.csv', encoding='latin1', index_col=0)",
                "true_label": "",
                "top5_preds": [
                    "loading a csv into a dataframe",
                    "join two dataframes along rows",
                    "load table in pandas",
                    "importing data with numpy",
                    "join two dataframes along columns"
                ]
            },
            {
                "code": "df.info(max_cols=120)",
                "true_label": "",
                "top5_preds": [
                    "load table in pandas",
                    "get the names of all the tables in the database",
                    "from dictionary to dataframe",
                    "loading a csv into a dataframe",
                    "line plot with a dataframe"
                ]
            },
            {
                "code": "static_data = []\ndynamic_data = []\nuseless_data = []",
                "true_label": "",
                "top5_preds": [
                    "add string to list using append",
                    "how to change the style of individual lines",
                    "getting data from the internet",
                    "loading json in python",
                    "load table in pandas"
                ]
            },
            {
                "code": "dynamic_data.append('average_pledge')",
                "true_label": "",
                "top5_preds": [
                    "line plots show the trend of a numerical variable over time",
                    "integrating datetime tools with pandas for time series",
                    "line plot with a dataframe",
                    "load table in pandas",
                    "ridge regression with one predictor on a grid"
                ]
            },
            {
                "code": "# future data\nuseless_data.append('average_pledge_end')",
                "true_label": "",
                "top5_preds": [
                    "integrating datetime tools with pandas for time series",
                    "line plots show the trend of a numerical variable over time",
                    "relationships between dataframes",
                    "introduction to the python datetime tools",
                    "add intercept in logistic regression"
                ]
            },
            {
                "code": "static_data.append('days_preparation')",
                "true_label": "",
                "top5_preds": [
                    "formatting datetimes as strings",
                    "convert date to datetime format",
                    "introduction to the python datetime tools",
                    "date ranges and frequencies",
                    "load table in pandas"
                ]
            },
            {
                "code": "dynamic_data.append('days_remaining')",
                "true_label": "",
                "top5_preds": [
                    "formatting datetimes as strings",
                    "date ranges and frequencies",
                    "convert date to datetime format",
                    "integrating datetime tools with pandas for time series",
                    "adding a date range"
                ]
            },
            {
                "code": "dynamic_data.append('days_running')",
                "true_label": "",
                "top5_preds": [
                    "formatting datetimes as strings",
                    "integrating datetime tools with pandas for time series",
                    "convert date to datetime format",
                    "compare variable with time",
                    "date ranges and frequencies"
                ]
            },
            {
                "code": "# future data\nuseless_data.append('db_backers_count')",
                "true_label": "",
                "top5_preds": [
                    "load table in pandas",
                    "from dictionary to dataframe",
                    "get a positive integer from a user",
                    "postgres sql lab",
                    "data given as a dictionary"
                ]
            },
            {
                "code": "# useless (numeric representation of parent category)\nuseless_data.append('db_category_id')",
                "true_label": "",
                "top5_preds": [
                    "from dictionary to dataframe",
                    "convert categorical variables",
                    "loading json in python",
                    "postgres sql lab",
                    "get a positive integer from a user"
                ]
            },
            {
                "code": "# future data\nuseless_data.append('db_comments_count')",
                "true_label": "",
                "top5_preds": [
                    "get a positive integer from a user",
                    "load table in pandas",
                    "from dictionary to dataframe",
                    "how to change the style of individual lines",
                    "detect the number of local variables declared in a function"
                ]
            },
            {
                "code": "# future data\nuseless_data.append('location_name_end')",
                "true_label": "",
                "top5_preds": [
                    "how to change the style of individual lines",
                    "obtaining metadata from crossref",
                    "formatting datetimes as strings",
                    "loading json in python",
                    "add edges in graph"
                ]
            },
            {
                "code": "static_data.append('location_state')",
                "true_label": "",
                "top5_preds": [
                    "getting data from the internet",
                    "loading json in python",
                    "load table in pandas",
                    "how to change the style of individual lines",
                    "from dictionary to dataframe"
                ]
            },
            {
                "code": "# future data\nuseless_data.append('location_state_end')",
                "true_label": "",
                "top5_preds": [
                    "obtaining metadata from crossref",
                    "how to change the style of individual lines",
                    "formatting datetimes as strings",
                    "from dictionary to dataframe",
                    "shifting data leading and lagging"
                ]
            },
            {
                "code": "static_data.append('location_type')",
                "true_label": "",
                "top5_preds": [
                    "loading json in python",
                    "getting data from the internet",
                    "using json to find your location",
                    "how to change the style of individual lines",
                    "load table in pandas"
                ]
            },
            {
                "code": "# future data\nuseless_data.append('location_type_end')",
                "true_label": "",
                "top5_preds": [
                    "how to change the style of individual lines",
                    "obtaining metadata from crossref",
                    "formatting datetimes as strings",
                    "loading json in python",
                    "from dictionary to dataframe"
                ]
            },
            {
                "code": "# useless\nuseless_data.append('name')",
                "true_label": "",
                "top5_preds": [
                    "how to change the style of individual lines",
                    "optimal value of k for dataset",
                    "loading json in python",
                    "from dictionary to dataframe",
                    "data given as a dictionary"
                ]
            },
            {
                "code": "dynamic_data.append('ratio_pledged_goal')",
                "true_label": "",
                "top5_preds": [
                    "plot multidimensional data in two dimensions",
                    "integrating datetime tools with pandas for time series",
                    "predicting a categorical response",
                    "exploratory data analysis on feature variables",
                    "relationships between dataframes"
                ]
            },
            {
                "code": "dynamic_data.append('ratio_running_duration')",
                "true_label": "",
                "top5_preds": [
                    "formatting datetimes as strings",
                    "parse time and visibility from json",
                    "integrating datetime tools with pandas for time series",
                    "time",
                    "load table in pandas"
                ]
            },
            {
                "code": "# already used to extract many features\nuseless_data.append('scraped_at')",
                "true_label": "",
                "top5_preds": [
                    "import polynomial features from sklearn",
                    "implementing bag of words in scikit learn",
                    "what is scikit learn?",
                    "exploratory data analysis on feature variables",
                    "load table in pandas"
                ]
            },
            {
                "code": "# useless\nuseless_data.append('slug')",
                "true_label": "",
                "top5_preds": [
                    "from dictionary to dataframe",
                    "loading json in python",
                    "get a positive integer from a user",
                    "calculating the mean of a vector with nans",
                    "optimal value of k for dataset"
                ]
            },
            {
                "code": "# useless\nuseless_data.append('source_url')",
                "true_label": "",
                "top5_preds": [
                    "loading json in python",
                    "getting data from the internet",
                    "obtaining metadata from crossref",
                    "from dictionary to dataframe",
                    "how to change the style of individual lines"
                ]
            },
            {
                "code": "# useless\nuseless_data.append('source_url_end')",
                "true_label": "",
                "top5_preds": [
                    "how to change the style of individual lines",
                    "loading json in python",
                    "getting data from the internet",
                    "add edges in graph",
                    "formatting datetimes as strings"
                ]
            },
            {
                "code": "dynamic_data.append('staff_pick')",
                "true_label": "",
                "top5_preds": [
                    "using interact for animation with data",
                    "load table in pandas",
                    "from dictionary to dataframe",
                    "tensorflow + keras",
                    "import polynomial features from sklearn"
                ]
            },
            {
                "code": "# future data\nuseless_data.append('staff_pick_end')",
                "true_label": "",
                "top5_preds": [
                    "using interact for animation with data",
                    "load table in pandas",
                    "from dictionary to dataframe",
                    "how to change the style of individual lines",
                    "relationships between dataframes"
                ]
            },
            {
                "code": "df.state.describe()",
                "true_label": "",
                "top5_preds": [
                    "create a one column dataframe with the values of a series",
                    "line plots show the trend of a numerical variable over time",
                    "load table in pandas",
                    "formatting datetimes as strings",
                    "line plot with a dataframe"
                ]
            },
            {
                "code": "# always live\nuseless_data.append('state')",
                "true_label": "",
                "top5_preds": [
                    "data given as a dictionary",
                    "how to change the style of individual lines",
                    "using interact for animation with data",
                    "line plots show the trend of a numerical variable over time",
                    "from dictionary to dataframe"
                ]
            },
            {
                "code": "# useless\nuseless_data.append('state_changed_at')",
                "true_label": "",
                "top5_preds": [
                    "from dictionary to dataframe",
                    "formatting datetimes as strings",
                    "see last entries of dataset",
                    "load table in pandas",
                    "get a positive integer from a user"
                ]
            },
            {
                "code": "# useless, future data\nuseless_data.append('state_changed_at_end')",
                "true_label": "",
                "top5_preds": [
                    "using interact for animation with data",
                    "shifting data leading and lagging",
                    "relationships between dataframes",
                    "add edges in graph",
                    "how to change the style of individual lines"
                ]
            },
            {
                "code": "len(df['db_location_id'].value_counts())",
                "true_label": "",
                "top5_preds": [
                    "from dictionary to dataframe",
                    "load table in pandas",
                    "find data type of each column",
                    "line plot with a dataframe",
                    "in pandas"
                ]
            },
            {
                "code": "# useless (ordinal representation of other columns)\nuseless_data.append('db_location_id')",
                "true_label": "",
                "top5_preds": [
                    "from dictionary to dataframe",
                    "postgres sql lab",
                    "sqlalchemy, sqlite, and dates",
                    "running a local postgres database",
                    "relationships between dataframes"
                ]
            },
            {
                "code": "# useless\nuseless_data.append('db_name')",
                "true_label": "",
                "top5_preds": [
                    "from dictionary to dataframe",
                    "postgres sql lab",
                    "running a local postgres database",
                    "load table in pandas",
                    "data given as a dictionary"
                ]
            },
            {
                "code": "# future data\nuseless_data.append('db_pledged')",
                "true_label": "",
                "top5_preds": [
                    "get a positive integer from a user",
                    "from dictionary to dataframe",
                    "data given as a dictionary",
                    "relationships between dataframes",
                    "load table in pandas"
                ]
            },
            {
                "code": "row = 1\ndict_data = json.loads(df.loc[row, 'db_project_data'])\n#pprint(dict_data)",
                "true_label": "",
                "top5_preds": [
                    "from dictionary to dataframe",
                    "loading json in python",
                    "data given as a dictionary",
                    "using json to find your location",
                    "load table in pandas"
                ]
            },
            {
                "code": "# usefull data already extracted\nuseless_data.append('db_project_data')",
                "true_label": "",
                "top5_preds": [
                    "from dictionary to dataframe",
                    "load table in pandas",
                    "data given as a dictionary",
                    "import polynomial features from sklearn",
                    "helpers to read in dataset"
                ]
            },
            {
                "code": "# useless\nuseless_data.append('db_project_id')",
                "true_label": "",
                "top5_preds": [
                    "from dictionary to dataframe",
                    "postgres sql lab",
                    "loading json in python",
                    "running a local postgres database",
                    "data given as a dictionary"
                ]
            },
            {
                "code": "# useless\nuseless_data.append('urls_url_end')",
                "true_label": "",
                "top5_preds": [
                    "how to change the style of individual lines",
                    "getting data from the internet",
                    "trend lines in pyplot",
                    "add edges in graph",
                    "formatting datetimes as strings"
                ]
            },
            {
                "code": "static_data.append('usd_goal')",
                "true_label": "",
                "top5_preds": [
                    "load table in pandas",
                    "loading json in python",
                    "getting data from the internet",
                    "import polynomial features from sklearn",
                    "heatmap with time"
                ]
            },
            {
                "code": "dynamic_data.append('usd_pledged')",
                "true_label": "",
                "top5_preds": [
                    "line plots show the trend of a numerical variable over time",
                    "integrating datetime tools with pandas for time series",
                    "import polynomial features from sklearn",
                    "exploratory data analysis on feature variables",
                    "load table in pandas"
                ]
            },
            {
                "code": "# future data\nuseless_data.append('usd_pledged_end')",
                "true_label": "",
                "top5_preds": [
                    "integrating datetime tools with pandas for time series",
                    "relationships between dataframes",
                    "line plots show the trend of a numerical variable over time",
                    "add intercept in logistic regression",
                    "shifting data leading and lagging"
                ]
            },
            {
                "code": "# predicted class\nstatic_data.append('class')",
                "true_label": "",
                "top5_preds": [
                    "import polynomial features from sklearn",
                    "load table in pandas",
                    "what is scikit learn?",
                    "loading json in python",
                    "class predictions for new sources"
                ]
            },
            {
                "code": "# useless\nuseless_data.append('ID')",
                "true_label": "",
                "top5_preds": [
                    "from dictionary to dataframe",
                    "data given as a dictionary",
                    "how to change the style of individual lines",
                    "loading json in python",
                    "loading up data with missing values"
                ]
            },
            {
                "code": "dynamic_data.append('faq_count_while_scraping')",
                "true_label": "",
                "top5_preds": [
                    "getting data from the internet",
                    "line plots show the trend of a numerical variable over time",
                    "load table in pandas",
                    "integrating datetime tools with pandas for time series",
                    "retrieving data from html page"
                ]
            },
            {
                "code": "dynamic_data.append('comments_count_creator_while_scraping')",
                "true_label": "",
                "top5_preds": [
                    "how to change the style of individual lines",
                    "load table in pandas",
                    "getting data from the internet",
                    "line plots show the trend of a numerical variable over time",
                    "retrieving data from html page"
                ]
            },
            {
                "code": "dynamic_data.append('comments_count_public_while_scraping')",
                "true_label": "",
                "top5_preds": [
                    "how to change the style of individual lines",
                    "load table in pandas",
                    "getting data from the internet",
                    "line plots show the trend of a numerical variable over time",
                    "exploratory data analysis eda global properties"
                ]
            },
            {
                "code": "dynamic_data.append('updates_count_while_scraping')",
                "true_label": "",
                "top5_preds": [
                    "line plots show the trend of a numerical variable over time",
                    "how to change the style of individual lines",
                    "getting data from the internet",
                    "integrating datetime tools with pandas for time series",
                    "load table in pandas"
                ]
            },
            {
                "code": "dynamic_data.append('updates_likes_sum_while_scraping')",
                "true_label": "",
                "top5_preds": [
                    "line plots show the trend of a numerical variable over time",
                    "getting data from the internet",
                    "load table in pandas",
                    "get a positive integer from a user",
                    "integrating datetime tools with pandas for time series"
                ]
            },
            {
                "code": "# future data\nuseless_data.append('category_position_end')",
                "true_label": "",
                "top5_preds": [
                    "integrating datetime tools with pandas for time series",
                    "relationships between dataframes",
                    "formatting datetimes as strings",
                    "line plots show the trend of a numerical variable over time",
                    "how to change the style of individual lines"
                ]
            },
            {
                "code": "static_data.append('country')",
                "true_label": "",
                "top5_preds": [
                    "loading json in python",
                    "getting data from the internet",
                    "load table in pandas",
                    "twitter application",
                    "from dictionary to dataframe"
                ]
            },
            {
                "code": "# timestamp, already used to extract days_preparation\n# not commonly accesible to public on website, therefore should not affect behavior\nuseless_data.append('created_at')",
                "true_label": "",
                "top5_preds": [
                    "formatting datetimes as strings",
                    "convert date to datetime format",
                    "transform the date column as a datetime type",
                    "parse time and visibility from json",
                    "introduction to the python datetime tools"
                ]
            },
            {
                "code": "df.loc[1, 'creator']",
                "true_label": "",
                "top5_preds": [
                    "change type of column",
                    "loading a csv into a dataframe",
                    "from dictionary to dataframe",
                    "create a one column dataframe with the values of a series",
                    "find data type of each column"
                ]
            },
            {
                "code": "# nothing usefull here, wrong format\nuseless_data.append('creator')",
                "true_label": "",
                "top5_preds": [
                    "formatting datetimes as strings",
                    "loading json in python",
                    "from dictionary to dataframe",
                    "convert date to datetime format",
                    "loading up data with missing values"
                ]
            },
            {
                "code": "# nothing usefull here, wrong format\nuseless_data.append('creator_end')",
                "true_label": "",
                "top5_preds": [
                    "formatting datetimes as strings",
                    "convert date to datetime format",
                    "loading json in python",
                    "integrating datetime tools with pandas for time series",
                    "obtaining metadata from crossref"
                ]
            },
            {
                "code": "dynamic_data.append('updates_likes_mean_while_scraping')",
                "true_label": "",
                "top5_preds": [
                    "line plots show the trend of a numerical variable over time",
                    "integrating datetime tools with pandas for time series",
                    "load table in pandas",
                    "line plot with a dataframe",
                    "using a dataframe and matplotlib commands"
                ]
            },
            {
                "code": "dynamic_data.append('updates_likes_min_while_scraping')",
                "true_label": "",
                "top5_preds": [
                    "getting data from the internet",
                    "load table in pandas",
                    "integrating datetime tools with pandas for time series",
                    "line plots show the trend of a numerical variable over time",
                    "using a dataframe and matplotlib commands"
                ]
            },
            {
                "code": "# useless\nuseless_data.append('creator_name')",
                "true_label": "",
                "top5_preds": [
                    "from dictionary to dataframe",
                    "loading json in python",
                    "obtaining metadata from crossref",
                    "formatting datetimes as strings",
                    "get a positive integer from a user"
                ]
            },
            {
                "code": "# useless\nuseless_data.append('creator_name_end')",
                "true_label": "",
                "top5_preds": [
                    "formatting datetimes as strings",
                    "obtaining metadata from crossref",
                    "loading json in python",
                    "how to change the style of individual lines",
                    "convert date to datetime format"
                ]
            },
            {
                "code": "static_data.append('currency')",
                "true_label": "",
                "top5_preds": [
                    "getting data from the internet",
                    "loading json in python",
                    "load table in pandas",
                    "twitter api access",
                    "how to change the style of individual lines"
                ]
            },
            {
                "code": "df.currency_symbol.value_counts()",
                "true_label": "",
                "top5_preds": [
                    "create a one column dataframe with the values of a series",
                    "convert date to datetime format",
                    "line plots show the trend of a numerical variable over time",
                    "convert text data into vector",
                    "plotting time series with pandas"
                ]
            },
            {
                "code": "# damaged and redundant data\nuseless_data.append('currency_symbol')",
                "true_label": "",
                "top5_preds": [
                    "from dictionary to dataframe",
                    "relationships between dataframes",
                    "how to change the style of individual lines",
                    "data given as a dictionary",
                    "integrating datetime tools with pandas for time series"
                ]
            },
            {
                "code": "# useless\nuseless_data.append('currency_trailing_code')",
                "true_label": "",
                "top5_preds": [
                    "how to change the style of individual lines",
                    "convert date to datetime format",
                    "convert integer or float data",
                    "introduction to the python datetime tools",
                    "postgres sql lab"
                ]
            },
            {
                "code": "# future data\nuseless_data.append('db_updates_count')",
                "true_label": "",
                "top5_preds": [
                    "get a positive integer from a user",
                    "load table in pandas",
                    "from dictionary to dataframe",
                    "data given as a dictionary",
                    "integrating datetime tools with pandas for time series"
                ]
            },
            {
                "code": "# useless\nuseless_data.append('db_url')",
                "true_label": "",
                "top5_preds": [
                    "running a local postgres database",
                    "postgres sql lab",
                    "load table in pandas",
                    "getting data from the internet",
                    "from dictionary to dataframe"
                ]
            },
            {
                "code": "static_data.append('db_video_url')",
                "true_label": "",
                "top5_preds": [
                    "getting data from the internet",
                    "load table in pandas",
                    "accessing databases via web apis",
                    "twitter application",
                    "add string to list using append"
                ]
            },
            {
                "code": "# already used to extract days_duration and days_remaining\nstatic_data.append('deadline_end')",
                "true_label": "",
                "top5_preds": [
                    "formatting datetimes as strings",
                    "parse time and visibility from json",
                    "date ranges and frequencies",
                    "parsing time",
                    "convert date to datetime format"
                ]
            },
            {
                "code": "df['disable_communication'].describe()",
                "true_label": "",
                "top5_preds": [
                    "formatting datetimes as strings",
                    "dataframe methods",
                    "load table in pandas",
                    "in pandas",
                    "create a one column dataframe with the values of a series"
                ]
            },
            {
                "code": "# always False\nuseless_data.append('disable_communication')",
                "true_label": "",
                "top5_preds": [
                    "get a positive integer from a user",
                    "exploratory data analysis eda global properties",
                    "loading json in python",
                    "analyzing network inefficiencies",
                    "how to change the style of individual lines"
                ]
            },
            {
                "code": "# future data\nuseless_data.append('disable_communication_end')",
                "true_label": "",
                "top5_preds": [
                    "how to change the style of individual lines",
                    "introduction to the python datetime tools",
                    "get a positive integer from a user",
                    "getting data from the internet",
                    "relationships between dataframes"
                ]
            },
            {
                "code": "static_data.append('goal')",
                "true_label": "",
                "top5_preds": [
                    "loading json in python",
                    "getting data from the internet",
                    "load table in pandas",
                    "add edges in graph",
                    "how to change the style of individual lines"
                ]
            },
            {
                "code": "# useless\nuseless_data.append('id')",
                "true_label": "",
                "top5_preds": [
                    "from dictionary to dataframe",
                    "loading json in python",
                    "data given as a dictionary",
                    "optimal value of k for dataset",
                    "how to change the style of individual lines"
                ]
            },
            {
                "code": "# already used to extract days_preparation and days_running\nstatic_data.append('launched_at')",
                "true_label": "",
                "top5_preds": [
                    "formatting datetimes as strings",
                    "convert date to datetime format",
                    "integrating datetime tools with pandas for time series",
                    "compare variable with time",
                    "parse time and visibility from json"
                ]
            },
            {
                "code": "# already used to extract data\nuseless_data.append('location')",
                "true_label": "",
                "top5_preds": [
                    "from dictionary to dataframe",
                    "loading up data with missing values",
                    "relationships between dataframes",
                    "data given as a dictionary",
                    "helpers to read in dataset"
                ]
            },
            {
                "code": "# future data\nuseless_data.append('location_end')",
                "true_label": "",
                "top5_preds": [
                    "how to change the style of individual lines",
                    "obtaining metadata from crossref",
                    "formatting datetimes as strings",
                    "add edges in graph",
                    "relationships between dataframes"
                ]
            },
            {
                "code": "# only Film & Video parent category contains 19 categories (19th is Webseries)\ndf[df.category_position == 19]['category_name'].value_counts()",
                "true_label": "",
                "top5_preds": [
                    "convert categorical variables",
                    "predicting a categorical response",
                    "list of categories",
                    "find data type of each column",
                    "create a one column dataframe with the values of a series"
                ]
            },
            {
                "code": "static_data.append('category_position')",
                "true_label": "",
                "top5_preds": [
                    "load table in pandas",
                    "getting data from the internet",
                    "loading json in python",
                    "from dictionary to dataframe",
                    "line plot with a dataframe"
                ]
            },
            {
                "code": "static_data.append('days_duration')",
                "true_label": "",
                "top5_preds": [
                    "formatting datetimes as strings",
                    "convert date to datetime format",
                    "load table in pandas",
                    "date ranges and frequencies",
                    "parse time and visibility from json"
                ]
            },
            {
                "code": "static_data.append('blurb')",
                "true_label": "",
                "top5_preds": [
                    "getting data from the internet",
                    "load table in pandas",
                    "how to change the style of individual lines",
                    "loading json in python",
                    "twitter application"
                ]
            },
            {
                "code": "# future data\nuseless_data.append('blurb_end')",
                "true_label": "",
                "top5_preds": [
                    "how to change the style of individual lines",
                    "trend lines in pyplot",
                    "getting data from the internet",
                    "load table in pandas",
                    "text data"
                ]
            },
            {
                "code": "df.loc[1,'category']",
                "true_label": "",
                "top5_preds": [
                    "convert categorical variables",
                    "loading a csv into a dataframe",
                    "load table in pandas",
                    "find all by term in field in case insensitive way",
                    "create a one column dataframe with the values of a series"
                ]
            },
            {
                "code": "# wrong format, useful data already extracted\nuseless_data.append('category')",
                "true_label": "",
                "top5_preds": [
                    "shortcut principal component analysis in scikit learn",
                    "import polynomial features from sklearn",
                    "predicting a categorical response",
                    "helpers to read in dataset",
                    "from dictionary to dataframe"
                ]
            },
            {
                "code": "# future data\nuseless_data.append('category_end')",
                "true_label": "",
                "top5_preds": [
                    "integrating datetime tools with pandas for time series",
                    "line plots show the trend of a numerical variable over time",
                    "relationships between dataframes",
                    "how to change the style of individual lines",
                    "formatting datetimes as strings"
                ]
            },
            {
                "code": "static_data.append('category_name')",
                "true_label": "",
                "top5_preds": [
                    "loading json in python",
                    "load table in pandas",
                    "getting data from the internet",
                    "from dictionary to dataframe",
                    "add string to list using append"
                ]
            },
            {
                "code": "# useless, redundant\nuseless_data.append('photo_end')",
                "true_label": "",
                "top5_preds": [
                    "how to change the style of individual lines",
                    "add edges in graph",
                    "relationships between dataframes",
                    "using interact for animation with data",
                    "trend lines in pyplot"
                ]
            },
            {
                "code": "dynamic_data.append('pledged')",
                "true_label": "",
                "top5_preds": [
                    "exploratory data analysis on feature variables",
                    "import polynomial features from sklearn",
                    "load table in pandas",
                    "polynomial regression with sklearn",
                    "line plots show the trend of a numerical variable over time"
                ]
            },
            {
                "code": "# future data\nuseless_data.append('pledged_end')",
                "true_label": "",
                "top5_preds": [
                    "integrating datetime tools with pandas for time series",
                    "how to change the style of individual lines",
                    "relationships between dataframes",
                    "shifting data leading and lagging",
                    "add intercept in logistic regression"
                ]
            },
            {
                "code": "df.loc[1, 'profile']",
                "true_label": "",
                "top5_preds": [
                    "from dictionary to dataframe",
                    "load table in pandas",
                    "loading a csv into a dataframe",
                    "convert text data into vector",
                    "line plot with a dataframe"
                ]
            },
            {
                "code": "# wrong format, useless\nuseless_data.append('profile')",
                "true_label": "",
                "top5_preds": [
                    "loading json in python",
                    "how to change the style of individual lines",
                    "formatting datetimes as strings",
                    "convert date to datetime format",
                    "from dictionary to dataframe"
                ]
            },
            {
                "code": "# future data\nuseless_data.append('profile_end')",
                "true_label": "",
                "top5_preds": [
                    "how to change the style of individual lines",
                    "line plots show the trend of a numerical variable over time",
                    "getting data from the internet",
                    "using interact for animation with data",
                    "integrating datetime tools with pandas for time series"
                ]
            },
            {
                "code": "# useless\nuseless_data.append('urls_url')",
                "true_label": "",
                "top5_preds": [
                    "loading json in python",
                    "getting data from the internet",
                    "how to change the style of individual lines",
                    "load table in pandas",
                    "what is scikit learn?"
                ]
            },
            {
                "code": "# useless\nuseless_data.append('db_end_time')",
                "true_label": "",
                "top5_preds": [
                    "formatting datetimes as strings",
                    "sqlalchemy, sqlite, and dates",
                    "integrating datetime tools with pandas for time series",
                    "convert date to datetime format",
                    "transform the date column as a datetime type"
                ]
            },
            {
                "code": "# future data\nuseless_data.append('db_faq_count')",
                "true_label": "",
                "top5_preds": [
                    "load table in pandas",
                    "get a positive integer from a user",
                    "from dictionary to dataframe",
                    "data given as a dictionary",
                    "loading up data with missing values"
                ]
            },
            {
                "code": "df['db_fb_comments_count'].describe()",
                "true_label": "",
                "top5_preds": [
                    "counting word frequency",
                    "load table in pandas",
                    "from dictionary to dataframe",
                    "in pandas",
                    "line plots show the trend of a numerical variable over time"
                ]
            },
            {
                "code": "# always 0\nuseless_data.append('db_fb_comments_count')",
                "true_label": "",
                "top5_preds": [
                    "get a positive integer from a user",
                    "bytes to integer conversion",
                    "counting word frequency",
                    "getting data from the internet",
                    "detect the number of local variables declared in a function"
                ]
            },
            {
                "code": "# future data\nuseless_data.append('db_fb_shares_count')",
                "true_label": "",
                "top5_preds": [
                    "get a positive integer from a user",
                    "bytes to integer conversion",
                    "getting data from the internet",
                    "convert integer or float data",
                    "convert data from string to float"
                ]
            },
            {
                "code": "len(df[df['goal'] != df['db_goal']])",
                "true_label": "",
                "top5_preds": [
                    "predicting a categorical response",
                    "using pandas",
                    "in pandas",
                    "line plot with a dataframe",
                    "dataframe methods"
                ]
            },
            {
                "code": "# redundant data\nuseless_data.append('db_goal')",
                "true_label": "",
                "top5_preds": [
                    "relationships between dataframes",
                    "from dictionary to dataframe",
                    "loading up data with missing values",
                    "postgres sql lab",
                    "load table in pandas"
                ]
            },
            {
                "code": "# useless data\nuseless_data.append('db_hours_remaining')",
                "true_label": "",
                "top5_preds": [
                    "integrating datetime tools with pandas for time series",
                    "introduction to the python datetime tools",
                    "formatting datetimes as strings",
                    "date ranges and frequencies",
                    "when arithmetic operations are performed between differently indexed time series pandas will automatically align on dates"
                ]
            },
            {
                "code": "static_data.append('db_image_url')",
                "true_label": "",
                "top5_preds": [
                    "getting data from the internet",
                    "accessing databases via web apis",
                    "load table in pandas",
                    "running a local postgres database",
                    "download and inspect the twitter samples dataset"
                ]
            },
            {
                "code": "df.loc[1,'photo']",
                "true_label": "",
                "top5_preds": [
                    "from dictionary to dataframe",
                    "load table in pandas",
                    "loading a csv into a dataframe",
                    "find maximum and the minimum value in a set",
                    "line plot with a dataframe"
                ]
            },
            {
                "code": "# wrong format, describes only 1 photo - redundant data\nuseless_data.append('photo')",
                "true_label": "",
                "top5_preds": [
                    "formatting datetimes as strings",
                    "loading json in python",
                    "how to change the style of individual lines",
                    "data given as a dictionary",
                    "dealing with missing values"
                ]
            },
            {
                "code": "# already used to extract class\nuseless_data.append('ratio_pledged_end_goal')",
                "true_label": "",
                "top5_preds": [
                    "relationships between dataframes",
                    "integrating datetime tools with pandas for time series",
                    "import polynomial features from sklearn",
                    "line plots show the trend of a numerical variable over time",
                    "predicting a categorical response"
                ]
            },
            {
                "code": "dynamic_data.append('backers_count')",
                "true_label": "",
                "top5_preds": [
                    "load table in pandas",
                    "data given as a dictionary",
                    "getting data from the internet",
                    "get a positive integer from a user",
                    "create a data dictionary"
                ]
            },
            {
                "code": "# future data\nuseless_data.append('backers_count_end')",
                "true_label": "",
                "top5_preds": [
                    "get a positive integer from a user",
                    "obtaining metadata from crossref",
                    "integrating datetime tools with pandas for time series",
                    "see last entries of dataset",
                    "shifting data leading and lagging"
                ]
            },
            {
                "code": "# future data\nuseless_data.append('category_name_end')",
                "true_label": "",
                "top5_preds": [
                    "integrating datetime tools with pandas for time series",
                    "line plots show the trend of a numerical variable over time",
                    "how to change the style of individual lines",
                    "load table in pandas",
                    "relationships between dataframes"
                ]
            },
            {
                "code": "static_data.append('category_parent')",
                "true_label": "",
                "top5_preds": [
                    "loading json in python",
                    "from dictionary to dataframe",
                    "load table in pandas",
                    "relationships between dataframes",
                    "getting data from the internet"
                ]
            },
            {
                "code": "# future data\nuseless_data.append('category_parent_end')",
                "true_label": "",
                "top5_preds": [
                    "relationships between dataframes",
                    "integrating datetime tools with pandas for time series",
                    "how to change the style of individual lines",
                    "from dictionary to dataframe",
                    "line plots show the trend of a numerical variable over time"
                ]
            },
            {
                "code": "# future data, we have our own prediction class\nuseless_data.append('state_end')",
                "true_label": "",
                "top5_preds": [
                    "making predictions for the testing data",
                    "class predictions for new sources",
                    "load table in pandas",
                    "predicting a categorical response",
                    "import polynomial features from sklearn"
                ]
            },
            {
                "code": "# already used for currency conversion to USD\nuseless_data.append('static_usd_rate')",
                "true_label": "",
                "top5_preds": [
                    "line plots show the trend of a numerical variable over time",
                    "from dictionary to dataframe",
                    "convert date to datetime format",
                    "load table in pandas",
                    "convert data from string to float"
                ]
            },
            {
                "code": "df.category_position.value_counts()",
                "true_label": "",
                "top5_preds": [
                    "create a one column dataframe with the values of a series",
                    "create a dataframe by joining series by column",
                    "convert categorical variables",
                    "transform categorical data into binary features",
                    "working with pandas series indexed by datetime"
                ]
            },
            {
                "code": "# cookbooks are 3rd in category Food (see kickstarter)\ndf[df.category_name == 'Cookbooks']['category_position'].value_counts()",
                "true_label": "",
                "top5_preds": [
                    "predicting a categorical response",
                    "create a one column dataframe with the values of a series",
                    "convert categorical variables",
                    "find data type of each column",
                    "find the most common words"
                ]
            },
            {
                "code": "df[df['blurb_end'] != df['db_description_short']][['blurb','db_description_short']].sample(5)",
                "true_label": "",
                "top5_preds": [
                    "predicting a categorical response",
                    "line plots show the trend of a numerical variable over time",
                    "create a one column dataframe with the values of a series",
                    "line plot with a dataframe",
                    "create dataframe with given values"
                ]
            },
            {
                "code": "# redundant data\nuseless_data.append('db_description_short')",
                "true_label": "",
                "top5_preds": [
                    "load table in pandas",
                    "postgres sql lab",
                    "relationships between dataframes",
                    "from dictionary to dataframe",
                    "how to change the style of individual lines"
                ]
            },
            {
                "code": "# keep due to inconsistency with days_duration\nstatic_data.append('db_duration')",
                "true_label": "",
                "top5_preds": [
                    "formatting datetimes as strings",
                    "convert date to datetime format",
                    "add string to list using append",
                    "integrating datetime tools with pandas for time series",
                    "date ranges and frequencies"
                ]
            },
            {
                "code": "# future data\nuseless_data.append('db_project_we_love')",
                "true_label": "",
                "top5_preds": [
                    "from dictionary to dataframe",
                    "load table in pandas",
                    "postgres sql lab",
                    "running a local postgres database",
                    "loading json in python"
                ]
            },
            {
                "code": "# useless\nuseless_data.append('db_start_time')",
                "true_label": "",
                "top5_preds": [
                    "integrating datetime tools with pandas for time series",
                    "convert date to datetime format",
                    "load table in pandas",
                    "formatting datetimes as strings",
                    "sqlalchemy, sqlite, and dates"
                ]
            },
            {
                "code": "# useless, we use our own classes\nuseless_data.append('db_status')",
                "true_label": "",
                "top5_preds": [
                    "how to change the style of individual lines",
                    "load table in pandas",
                    "from dictionary to dataframe",
                    "getting data from the internet",
                    "get a positive integer from a user"
                ]
            },
            {
                "code": "df.location_is_root.describe()",
                "true_label": "",
                "top5_preds": [
                    "create a one column dataframe with the values of a series",
                    "find data type of each column",
                    "load table in pandas",
                    "formatting datetimes as strings",
                    "dataframe methods"
                ]
            },
            {
                "code": "# always False\nuseless_data.append('location_is_root')",
                "true_label": "",
                "top5_preds": [
                    "loading json in python",
                    "obtaining metadata from crossref",
                    "import polynomial features from sklearn",
                    "relationships between dataframes",
                    "predicting test data"
                ]
            },
            {
                "code": "useless_data.append('db_creators_url')",
                "true_label": "",
                "top5_preds": [
                    "sqlalchemy, sqlite, and dates",
                    "postgres sql lab",
                    "running a local postgres database",
                    "load table in pandas",
                    "store the sources in a database"
                ]
            },
            {
                "code": "# damaged redundant data\nuseless_data.append('db_currency')",
                "true_label": "",
                "top5_preds": [
                    "from dictionary to dataframe",
                    "postgres sql lab",
                    "load table in pandas",
                    "data given as a dictionary",
                    "get a positive integer from a user"
                ]
            },
            {
                "code": "# ordinal representation of category_name\nuseless_data.append('db_subcategory_id')",
                "true_label": "",
                "top5_preds": [
                    "convert categorical variables",
                    "convert integer or float data",
                    "get a positive integer from a user",
                    "from dictionary to dataframe",
                    "convert data from string to float"
                ]
            },
            {
                "code": "# useless, future data\nuseless_data.append('static_usd_rate_end')",
                "true_label": "",
                "top5_preds": [
                    "line plots show the trend of a numerical variable over time",
                    "integrating datetime tools with pandas for time series",
                    "how to change the style of individual lines",
                    "introduction to the python datetime tools",
                    "getting data from the internet"
                ]
            },
            {
                "code": "df.loc[1, 'urls']",
                "true_label": "",
                "top5_preds": [
                    "load table in pandas",
                    "loading a csv into a dataframe",
                    "convert text data into vector",
                    "what is scikit learn?",
                    "retrieving data from html page"
                ]
            },
            {
                "code": "# useless\nuseless_data.append('urls')",
                "true_label": "",
                "top5_preds": [
                    "loading json in python",
                    "how to change the style of individual lines",
                    "getting data from the internet",
                    "add edges in graph",
                    "what is scikit learn?"
                ]
            },
            {
                "code": "# useless\nuseless_data.append('urls_end')",
                "true_label": "",
                "top5_preds": [
                    "how to change the style of individual lines",
                    "getting data from the internet",
                    "trend lines in pyplot",
                    "add edges in graph",
                    "add string to list using append"
                ]
            },
            {
                "code": "# useless for prediction but can serve for project identification so we will keep it\nstatic_data.append('url_name')",
                "true_label": "",
                "top5_preds": [
                    "getting data from the internet",
                    "load table in pandas",
                    "loading json in python",
                    "from dictionary to dataframe",
                    "twitter api access"
                ]
            },
            {
                "code": "df.spotlight.describe()",
                "true_label": "",
                "top5_preds": [
                    "line plots show the trend of a numerical variable over time",
                    "formatting datetimes as strings",
                    "spark dataframes",
                    "line plot with a dataframe",
                    "working with pandas series indexed by datetime"
                ]
            },
            {
                "code": "# always False\nuseless_data.append('spotlight')",
                "true_label": "",
                "top5_preds": [
                    "how to change the style of individual lines",
                    "counting triangles in a social network",
                    "line plots show the trend of a numerical variable over time",
                    "loading json in python",
                    "calculating the mean of a vector with nans"
                ]
            },
            {
                "code": "# future data\nuseless_data.append('spotlight_end')",
                "true_label": "",
                "top5_preds": [
                    "how to change the style of individual lines",
                    "line plots show the trend of a numerical variable over time",
                    "integrating datetime tools with pandas for time series",
                    "plot using matplotlib",
                    "trend lines in pyplot"
                ]
            },
            {
                "code": "static_data.append('location_name')",
                "true_label": "",
                "top5_preds": [
                    "loading json in python",
                    "getting data from the internet",
                    "using json to find your location",
                    "load table in pandas",
                    "from dictionary to dataframe"
                ]
            },
            {
                "code": "# useless\nuseless_data.append('name_end')",
                "true_label": "",
                "top5_preds": [
                    "how to change the style of individual lines",
                    "loading json in python",
                    "optimal value of k for dataset",
                    "add string to list using append",
                    "getting data from the internet"
                ]
            },
            {
                "code": "static_data.append('db_description_full')",
                "true_label": "",
                "top5_preds": [
                    "getting data from the internet",
                    "displaying the data",
                    "accessing databases via web apis",
                    "load table in pandas",
                    "get the names of all the tables in the database"
                ]
            },
            {
                "code": "dynamic_data.append('updates_likes_max_while_scraping')",
                "true_label": "",
                "top5_preds": [
                    "integrating datetime tools with pandas for time series",
                    "load table in pandas",
                    "line plots show the trend of a numerical variable over time",
                    "getting data from the internet",
                    "exploratory data analysis eda global properties"
                ]
            },
            {
                "code": "static_data.append('blurb')",
                "true_label": "",
                "top5_preds": [
                    "getting data from the internet",
                    "load table in pandas",
                    "how to change the style of individual lines",
                    "loading json in python",
                    "twitter application"
                ]
            }
        ],
        [
            {
                "code": "import json\n\nwith open('logins.json', 'r') as file:\n    logins = json.load(file)",
                "true_label": "",
                "top5_preds": [
                    "loading json in python",
                    "ipython notebook as json",
                    "using json to find your location",
                    "what is scikit learn?",
                    "getting data from the internet"
                ]
            },
            {
                "code": "import pandas as pd\nfrom matplotlib import pyplot as plt\n\ndf = pd.DataFrame.from_dict(logins)",
                "true_label": "",
                "top5_preds": [
                    "plot using pandas plotting",
                    "line plot with a dataframe",
                    "from dictionary to dataframe",
                    "using a dataframe and matplotlib commands",
                    "load table in pandas"
                ]
            },
            {
                "code": "df.head()",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "loading a csv into a dataframe",
                    "load table in pandas",
                    "create a one column dataframe with the values of a series",
                    "convert date to datetime format"
                ]
            },
            {
                "code": "df['login_time'] = pd.to_datetime(df['login_time'])\n\nfirst_login = df['login_time'].iloc[0]\n\nfirst_login",
                "true_label": "",
                "top5_preds": [
                    "convert date to datetime format",
                    "transform the date column as a datetime type",
                    "working with pandas series indexed by datetime",
                    "plotting time series with pandas",
                    "load table in pandas"
                ]
            },
            {
                "code": "df['time_since'] = df['login_time'] - first_login",
                "true_label": "",
                "top5_preds": [
                    "integrating datetime tools with pandas for time series",
                    "formatting datetimes as strings",
                    "load table in pandas",
                    "convert date to datetime format",
                    "line plots show the trend of a numerical variable over time"
                ]
            },
            {
                "code": "df.head(10)",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "loading a csv into a dataframe",
                    "optimal value of k for dataset",
                    "load table in pandas",
                    "using a dataframe and matplotlib commands"
                ]
            },
            {
                "code": "with open('ultimate_data_challenge.json', 'r') as file:\n    ultimate_data = json.load(file)",
                "true_label": "",
                "top5_preds": [
                    "loading json in python",
                    "using json to find your location",
                    "data given as a dictionary",
                    "parse time and visibility from json",
                    "getting data from the internet"
                ]
            },
            {
                "code": "udf = pd.DataFrame.from_dict(ultimate_data)\n\nudf.info()",
                "true_label": "",
                "top5_preds": [
                    "dataframe methods",
                    "from dictionary to dataframe",
                    "integrating datetime tools with pandas for time series",
                    "loading a csv into a dataframe",
                    "convert data from string to float"
                ]
            },
            {
                "code": "udf.head()",
                "true_label": "",
                "top5_preds": [
                    "import polynomial features from sklearn",
                    "join two dataframes along rows",
                    "loading a csv into a dataframe",
                    "formatting datetimes as strings",
                    "line plot with a dataframe"
                ]
            },
            {
                "code": "udf.groupby(['phone']).size()",
                "true_label": "",
                "top5_preds": [
                    "counting word frequency",
                    "from dictionary to dataframe",
                    "find data type of each column",
                    "line plot with a dataframe",
                    "transforming text into numbers"
                ]
            },
            {
                "code": "udf.describe()",
                "true_label": "",
                "top5_preds": [
                    "import polynomial features from sklearn",
                    "getting data from the internet",
                    "accessing databases via web apis",
                    "formatting datetimes as strings",
                    "importing data with numpy"
                ]
            },
            {
                "code": "udf['phone'] = udf['phone'].fillna('iPhone')\n\nudf['avg_rating_by_driver'] = udf['avg_rating_by_driver'].fillna(4.778158)\n\nudf['avg_rating_of_driver'] = udf['avg_rating_of_driver'].fillna(4.601559)\n\nudf.info()",
                "true_label": "",
                "top5_preds": [
                    "convert data from string to float",
                    "get a positive integer from a user",
                    "create a one column dataframe with the values of a series",
                    "create dataframe with given values",
                    "convert integer or float data"
                ]
            },
            {
                "code": "udf['last_trip_date'].sort_values(ascending = False)[0:10]\n#last data is from 7/1",
                "true_label": "",
                "top5_preds": [
                    "convert date to datetime format",
                    "formatting datetimes as strings",
                    "see last entries of dataset",
                    "sorting data",
                    "select every row after a specific row"
                ]
            },
            {
                "code": "udf['active'] = udf['last_trip_date'] >= '2014-06-02'",
                "true_label": "",
                "top5_preds": [
                    "integrating datetime tools with pandas for time series",
                    "convert date to datetime format",
                    "transform the date column as a datetime type",
                    "formatting datetimes as strings",
                    "line plots show the trend of a numerical variable over time"
                ]
            },
            {
                "code": "udf.head(10)",
                "true_label": "",
                "top5_preds": [
                    "import polynomial features from sklearn",
                    "use sklearn kfold",
                    "line plot with a dataframe",
                    "join two dataframes along rows",
                    "line plots show the trend of a numerical variable over time"
                ]
            },
            {
                "code": "udf.groupby('active').size()",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "from dictionary to dataframe",
                    "counting word frequency",
                    "predicting a categorical response",
                    "line plots show the trend of a numerical variable over time"
                ]
            },
            {
                "code": "active_by_city = udf.groupby('city')['active'].sum() / udf.groupby('city')['active'].size()\n\nactive_by_city = active_by_city.sort_values()\n_ = active_by_city.plot(kind = 'bar', rot = 0)\n_ = plt.xlabel(\"\")\n_ = plt.title(\"Proportion of users active by city\")\nplt.show()",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "ploting out data with box plots",
                    "predicting a categorical response",
                    "line plots show the trend of a numerical variable over time",
                    "pandas plotting"
                ]
            },
            {
                "code": "active_by_phone = udf.groupby('phone')['active'].sum() / udf.groupby('phone')['active'].size()\n\nactive_by_phone = active_by_phone.sort_values()\n_ = active_by_phone.plot(kind = 'bar', rot = 0)\n_ = plt.xlabel(\"\")\n_ = plt.title(\"Proportion of users active by type of phone\")\nplt.show()",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "predicting a categorical response",
                    "ploting out data with box plots",
                    "line plots show the trend of a numerical variable over time",
                    "sorting data"
                ]
            },
            {
                "code": "rating_by_active = udf.groupby('active')['avg_rating_of_driver'].sum() / udf.groupby('active')['avg_rating_of_driver'].size()\n\nrating_by_active",
                "true_label": "",
                "top5_preds": [
                    "get a positive integer from a user",
                    "predicting a categorical response",
                    "calculate average by group",
                    "convert data from string to float",
                    "groupby"
                ]
            },
            {
                "code": "driver_by_active = udf.groupby('active')['avg_rating_by_driver'].sum() / udf.groupby('active')['avg_rating_by_driver'].size()\n\ndriver_by_active",
                "true_label": "",
                "top5_preds": [
                    "calculate average by group",
                    "get a positive integer from a user",
                    "groupby",
                    "convert data from string to float",
                    "group by operator"
                ]
            },
            {
                "code": "surge_by_active = udf.groupby('active')['avg_surge'].sum() / udf.groupby('active')['avg_surge'].size()\n\nsurge_by_active",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "equally spaced numbers on a grid",
                    "survey",
                    "survey data",
                    "calculate the mean windspeed for each month in the dataset"
                ]
            },
            {
                "code": "weekday_by_active = udf.groupby('active')['weekday_pct'].sum() / udf.groupby('active')['weekday_pct'].size()\n\nweekday_by_active",
                "true_label": "",
                "top5_preds": [
                    "formatting datetimes as strings",
                    "convert date to datetime format",
                    "line plots show the trend of a numerical variable over time",
                    "line plot with a dataframe",
                    "groupby"
                ]
            },
            {
                "code": "from sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import classification_report\n\ndef cv_score(clf, x, y, score_func=accuracy_score):\n    result = 0\n    nfold = 5\n    for train, test in KFold(nfold, random_state = 42).split(x): # split data into train/test groups, 5 times\n        clf.fit(x[train], y.iloc[train]) # fit\n        result += score_func(clf.predict(x[test]), y.iloc[test]) # evaluate score function on held-out data\n    return result / nfold # average",
                "true_label": "",
                "top5_preds": [
                    "check accuracy / score for a logistic classifier",
                    "predicting a categorical response",
                    "use sklearn kfold",
                    "using the classify function",
                    "fit a polynomial"
                ]
            },
            {
                "code": "#convert categorial variables to boolean variable for classification\nudf['iPhone'] = (udf['phone'] == 'iPhone')\n\nudf = pd.concat([udf, pd.get_dummies(udf['city'])], axis=1)\nudf.head()",
                "true_label": "",
                "top5_preds": [
                    "convert categorical variables",
                    "transform categorical data into binary features",
                    "dataframe methods",
                    "from dictionary to dataframe",
                    "find data type of each column"
                ]
            },
            {
                "code": "variables = ['Astapor', 'King\\'s Landing', 'Winterfell', 'iPhone', 'avg_dist', 'avg_rating_by_driver', 'avg_rating_of_driver', 'surge_pct', 'avg_surge', \n        'trips_in_first_30_days', 'ultimate_black_user', 'weekday_pct']\n\nXtrain, Xtest, ytrain, ytest = train_test_split(udf[variables].values, udf['active'], random_state = 42, test_size = 0.2)\n\nlog_clf = LogisticRegression()\ncv_score(log_clf, Xtrain, ytrain)",
                "true_label": "",
                "top5_preds": [
                    "fit a polynomial",
                    "import polynomial features from sklearn",
                    "equally spaced numbers on a grid",
                    "load table in pandas",
                    "ridge regression with polynomial features on a grid"
                ]
            },
            {
                "code": "log_clf = LogisticRegression(class_weight = 'balanced')\n\nlog_clf.fit(Xtrain, ytrain)\nprint(classification_report(ytrain, log_clf.predict(Xtrain)))",
                "true_label": "",
                "top5_preds": [
                    "check accuracy / score for a logistic classifier",
                    "logistic regression using scikit learn",
                    "logistic regression using tensorflow",
                    "using logistic regression instead",
                    "multiclass logistic regression"
                ]
            },
            {
                "code": "from sklearn.ensemble import RandomForestClassifier\n\nrf_clf = RandomForestClassifier(random_state = 42, class_weight = 'balanced')\ncv_score(rf_clf, Xtrain, ytrain)",
                "true_label": "",
                "top5_preds": [
                    "what is scikit learn?",
                    "polynomial regression with sklearn",
                    "scikit learn",
                    "predicting a categorical response",
                    "use sklearn kfold"
                ]
            },
            {
                "code": "rf_clf = RandomForestClassifier(class_weight = 'balanced', random_state = 42)\n\nrf_clf.fit(Xtrain, ytrain)\nprint(classification_report(ytrain, rf_clf.predict(Xtrain)))",
                "true_label": "",
                "top5_preds": [
                    "polynomial regression with sklearn",
                    "what is scikit learn?",
                    "scikit learn",
                    "logistic regression using scikit learn",
                    "import polynomial features from sklearn"
                ]
            },
            {
                "code": "from sklearn.model_selection import GridSearchCV\n\nparam_grid = {'max_depth':[5,10,100,500], 'min_impurity_decrease':[1e-7,1e-6,1e-5, 1e-4, 1e-3, 1e-2]}\nrf_clf = RandomForestClassifier(class_weight = 'balanced')\nrf_clf_cv = GridSearchCV(rf_clf, param_grid, cv = 5)\nrf_clf_cv.fit(Xtrain, ytrain)\n\nprint(rf_clf_cv.best_params_)",
                "true_label": "",
                "top5_preds": [
                    "polynomial regression with sklearn",
                    "ridge regression with polynomial features on a grid",
                    "ridge regression with one predictor on a grid",
                    "scikit learn",
                    "what is scikit learn?"
                ]
            },
            {
                "code": "param_grid = {'max_depth':[50,100,150,250], 'min_impurity_decrease':[5e-5, 1e-5, 5e-4, 1e-4, 5e-3, 1e-3]}\nrf_clf = RandomForestClassifier(class_weight = 'balanced')\nrf_clf_cv = GridSearchCV(rf_clf, param_grid, cv = 5)\nrf_clf_cv.fit(Xtrain, ytrain)\n\nprint(rf_clf_cv.best_params_)",
                "true_label": "",
                "top5_preds": [
                    "ridge regression with polynomial features on a grid",
                    "ridge regression with one predictor on a grid",
                    "equally spaced numbers on a grid",
                    "polynomial regression with sklearn",
                    "predicting a continuous response using linear regression"
                ]
            },
            {
                "code": "rf_clf_tuned = RandomForestClassifier(max_depth = 50, min_impurity_decrease = 5e-05, class_weight = 'balanced', random_state = 42)\nprint(cv_score(rf_clf_tuned, Xtrain, ytrain))",
                "true_label": "",
                "top5_preds": [
                    "polynomial regression with sklearn",
                    "predicting a categorical response",
                    "what is scikit learn?",
                    "scikit learn",
                    "predicting a continuous response using linear regression"
                ]
            },
            {
                "code": "from sklearn.svm import SVC\n\nsv_clf = SVC(class_weight = 'balanced')\n\nsv_clf.fit(Xtrain, ytrain)\n\nprint(classification_report(ytrain, sv_clf.predict(Xtrain)))",
                "true_label": "",
                "top5_preds": [
                    "what is scikit learn?",
                    "predicting a continuous response using linear regression",
                    "scikit learn",
                    "polynomial regression with sklearn",
                    "import polynomial features from sklearn"
                ]
            },
            {
                "code": "sv_clf = SVC(class_weight = 'balanced')\nprint(cv_score(sv_clf, Xtrain, ytrain))",
                "true_label": "",
                "top5_preds": [
                    "what is scikit learn?",
                    "predicting a categorical response",
                    "predicting a continuous response using linear regression",
                    "polynomial regression with sklearn",
                    "scikit learn"
                ]
            },
            {
                "code": "df = df.sort_values(by = 'login_time')\ndf = df.reset_index(drop=True)\ndf.head(10)",
                "true_label": "",
                "top5_preds": [
                    "from dictionary to dataframe",
                    "loading a csv into a dataframe",
                    "load table in pandas",
                    "convert date to datetime format",
                    "formatting datetimes as strings"
                ]
            },
            {
                "code": "first_login = pd.to_datetime(df['login_time'].iloc[0])\n\nfirst_login",
                "true_label": "",
                "top5_preds": [
                    "convert date to datetime format",
                    "transform the date column as a datetime type",
                    "integrating datetime tools with pandas for time series",
                    "formatting datetimes as strings",
                    "load table in pandas"
                ]
            },
            {
                "code": "from datetime import timedelta\nd = timedelta(minutes = 15)\n\ndf['period'] = (df['time_since'] / d).astype(int)\ndf.head(20)",
                "true_label": "",
                "top5_preds": [
                    "convert date to datetime format",
                    "formatting datetimes as strings",
                    "plotting time series with pandas",
                    "integrating datetime tools with pandas for time series",
                    "transform the date column as a datetime type"
                ]
            },
            {
                "code": "df['timeofday'] = (df['period'] % 96) * d\n#df['timeofday'] = pd.to_datetime(df['timeofday'])\ndf.head(20)",
                "true_label": "",
                "top5_preds": [
                    "convert date to datetime format",
                    "plotting time series with pandas",
                    "formatting datetimes as strings",
                    "integrating datetime tools with pandas for time series",
                    "transform the date column as a datetime type"
                ]
            },
            {
                "code": "number_logins = df.groupby(['period']).size()\nplt.plot(number_logins)\nplt.title(\"Number of logins by 15-minute interval\")\nplt.show()",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "line plots show the trend of a numerical variable over time",
                    "plotting time series with pandas",
                    "ploting out data with box plots",
                    "likelihood of the binomial distribution"
                ]
            },
            {
                "code": "logins_by_time = df.groupby(['timeofday']).size()\nlogins_by_time.plot(kind='line', rot = 50)\nplt.title(\"Total number of logins by time of day\")\nplt.show()",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "ploting out data with box plots",
                    "line plots show the trend of a numerical variable over time",
                    "plotting time series with pandas",
                    "pandas plotting"
                ]
            },
            {
                "code": "df['day'] = (df['time_since'] / timedelta(days = 1)).astype(int)\nlogins_by_day = df.groupby(['day']).size()\nlogins_by_day.plot(kind='line', rot = 50)\nplt.title(\"Total number of logins by day\")\nplt.show()",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "line plots show the trend of a numerical variable over time",
                    "ploting out data with box plots",
                    "plotting time series with pandas",
                    "integrating datetime tools with pandas for time series"
                ]
            },
            {
                "code": "df['dayofweek'] = (df['day'] + 4) % 7\n#weekdays = {0:\"Sunday\", 1:\"Monday\", 2:\"Tuesday\", 3:\"Wednesday\", 4: \"Thursday\", 5:\"Friday\", 6:\"Saturday\"}\n#df['dayofweek'].replace(weekdays, inplace=True)",
                "true_label": "",
                "top5_preds": [
                    "convert date to datetime format",
                    "plotting time series with pandas",
                    "create a one column dataframe with the values of a series",
                    "create dataframe with given values",
                    "line plot with a dataframe"
                ]
            },
            {
                "code": "logins_by_weekday = df.groupby(['dayofweek']).size()\nlogins_by_weekday.plot(kind='bar', rot = 50)\nplt.title(\"Total number of logins by day of week\")\nplt.show()",
                "true_label": "",
                "top5_preds": [
                    "ploting out data with box plots",
                    "line plot with a dataframe",
                    "plot histogram",
                    "plotting time series with pandas",
                    "pandas plotting"
                ]
            },
            {
                "code": "rf_clf_tuned = RandomForestClassifier(max_depth = 50, min_impurity_decrease = 5e-05, class_weight = 'balanced', random_state = 42)\nrf_clf_tuned.fit(Xtrain, ytrain)\nprint(classification_report(ytest, rf_clf_tuned.predict(Xtest)))\nprint(accuracy_score(ytest, rf_clf_tuned.predict(Xtest)))",
                "true_label": "",
                "top5_preds": [
                    "check accuracy / score for a logistic classifier",
                    "predicting a categorical response",
                    "using the classify function",
                    "what is scikit learn?",
                    "polynomial regression with sklearn"
                ]
            },
            {
                "code": "param_grid = {'max_depth':[50,100,150,250], 'min_impurity_decrease':[5e-5, 1e-5, 5e-4, 1e-4, 5e-3, 1e-3]}\nrf_clf = RandomForestClassifier(class_weight = 'balanced')\nrf_clf_cv = GridSearchCV(rf_clf, param_grid, cv = 5)\nrf_clf_cv.fit(Xtrain, ytrain)\n\nprint(rf_clf_cv.best_params_)",
                "true_label": "",
                "top5_preds": [
                    "ridge regression with polynomial features on a grid",
                    "ridge regression with one predictor on a grid",
                    "equally spaced numbers on a grid",
                    "polynomial regression with sklearn",
                    "predicting a continuous response using linear regression"
                ]
            }
        ],
        [
            {
                "code": "import os\nimport requests\n\nr = requests.get('http://www.bom.gov.au/water/hrs/content/config/site_config.json')\nhrs_metadata = r.json()\n\nfor station in hrs_metadata['stations']['features']:\n    station_id = station['properties']['AWRC_ID']\n    filename = '{0}_daily_ts.csv'.format(station_id)\n\n    url = \"http://www.bom.gov.au/water/hrs/content/data/{0}/{1}\".format(station_id, filename)\n\n    print(\"Downloading: {0}\".format(url))\n    \n    csv_response = requests.get(url)\n    with open(os.path.join('hrs_data', filename), 'w') as f:\n        f.write(csv_response.text)\n        ",
                "true_label": "",
                "top5_preds": [
                    "loading json in python",
                    "download and inspect the twitter samples dataset",
                    "getting data from the internet",
                    "using json to find your location",
                    "twitter api access"
                ]
            },
            {
                "code": "import os\nimport datetime\nimport pandas as pd",
                "true_label": "",
                "top5_preds": [
                    "convert date to datetime format",
                    "formatting datetimes as strings",
                    "importing data with numpy",
                    "convert list to numpy array",
                    "integrating datetime tools with pandas for time series"
                ]
            },
            {
                "code": "from phildb.create import create\ncreate('hrs_db')",
                "true_label": "",
                "top5_preds": [
                    "running a local postgres database",
                    "postgres sql lab",
                    "sqlalchemy, sqlite, and dates",
                    "accessing databases via web apis",
                    "mongodb"
                ]
            },
            {
                "code": "from phildb.database import PhilDB\ndb = PhilDB('hrs_db')",
                "true_label": "",
                "top5_preds": [
                    "postgres sql lab",
                    "running a local postgres database",
                    "mongodb",
                    "sqlalchemy, sqlite, and dates",
                    "accessing databases via web apis"
                ]
            },
            {
                "code": "db.add_measurand('Q', 'STREAMFLOW', 'Streamflow')\ndb.add_source('BOM_HRS', 'Bureau of Meteorology; Hydrological Reference Stations dataset.')",
                "true_label": "",
                "top5_preds": [
                    "exploring the database with sql",
                    "accessing databases via web apis",
                    "exploring the database",
                    "sqlalchemy, sqlite, and dates",
                    "postgres sql lab"
                ]
            },
            {
                "code": "freq = 'D'\nhrs_header_len = 18",
                "true_label": "",
                "top5_preds": [
                    "convert date to datetime format",
                    "formatting datetimes as strings",
                    "date ranges and frequencies",
                    "equally spaced numbers on a grid",
                    "reading and writing binary files"
                ]
            },
            {
                "code": "def read_hrs_series(filename):\n    with open(filename) as datafile:\n        header=[next(datafile) for x in range(hrs_header_len)]\n        header = ''.join(header)\n        df = pd.read_csv(filename, parse_dates=True, index_col='Date', skiprows=hrs_header_len)\n\n        return header, df['Q']",
                "true_label": "",
                "top5_preds": [
                    "read the dataset",
                    "helpers to read in dataset",
                    "read table",
                    "read the dataset point",
                    "read data point"
                ]
            },
            {
                "code": "datafiles = [ f for f in os.listdir('hrs_data') if f.endswith('_daily_ts.csv')]",
                "true_label": "",
                "top5_preds": [
                    "formatting datetimes as strings",
                    "convert date to datetime format",
                    "reading in the files",
                    "load table in pandas",
                    "equally spaced numbers on a grid"
                ]
            }
        ],
        [
            {
                "code": "import io\nimport re\nimport networkx as nx\nimport matplotlib.pyplot as plt\nfrom networkx.algorithms import bipartite\nimport numpy as np\nimport random as rm\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport io\n\nmoviedata = pd.read_csv('moviedata.csv')\nlinklist = []\nnodes = []\nmovie_nodes = []\nmovie_links = []\n\n#First round of processing, data is sorted to movie and actor nodes respectively\nfor index, row in moviedata.iterrows():\n    movie_nodes.append(row.Title)\n    \n    for j in list(row.Actors.replace(\", \",\",\").split(\",\")):\n        nodes.append(j)\n        movie_links.append((row.Title,j))\n        for n in list(row.Actors.replace(\", \",\",\").split(\",\")):\n            linklist.append((j,n))\n\n#If a movie shares an actor with another movie, this connects the movies \np_movie_links = []\nfor i in movie_links:\n    for j in movie_links:\n        if(i[1] == j[1]):\n            p_movie_links.append((i[0],j[0]))\n\n#Removes doublicates from actor links\nnodes = list(set(nodes))\nG = nx.DiGraph()\nG.add_edges_from(linklist)\nlinklist = [i for i in linklist if i not in G.selfloop_edges()]\nG.remove_edges_from(G.selfloop_edges())\n\n#Print sizes:\nprint(len(nodes))\nprint(len(linklist))\n\nprint(len(movie_nodes))\nprint(len(p_movie_links))",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "polynomial regression with sklearn",
                    "counting triangles in a social network",
                    "importing data with numpy",
                    "plot using matplotlib"
                ]
            },
            {
                "code": "#Plot actor connectivity\nd=G.degree()\nplt.figure(1,figsize=(30,30))\npos=nx.spring_layout(G,k=20/(G.number_of_nodes()**0.5))\nnx.draw(G, with_labels = True, node_size=[v[1] * 20 for v in d],font_size=6,pos=pos,edge_color='grey',node_color='#A0CBE2')\nplt.show()",
                "true_label": "",
                "top5_preds": [
                    "graph",
                    "add edges in graph",
                    "equally spaced numbers on a grid",
                    "counting triangles in a social network",
                    "line plot with a dataframe"
                ]
            },
            {
                "code": "from fa2 import ForceAtlas2\n\nG_und = G.to_undirected()\ndict(G_und.degree()).values()\nforceatlas2 = ForceAtlas2(\n                          # Behavior alternatives\n                          outboundAttractionDistribution=False,  # Dissuade hubs\n                          linLogMode=False,  # NOT IMPLEMENTED\n                          adjustSizes=False,  # Prevent overlap (NOT IMPLEMENTED)\n                          edgeWeightInfluence=1.0,\n\n                          # Performance\n                          jitterTolerance=1.0,  # Tolerance\n                          barnesHutOptimize=True,\n                          barnesHutTheta=1.2,\n                          multiThreaded=False,  # NOT IMPLEMENTED\n\n                          # Tuning\n                          scalingRatio=2.0,\n                          strongGravityMode=False,\n                          gravity=20.0,\n\n                          # Log\n                          verbose=True)\n\npositions = forceatlas2.forceatlas2_networkx_layout(G_und, pos=None, iterations=100)",
                "true_label": "",
                "top5_preds": [
                    "traffic sign classification with keras",
                    "co variance matrix",
                    "add edges in graph",
                    "attributes of geometries points",
                    "scipy"
                ]
            },
            {
                "code": "#Create figure:\nplt.figure(figsize=(14,14))\nnx.draw_networkx(G_und, pos=positions,with_labels=False, front_weight='bold',node_size=[6*i for i in dict(G_und.degree()).values()])\nplt.xlim(-1450,1450)\nplt.ylim(-1450,1450)\nplt.axis('off')\nplt.show()",
                "true_label": "",
                "top5_preds": [
                    "create a graph",
                    "graph",
                    "add edges in graph",
                    "equally spaced numbers on a grid",
                    "counting triangles in a social network"
                ]
            },
            {
                "code": "#Convert the plot sections from a list of strings to one string\nmovie_6_8_plots1=\"\".join(movie_6_8_plots)\n\n#processing\n\n#Tokenization & remove all \".\"s and \\d's\nprint(len(movie_6_8_plots1))\n#Remove newlines\nmovie_6_8_plots1= movie_6_8_plots1.replace('\\\\n',\" \").replace('.','')\nprint(len(movie_6_8_plots1))\n\ntokenizer = RegexpTokenizer(r'\\w+')\nmovie_6_8_plots1_tokens = tokenizer.tokenize(movie_6_8_plots1)\nprint(len(movie_6_8_plots1))\n\n#Remove stop words & lower\nstopset = set(stopwords.words('english'))\nmovie_6_8_plots1_tokens = [w for w in movie_6_8_plots1_tokens if not w in stopset]\n\nprint(len(movie_6_8_plots1_tokens))\nprint(len(set(movie_6_8_plots1_tokens)))\n\n#calculate the tf and idf of every word:\nimport math\nfrom collections import Counter\n\n#get the unique words:\nplot_unique_words = set(movie_6_8_plots1_tokens)\n\nplot_counts = Counter(movie_6_8_plots1_tokens)\nindex = 0 \ntf_idf_plot = []\nfor n in plot_unique_words.union(plot_unique_words):\n    n_t = 0\n    if n in plot_unique_words:\n        n_t = n_t+1\n        \n    word_idf = math.log10(2/n_t)    \n\n    tf_idf_plot.append((n, plot_counts[n]*word_idf))\n    \n    \n# word cloud\n\nsortedlist = sorted(tf_idf_plot, key = lambda x: x[1], reverse =True)\ntext = \"\"\nfor i in range(100):\n    text = text + int(sortedlist[i][1])*(sortedlist[i][0] + \" \")\nwc = WordCloud(background_color=\"white\", max_words=300, collocations = False)\nwc.generate(text)\n\n# Show\nplt.figure(figsize=(15,10))\nplt.title(\"Movies Rated 6-8\")\nplt.imshow(wc, interpolation='bilinear')\nplt.axis(\"off\")\nplt.show() ",
                "true_label": "",
                "top5_preds": [
                    "formatting datetimes as strings",
                    "convert date to datetime format",
                    "trend lines in pyplot",
                    "transforming text into numbers",
                    "remove duplicates from a list"
                ]
            },
            {
                "code": "#Convert the plot sections from a list of strings to one string\nmovie_8_10_plots1=\"\".join(movie_8_10_plots)\n\n#processing\n\n#Tokenization & remove all \".\"s and \\d's\nprint(len(movie_8_10_plots1))\n#Remove newlines\nmovie_8_10_plots1= movie_8_10_plots1.replace('\\\\n',\" \").replace('.','')\nprint(len(movie_8_10_plots1))\n\ntokenizer = RegexpTokenizer(r'\\w+')\nmovie_8_10_plots1_tokens = tokenizer.tokenize(movie_8_10_plots1)\nprint(len(movie_8_10_plots1))\n\n#Remove stop words & lower\nstopset = set(stopwords.words('english'))\nmovie_8_10_plots1_tokens = [w for w in movie_8_10_plots1_tokens if not w in stopset]\n\nprint(len(movie_8_10_plots1_tokens))\nprint(len(set(movie_8_10_plots1_tokens)))\n\n#calculate the tf and idf of every word:\n\n#get the unique words:\nplot_unique_words = set(movie_8_10_plots1_tokens)\n\nplot_counts = Counter(movie_8_10_plots1_tokens)\nindex = 0 \ntf_idf_plot = []\nfor n in plot_unique_words.union(plot_unique_words):\n    n_t = 0\n    if n in plot_unique_words:\n        n_t = n_t+1\n        \n    word_idf = math.log10(2/n_t)    \n\n    tf_idf_plot.append((n, plot_counts[n]*word_idf))\n    \n    \n# word cloud\n\nsortedlist = sorted(tf_idf_plot, key = lambda x: x[1], reverse =True)\ntext = \"\"\nfor i in range(100):\n    text = text + int(sortedlist[i][1])*(sortedlist[i][0] + \" \")\nwc = WordCloud(background_color=\"white\", max_words=300, collocations = False)\nwc.generate(text)\n\n# Show\nplt.figure(figsize=(15,10))\nplt.title(\"Movies Rated 8-10\")\nplt.imshow(wc, interpolation='bilinear')\nplt.axis(\"off\")\nplt.show() ",
                "true_label": "",
                "top5_preds": [
                    "formatting datetimes as strings",
                    "convert date to datetime format",
                    "transforming text into numbers",
                    "remove duplicates from a list",
                    "trend lines in pyplot"
                ]
            },
            {
                "code": "#Look at movies with rating above 7 only\npopularmovie_casts=[]\nfor index, row in movies.iterrows():\n    \n    film=movies.Title[index]+' ('+str(movies.Year[index])+' film)'\n    if movies.Rating[index]>7:\n        \n        \n\n        try:\n            # get the section of a page. In this case the Cast description \n            section = wikipedia.WikipediaPage(film).section('Cast')\n\n            # that will return fairly clean text, but the next line of code\n            # will help clean that up.\n            section = section.replace('\\n','').replace(\"\\'\",\"\")\n            popularmovie_casts.append(section)\n\n        except:\n            try: \n                film=movies.Title[index]+' (film)'\n                section = wikipedia.WikipediaPage(film).section('Cast')\n\n                section = section.replace('\\n','').replace(\"\\'\",\"\")\n                popularmovie_casts.append(section)\n\n                #Skip movie if it doesnt findt it \n\n            except:   \n                try: \n                    film=movies.Title[index]\n                    \n                    section = wikipedia.WikipediaPage(film).section('Cast')\n\n                    section = section.replace('\\n','').replace(\"\\'\",\"\")\n                    popularmovie_casts.append(section)\n\n                except:\n                    try: \n                        film=movies.Title[index]+' ('+str(movies.Year[index])+' American film)'\n                        section = wikipedia.WikipediaPage(film).section('Cast')\n\n                        section = section.replace('\\n','').replace(\"\\'\",\"\")\n                        popularmovie_cassts.append(section)\n\n                    except:\n                        pass\n",
                "true_label": "",
                "top5_preds": [
                    "vectorize words in movie reviews",
                    "predicting a categorical response",
                    "find maximum and the minimum value in a set",
                    "queries about movies",
                    "ploting out data with box plots"
                ]
            },
            {
                "code": "#Look at movies with ratings less than 6only\nunpopularmovie_casts=[]\nfor index, row in movies.iterrows():\n    #print(index)\n    film=movies.Title[index]+' ('+str(movies.Year[index])+' film)'\n    if movies.Rating[index]<6:\n        \n        #print(film)\n\n        try:\n            # get the section of a page. In this case the Cast description \n            section = wikipedia.WikipediaPage(film).section('Cast')\n\n            section = section.replace('\\n','').replace(\"\\'\",\"\")\n            unpopularmovie_casts.append(section)\n\n        except:\n            try: \n                film=movies.Title[index]+' (film)'\n                section = wikipedia.WikipediaPage(film).section('Cast')\n\n                section = section.replace('\\n','').replace(\"\\'\",\"\")\n                unpopularmovie_casts.append(section)\n\n                #Skip movie if it doesnt findt it \n\n            except:   \n                try: \n                    film=movies.Title[index]\n                    section = wikipedia.WikipediaPage(film).section('Cast')\n\n                    section = section.replace('\\n','').replace(\"\\'\",\"\")\n                    unpopularmovie_casts.append(section)\n\n                except:\n                    try: \n                        film=movies.Title[index]+' ('+str(movies.Year[index])+' American film)'\n                        section = wikipedia.WikipediaPage(film).section('Cast')\n\n                        section = section.replace('\\n','').replace(\"\\'\",\"\")\n                        unpopularmovie_cassts.append(section)\n\n                    except:\n                        pass\n",
                "true_label": "",
                "top5_preds": [
                    "optimal value of k for dataset",
                    "predicting a categorical response",
                    "queries about movies",
                    "vectorize words in movie reviews",
                    "find maximum and the minimum value in a set"
                ]
            },
            {
                "code": "#Convert the cast of popularmovies from a list of strings to one string\ncast1=\"\".join(popularmovie_casts)",
                "true_label": "",
                "top5_preds": [
                    "create a list of all words",
                    "convert a tuple to a string",
                    "add string to list using append",
                    "converting to and from strings",
                    "sum all the numbers in a list"
                ]
            },
            {
                "code": "#processing\n\n#Tokenization & remove all \".\"s and \\d's\nprint(len(cast1))\n#Remove newlines\ncast1= cast1.replace('\\\\n',\" \").replace('.','')\nprint(len(cast1))\n\ntokenizer = RegexpTokenizer(r'\\w+')\ncast_tokens = tokenizer.tokenize(cast1)\nprint(len(cast_tokens))\n\n#Remove stop words & lower\nstopset = set(stopwords.words('english'))\ncast_tokens = [w for w in cast_tokens if not w in stopset]\n\nprint(len(cast_tokens))\nprint(len(set(cast_tokens)))\n\n#calculate the tf and idf of every word:\n\n#get the unique words:\ncast_unique_words = set(cast_tokens)\n\ncast_counts = Counter(cast_tokens)\nindex = 0 \ntf_idf_cast = []\nfor n in cast_unique_words.union(cast_unique_words):\n    n_t = 0\n    if n in cast_unique_words:\n        n_t = n_t+1\n        \n    word_idf = math.log10(2/n_t)    \n\n    tf_idf_cast.append((n, cast_counts[n]*word_idf))\n\n#word cloud\nfrom PIL import Image\nfrom wordcloud import WordCloud\n\nsortedlist = sorted(tf_idf_cast, key = lambda x: x[1], reverse =True)\ntext = \"\"\nfor i in range(100):\n    text = text + int(sortedlist[i][1])*(sortedlist[i][0] + \" \")\nwc = WordCloud(background_color=\"white\", max_words=300, collocations = False)\nwc.generate(text)\n\n# Show\nplt.figure(figsize=(15,10))\nplt.imshow(wc, interpolation='bilinear')\nplt.axis(\"off\")\nplt.show() ",
                "true_label": "",
                "top5_preds": [
                    "formatting datetimes as strings",
                    "tokenization, stop words, punctuation",
                    "transforming text into numbers",
                    "convert date to datetime format",
                    "exploring regex"
                ]
            },
            {
                "code": "#Find the partition and print the modularity\nimport community\n#first compute the best partition\npartition = community.best_partition(G_und)\nprint(community.modularity(partition,G_und))",
                "true_label": "",
                "top5_preds": [
                    "ridge regression with polynomial features on a grid",
                    "fit a polynomial",
                    "ridge regression with one predictor on a grid",
                    "equally spaced numbers on a grid",
                    "import polynomial features from sklearn"
                ]
            },
            {
                "code": "#Generate colors:\nimport random\n\nCOLORS = [(139, 0, 0), \n          (0, 100, 0),\n          (0, 0, 139)]\n\ndef random_color():\n    return random.choice(COLORS)\n\n#begin figure\nplt.figure(figsize=(14,14))\nplt.xlim(-1450,1450)\nplt.ylim(-1450,1450)\nplt.axis('off')\n#Create communities graph:\ncount = 0.\nfor com in set(partition.values()) :\n    count = count + 1.\n    list_nodes = [nodes for nodes in partition.keys()\n                                if partition[nodes] == com]\n    nx.draw_networkx_nodes(G_und, positions, list_nodes, node_size = 20,\n                                node_color = np.random.rand(1,4))\n\n\nnx.draw_networkx_edges(G_und,positions, alpha=0.5)\nplt.show()",
                "true_label": "",
                "top5_preds": [
                    "plot using matplotlib",
                    "how to change the color of a plot",
                    "create a scatter plot",
                    "create a line plot",
                    "heatmap with time"
                ]
            },
            {
                "code": "import prettytable # Requires pip install prettytable in the conda console \n\n#prints the community matrix\nc_matrix = []\nfor com in set(partition.values()):\n    list_nodes = [nodes for nodes in partition.keys() if partition[nodes] == com]\n    c_matrix.append([com,len(list_nodes)])\n\nx = prettytable.PrettyTable([\"Community:\",\"Count\"])\n\nfor n in c_matrix:    \n    x.add_row([n[0], n[1]])\n\nprint(x)",
                "true_label": "",
                "top5_preds": [
                    "remove duplicates from a list",
                    "equally spaced numbers on a grid",
                    "co variance matrix",
                    "matrix matrix multiplication",
                    "relationships between dataframes"
                ]
            },
            {
                "code": "G_m = nx.DiGraph()\n\n\n#Set node attributes\nfor i in movie_nodes:\n    n = moviedata.loc[moviedata['Title'] == i]\n    G_m.add_node(i, attr_dict = {'Rating' : n.Rating.astype(float),'Income' : n.Revenue.astype(float),'Score': n.Metascore, 'Votes':n.Votes})\n\n#Remove doublicates\nG_m.add_edges_from(p_movie_links)\nG_m.remove_edges_from(G_m.selfloop_edges())\nG_und_m = G_m.to_undirected()\n\n#Generate colors:\ncols = []\nfor i in G_und_m.nodes():\n    try:\n        if int(G_m.node[i]['attr_dict']['Rating']) >= 8:\n            cols.append('#32CD32');\n        elif int(G_m.node[i]['attr_dict']['Rating']) >= 7:\n            cols.append('#98FB98')\n        elif int(G_m.node[i]['attr_dict']['Rating']) >= 6: \n            cols.append('#ffff00')\n        else: \n            cols.append('#ff0000')\n    except:\n        cols.append('#ff0000')\n\n\npositions_m = forceatlas2.forceatlas2_networkx_layout(G_und_m, pos=None, iterations=200)\n    \n#Create movie figure:\nplt.figure(figsize=(14,14))\nnx.draw_networkx(G_und_m, pos=positions_m,with_labels=False, front_weight='bold',node_size=30,node_color=cols)\nplt.xlim(-1450,1450)\nplt.ylim(-1450,1450)\nplt.axis('off')\nplt.show()",
                "true_label": "",
                "top5_preds": [
                    "create a graph",
                    "add edges in graph",
                    "graph",
                    "relationships between dataframes",
                    "line plot with a dataframe"
                ]
            },
            {
                "code": "#Create movie figure:\nplt.figure(figsize=(14,14))\nnx.draw_networkx(G_und_m, pos=positions_m,with_labels=False, front_weight='bold',node_size=[6*i for i in dict(G_und_m.degree()).values()],node_color=cols)\nplt.xlim(-1450,1450)\nplt.ylim(-1450,1450)\nplt.axis('off')\nplt.show()",
                "true_label": "",
                "top5_preds": [
                    "create a graph",
                    "graph",
                    "plot using matplotlib",
                    "polynomial regression with sklearn",
                    "add edges in graph"
                ]
            },
            {
                "code": "#print degree distribution for movie plot\ndegree_sequence = sorted([d for n, d in G_und_m.degree()], reverse=True)\ndegreeCount = collections.Counter(degree_sequence)\ndeg, cnt = zip(*degreeCount.items())\n\nfig, ax = plt.subplots()\nplt.bar(deg, cnt, width=0.80, color='b')\n\nplt.title(\"Degree Histogram\")\nplt.ylabel(\"Count\")\nplt.xlabel(\"Degree\")\nplt.show()",
                "true_label": "",
                "top5_preds": [
                    "predicting a categorical response",
                    "line plots show the trend of a numerical variable over time",
                    "counting triangles in a social network",
                    "line plot with a dataframe",
                    "equally spaced numbers on a grid"
                ]
            },
            {
                "code": "#Create linear distribution plot and loglog\nmaxd = max([int(j) for i,j in G_und_m.degree()])\nmind = min([int(j) for i,j in G_und_m.degree()])\ndegreeslist = [int(j) for i,j in G_und_m.degree()]\nhist, binList = np.histogram(degreeslist, maxd)\nplt.plot((binList[1:]+binList[:-1]),hist, 'o', mfc='none')\nplt.title(\"Linear distribution plot\")\nplt.ylabel('count')\nplt.xlabel(\"Degree\")\nplt.show()\n#Generate log-log plot\nplt.loglog((binList[1:]+binList[:-1]),hist, 'o', mfc='none')\nplt.title(\"Log-Log distribution plot\")\nplt.xlabel('k')\nplt.ylabel('count')\nplt.show()",
                "true_label": "",
                "top5_preds": [
                    "likelihood of the binomial distribution",
                    "ridge regression with polynomial features on a grid",
                    "likelihood of the binomial",
                    "ridge regression with one predictor on a grid",
                    "maximum likelihood estimate of the binomial"
                ]
            },
            {
                "code": "#Ratings histogram\nplt.ylabel('count')\nplt.xlabel(\"Rating\")\nplt.hist(moviedata.Rating)",
                "true_label": "",
                "top5_preds": [
                    "line plots show the trend of a numerical variable over time",
                    "plot histogram",
                    "ploting out data with box plots",
                    "predicting a categorical response",
                    "plotting time series with pandas"
                ]
            },
            {
                "code": "#Create where income determines node size, and colors are rating:\nnode_size = []\nfor i in G_und_m.nodes():\n    try:\n        node_size.append(int(G_m.node[i]['attr_dict']['Income']))\n    except:\n        node_size.append(0)\n\nplt.figure(figsize=(14,14))\nnx.draw_networkx(G_und_m, pos=positions_m,with_labels=False, front_weight='bold',node_size=node_size,node_color=cols)\nplt.xlim(-1450,1450)\nplt.ylim(-1450,1450)\nplt.axis('off')\nplt.show()",
                "true_label": "",
                "top5_preds": [
                    "create a graph",
                    "graph",
                    "get a positive integer from a user",
                    "line plot with a dataframe",
                    "predicting a categorical response"
                ]
            },
            {
                "code": "#Plot the movie earnings\nplt.figure(figsize=(6,6))\nplt.ylabel(\"Earnings in mil\")\nplt.xlabel(\"Rating\")\nplt.hist(node_size)",
                "true_label": "",
                "top5_preds": [
                    "plot using matplotlib",
                    "line plots show the trend of a numerical variable over time",
                    "plot histogram",
                    "plotting time series with pandas",
                    "ploting out data with box plots"
                ]
            },
            {
                "code": "#Create eigenvector graph\nplt.figure(figsize=(14,14))\nbet_eig = nx.eigenvector_centrality(G)\nnx.draw_networkx(G_und, pos=positions,with_labels=False, front_weight='bold',node_size=[bet_eig[i]*2000 for i in G_und.nodes()])\nplt.xlim(-1450,1450)\nplt.ylim(-1450,1450)\nplt.axis('off')\nplt.show()",
                "true_label": "",
                "top5_preds": [
                    "graph",
                    "equally spaced numbers on a grid",
                    "add edges in graph",
                    "create a graph",
                    "counting triangles in a social network"
                ]
            },
            {
                "code": "#Create Betweenness graph:\nplt.figure(figsize=(14,14))\nbet = nx.betweenness_centrality(G)\nnx.draw_networkx(G_und, pos=positions,with_labels=False, front_weight='bold',node_size=[bet[i]*6000 for i in G_und.nodes()])\nplt.xlim(-1450,1450)\nplt.ylim(-1450,1450)\nplt.axis('off')\nplt.show()",
                "true_label": "",
                "top5_preds": [
                    "add edges in graph",
                    "equally spaced numbers on a grid",
                    "counting triangles in a social network",
                    "graph",
                    "create a graph"
                ]
            },
            {
                "code": "#plot movie rating vs earning:\nplt.figure(figsize=(6,6))\nplt.title(\"Rating vs revenue\")\nplt.ylabel(\"Earnings in mil\")\nplt.xlabel(\"Rating\")\nplt.plot(moviedata.Rating,moviedata.Revenue,\"o\")",
                "true_label": "",
                "top5_preds": [
                    "line plots show the trend of a numerical variable over time",
                    "plot using matplotlib",
                    "line plot with a dataframe",
                    "plotting in python",
                    "plotting time series with pandas"
                ]
            },
            {
                "code": "#Convert the casts of unpopularmove from a list of strings to one string\ncast1=\"\".join(unpopularmovie_casts)",
                "true_label": "",
                "top5_preds": [
                    "create a list of all words",
                    "add string to list using append",
                    "formatting datetimes as strings",
                    "convert a tuple to a string",
                    "converting to and from strings"
                ]
            },
            {
                "code": "#processing\n#Tokenization & remove all \".\"s and \\d's\nprint(len(cast1))\n#Remove newlines\ncast1= cast1.replace('\\\\n',\" \").replace('.','')\nprint(len(cast1))\n\ntokenizer = RegexpTokenizer(r'\\w+')\ncast_tokens = tokenizer.tokenize(cast1)\nprint(len(cast_tokens))\n\n#Remove stop words & lower\nstopset = set(stopwords.words('english'))\ncast_tokens = [w for w in cast_tokens if not w in stopset]\n\nprint(len(cast_tokens))\nprint(len(set(cast_tokens)))\n\n\n#calculate the tf and idf of every word:\n\n\n#get the unique words:\ncast_unique_words = set(cast_tokens)\n\ncast_counts = Counter(cast_tokens)\nindex = 0 \ntf_idf_cast = []\nfor n in cast_unique_words.union(cast_unique_words):\n    n_t = 0\n    if n in cast_unique_words:\n        n_t = n_t+1\n        \n    word_idf = math.log10(2/n_t)    \n\n    tf_idf_cast.append((n, cast_counts[n]*word_idf))\n\n#word cloud\n\nsortedlist = sorted(tf_idf_cast, key = lambda x: x[1], reverse =True)\ntext = \"\"\nfor i in range(100):\n    text = text + int(sortedlist[i][1])*(sortedlist[i][0] + \" \")\nwc = WordCloud(background_color=\"white\", max_words=300, collocations = False)\nwc.generate(text)\n\n# Show\nplt.figure(figsize=(15,10))\nplt.imshow(wc, interpolation='bilinear')\nplt.axis(\"off\")\nplt.show() ",
                "true_label": "",
                "top5_preds": [
                    "formatting datetimes as strings",
                    "tokenization, stop words, punctuation",
                    "transforming text into numbers",
                    "convert date to datetime format",
                    "exploring regex"
                ]
            },
            {
                "code": "import nltk\n#Set the path for the Data Set S1 txt file from Lab MT\npath = 'sentimentWords.TXT'\nheader = ['word', 'hapiness_rank', 'happiness_average', 'hapiness_standard_deviation', 'twitter_rank', 'google_rank', 'nyt_rank', 'lyrics_rank']\nhappy_data = pd.read_csv(path, delimiter='\\t',skiprows=3)\nhappinessDict = dictionary = dict(zip(happy_data.word, happy_data.happiness_average))\n\n#function that calculates sentiment\n\ndef how_happy(tokens):# Given tokens return happines\n    \n    happiness_counter=[]\n    for word in tokens:\n        word = word.lower()\n                \n        happiness_word=happinessDict.get(word,0)\n        if happiness_word != 0:\n            happiness_counter.append(happiness_word)\n    \n    \n    happiness_counter=np.mean(happiness_counter)\n    return happiness_counter\n",
                "true_label": "",
                "top5_preds": [
                    "importing data with numpy",
                    "load table in pandas",
                    "import polynomial features from sklearn",
                    "reading in the files",
                    "what is scikit learn?"
                ]
            },
            {
                "code": "popularmovie_plots=movie_8_10_plots+movie_6_8_plots\n\n\nsentiment_popularmovie_plot=[]\n\nfor n in popularmovie_plots:\n    \n    try:\n        sentiment_popularmovie_plot.append(how_happy(nltk.word_tokenize(n)))\n        \n    except:\n        pass",
                "true_label": "",
                "top5_preds": [
                    "vectorize words in movie reviews",
                    "find the most common words",
                    "ploting out data with box plots",
                    "line plot with a dataframe",
                    "most similar words"
                ]
            },
            {
                "code": "unpopularmovie_plots=movie_0_2_plots+movie_2_4_plots+movie_4_6_plots\n\nsentiment_unpopularmovie_plot=[]\n\nfor n in unpopularmovie_plots:\n    \n    try:\n        sentiment_unpopularmovie_plot.append(how_happy(nltk.word_tokenize(n)))\n        \n    except:\n        pass",
                "true_label": "",
                "top5_preds": [
                    "predicting a categorical response",
                    "vectorize words in movie reviews",
                    "ploting out data with box plots",
                    "plot using matplotlib",
                    "line plot with a dataframe"
                ]
            },
            {
                "code": "#remove nans\nsentiment_popularmovie_plot = [x for x in sentiment_popularmovie_plot if str(x) != 'nan']\n#remove nans\nsentiment_unpopularmovie_plot = [x for x in sentiment_unpopularmovie_plot if str(x) != 'nan']\n",
                "true_label": "",
                "top5_preds": [
                    "calculating the mean of a vector with nans",
                    "drop nan values",
                    "remove duplicates from a list",
                    "predicting a categorical response",
                    "computing the covariance when there are nan s"
                ]
            },
            {
                "code": "plt.hist(sentiment_popularmovie_plot)\nplt.title(\"Sentiment distribution of Popular movie's Plot sections\")\nplt.ylabel('count')\nplt.xlabel('Sentiment')\n\n#plt.xlim(3,8)\nplt.show()\n\nmean_popularmovie_plot=np.mean(sentiment_popularmovie_plot)\nprint('Mean sentiment of popularmovie plots:')\nprint(mean_popularmovie_plot)\nstd_popularmovie_plot=np.std(sentiment_popularmovie_plot)\nprint('Std sentiment of popularmovie plots:')\nprint(std_popularmovie_plot)",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "line plots show the trend of a numerical variable over time",
                    "visualize the distribution histogram of x using sns distplot",
                    "pandas plotting",
                    "pandas plotting documentation"
                ]
            },
            {
                "code": "#Create histogram of degrees\nimport collections\ndegree_sequence = sorted([d for n, d in G_und.degree()], reverse=True)  # degree sequence\ndegreeCount = collections.Counter(degree_sequence)\ndeg, cnt = zip(*degreeCount.items())\n\nfig, ax = plt.subplots()\nplt.bar(deg, cnt, width=0.80, color='b')\n\nplt.title(\"Degree Histogram\")\nplt.ylabel(\"Count\")\nplt.xlabel(\"Degree\")\nplt.show()",
                "true_label": "",
                "top5_preds": [
                    "line plots show the trend of a numerical variable over time",
                    "counting triangles in a social network",
                    "predicting a categorical response",
                    "line plot with a dataframe",
                    "remove duplicates from a list"
                ]
            },
            {
                "code": "# Create linear distribution and loglog plot\nmaxd = max([int(j) for i,j in G_und.degree()])\nmind = min([int(j) for i,j in G_und.degree()])\ndegreeslist = [int(j) for i,j in G_und.degree()]\nhist, binList = np.histogram(degreeslist, maxd)\nplt.plot((binList[1:]+binList[:-1]),hist, 'o', mfc='none')\nplt.title(\"Linear distribution plot\")\nplt.ylabel('count')\nplt.xlabel(\"Degree\")\nplt.show()\n#Generate log-log plot\nplt.loglog((binList[1:]+binList[:-1]),hist, 'o', mfc='none')\nplt.title(\"Log-Log distribution plot\")\nplt.xlabel('k')\nplt.ylabel('count')\nplt.show()",
                "true_label": "",
                "top5_preds": [
                    "likelihood of the binomial distribution",
                    "likelihood of the binomial",
                    "ridge regression with polynomial features on a grid",
                    "ridge regression with one predictor on a grid",
                    "ploting out data with box plots"
                ]
            },
            {
                "code": "#Print most connected nodes by different measures\nimport operator\ndef sort_print_top3(dictionary):\n    print(sorted([(i[0],dictionary[i[0]]) for i in G_und.nodes(data = True)],key = lambda x:x[1])[-10:],\"\\n\")\n\n\nund_degree = dict(G_und.degree())\nprint(\"Highest degrees\")\nsort_print_top3(und_degree)\nprint(\"Highest betweeness\")\nsort_print_top3(bet)\nprint(\"Highest eigenvector\")\nsort_print_top3(bet_eig)\n",
                "true_label": "",
                "top5_preds": [
                    "find the most common words",
                    "remove duplicates from a list",
                    "find maximum and the minimum value in a set",
                    "most common words",
                    "equally spaced numbers on a grid"
                ]
            },
            {
                "code": "#plot movie rating vs earning:\nplt.figure(figsize=(6,6))\nplt.title(\"Metascore vs revenue\")\nplt.ylabel(\"Earnings in mil\")\nplt.xlabel(\"Metascore\")\nplt.plot(moviedata.Metascore,moviedata.Revenue,\"o\")",
                "true_label": "",
                "top5_preds": [
                    "line plots show the trend of a numerical variable over time",
                    "plot using matplotlib",
                    "line plot with a dataframe",
                    "plotting in python",
                    "plot using pandas plotting"
                ]
            },
            {
                "code": "#Generate colors based on meta score:\ncols = []\nScores = []\nfor i in G_und_m.nodes():\n    try:\n        Scores.append(int(G_m.node[i]['attr_dict']['Score']))\n        if int(G_m.node[i]['attr_dict']['Score'] /10) >= 8:\n            cols.append('#32CD32');\n        elif int(G_m.node[i]['attr_dict']['Score']/10) >= 6:\n            cols.append('#98FB98')\n        elif int(G_m.node[i]['attr_dict']['Score']/10) >= 4: \n            cols.append('#ffff00')\n        else: \n            cols.append('#ff0000')\n    except:\n        Scores.append(0)\n        cols.append('#ff0000')\n\n#Create figure:\nplt.figure(figsize=(14,14))\nnx.draw_networkx(G_und_m, pos=positions_m,with_labels=False, front_weight='bold',node_size=[6*i for i in dict(G_und_m.degree()).values()],node_color=cols)\nplt.xlim(-1450,1450)\nplt.ylim(-1450,1450)\nplt.axis('off')\nplt.show()",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "import polynomial features from sklearn",
                    "predicting a categorical response",
                    "find data type of each column",
                    "list of categories"
                ]
            },
            {
                "code": "#Create figure where node size is movie earnings:\nplt.figure(figsize=(14,14))\nnx.draw_networkx(G_und_m, pos=positions_m,with_labels=False, front_weight='bold',node_size=node_size,node_color=cols)\nplt.xlim(-1450,1450)\nplt.ylim(-1450,1450)\nplt.axis('off')\nplt.show()",
                "true_label": "",
                "top5_preds": [
                    "create a graph",
                    "graph",
                    "counting triangles in a social network",
                    "line plot with a dataframe",
                    "graph analysis"
                ]
            },
            {
                "code": "#plot average movie score\nplt.figure(figsize=(6,6))\nplt.ylabel(\"Count\")\nplt.xlabel(\"Metascore\")\nplt.hist(Scores)",
                "true_label": "",
                "top5_preds": [
                    "plot histogram",
                    "line plots show the trend of a numerical variable over time",
                    "line plot with a dataframe",
                    "sum all the numbers in a list",
                    "plot using matplotlib"
                ]
            },
            {
                "code": "#Create Eigenvector graph\nplt.figure(figsize=(14,14))\nbet_eig = nx.eigenvector_centrality(G_und_m)\nnx.draw_networkx(G_und_m, pos=positions_m,with_labels=False, front_weight='bold',node_size=[bet_eig[i]*2000 for i in G_und_m.nodes()],node_color=cols)\nplt.xlim(-1450,1450)\nplt.ylim(-1450,1450)\nplt.axis('off')\nplt.show()",
                "true_label": "",
                "top5_preds": [
                    "graph",
                    "add edges in graph",
                    "create a graph",
                    "counting triangles in a social network",
                    "ridge regression with polynomial features on a grid"
                ]
            }
        ],
        [
            {
                "code": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline",
                "true_label": "",
                "top5_preds": [
                    "plot using matplotlib",
                    "line plot with a dataframe",
                    "plotting time series with pandas",
                    "matplotlib",
                    "trend lines in pyplot"
                ]
            },
            {
                "code": "# Demographics\n\ndemo03 = pd.read_csv('DEMO_C_03.csv')\ndemo05 = pd.read_csv('DEMO_D_05.csv')\ndemo07 = pd.read_csv('DEMO_E_07.csv')\ndemo09 = pd.read_csv('DEMO_F_09.csv')\ndemo11 = pd.read_csv('DEMO_G_11.csv')\ndemo13 = pd.read_csv('DEMO_H_13.csv')\ndemo15 = pd.read_csv('DEMO_I_15.csv')\n\n# HDL\n\nhdl03 = pd.read_csv('L13_C.csv') # also contains total cholesterol in 2003\nhdl05 = pd.read_csv('HDL_D_05.csv')\nhdl07 = pd.read_csv('HDL_E_07.csv')\nhdl09 = pd.read_csv('HDL_F_09.csv')\nhdl11 = pd.read_csv('HDL_G_11.csv')\nhdl13 = pd.read_csv('HDL_H_13.csv')\nhdl15 = pd.read_csv('HDL_I_15.csv')\n\n# Triglyceride\n\ntrig03 = pd.read_csv('L13AM_C.csv')\ntrig05 = pd.read_csv('TRIGLY_D_05.csv')\ntrig07 = pd.read_csv('TRIGLY_E_07.csv')\ntrig09 = pd.read_csv('TRIGLY_F_09.csv')\ntrig11 = pd.read_csv('TRIGLY_G_11.csv')\ntrig13 = pd.read_csv('TRIGLY_H_13.csv')\ntrig15 = pd.read_csv('BIOPRO_I.csv') # triglyceride in 2015\n\n# Total Cholesterol (2003 data is included in hdl03)\n\ntchol05 = pd.read_csv('TCHOL_D_05.csv')\ntchol07 = pd.read_csv('TCHOL_E_07.csv')\ntchol09 = pd.read_csv('TCHOL_F_09.csv')\ntchol11 = pd.read_csv('TCHOL_G_11.csv')\ntchol13 = pd.read_csv('TCHOL_H_13.csv')\ntchol15 = pd.read_csv('TCHOL_I_15.csv')",
                "true_label": "",
                "top5_preds": [
                    "loading a csv into a dataframe",
                    "importing data with numpy",
                    "importing data with pandas",
                    "load table in pandas",
                    "line plot with a dataframe"
                ]
            },
            {
                "code": "# Demographics\n\ndemo = pd.concat([demo03, demo05, demo07, demo09, demo11, demo13, demo15], sort=False)\ndemo = demo[['SEQN','RIAGENDR', 'RIDAGEYR', 'RIDRETH1','DMDEDUC3', 'DMDEDUC2',\n             'INDFMINC','INDFMIN2','WTINT2YR','WTMEC2YR']]\ndemo.columns = ['Index', 'Gender', 'Age', 'Ethnicity', 'Education 6-19', 'Education 20+', \n              'Income 2003-05', 'Income 2007+', 'Weight Int', 'Weight MEC']\ndemo.set_index('Index', inplace = True)\n\n# Combine columns\n\ndemo['Education 6-19'] = demo['Education 6-19'].fillna(0.0)\ndemo['Education 20+'] = demo['Education 20+'].fillna(0.0)\ndemo['Income 2003-05'] = demo['Income 2003-05'].fillna(0.0)\ndemo['Income 2007+'] = demo['Income 2007+'].fillna(0.0)\ndemo['Education'] = demo['Education 6-19'] + demo['Education 20+']\ndemo['Income'] = demo['Income 2003-05'] + demo['Income 2007+']\ndemo.drop(['Education 6-19', 'Education 20+', 'Income 2003-05', 'Income 2007+'], axis=1, inplace = True)",
                "true_label": "",
                "top5_preds": [
                    "join two dataframes along rows",
                    "formatting datetimes as strings",
                    "importing data with numpy",
                    "remove duplicates from a list",
                    "join two dataframes along columns"
                ]
            },
            {
                "code": "# HDL\n\nhdl = pd.concat([hdl03, hdl05, hdl07, hdl09, hdl11, hdl13, hdl15], sort=False)\nhdl = hdl[['SEQN', 'LBDHDD', 'LBXHDD']]\nhdl.columns = ['Index', 'HDL1', 'HDL2']\nhdl.set_index('Index', inplace = True)\n\n# Combine columns\n\nhdl['HDL1'] = hdl['HDL1'].fillna(0.0)\nhdl['HDL2'] = hdl['HDL2'].fillna(0.0)\nhdl['HDL'] = hdl['HDL1'] + hdl['HDL2']\nhdl.drop(['HDL1', 'HDL2'], axis=1, inplace=True)",
                "true_label": "",
                "top5_preds": [
                    "from dictionary to dataframe",
                    "join two dataframes along rows",
                    "loading a csv into a dataframe",
                    "load table in pandas",
                    "relationships between dataframes"
                ]
            },
            {
                "code": "# Tryglyceride\n\ntrig = pd.concat([trig03, trig05, trig07, trig09, trig11, trig13, trig15], sort=False)\ntrig = trig[['SEQN', 'WTSAF2YR', 'LBXTR', 'LBXSTR']]\ntrig.columns = ['Index', 'Weight Fast', 'Triglyceride', 'Triglyceride2']\ntrig.set_index('Index', inplace = True)\n\n# Combine columns\n\ntrig['Triglyceride'] = trig['Triglyceride'].fillna(0.0)\ntrig['Triglyceride2'] = trig['Triglyceride2'].fillna(0.0)\ntrig['Triglyceride'] = trig['Triglyceride'] + trig['Triglyceride2']\ntrig.drop(['Triglyceride2'], axis=1, inplace=True)",
                "true_label": "",
                "top5_preds": [
                    "line plots show the trend of a numerical variable over time",
                    "importing data with numpy",
                    "find maximum and the minimum value in a set",
                    "line plot with a dataframe",
                    "integrating datetime tools with pandas for time series"
                ]
            },
            {
                "code": "# Total Cholesterol\n\ntchol = pd.concat([hdl03, tchol05, tchol07, tchol09, tchol11, tchol13, tchol15], sort=False)\ntchol = tchol[['SEQN', 'LBXTC']]\ntchol.columns = ['Index', 'Total Chol']\ntchol.set_index('Index', inplace = True)",
                "true_label": "",
                "top5_preds": [
                    "find data type of each column",
                    "add an item in a tuple",
                    "load table in pandas",
                    "create a one column dataframe with the values of a series",
                    "add string to list using append"
                ]
            },
            {
                "code": "# Combine all into one data frame\n\nfrom functools import reduce\n\ndfs = [demo, hdl, trig, tchol]\ndf = reduce(lambda left,right: left.join(right), dfs)\ndf = df[['Age', 'Gender', 'Ethnicity', 'Education', 'Income', 'HDL', \n         'Triglyceride', 'Total Chol', 'Weight Int', 'Weight MEC', 'Weight Fast']]\ndf.head().transpose()",
                "true_label": "",
                "top5_preds": [
                    "create a dataframe by joining series by column",
                    "join two dataframes along rows",
                    "combine two dataframes into one",
                    "load table in pandas",
                    "join two dataframes along columns"
                ]
            },
            {
                "code": "df['Age'].describe()",
                "true_label": "",
                "top5_preds": [
                    "working with pandas series indexed by datetime",
                    "formatting datetimes as strings",
                    "create a one column dataframe with the values of a series",
                    "integrating datetime tools with pandas for time series",
                    "convert date to datetime format"
                ]
            },
            {
                "code": "# Check for missing values (Yellow bar indicades missing value)\n\nsns.heatmap(df.isnull(), yticklabels = False, cbar=False, cmap = 'viridis')",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "dataframe methods",
                    "heatmap with time",
                    "using a dataframe and matplotlib commands",
                    "create dataframe with given values"
                ]
            },
            {
                "code": "demo05['WTINT2YR'].sum()",
                "true_label": "",
                "top5_preds": [
                    "create a one column dataframe with the values of a series",
                    "integrating datetime tools with pandas for time series",
                    "load table in pandas",
                    "line plots show the trend of a numerical variable over time",
                    "working with pandas series indexed by datetime"
                ]
            },
            {
                "code": "trig05['WTSAF2YR'].sum()",
                "true_label": "",
                "top5_preds": [
                    "integrating datetime tools with pandas for time series",
                    "sum all the numbers in a list",
                    "line plots show the trend of a numerical variable over time",
                    "fit a polynomial",
                    "creating polynomial features"
                ]
            },
            {
                "code": "df['Weight Int'] = df['Weight Int']/7\ndf['Weight MEC'] = df['Weight MEC']/7\ndf['Weight Fast'] = df['Weight Fast']/7\ndf.head().transpose()",
                "true_label": "",
                "top5_preds": [
                    "create a one column dataframe with the values of a series",
                    "convert data from string to float",
                    "create dataframe with given values",
                    "line plot with a dataframe",
                    "pandas apply"
                ]
            },
            {
                "code": "df['Weight Int'] = df['Weight Int']/df['Weight Int'].mean()\ndf['Weight MEC'] = df['Weight MEC']/df['Weight MEC'].mean()\ndf['Weight Fast'] = df['Weight Fast']/df['Weight Fast'].mean()\ndf.head().transpose()",
                "true_label": "",
                "top5_preds": [
                    "calculating the mean of a vector with nans",
                    "the mean",
                    "line plot with a dataframe",
                    "create a one column dataframe with the values of a series",
                    "convert data from string to float"
                ]
            },
            {
                "code": "df['Weight MEC'].sum()",
                "true_label": "",
                "top5_preds": [
                    "create a one column dataframe with the values of a series",
                    "summarize a specific column",
                    "transform weight column",
                    "summarize the dataframe",
                    "dataframe methods"
                ]
            },
            {
                "code": "# Taking a subsample of college students age 18-24 \ndf_hdl = df[(df['Age'] > 17) & (df['Age'] < 25) & \n            (df['Education'].isin([3.0, 4.0, 5.0, 13.0, 14.0, 15.0]))\n           ][['Age', 'Gender', 'Ethnicity', 'Income', 'HDL', 'Weight MEC']].copy()\n\n# Check for missing values\nsns.heatmap(df_hdl.isnull(), yticklabels = False, cbar=False, cmap = 'viridis')",
                "true_label": "",
                "top5_preds": [
                    "dataframe methods",
                    "split a dataframe into a testing",
                    "find data type of each column",
                    "create dataframe with given values",
                    "line plot with a dataframe"
                ]
            },
            {
                "code": "# Fill in the missing value by taking a sample average:\ndf_hdl['HDL'].fillna(df_hdl['HDL'].mean(), inplace=True)\n\n# Adjusting for sub-sample weights\ndf_hdl['Weight MEC'] = df_hdl['Weight MEC']/df_hdl['Weight MEC'].mean()\n\n# Note that the updated weights sum to the sub-sample size:\ndf_hdl['Weight MEC'].sum()",
                "true_label": "",
                "top5_preds": [
                    "create a one column dataframe with the values of a series",
                    "create dataframe with given values",
                    "line plot with a dataframe",
                    "calculate average by group",
                    "loading up data with missing values"
                ]
            },
            {
                "code": "weighted_estimate(hdl_values_mid, hdl_weights_mid, 0.05)",
                "true_label": "",
                "top5_preds": [
                    "predicting a categorical response",
                    "predicting a continuous response using linear regression",
                    "integrating datetime tools with pandas for time series",
                    "resampling with weights",
                    "line plots show the trend of a numerical variable over time"
                ]
            },
            {
                "code": "weighted_estimate(hdl_values_high, hdl_weights_high, 0.05)",
                "true_label": "",
                "top5_preds": [
                    "predicting a categorical response",
                    "predicting a continuous response using linear regression",
                    "credible interval vs confidence interval",
                    "resampling with weights",
                    "line plots show the trend of a numerical variable over time"
                ]
            },
            {
                "code": "f, ax = plt.subplots(figsize=(10, 3))\nsns.boxplot(y='Ethnicity', x='HDL', data=df_hdl, palette='coolwarm')\nsns.despine(trim=True, left=True)",
                "true_label": "",
                "top5_preds": [
                    "ploting out data with box plots",
                    "line plot with a dataframe",
                    "using a dataframe and matplotlib commands",
                    "box plot",
                    "pandas plotting"
                ]
            },
            {
                "code": "df_hdl.groupby('Ethnicity')['HDL'].describe()",
                "true_label": "",
                "top5_preds": [
                    "dataframe methods",
                    "line plot with a dataframe",
                    "find data type of each column",
                    "formatting datetimes as strings",
                    "from dictionary to dataframe"
                ]
            },
            {
                "code": "hdl_values_black = np.array(df_hdl[df_hdl['Ethnicity'] == 'Black']['HDL'])\nhdl_weights_black = np.array(df_hdl[df_hdl['Ethnicity'] == 'Black']['Weight MEC'] /\n                          df_hdl[df_hdl['Ethnicity'] == 'Black']['Weight MEC'].mean())\n\nhdl_values_white = np.array(df_hdl[df_hdl['Ethnicity'] == 'White']['HDL'])\nhdl_weights_white = np.array(df_hdl[df_hdl['Ethnicity'] == 'White']['Weight MEC'] /\n                          df_hdl[df_hdl['Ethnicity'] == 'White']['Weight MEC'].mean())\n\nhdl_values_mexican = np.array(df_hdl[df_hdl['Ethnicity'] == 'Mexican']['HDL'])\nhdl_weights_mexican = np.array(df_hdl[df_hdl['Ethnicity'] == 'Mexican']['Weight MEC'] / \n                           df_hdl[df_hdl['Ethnicity'] == 'Mexican']['Weight MEC'].mean())\n\nhdl_values_hispanic = np.array(df_hdl[df_hdl['Ethnicity'] == 'Hispanic']['HDL'])\nhdl_weights_hispanic = np.array(df_hdl[df_hdl['Ethnicity'] == 'Hispanic']['Weight MEC'] / \n                           df_hdl[df_hdl['Ethnicity'] == 'Hispanic']['Weight MEC'].mean())\n\nhdl_values_other = np.array(df_hdl[df_hdl['Ethnicity'] == 'Other']['HDL'])\nhdl_weights_other = np.array(df_hdl[df_hdl['Ethnicity'] == 'Other']['Weight MEC'] / \n                           df_hdl[df_hdl['Ethnicity'] == 'Other']['Weight MEC'].mean())",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "predicting a categorical response",
                    "find data type of each column",
                    "dataframe methods",
                    "traffic sign classification with keras"
                ]
            },
            {
                "code": "weighted_estimate(hdl_values_black, hdl_weights_black, 0.05)",
                "true_label": "",
                "top5_preds": [
                    "predicting a categorical response",
                    "predicting a continuous response using linear regression",
                    "ridge regression with one predictor on a grid",
                    "line plot with a dataframe",
                    "ridge regression with polynomial features on a grid"
                ]
            },
            {
                "code": "weighted_estimate(hdl_values_white, hdl_weights_white, 0.05)",
                "true_label": "",
                "top5_preds": [
                    "predicting a categorical response",
                    "predicting a continuous response using linear regression",
                    "line plot with a dataframe",
                    "ridge regression with polynomial features on a grid",
                    "ridge regression with one predictor on a grid"
                ]
            },
            {
                "code": "weighted_estimate(hdl_values_mexican, hdl_weights_mexican, 0.05)",
                "true_label": "",
                "top5_preds": [
                    "integrating datetime tools with pandas for time series",
                    "predicting a categorical response",
                    "predicting a continuous response using linear regression",
                    "find maximum and the minimum value in a set",
                    "resampling with weights"
                ]
            },
            {
                "code": "weighted_estimate(hdl_values_hispanic, hdl_weights_hispanic, 0.05)",
                "true_label": "",
                "top5_preds": [
                    "predicting a categorical response",
                    "predicting a continuous response using linear regression",
                    "credible interval vs confidence interval",
                    "integrating datetime tools with pandas for time series",
                    "optimal value of k for dataset"
                ]
            },
            {
                "code": "weighted_estimate(hdl_values_other, hdl_weights_other, 0.05)",
                "true_label": "",
                "top5_preds": [
                    "predicting a categorical response",
                    "predicting a continuous response using linear regression",
                    "integrating datetime tools with pandas for time series",
                    "resampling with weights",
                    "use numpy to generate an array of random numbers sampled from a standard normal distribution"
                ]
            },
            {
                "code": "# Taking a subsample of college students age 18-24 \ndf_trig = df[(df['Age'] > 17) & (df['Age'] < 25) & \n             (df['Education'].isin([3.0, 4.0, 5.0, 13.0, 14.0, 15.0]))\n            ][['Age', 'Gender', 'Ethnicity', 'Income', 'Triglyceride', 'Weight Fast']].copy()\n\n# Check for missing values\nsns.heatmap(df_trig.isnull(), yticklabels = False, cbar=False, cmap = 'viridis')",
                "true_label": "",
                "top5_preds": [
                    "predicting a categorical response",
                    "split a dataframe into a testing",
                    "find data type of each column",
                    "ploting out data with box plots",
                    "create dataframe with given values"
                ]
            },
            {
                "code": "# Note that the missing values occur together, so we drop them:\ndf_trig = df_trig.dropna()\n\n# Adjusting for subsample weights\ndf_trig['Weight Fast'] = df_trig['Weight Fast']/df_trig['Weight Fast'].mean()\n\n# Note that the updated weights sum to the sub-sample size:\ndf_trig['Weight Fast'].sum()",
                "true_label": "",
                "top5_preds": [
                    "line plots show the trend of a numerical variable over time",
                    "resampling and frequency conversion",
                    "predicting a categorical response",
                    "create a one column dataframe with the values of a series",
                    "the mean of difference of variables"
                ]
            },
            {
                "code": "trig15['WTSAF2YR'] = demo15['WTMEC2YR']*4/5",
                "true_label": "",
                "top5_preds": [
                    "integrating datetime tools with pandas for time series",
                    "line plots show the trend of a numerical variable over time",
                    "add an item in a tuple",
                    "ridge regression with one predictor on a grid",
                    "linear regression of many variables"
                ]
            },
            {
                "code": "df_hdl.groupby('Gender')['HDL'].describe()",
                "true_label": "",
                "top5_preds": [
                    "dataframe methods",
                    "formatting datetimes as strings",
                    "line plots show the trend of a numerical variable over time",
                    "line plot with a dataframe",
                    "find data type of each column"
                ]
            },
            {
                "code": "hdl_values_male = np.array(df_hdl[df_hdl['Gender'] == 'Male']['HDL'])\nhdl_weights_male = np.array(df_hdl[df_hdl['Gender'] == 'Male']['Weight MEC'] /\n                           df_hdl[df_hdl['Gender'] == 'Male']['Weight MEC'].mean())\n\nhdl_values_female = np.array(df_hdl[df_hdl['Gender'] == 'Female']['HDL'])\nhdl_weights_female = np.array(df_hdl[df_hdl['Gender'] == 'Female']['Weight MEC'] /\n                             df_hdl[df_hdl['Gender'] == 'Female']['Weight MEC'].mean())",
                "true_label": "",
                "top5_preds": [
                    "dataframe methods",
                    "find data type of each column",
                    "line plot with a dataframe",
                    "predicting a categorical response",
                    "survey data"
                ]
            },
            {
                "code": "weighted_estimate(hdl_values_female, hdl_weights_female, 0.05)",
                "true_label": "",
                "top5_preds": [
                    "predicting a categorical response",
                    "predicting a continuous response using linear regression",
                    "resampling with weights",
                    "credible interval vs confidence interval",
                    "integrating datetime tools with pandas for time series"
                ]
            },
            {
                "code": "weighted_estimate(hdl_values_male, hdl_weights_male, 0.05)",
                "true_label": "",
                "top5_preds": [
                    "predicting a categorical response",
                    "predicting a continuous response using linear regression",
                    "ridge regression with one predictor on a grid",
                    "resampling with weights",
                    "integrating datetime tools with pandas for time series"
                ]
            },
            {
                "code": "f, ax = plt.subplots(figsize=(10, 2))\nsns.boxplot(y='Income', x='HDL', data=df_hdl, palette='coolwarm')\nsns.despine(trim=True, left=True)",
                "true_label": "",
                "top5_preds": [
                    "ploting out data with box plots",
                    "line plot with a dataframe",
                    "using a dataframe and matplotlib commands",
                    "box plot",
                    "pandas plotting"
                ]
            },
            {
                "code": "df_hdl.groupby('Income')['HDL'].describe()",
                "true_label": "",
                "top5_preds": [
                    "formatting datetimes as strings",
                    "line plot with a dataframe",
                    "line plots show the trend of a numerical variable over time",
                    "dataframe methods",
                    "find data type of each column"
                ]
            },
            {
                "code": "hdl_values_low = np.array(df_hdl[df_hdl['Income'] == 'low']['HDL'])\nhdl_weights_low = np.array(df_hdl[df_hdl['Income'] == 'low']['Weight MEC'] /\n                          df_hdl[df_hdl['Income'] == 'low']['Weight MEC'].mean())\n\nhdl_values_mid = np.array(df_hdl[df_hdl['Income'] == 'mid']['HDL'])\nhdl_weights_mid = np.array(df_hdl[df_hdl['Income'] == 'mid']['Weight MEC'] /\n                          df_hdl[df_hdl['Income'] == 'mid']['Weight MEC'].mean())\n\nhdl_values_high = np.array(df_hdl[df_hdl['Income'] == 'high']['HDL'])\nhdl_weights_high = np.array(df_hdl[df_hdl['Income'] == 'high']['Weight MEC'] / \n                           df_hdl[df_hdl['Income'] == 'high']['Weight MEC'].mean())",
                "true_label": "",
                "top5_preds": [
                    "predicting a categorical response",
                    "line plot with a dataframe",
                    "credible interval vs confidence interval",
                    "dataframe methods",
                    "resampling with weights"
                ]
            },
            {
                "code": "weighted_estimate(hdl_values_low, hdl_weights_low, 0.05)",
                "true_label": "",
                "top5_preds": [
                    "predicting a categorical response",
                    "predicting a continuous response using linear regression",
                    "ridge regression with one predictor on a grid",
                    "resampling with weights",
                    "credible interval vs confidence interval"
                ]
            },
            {
                "code": "# Taking a subsample of college students age 18-24 \ndf_tchol = df[(df['Age'] > 17) & (df['Age'] < 25) & \n              (df['Education'].isin([3.0, 4.0, 5.0, 13.0, 14.0, 15.0]))\n            ][['Age', 'Gender', 'Ethnicity', 'Income', 'Total Chol', 'Weight MEC']].copy()\n\n# Check for missing values\nsns.heatmap(df_tchol.isnull(), yticklabels = False, cbar=False, cmap = 'viridis')",
                "true_label": "",
                "top5_preds": [
                    "predicting a categorical response",
                    "split a dataframe into a testing",
                    "find data type of each column",
                    "credible interval vs confidence interval",
                    "integrating datetime tools with pandas for time series"
                ]
            },
            {
                "code": "# Fill in the missing value by taking a sample average:\ndf_tchol['Total Chol'] = df_tchol['Total Chol'].fillna(df_tchol['Total Chol'].mean())\n\n# Adjusting for subsample weights\ndf_tchol['Weight MEC'] = df_tchol['Weight MEC']/df_tchol['Weight MEC'].mean()\n\n# Note that the updated weights sum to the sub-sample size:\ndf_tchol['Weight MEC'].sum()",
                "true_label": "",
                "top5_preds": [
                    "predicting a categorical response",
                    "create a one column dataframe with the values of a series",
                    "resampling and frequency conversion",
                    "line plot with a dataframe",
                    "line plots show the trend of a numerical variable over time"
                ]
            },
            {
                "code": "# Mapping income and ethnicity\n\ndef income_map( x ):\n    if x in [1.0, 2.0, 3.0, 4.0, 13.0]:\n        return 'low'\n    elif x in [5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 12.0]:\n        return 'mid'\n    elif x in [11.0, 14.0, 15.0]:\n        return 'high'\n    else:\n        return np.nan\n\nethnicity_map = {1:'Mexican', 2:'Hispanic', 3:'White', 4:'Black', 5:'Other'}\ngender_map = {1.0:'Male', 2.0: 'Female'}\n\ndf_hdl['Income'] = df_hdl['Income'].apply(income_map)\ndf_trig['Income'] = df_trig['Income'].apply(income_map)\ndf_tchol['Income'] = df_tchol['Income'].apply(income_map)\n\ndf_hdl['Gender'] = df_hdl['Gender'].map(gender_map)\ndf_trig['Gender'] = df_trig['Gender'].map(gender_map)\ndf_tchol['Gender'] = df_tchol['Gender'].map(gender_map)\n\ndf_hdl['Ethnicity'] = df_hdl['Ethnicity'].map(ethnicity_map)\ndf_trig['Ethnicity'] = df_trig['Ethnicity'].map(ethnicity_map)\ndf_tchol['Ethnicity'] = df_tchol['Ethnicity'].map(ethnicity_map)",
                "true_label": "",
                "top5_preds": [
                    "convert data from string to float",
                    "convert integer or float data",
                    "from dictionary to dataframe",
                    "converting symbols to identifiers",
                    "convert strings to numbers"
                ]
            },
            {
                "code": "# Define a function that retuns (a, b, c) where a is the point estimate of the mean, \n# and (b, c) is the 100*(1-alpha)% confidence interval\n\nimport scipy.stats as st\n\ndef weighted_estimate( values, weights, alpha ):\n    \n    mean = np.average( values, weights = weights )\n    S = np.sqrt((np.average( values**2, weights = weights ) - mean**2 )\n                /( 1-np.sum(weights**2)/len(weights)**2) )\n\n    return (mean, mean - st.t.ppf(1-alpha/2, len(weights)-1)*S/np.sqrt(len(weights)), \n            mean + st.t.ppf(1-alpha/2, len(weights)-1)*S/np.sqrt(len(weights)) )    ",
                "true_label": "",
                "top5_preds": [
                    "likelihood of the binomial distribution",
                    "fit a polynomial",
                    "predicting a categorical response",
                    "likelihood of the binomial",
                    "resampling with weights"
                ]
            },
            {
                "code": "df_hdl.head()",
                "true_label": "",
                "top5_preds": [
                    "load table in pandas",
                    "loading a csv into a dataframe",
                    "line plot with a dataframe",
                    "find data type of each column",
                    "from dictionary to dataframe"
                ]
            },
            {
                "code": "df_hdl['HDL'].count()",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "load table in pandas",
                    "find data type of each column",
                    "dataframe methods",
                    "in pandas"
                ]
            },
            {
                "code": "f, ax = plt.subplots(figsize=(10, 2))\nsns.boxplot(y='Gender', x='HDL', data=df_hdl, palette='coolwarm')\nsns.despine(trim=True, left=True)",
                "true_label": "",
                "top5_preds": [
                    "ploting out data with box plots",
                    "line plot with a dataframe",
                    "using a dataframe and matplotlib commands",
                    "box plot",
                    "pandas plotting"
                ]
            },
            {
                "code": "weighted_estimate(trig_values_mid, trig_weights_mid, 0.05)",
                "true_label": "",
                "top5_preds": [
                    "predicting a categorical response",
                    "line plots show the trend of a numerical variable over time",
                    "predicting a continuous response using linear regression",
                    "integrating datetime tools with pandas for time series",
                    "credible interval vs confidence interval"
                ]
            },
            {
                "code": "weighted_estimate(trig_values_high, trig_weights_high, 0.05)",
                "true_label": "",
                "top5_preds": [
                    "predicting a categorical response",
                    "credible interval vs confidence interval",
                    "predicting a continuous response using linear regression",
                    "ridge regression with one predictor on a grid",
                    "line plots show the trend of a numerical variable over time"
                ]
            },
            {
                "code": "f, axes = plt.subplots(2, 1, figsize=(10, 6))\nsns.boxplot(y='Ethnicity', x='Triglyceride', data=df_trig, palette='coolwarm', ax=axes[0])\nsns.boxplot(y='Ethnicity', x='Triglyceride', data=df_trig, palette='coolwarm', ax=axes[1], showfliers=False)\nsns.despine(trim=True, left=True)\naxes[1].set_title(\"Hiding Outlier\")\nf.tight_layout()",
                "true_label": "",
                "top5_preds": [
                    "ploting out data with box plots",
                    "line plot with a dataframe",
                    "plot using pandas plotting",
                    "create box plots",
                    "pandas plotting"
                ]
            },
            {
                "code": "df_trig.groupby('Ethnicity')['Triglyceride'].describe()",
                "true_label": "",
                "top5_preds": [
                    "line plots show the trend of a numerical variable over time",
                    "find all by term in field in case insensitive way",
                    "line plot with a dataframe",
                    "dataframe methods",
                    "create a one column dataframe with the values of a series"
                ]
            },
            {
                "code": "trig_values_black = np.array(df_trig[df_trig['Ethnicity'] == 'Black']['Triglyceride'])\ntrig_weights_black = np.array(df_trig[df_trig['Ethnicity'] == 'Black']['Weight Fast'] /\n                          df_trig[df_trig['Ethnicity'] == 'Black']['Weight Fast'].mean())\n\ntrig_values_white = np.array(df_trig[df_trig['Ethnicity'] == 'White']['Triglyceride'])\ntrig_weights_white = np.array(df_trig[df_trig['Ethnicity'] == 'White']['Weight Fast'] /\n                          df_trig[df_trig['Ethnicity'] == 'White']['Weight Fast'].mean())\n\ntrig_values_mexican = np.array(df_trig[df_trig['Ethnicity'] == 'Mexican']['Triglyceride'])\ntrig_weights_mexican = np.array(df_trig[df_trig['Ethnicity'] == 'Mexican']['Weight Fast'] / \n                           df_trig[df_trig['Ethnicity'] == 'Mexican']['Weight Fast'].mean())\n\ntrig_values_hispanic = np.array(df_trig[df_trig['Ethnicity'] == 'Hispanic']['Triglyceride'])\ntrig_weights_hispanic = np.array(df_trig[df_trig['Ethnicity'] == 'Hispanic']['Weight Fast'] / \n                           df_trig[df_trig['Ethnicity'] == 'Hispanic']['Weight Fast'].mean())\n\ntrig_values_other = np.array(df_trig[df_trig['Ethnicity'] == 'Other']['Triglyceride'])\ntrig_weights_other = np.array(df_trig[df_trig['Ethnicity'] == 'Other']['Weight Fast'] / \n                           df_trig[df_trig['Ethnicity'] == 'Other']['Weight Fast'].mean())",
                "true_label": "",
                "top5_preds": [
                    "ridge regression with polynomial features on a grid",
                    "traffic sign classification with keras",
                    "ridge regression with one predictor on a grid",
                    "predicting a categorical response",
                    "line plots show the trend of a numerical variable over time"
                ]
            },
            {
                "code": "weighted_estimate(trig_values_black, trig_weights_black, 0.05)",
                "true_label": "",
                "top5_preds": [
                    "predicting a categorical response",
                    "ridge regression with polynomial features on a grid",
                    "ridge regression with one predictor on a grid",
                    "line plots show the trend of a numerical variable over time",
                    "predicting a continuous response using linear regression"
                ]
            },
            {
                "code": "weighted_estimate(trig_values_white, trig_weights_white, 0.05)",
                "true_label": "",
                "top5_preds": [
                    "predicting a categorical response",
                    "ridge regression with polynomial features on a grid",
                    "visualizing uncertainty",
                    "ridge regression with one predictor on a grid",
                    "line plots show the trend of a numerical variable over time"
                ]
            },
            {
                "code": "weighted_estimate(trig_values_mexican, trig_weights_mexican, 0.05)",
                "true_label": "",
                "top5_preds": [
                    "integrating datetime tools with pandas for time series",
                    "predicting a categorical response",
                    "find maximum and the minimum value in a set",
                    "fit a polynomial",
                    "ridge regression with polynomial features on a grid"
                ]
            },
            {
                "code": "weighted_estimate(trig_values_hispanic, trig_weights_hispanic, 0.05)",
                "true_label": "",
                "top5_preds": [
                    "predicting a categorical response",
                    "credible interval vs confidence interval",
                    "predicting a continuous response using linear regression",
                    "fit a polynomial",
                    "check accuracy / score for a logistic classifier"
                ]
            },
            {
                "code": "weighted_estimate(trig_values_other, trig_weights_other, 0.05)",
                "true_label": "",
                "top5_preds": [
                    "predicting a categorical response",
                    "predicting a continuous response using linear regression",
                    "integrating datetime tools with pandas for time series",
                    "line plots show the trend of a numerical variable over time",
                    "ridge regression with one predictor on a grid"
                ]
            },
            {
                "code": "df_tchol.head()",
                "true_label": "",
                "top5_preds": [
                    "load table in pandas",
                    "line plot with a dataframe",
                    "working with pandas series indexed by datetime",
                    "line plots show the trend of a numerical variable over time",
                    "create a one column dataframe with the values of a series"
                ]
            }
        ],
        [
            {
                "code": "import csv\nf = open(\"guns.csv\", \"r\")\ntext = csv.reader(f)\ndata = list(text)\nprint(data[:5])",
                "true_label": "",
                "top5_preds": [
                    "getting data from the internet",
                    "select every row after a specific row",
                    "reading and writing csv files",
                    "reading in and sampling from the data",
                    "read text file point"
                ]
            },
            {
                "code": "headers = data[0]\ndata = data[1:]\nprint(headers)\nprint(data[:5])",
                "true_label": "",
                "top5_preds": [
                    "retrieving data from html page",
                    "python data type list",
                    "getting data from the internet",
                    "reading in and sampling from the data",
                    "formatting datetimes as strings"
                ]
            },
            {
                "code": "years = [item[1] for item in data]\nyear_counts = {}\nfor year in years:\n    if year in year_counts:\n        year_counts[year] += 1\n    else:\n        year_counts[year] = 1\n\nprint(year_counts)",
                "true_label": "",
                "top5_preds": [
                    "sum all the numbers in a list",
                    "add an item in a tuple",
                    "remove duplicates from a list",
                    "create a list of retweet count and status tuples",
                    "convert date to datetime format"
                ]
            },
            {
                "code": "import datetime\ndates = [datetime.datetime(year = int(item[1]), month=int(item[2]), day=1) for item in data]\nprint(dates[:5])\ndate_counts = {}\n\n",
                "true_label": "",
                "top5_preds": [
                    "sum all the numbers in a list",
                    "convert date to datetime format",
                    "formatting datetimes as strings",
                    "remove duplicates from a list",
                    "convert list to numpy array"
                ]
            },
            {
                "code": "for date in dates:\n    if date in date_counts:\n        date_counts[date] += 1\n    else:\n        date_counts[date] = 1\n            \nprint(date_counts)",
                "true_label": "",
                "top5_preds": [
                    "sum all the numbers in a list",
                    "remove duplicates from a list",
                    "find duplicate dates",
                    "create a list of retweet count and status tuples",
                    "date ranges and frequencies"
                ]
            },
            {
                "code": "sex = [item[5] for item in data]\nsex_counts = {}\n\nfor item in sex:\n    if item in sex_counts:\n        sex_counts[item] += 1\n    else:\n        sex_counts[item] = 1\n\nprint(sex_counts)\n",
                "true_label": "",
                "top5_preds": [
                    "remove duplicates from a list",
                    "sum all the numbers in a list",
                    "find the most common words",
                    "create a list of retweet count and status tuples",
                    "counting word frequency"
                ]
            },
            {
                "code": "race = [item[7] for item in data]\nrace_counts = {}\n\nfor item in race:\n    if item in race_counts:\n        race_counts[item] += 1\n    else:\n        race_counts[item] = 1\n\nprint(race_counts)\n",
                "true_label": "",
                "top5_preds": [
                    "remove duplicates from a list",
                    "sum all the numbers in a list",
                    "find the most common words",
                    "find the repeated items of a tuple",
                    "add an item in a tuple"
                ]
            },
            {
                "code": "import csv\nf = open(\"census.csv\", \"r\")\ncsv_data = csv.reader(f)\ncensus = list(csv_data)\nprint(census)",
                "true_label": "",
                "top5_preds": [
                    "loading json in python",
                    "importing data with numpy",
                    "loading a csv into a dataframe",
                    "convert date to datetime format",
                    "python data type list"
                ]
            },
            {
                "code": "mapping = {}\nfor key, value in race_counts.items():\n    if key == \"Asian/Pacific Islander\":\n        mapping[key] = census[1][14] + census[1][15]\n    elif key == \"Black\":\n        mapping[key] = census[1][12]\n    elif key == \"Hispanic\":\n        mapping[key] = census[1][11]\n    elif key == \"Native American/Native Alaskan\":\n        mapping[key] = census[1][13]\n    elif key == \"White\":\n        mapping[key] = census[1][10]\n\nrace_per_hundredk = {}\n\nfor key, value in race_counts.items():\n    race_per_hundredk[key] = (value / int(mapping[key])) * 100000\n\nprint(race_per_hundredk)\n",
                "true_label": "",
                "top5_preds": [
                    "from dictionary to dataframe",
                    "convert a tuple to a dictionary",
                    "remove duplicates from a list",
                    "Create a dictionary with ICD9 code as keys",
                    "dictionaries"
                ]
            },
            {
                "code": "intents = [item[3] for item in data]\nraces = [item[7] for item in data]\nhomicide_race_per_hundredk = {}\n\nfor i, race in enumerate(races):\n    if intents[i] == \"Homicide\":\n        if race not in homicide_race_per_hundredk:\n            homicide_race_per_hundredk[race] = 1\n        else:\n            homicide_race_per_hundredk[race] += 1\n\nfor key, value in homicide_race_per_hundredk.items():\n    homicide_race_per_hundredk[key] = (value / int(mapping[key])) * 100000\n\nprint(homicide_race_per_hundredk)",
                "true_label": "",
                "top5_preds": [
                    "remove duplicates from a list",
                    "replace last value of tuples in a list",
                    "predicting test data",
                    "data given as a dictionary",
                    "get a positive integer from a user"
                ]
            },
            {
                "code": "homicide_month = {}\n\nfor i, date in enumerate(dates):\n    if intents[i] == \"Homicide\":\n        if date.strftime(\"%b\") not in homicide_month:\n            homicide_month[date.strftime(\"%b\")] = 1\n        else:\n            homicide_month[date.strftime(\"%b\")] += 1\n\nprint(homicide_month)\n        \n        \n    ",
                "true_label": "",
                "top5_preds": [
                    "convert date to datetime format",
                    "formatting datetimes as strings",
                    "calculate absolute time of the first arrivals at the station",
                    "find duplicate dates",
                    "sum all the numbers in a list"
                ]
            },
            {
                "code": "gender_homicide = {}\n\nfor i, gender in enumerate(sex):\n    if intents[i] == \"Homicide\":\n        if gender not in gender_homicide:\n            gender_homicide[gender] = 1\n        else:\n            gender_homicide[gender] += 1\nprint(gender_homicide)",
                "true_label": "",
                "top5_preds": [
                    "counting triangles in a social network",
                    "remove duplicates from a list",
                    "predicting a categorical response",
                    "relationships between dataframes",
                    "add edges in graph"
                ]
            },
            {
                "code": "places = [item[9] for item in data]\neducation = [item[10] for item in data]\n\ndeath_location = {}\ndeath_education = {}\n\nfor item in places:\n    if item in death_location:\n        death_location[item] += 1\n    else:\n        death_location[item] = 1\n\nprint(death_location)",
                "true_label": "",
                "top5_preds": [
                    "add an item in a tuple",
                    "remove duplicates from a list",
                    "data given as a dictionary",
                    "sum all the numbers in a list",
                    "replace last value of tuples in a list"
                ]
            },
            {
                "code": "places = [item[9] for item in data]\neducation = [item[10] for item in data]\n\ndeath_location = {}\ndeath_education = {}\n\nfor item in places:\n    if item in death_location:\n        death_location[item] += 1\n    else:\n        death_location[item] = 1\n\nprint(death_location)",
                "true_label": "",
                "top5_preds": [
                    "add an item in a tuple",
                    "remove duplicates from a list",
                    "data given as a dictionary",
                    "sum all the numbers in a list",
                    "replace last value of tuples in a list"
                ]
            }
        ],
        [
            {
                "code": "# encoding=utf8",
                "true_label": "",
                "top5_preds": [
                    "convert text data into vector",
                    "getting data from the internet",
                    "matching metacharacters literally",
                    "convert date to datetime format",
                    "formatting datetimes as strings"
                ]
            },
            {
                "code": "from collections import deque\nfrom itertools   import product, combinations, chain\nimport random\n\nCoins     = ''.join   # A coin sequence; a str: 'HHHT'.\nBelief    = frozenset # A set of possible coin sequences: {'HHHT', 'TTTH'}.\nPosition  = int       # An index into a coin sequence.\nMove      = set       # A set of positions to flip: {0, 2}\nStrategy  = list      # A list of Moves: [{0, 1, 2, 3}, {0, 2}, ...]",
                "true_label": "",
                "top5_preds": [
                    "add an item in a tuple",
                    "sum all the numbers in a list",
                    "multiply all the numbers in a list",
                    "equally spaced numbers on a grid",
                    "remove duplicates from a list"
                ]
            },
            {
                "code": "def all_moves() -> [Move]: \n    \"List of all possible moves.\"\n    return [set(m) for m in powerset(range(4))]\n\ndef all_coins() -> Belief:\n    \"The belief set consisting of all possible coin sequences.\"\n    return Belief(map(Coins, product('HT', repeat=4)))\n\ndef rotations(coins) -> {Coins}: \n    \"A set of all possible rotations of a coin sequence.\"\n    return {coins[r:] + coins[:r] for r in range(4)}\n\ndef flip(coins, move) -> Coins:\n    \"Flip the coins in the positions specified by the move (but leave 'HHHH' alone).\"\n    if 'T' not in coins: return coins # Don't flip 'HHHH'\n    coins = list(coins) # Need a mutable sequence\n    for i in move:\n        coins[i] = ('H' if coins[i] == 'T' else 'T')\n    return Coins(coins)\n\ndef update(belief, move) -> Belief:\n    \"Update belief: consider all possible rotations, then flip.\"\n    return Belief(flip(c, move)\n                  for coins in belief\n                  for c in rotations(coins))\n\nflatten = chain.from_iterable\n\ndef powerset(iterable): \n    \"powerset([1,2,3]) --> () (1,) (2,) (3,) (1,2) (1,3) (2,3) (1,2,3)\"\n    # https://docs.python.org/3/library/itertools.html#itertools-recipes\n    s = list(iterable)\n    return flatten(combinations(s, r) for r in range(len(s) + 1))",
                "true_label": "",
                "top5_preds": [
                    "addition of two polynomials",
                    "multiplication of two polynomials",
                    "to_tuple",
                    "creating polynomial features",
                    "adding non uniform transition probabilities"
                ]
            },
            {
                "code": "all_moves()",
                "true_label": "",
                "top5_preds": [
                    "how to change the style of individual lines",
                    "add edges in graph",
                    "attributes of geometries points",
                    "find maximum and the minimum value in a set",
                    "sum all the numbers in a list"
                ]
            },
            {
                "code": "all_coins()",
                "true_label": "",
                "top5_preds": [
                    "sum all the numbers in a list",
                    "get a positive integer from a user",
                    "getting data from the internet",
                    "equally spaced numbers on a grid",
                    "bytes to integer conversion"
                ]
            },
            {
                "code": "rotations('HHHT')",
                "true_label": "",
                "top5_preds": [
                    "convert date to datetime format",
                    "formatting datetimes as strings",
                    "equally spaced numbers on a grid",
                    "plotting time series with pandas",
                    "convert text data into vector"
                ]
            },
            {
                "code": "flip('HHHT', {0, 2})",
                "true_label": "",
                "top5_preds": [
                    "convert date to datetime format",
                    "add an item in a tuple",
                    "equally spaced numbers on a grid",
                    "trips by day hour mapper",
                    "convert binary to hexadecimal"
                ]
            },
            {
                "code": "update(all_coins(), {0, 1, 2, 3})",
                "true_label": "",
                "top5_preds": [
                    "sum all the numbers in a list",
                    "get a positive integer from a user",
                    "addition of two polynomials",
                    "find maximum and the minimum value in a set",
                    "getting data from the internet"
                ]
            },
            {
                "code": "list(powerset([1,2,3]))",
                "true_label": "",
                "top5_preds": [
                    "remove duplicates from a list",
                    "multiply all the numbers in a list",
                    "sum all the numbers in a list",
                    "find maximum and the minimum value in a set",
                    "equally spaced numbers on a grid"
                ]
            },
            {
                "code": "def search(start, goal, actions, result) -> Strategy:\n    \"Breadth-first search from start state to goal; return strategy to get to goal.\"\n    explored = set()\n    queue = deque([(Strategy(), start)])\n    while queue:\n        (strategy, state) = queue.popleft()\n        if state == goal:\n            return strategy\n        for action in actions:\n            state2 = result(state, action)\n            if state2 not in explored:\n                queue.append((strategy + [action], state2))\n                explored.add(state2)",
                "true_label": "",
                "top5_preds": [
                    "perform gradient ascent point",
                    "stitching images along a minimum cost path",
                    "find the minimum cost path",
                    "create a graph",
                    "gradient based stochastic optimization"
                ]
            },
            {
                "code": "def coin_search() -> Strategy: \n    \"Use `search` to solve the Coin Flip problem.\"\n    return search(start=all_coins(), goal={'HHHH'}, actions=all_moves(), result=update)\n\ncoin_search()",
                "true_label": "",
                "top5_preds": [
                    "building a mini lsst broker for data management and discovery",
                    "ranges",
                    "getting data from the internet",
                    "fetch and cache helper",
                    "most common words"
                ]
            },
            {
                "code": "def winning(strategy, k=100000) -> bool:\n    \"Is this a winning strategy? A probabilistic algorithm.\"\n    return all(play(strategy) == 'HHHH'\n               for _ in range(k))\n\ndef play(strategy, starting_coins=list(all_coins())) -> Coins:\n    \"Play strategy for one game against a random Devil; return final state of coins.\"\n    coins = random.choice(starting_coins)\n    for move in strategy:\n        if 'T' not in coins: return coins\n        coins = random.choice(list(rotations(coins)))\n        coins = flip(coins, move)\n    return coins\n\nwinning(strategy=coin_search())",
                "true_label": "",
                "top5_preds": [
                    "coefficient of determination",
                    "manually find the control gains k matrix",
                    "making a precision recall curve",
                    "predicting a categorical response",
                    "stitching images along a minimum cost path"
                ]
            },
            {
                "code": "def Coins(coins) -> str: \n    \"The canonical representation (after rotation) of the 'H'/'T' sequence.\"\n    return min(rotations(''.join(coins)))",
                "true_label": "",
                "top5_preds": [
                    "convert integer or float data",
                    "function to_binary",
                    "convert binary to hexadecimal",
                    "convert data from string to float",
                    "convert date to datetime format"
                ]
            },
            {
                "code": "assert Coins('HHHT') == Coins('HHTH') == Coins('HTHH') == Coins('THHH') == 'HHHT'",
                "true_label": "",
                "top5_preds": [
                    "equally spaced numbers on a grid",
                    "get a positive integer from a user",
                    "find maximum and the minimum value in a set",
                    "ridge regression with one predictor on a grid",
                    "add an item in a tuple"
                ]
            },
            {
                "code": "coin_search()",
                "true_label": "",
                "top5_preds": [
                    "get a positive integer from a user",
                    "getting data from the internet",
                    "obtaining metadata from crossref",
                    "addition of two polynomials",
                    "accessing twitter"
                ]
            },
            {
                "code": "def all_moves(N=4) -> [Move]:\n    \"All canonical moves for a sequence of N coins.\"\n    return [set(i for i in range(N) if coins[i] == 'H')\n            for coins in sorted(all_coins(N))]\n\ndef all_coins(N=4) -> Belief:\n    \"Return the belief set consisting of all possible coin sequences.\"\n    return Belief(map(Coins, product('HT', repeat=N)))\n\ndef rotations(coins) -> {Coins}: \n    \"A list of all possible rotations of a coin sequence.\"\n    return {coins[r:] + coins[:r] for r in range(len(coins))}\n\ndef coin_search(N=4) -> Strategy: \n    \"Use the generic `search` function to solve the Coin Flip problem.\"\n    return search(start=all_coins(N), goal={'H' * N}, actions=all_moves(N), result=update)",
                "true_label": "",
                "top5_preds": [
                    "find the most common words",
                    "most common words",
                    "adding non uniform transition probabilities",
                    "collocations bigrams",
                    "collect them in a list print the elements backwards zero not included"
                ]
            },
            {
                "code": "assert all_moves(3) == [{0, 1, 2}, {0, 1}, {0}, set()]\nassert all_moves(4) == [{0, 1, 2, 3}, {0, 1, 2}, {0, 1}, {0, 2}, {0}, set()]\n\nassert all_coins(4) == {'HHHH', 'HHHT', 'HHTT', 'HTHT', 'HTTT', 'TTTT'}\nassert all_coins(5) == {'HHHHH','HHHHT', 'HHHTT','HHTHT','HHTTT', 'HTHTT', 'HTTTT', 'TTTTT'}\n\nassert rotations('HHHHHT') == {'HHHHHT', 'HHHHTH', 'HHHTHH', 'HHTHHH', 'HTHHHH', 'THHHHH'}\nassert update({'TTTTTTT'}, {3}) == {'HTTTTTT'}\nassert (update(rotations('HHHHHT'), {0}) == update({'HHTHHH'}, {1}) == update({'THHHHH'}, {2})\n        == {'HHHHHH', 'HHHHTT', 'HHHTHT', 'HHTHHT'})\n\nassert coin_search(4) == [\n {0, 1, 2, 3},\n {0, 2},\n {0, 1, 2, 3},\n {0, 1},\n {0, 1, 2, 3},\n {0, 2},\n {0, 1, 2, 3},\n {0, 1, 2},\n {0, 1, 2, 3},\n {0, 2},\n {0, 1, 2, 3},\n {0, 1},\n {0, 1, 2, 3},\n {0, 2},\n {0, 1, 2, 3}]",
                "true_label": "",
                "top5_preds": [
                    "sum all the numbers in a list",
                    "remove duplicates from a list",
                    "collect them in a list print the elements backwards zero not included",
                    "iteration over sets",
                    "multiply all the numbers in a list"
                ]
            },
            {
                "code": "{N: len(all_coins(N))\n for N in range(1, 13)}",
                "true_label": "",
                "top5_preds": [
                    "sum all the numbers in a list",
                    "read numbers until and print their mean and standard deviation without using a list",
                    "get a positive integer from a user",
                    "counting triangles in a social network",
                    "find the most common words"
                ]
            },
            {
                "code": "{N: coin_search(N) for N in range(1, 8)}",
                "true_label": "",
                "top5_preds": [
                    "sum all the numbers in a list",
                    "counting triangles in a social network",
                    "multiply all the numbers in a list",
                    "equally spaced numbers on a grid",
                    "creating polynomial features"
                ]
            },
            {
                "code": "%time strategy = coin_search(8)",
                "true_label": "",
                "top5_preds": [
                    "get a positive integer from a user",
                    "formatting datetimes as strings",
                    "bytes to integer conversion",
                    "pick a random integer using the random module",
                    "predicting a categorical response"
                ]
            },
            {
                "code": "len(strategy)",
                "true_label": "",
                "top5_preds": [
                    "formatting datetimes as strings",
                    "find maximum and the minimum value in a set",
                    "tensorflow + keras",
                    "fit a polynomial",
                    "integrating datetime tools with pandas for time series"
                ]
            },
            {
                "code": "def show(moves, N=4):\n    \"For each move, print the move number, move, and belief state.\"\n    belief = all_coins(N)\n    order = sorted(belief)\n    for (i, move) in enumerate(moves, 1):\n        belief = update(belief, move)\n        print('{:3} | {:8} | {}'.format(\n              i, movestr(move, N), beliefstr(belief, order)))\n\ndef beliefstr(belief, order) -> str: \n    return join(((coins if coins in belief else ' ' * len(coins))\n                 for coins in order), ' ')\n\ndef movestr(move, N) -> str: \n    return join((i if i in move else ' ') \n                for i in range(N))\n    \ndef join(items, sep='') -> str: \n    return sep.join(map(str, items))",
                "true_label": "",
                "top5_preds": [
                    "displaying the data",
                    "print the index of the dataset",
                    "plot the training",
                    "draw flights graph",
                    "plot the data"
                ]
            },
            {
                "code": "show(coin_search(2), 2)",
                "true_label": "",
                "top5_preds": [
                    "get a positive integer from a user",
                    "visualizing uncertainty",
                    "predicting a categorical response",
                    "getting data from the internet",
                    "rounding, overflow, linear algebra"
                ]
            }
        ],
        [
            {
                "code": "import numpy as np\nimport pandas as pd\ndf=pd.DataFrame(np.random.randn(4,3),columns=[\"A\",\"B\",\"C\"],index=list(\"abcd\"))\nprint(df.index)\nprint(df.columns)\n\nprint(\"type of df.A \",type(df.A))\nprint(\"type of df[A]:\",type(df[\"A\"]))\nprint(\"type of df[[A]]:\",type(df[[\"A\"]]))\nprint(\"df.A\\n\",df.A)\nprint(\"df[[\\\"A\\\"]]\\n\",df[[\"A\"]])\n\nprint(\"df.A.values:\",df.A.values)\nprint(\"type of df.A.values:\",type(df.A.values))\n\nprint(\"df[A,B] values:\\n\",df[[\"A\",\"B\"]].values)\nprint(\"flatten:\",df[[\"A\",\"B\"]].values.flatten())\nprint(\"type of flatten:\",type(df[[\"A\",\"B\"]].values.flatten()))\nprint(\"reshape of df[A,B]\\n\",df[[\"A\",\"B\"]].values.reshape(-1,1))\nprint(\"type of reshape:\",type(df[[\"A\",\"B\"]].values.reshape(-1,1)))\nprint(\"df.values\",df.values)\ndf.head(2)",
                "true_label": "",
                "top5_preds": [
                    "find data type of each column",
                    "dataframe methods",
                    "convert categorical variables",
                    "what is the type of the columns?",
                    "change type of column"
                ]
            },
            {
                "code": "x=df[[\"A\"]]\ny=df[\"A\"]\nprint('df[[\\\"A\\\"]]: type is',type(x),\"values is \",x.values)\nprint(\"df[\\\"A\\\"]: type is\",type(y),\"values is \",y.values)\n",
                "true_label": "",
                "top5_preds": [
                    "find data type of each column",
                    "change type of column",
                    "line plot with a dataframe",
                    "convert categorical variables",
                    "dataframe methods"
                ]
            },
            {
                "code": "x=np.random.permutation(len(df))\nprint(\"type of permutation is\",type(x),\"x=\",x)\ndf=df.take(x)\nprint(df)\ndf1=df.sample(2)\nprint(\"sample:\\n\",df1)\ndf1=df.sample(frac=0.5)\nprint(\"sample with fraction of 0.5:\\n\",df1)\n\nprint(\"shuffle between 0 and 9\")\nx=np.random.permutation(10)\nprint(x)",
                "true_label": "",
                "top5_preds": [
                    "create a one column dataframe with the values of a series",
                    "predicting a categorical response",
                    "pandas apply",
                    "import polynomial features from sklearn",
                    "use numpy to generate an array of random numbers sampled from a standard normal distribution"
                ]
            },
            {
                "code": "print(df.empty)\ndf=df.sort_index()\nprint(df)\ndf=df.sort_values(by=[\"B\",\"C\"],ascending=False)\nprint(df)\nprint(\"df.sum():\\n\",df.sum())\nprint(\"df.max():\\n\",df.max())\nprint(\"df.std():\\n\",df.std())\nprint(\"df.var():\\n\",df.var())\nprint(\"df[\\\"A\\\"].sum():\\n\",df[\"A\"].sum())\nprint(\"df[[\\\"A\\\"]].sum():\\n\",df[[\"A\"]].sum())\ndf.tail(2)\n",
                "true_label": "",
                "top5_preds": [
                    "create a one column dataframe with the values of a series",
                    "find data type of each column",
                    "dataframe methods",
                    "sorting data",
                    "create dataframe with given values"
                ]
            },
            {
                "code": "df.apply(np.sum)\n",
                "true_label": "",
                "top5_preds": [
                    "get the sum of all the columns in mat",
                    "create a one column dataframe with the values of a series",
                    "line plot with a dataframe",
                    "sum all the numbers in a list",
                    "pandas apply"
                ]
            },
            {
                "code": "df.applymap(lambda x:x*10)",
                "true_label": "",
                "top5_preds": [
                    "pandas apply",
                    "create a one column dataframe with the values of a series",
                    "line plot with a dataframe",
                    "create an array of linearly spaced points",
                    "create dataframe with given values"
                ]
            },
            {
                "code": "df.apply(lambda x:x.max()-x.min())",
                "true_label": "",
                "top5_preds": [
                    "create a one column dataframe with the values of a series",
                    "integrating datetime tools with pandas for time series",
                    "plotting time series with pandas",
                    "line plot with a dataframe",
                    "line plots show the trend of a numerical variable over time"
                ]
            },
            {
                "code": "df[\"A\"].map(lambda x:x*10)",
                "true_label": "",
                "top5_preds": [
                    "create a one column dataframe with the values of a series",
                    "pandas apply",
                    "line plot with a dataframe",
                    "create dataframe with given values",
                    "dataframe methods"
                ]
            },
            {
                "code": "print(df.loc[\"a\":\"c\",:])\nprint(df.loc[\"a\":\"d\":2,[\"A\",\"C\"]])\nprint(df.loc[:,\"A\":\"C\":2])\nx=df.loc[\"a\"]\nprint(type(x))\nx=df.loc[[\"a\"]]\nprint(type(x))\nprint(df.A)\nx=df.loc[[\"a\",\"d\"],[\"A\"]]\nprint(type(x),x)\n\n#loc[label1] returns a series, loc[label1,label2] returns a scalar\nx=df.loc[\"a\"]\nprint(type(x),x)\nx=df.loc[\"a\",\"C\"]\nprint(type(x),x)\nx=df.at[\"a\",\"C\"]\nprint(type(x),x)\ndf.head()",
                "true_label": "",
                "top5_preds": [
                    "convert categorical variables",
                    "find data type of each column",
                    "loading a csv into a dataframe",
                    "load table in pandas",
                    "change type of column"
                ]
            },
            {
                "code": "print(df.iloc[1:5,:])\nprint(df.iloc[0:100:2,1:])\nprint(df.iloc[[0,3],1:100:2])\nprint(df.iloc[:,[0,1]])\n#iloc[n1,:] or iloc[:,n1] returns a series\nprint(df.iloc[1])\nx=df.iloc[:,2]\nprint(type(x),x)\n\n#iloc[n1,n2] is the same as iat[n1,n2]\nx=df.iloc[1,2]\nprint(type(x),x)\nx=df.iat[1,2]\nprint(type(x),x)\ndf.head()",
                "true_label": "",
                "top5_preds": [
                    "select rows and last five columns by position",
                    "find data type of each column",
                    "select every row up",
                    "selecting specific columns in a dataframe",
                    "select rows by position"
                ]
            },
            {
                "code": "print(\"df[1:3:2]\\n\",df[1:3:2])\nprint(\"df.iloc[1:3:2]\\n\",df.iloc[1:3:2])\nprint(\"df[1:3][\\\"A\\\"]:\\n\",df[1:3][\"A\"])\nprint(\"type of df[1:3][A]:\\n\",type(df[1:3][\"A\"]),df[1:3][\"A\"].values)",
                "true_label": "",
                "top5_preds": [
                    "find data type of each column",
                    "convert categorical variables",
                    "convert date to datetime format",
                    "change type of column",
                    "line plot with a dataframe"
                ]
            },
            {
                "code": "#loc can be used to add a new row or edit an existing row\ndf.loc[\"e\"]=dict(A=1,B=2,C=3)\ndf.loc[\"a\"]=dict(A=2,B=4,C=5)\nprint(df)\n# iloc can be used to edit an existing row\ndf.iloc[len(df.index)-1]=dict(A=3,B=8,C=1)\ndf.head()",
                "true_label": "",
                "top5_preds": [
                    "from dictionary to dataframe",
                    "create a one column dataframe with the values of a series",
                    "create dataframe with given values",
                    "selecting specific columns in a dataframe",
                    "in pandas"
                ]
            },
            {
                "code": "df.A=[1]*len(df.index)\ndf[\"F\"]=[2]*len(df.index)\nprint(df)\ndf[\"F\"]=np.nan\nprint(\"after df.A.dropna()\\n\",df.A.dropna())\nprint(\"after df.dropna()\\n\",df.dropna())\ndf.head()",
                "true_label": "",
                "top5_preds": [
                    "create dataframe with given values",
                    "create a one column dataframe with the values of a series",
                    "dataframe methods",
                    "create a dataframe",
                    "in pandas"
                ]
            },
            {
                "code": "print(df)\ndf[[\"A\",\"B\"]].drop_duplicates()\n\nprint(\"set the first row to na:\\n\")\ndf[0:1]=np.nan\nprint(\"after dropna:\\n\",df.dropna())\nprint(\"after fillna:\\n\",df.fillna(0))\nprint(\"df.mean\\n\",df.mean())\nvalues=dict(df.mean())\nprint(\"after fillna with mean of each column:\\n\",df.fillna(values))\ndf.head()\n",
                "true_label": "",
                "top5_preds": [
                    "create dataframe with given values",
                    "create a dataframe",
                    "dataframe methods",
                    "create a data dictionary",
                    "from dictionary to dataframe"
                ]
            },
            {
                "code": "print(df)\n\nprint(\"A>0 and B>0:\\n\",df[(df[\"A\"]>0) & (df[\"B\"]>0)])\nprint(\"A>0 and B>0 with query:\\n\")\ndf.query(\"A>0 & B>0\")\n",
                "true_label": "",
                "top5_preds": [
                    "filtering with boolean arrays",
                    "what is conditional probability good for?",
                    "sql LIKE operator",
                    "split a dataframe into a testing",
                    "create dataframe with given values"
                ]
            },
            {
                "code": "import re\nres={\"host\":[\"lwn123.ihep.ac.cn\",\"aws123\",\"lwn139\",\"aws188\"],\"value\":[1,2,3,4]}\ndf2=pd.DataFrame(res)\ndef host_is_aws(hostname):\n    if re.match(r'aws.*',hostname):\n        return True\n    else:\n        return False\ndf_lwn=df2[df2.host.map(host_is_aws)]\ndf_lwn.head()\n",
                "true_label": "",
                "top5_preds": [
                    "find data type of each column",
                    "create dataframe with given values",
                    "dataframe methods",
                    "pandas regex",
                    "join two dataframes along rows"
                ]
            },
            {
                "code": "print(\"randn(3):\\n\",np.random.randn(3))\nprint(\"randn(3,2):\\n\",np.random.randn(3,2))\ns=pd.Series(np.random.randn(3),index=list(\"ABC\"))\n\ns.head()",
                "true_label": "",
                "top5_preds": [
                    "create a one column dataframe with the values of a series",
                    "line plots show the trend of a numerical variable over time",
                    "plotting time series with pandas",
                    "formatting datetimes as strings",
                    "load table in pandas"
                ]
            }
        ],
        [
            {
                "code": "url_template = \"http://climate.weather.gc.ca/climate_data/bulk_data_e.html?format=csv&stationID=5415&Year={year}&Month={month}&timeframe=1&submit=Download+Data\"",
                "true_label": "",
                "top5_preds": [
                    "getting data from the internet",
                    "load table in pandas",
                    "importing data with pandas",
                    "downloading the data",
                    "retrieving data from html page"
                ]
            },
            {
                "code": "url = url_template.format(month=3, year=2012)\nurl",
                "true_label": "",
                "top5_preds": [
                    "formatting datetimes as strings",
                    "convert date to datetime format",
                    "add string to list using append",
                    "convert a tuple to a string",
                    "plotting time series with pandas"
                ]
            },
            {
                "code": "import pandas as pd\nweather_mar2012 = pd.read_csv(url, skiprows=15, index_col='Date/Time', parse_dates=True, encoding='latin1')",
                "true_label": "",
                "top5_preds": [
                    "convert date to datetime format",
                    "importing data with pandas",
                    "importing data with numpy",
                    "load table in pandas",
                    "loading a csv into a dataframe"
                ]
            },
            {
                "code": "weather_mar2012.head()",
                "true_label": "",
                "top5_preds": [
                    "convert date to datetime format",
                    "working with pandas series indexed by datetime",
                    "integrating datetime tools with pandas for time series",
                    "plotting time series with pandas",
                    "line plots show the trend of a numerical variable over time"
                ]
            },
            {
                "code": "wiki = \"https://en.wikipedia.org/wiki/States_and_territories_of_Australia\"",
                "true_label": "",
                "top5_preds": [
                    "create a list of all words",
                    "formatting datetimes as strings",
                    "importing data with numpy",
                    "getting data from the internet",
                    "sum all the numbers in a list"
                ]
            },
            {
                "code": "page = urlopen(wiki)",
                "true_label": "",
                "top5_preds": [
                    "getting data from the internet",
                    "retrieving data from html page",
                    "sum all the numbers in a list",
                    "what is scikit learn?",
                    "formatting datetimes as strings"
                ]
            },
            {
                "code": "if sys.version_info[0] == 3:\n    page = page.read()",
                "true_label": "",
                "top5_preds": [
                    "getting data from the internet",
                    "retrieving data from html page",
                    "running a local postgres database",
                    "read numbers until and print their mean and standard deviation without using a list",
                    "download and inspect the twitter samples dataset"
                ]
            },
            {
                "code": "soup = BeautifulSoup(page, \"lxml\")",
                "true_label": "",
                "top5_preds": [
                    "retrieving data from html page",
                    "getting data from the internet",
                    "load table in pandas",
                    "formatting datetimes as strings",
                    "what is scikit learn?"
                ]
            },
            {
                "code": " print (soup.prettify())",
                "true_label": "",
                "top5_preds": [
                    "retrieving data from html page",
                    "getting data from the internet",
                    "web scraping",
                    "formatting datetimes as strings",
                    "the most famous quote in regex dom"
                ]
            },
            {
                "code": "soup.title.string",
                "true_label": "",
                "top5_preds": [
                    "retrieving data from html page",
                    "the most famous quote in regex dom",
                    "getting data from the internet",
                    "matching metacharacters literally",
                    "formatting datetimes as strings"
                ]
            },
            {
                "code": "all_tables = soup.findAll('table')\nprint(all_tables)",
                "true_label": "",
                "top5_preds": [
                    "retrieving data from html page",
                    "load table in pandas",
                    "get the names of all the tables in the database",
                    "getting data from the internet",
                    "sum all the numbers in a list"
                ]
            },
            {
                "code": "right_table=soup.find('table', class_='wikitable sortable')\nprint (right_table)",
                "true_label": "",
                "top5_preds": [
                    "getting data from the internet",
                    "retrieving data from html page",
                    "select every row after a specific row",
                    "accessing twitter",
                    "find maximum and the minimum value in a set"
                ]
            },
            {
                "code": "head_row = right_table.find('tr')\nprint (head_row)",
                "true_label": "",
                "top5_preds": [
                    "select every row after a specific row",
                    "retrieving data from html page",
                    "the most famous quote in regex dom",
                    "load table in pandas",
                    "find maximum and the minimum value in a set"
                ]
            },
            {
                "code": "header_list = []\nheaders = head_row.findAll('th')\nfor header in headers:\n    #print header.find(text = True)\n    header_list.append(header.find(text = True))\nheader_list",
                "true_label": "",
                "top5_preds": [
                    "retrieving data from html page",
                    "getting data from the internet",
                    "convert text data into vector",
                    "add string to list using append",
                    "add an item in a tuple"
                ]
            },
            {
                "code": "flag=[]\nstate=[]\nabbrev = []\nISO = []\nPostal =[]\nType = []\nCapital = []\npopulation = []\nArea = []\nfor row in right_table.findAll(\"tr\"):\n    cells = row.findAll('td')\n    if len(cells) > 0 and len(cells) == 9:\n        flag.append(cells[0].find(text=True))\n        state.append(cells[1].find(text=True))\n        abbrev.append(cells[2].find(text=True))\n        ISO.append(cells[3].find(text=True))\n        Postal.append(cells[4].find(text=True))\n        Type.append(cells[5].find(text=True))\n        Capital.append(cells[6].find(text=True))\n        population.append(cells[7].find(text=True))\n        Area.append(cells[8].find(text=True))",
                "true_label": "",
                "top5_preds": [
                    "how to change the style of individual lines",
                    "add an item in a tuple",
                    "retrieving data from html page",
                    "add string to list using append",
                    "importing data with numpy"
                ]
            },
            {
                "code": "weather_mar2012 = weather_mar2012.dropna(axis=1, how='any')",
                "true_label": "",
                "top5_preds": [
                    "integrating datetime tools with pandas for time series",
                    "join two dataframes along rows",
                    "convert date to datetime format",
                    "in pandas",
                    "using pandas"
                ]
            },
            {
                "code": "weather_mar2012 = weather_mar2012.drop(['Year', 'Month', 'Day', 'Time'], axis=1)\nweather_mar2012[:5]",
                "true_label": "",
                "top5_preds": [
                    "convert date to datetime format",
                    "plotting time series with pandas",
                    "load table in pandas",
                    "select every row after a specific row",
                    "formatting datetimes as strings"
                ]
            },
            {
                "code": "def download_weather_month(year, month):\n    url = url_template.format(year=year, month=month)\n    weather_data = pd.read_csv(url, skiprows=15, index_col='Date/Time', parse_dates=True)\n    weather_data = weather_data.dropna(axis=1)\n    weather_data.columns = [col.replace('\\xb0', '') for col in weather_data.columns]\n    weather_data = weather_data.drop(['Year', 'Day', 'Month', 'Time'], axis=1)\n    return weather_data",
                "true_label": "",
                "top5_preds": [
                    "download and inspect the twitter samples dataset",
                    "getting data from the internet",
                    "get the data",
                    "calculate the mean windspeed for each month in the dataset",
                    "download the newsgroups dataset"
                ]
            },
            {
                "code": "download_weather_month(2012, 1).head()",
                "true_label": "",
                "top5_preds": [
                    "convert date to datetime format",
                    "calculate the mean windspeed for each month in the dataset",
                    "formatting datetimes as strings",
                    "heatmap with time",
                    "load table in pandas"
                ]
            },
            {
                "code": "data_by_month = [download_weather_month(2012, i) for i in range(1, 12)]",
                "true_label": "",
                "top5_preds": [
                    "getting data from the internet",
                    "convert date to datetime format",
                    "calculate the mean windspeed for each month in the dataset",
                    "sum all the numbers in a list",
                    "formatting datetimes as strings"
                ]
            },
            {
                "code": "weather_2012 = pd.concat(data_by_month)",
                "true_label": "",
                "top5_preds": [
                    "convert date to datetime format",
                    "working with pandas series indexed by datetime",
                    "create a one column dataframe with the values of a series",
                    "plotting time series with pandas",
                    "integrating datetime tools with pandas for time series"
                ]
            },
            {
                "code": "weather_2012.info()",
                "true_label": "",
                "top5_preds": [
                    "importing data with numpy",
                    "integrating datetime tools with pandas for time series",
                    "load table in pandas",
                    "introduction to the python datetime tools",
                    "convert date to datetime format"
                ]
            },
            {
                "code": "weather_2012.to_csv('weather_2012.csv')",
                "true_label": "",
                "top5_preds": [
                    "convert date to datetime format",
                    "from dictionary to dataframe",
                    "loading a csv into a dataframe",
                    "importing data with pandas",
                    "formatting datetimes as strings"
                ]
            },
            {
                "code": "!ls",
                "true_label": "",
                "top5_preds": [
                    "check a list is empty or not",
                    "convert list to numpy array",
                    "formatting datetimes as strings",
                    "add string to list using append",
                    "sum all the numbers in a list"
                ]
            },
            {
                "code": "import sys\nif sys.version_info[0] == 3:\n    from urllib.request import urlopen\nelse:\n    from urllib import urlopen\nfrom bs4 import BeautifulSoup",
                "true_label": "",
                "top5_preds": [
                    "getting data from the internet",
                    "retrieving data from html page",
                    "running a local postgres database",
                    "accessing databases via web apis",
                    "connect to a remote database"
                ]
            },
            {
                "code": "page = urlopen(wiki)",
                "true_label": "",
                "top5_preds": [
                    "getting data from the internet",
                    "retrieving data from html page",
                    "sum all the numbers in a list",
                    "what is scikit learn?",
                    "formatting datetimes as strings"
                ]
            }
        ],
        [
            {
                "code": "\nimport warnings\nwarnings.simplefilter('ignore')\n\nfrom clustering.clusters import *",
                "true_label": "",
                "top5_preds": [
                    "calculating the mean of a vector with nans",
                    "predicting a categorical response",
                    "equally spaced numbers on a grid",
                    "credible interval vs confidence interval",
                    "using k nearest neighbor for imputing missing data"
                ]
            }
        ],
        [
            {
                "code": "# header code\nimport numpy as np\nimport scipy as sp\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\nfrom statsmodels import discrete\nimport re\nimport pandas as pd\nimport math \nimport csv\nimport time\nimport dateutil\nfrom datetime import datetime\nimport seaborn as sns\n# pandas options plus some more\npd.set_option('display.width', 1000)\npd.set_option('display.max_columns', 100)\npd.set_option('display.notebook_repr_html', True)\npd.options.display.float_format = '{:,.2f}'.format\nsns.set_style(\"whitegrid\")\nsns.set_context(\"poster\")\nimport matplotlib as mpl\nimport matplotlib.cm as cm\nimport matplotlib.pyplot as plt\nfrom matplotlib import gridspec\nfrom matplotlib import ticker\n\nfrom IPython.display import Image\nfrom IPython.core.display import HTML\n\n\nmillnames = ['',' Thousand',' Million',' Billion',' Trillion']\ndef millify(n, pos):\n    n = float(n)\n    millidx = max(0,min(len(millnames)-1,\n                        int(math.floor(0 if n == 0 else math.log10(abs(n))/3))))\n    thingtoreturn = n / 10**(3 * millidx)\n    if thingtoreturn % 1 == 0:\n        return '{:.0f}{}'.format(thingtoreturn, millnames[millidx])\n    elif thingtoreturn % 0.1 == 0:\n        return '{:.1f}{}'.format(thingtoreturn, millnames[millidx])\n    else:\n        return '{:.2f}{}'.format(thingtoreturn, millnames[millidx])",
                "true_label": "",
                "top5_preds": [
                    "importing data with numpy",
                    "import polynomial features from sklearn",
                    "integrating datetime tools with pandas for time series",
                    "plotting time series with pandas",
                    "using a dataframe and matplotlib commands"
                ]
            },
            {
                "code": "# Figure 1\nImage(\"./exports/figures/Political Affiliation of Municipality Presidents in Serbia 2012-2016.png\", width=1000)",
                "true_label": "",
                "top5_preds": [
                    "how to change the size of a plot",
                    "matplotlib",
                    "trend lines in pyplot",
                    "plot using matplotlib",
                    "formatting datetimes as strings"
                ]
            },
            {
                "code": "# Municipality Map\nImage(\"./exports/figures/municipalitiesmap.png\", width=450)",
                "true_label": "",
                "top5_preds": [
                    "using json to find your location",
                    "importing data with numpy",
                    "equally spaced numbers on a grid",
                    "heatmap with time",
                    "import polynomial features from sklearn"
                ]
            }
        ],
        [
            {
                "code": "import numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport scipy.integrate\n\nlat = -81\nlon = -85\nelev = 0\n\nz = np.arange(1, 2e5, 1e2) # depth below a rock surface in g/cm^2\npressure = 833 # hPa",
                "true_label": "",
                "top5_preds": [
                    "equally spaced numbers on a grid",
                    "create an array of linearly spaced points",
                    "line plot with a dataframe",
                    "heatmap with time",
                    "plot using matplotlib"
                ]
            },
            {
                "code": "H = (1013.25 - pressure) * 1.019716",
                "true_label": "",
                "top5_preds": [
                    "ridge regression with one predictor on a grid",
                    "fit a polynomial",
                    "ridge regression with polynomial features on a grid",
                    "numpy",
                    "heatmap with time"
                ]
            },
            {
                "code": "sec2yrs = 3.15576e7\nphi_vert_slhl = sec2yrs * (258.5 * (100 ** 2.66) / ((z + 21000)* \n                     (((z+1000)**1.66) + 75*(100**1.66))))*np.exp(-5.5e-6 * z)",
                "true_label": "",
                "top5_preds": [
                    "formatting datetimes as strings",
                    "line plots show the trend of a numerical variable over time",
                    "linear algebra",
                    "linear regression of many variables",
                    "fit a polynomial"
                ]
            },
            {
                "code": "def Rv0(z):\n    a = 3.15576e7*258.5*100**2.66 * np.exp(-5.5e-6*z)\n    b = z + 21000\n    c = (z + 1000)**1.66 + 75*100**1.66\n    dadz = 3.15576e7*258.5*100**2.66 * -5.5e-6 * np.exp(-5.5e-6*z)\n    dbdz = 1\n    dcdz = 1.66 * (z + 1000) ** 0.66\n    \n    # In the following, apply product and quotient rules.\n    # also, the negative applied because we want a positive stopping rate\n    return -(b * c * dadz - a * (dbdz * c + b * dcdz)) / (b * c) ** 2\n\nR_vert_slhl = Rv0(z)",
                "true_label": "",
                "top5_preds": [
                    "function to find dbZ given Pr radar equation",
                    "co variance matrix",
                    "create an array of zeros",
                    "solve equation for x",
                    "filling the mask"
                ]
            },
            {
                "code": "def mu_atten(z):\n\n        \"\"\" this subfunction returns the effective atmospheric attenuation\n        length for muons that will have a range z once they enter rock \"\"\"\n\n        \"\"\" define range/momentum relation. table for muons in standard rock in\n        Groom and others 2001. Units are range in g cm-2 (column 2).\n        Momentum in MeV/c (column 1)\"\"\"\n        data = np.array([\n                [4.704e1, 8.400e-1],\n                [5.616e1, 1.530e0],\n                [6.802e1, 2.854e0],\n                [8.509e1, 5.687e0],\n                [1.003e2, 9.133e0],\n                [1.527e2, 2.675e1],\n                [1.764e2, 3.695e1],\n                [2.218e2, 5.878e1],\n                [2.868e2, 9.331e1],\n                [3.917e2, 1.523e2],\n                [4.945e2, 2.114e2],\n                [8.995e2, 4.418e2],\n                [1.101e3, 5.534e2],\n                [1.502e3, 7.712e2],\n                [2.103e3, 1.088e3],\n                [3.104e3, 1.599e3],\n                [4.104e3, 2.095e3],\n                [8.105e3, 3.998e3],\n                [1.011e4, 4.920e3],\n                [1.411e4, 6.724e3],\n                [2.011e4, 9.360e3],\n                [3.011e4, 1.362e4],\n                [4.011e4, 1.776e4],\n                [8.011e4, 3.343e4],\n                [1.001e5, 4.084e4],\n                [1.401e5, 5.495e4],\n                [2.001e5, 7.459e4],\n                [3.001e5, 1.040e5],\n                [4.001e5, 1.302e5],\n                [8.001e5, 2.129e5]]) # ignore ranges larger than 2e5 g/cm2\n    \n        # obtain momenta (use log-linear interpolation)\n        P_MeVc = np.exp(np.interp(np.log(z), np.log(data[:, 1]), np.log(data[:, 0])))\n    \n        # obtain attenuation lengths\n        # This is the equation found in the Boezio/CAPRICE papers (linear relation between\n        # mean momentum and attenuation length in the 190-1000 g/cm^2 range)\n        return 263 + 150 * (P_MeVc / 1000)\n    \nR_vert_site = R_vert_slhl * np.exp(H / mu_atten(z))",
                "true_label": "",
                "top5_preds": [
                    "pi by means of the arithmetic geometric mean",
                    "co variance matrix",
                    "function to find dbZ given Pr radar equation",
                    "covariance matrix",
                    "compute covariance matrix"
                ]
            },
            {
                "code": "phi_vert_site = []\nlen_z = len(z)\nfor i in range(len_z):\n    #phi_vert_site(i) = integral(@(x) Rv0(x).*exp(H./mu_atten(x)) , z(i) , 2e5 )\n    ans, err = scipy.integrate.quad(lambda x:\n                Rv0(x)*np.exp(H/mu_atten(x)), z[i], 2e5,  args=(), full_output=0, epsabs=1.49e-08, epsrel=1.49e-08, limit=100)\n    phi_vert_site.append(ans)",
                "true_label": "",
                "top5_preds": [
                    "likelihood of the binomial distribution",
                    "create an array of linearly spaced points",
                    "pi by means of the arithmetic geometric mean",
                    "compute covariance matrix",
                    "likelihood of the binomial"
                ]
            },
            {
                "code": "phi_200k = (3.15576e7 * 258.5*(100**2.66)/((2e5+21000)*(((2e5+1000)**1.66)\n                        + 75*(100**1.66))))*np.exp(-5.5e-6 * 2e5)\nphi_vert_site = phi_vert_site + phi_200k",
                "true_label": "",
                "top5_preds": [
                    "pi by means of the arithmetic geometric mean",
                    "fit a polynomial",
                    "co variance matrix",
                    "fitting an nth degree polynomial",
                    "use numpy to generate a random number"
                ]
            },
            {
                "code": "K_mu = 1.268           # ratio of positive and negative muons\nf_mu_neg = 1 / (1 + K_mu)",
                "true_label": "",
                "top5_preds": [
                    "traffic sign classification with keras",
                    "likelihood of the binomial",
                    "likelihood of the binomial distribution",
                    "scikit learn",
                    "principal component analysis with random data"
                ]
            },
            {
                "code": "# angular distribution exponent\nnofz = 3.21 - 0.297 * np.log((z + H) / 100 + 42) + 1.21e-5 * (z + H)\n\n# derivative of exponent: d(n(z))/dz\ndndz = -0.297 / (z + H + 4200) + 1.21e-5",
                "true_label": "",
                "top5_preds": [
                    "pi by means of the arithmetic geometric mean",
                    "use numpy to generate an array of random numbers sampled from a standard normal distribution",
                    "fit a polynomial",
                    "likelihood of the binomial distribution",
                    "line plots show the trend of a numerical variable over time"
                ]
            },
            {
                "code": "phi = phi_vert_site * 2 * np.pi / (nofz+1)",
                "true_label": "",
                "top5_preds": [
                    "pi by means of the arithmetic geometric mean",
                    "fit a polynomial",
                    "use numpy to generate an array of random numbers sampled from a standard normal distribution",
                    "create an array of linearly spaced points",
                    "diagonal sum in a spiral"
                ]
            },
            {
                "code": "R = -f_mu_neg * (2 * np.pi * -R_vert_site / (nofz+1) - 2 *\n                     np.pi*phi_vert_site*dndz/((nofz+1)**2))",
                "true_label": "",
                "top5_preds": [
                    "scipy",
                    "ridge regression with polynomial features on a grid",
                    "diagonal sum in a spiral",
                    "analytical tools for seismic data",
                    "use numpy to generate an array of random numbers sampled from a standard normal distribution"
                ]
            },
            {
                "code": "# Depth-dependent parts of the fast muon reaction cross-section\nBeta = 0.846 - 0.015 * np.log((z / 100) + 1) + 0.003139 * (np.log((z/100)+1)**2)\nEbar = 7.6 + 321.7*(1 - np.exp(-8.059e-6*z)) + 50.7 * (1-np.exp(-5.05e-7**z))",
                "true_label": "",
                "top5_preds": [
                    "line plots show the trend of a numerical variable over time",
                    "ridge regression with polynomial features on a grid",
                    "principal component analysis with random data",
                    "linear regression of many variables",
                    "ridge regression with one predictor on a grid"
                ]
            }
        ],
        [
            {
                "code": "# Specify time series\ntimeseries_list = ['T_MAX','P_CALC','sin_Hr','cos_Hr', 'sin_day_of_year','cos_day_of_year']\n\n# Formatting time series\ndurham_tbl.timeseries_formatting(timeid='datetime',timeseries=timeseries_list, extra_columns=[], timeid_informat='anydtdtm19.')",
                "true_label": "",
                "top5_preds": [
                    "formatting datetimes as strings",
                    "plotting time series with pandas",
                    "integrating datetime tools with pandas for time series",
                    "convert date to datetime format",
                    "working with pandas series indexed by datetime"
                ]
            },
            {
                "code": "durham_tbl.timeid_type",
                "true_label": "",
                "top5_preds": [
                    "convert date to datetime format",
                    "integrating datetime tools with pandas for time series",
                    "formatting datetimes as strings",
                    "plotting time series with pandas",
                    "line plots show the trend of a numerical variable over time"
                ]
            },
            {
                "code": "# Accumulate time series\ndurham_tbl.timeseries_accumlation(acc_interval='hour', acc_method_byvar={'T_MAX':'max', \n                                                                         'sin_Hr':'avg',\n                                                                         'cos_Hr':'avg',\n                                                                        'sin_day_of_year':'avg', \n                                                                        'cos_day_of_year':'avg'})",
                "true_label": "",
                "top5_preds": [
                    "line plots show the trend of a numerical variable over time",
                    "cacluate totals by group",
                    "summarize the dataframe",
                    "credible interval vs confidence interval",
                    "integrating datetime tools with pandas for time series"
                ]
            },
            {
                "code": "# Make time series into subsequences\ndurham_tbl.prepare_subsequences(seq_len=5, target='T_MAX', predictor_timeseries=timeseries_list)",
                "true_label": "",
                "top5_preds": [
                    "create a one column dataframe with the values of a series",
                    "load table in pandas",
                    "formatting datetimes as strings",
                    "optimal value of k for dataset",
                    "plotting time series with pandas"
                ]
            },
            {
                "code": "# Split time series into train and test -- python time!\nvalidation_start = datetime.date(2017,1,1)\ntesting_start = datetime.date(2017,11,1)\n\ntrain_tbl, valid_tbl, test_tbl = durham_tbl.timeseries_partition(validation_start=validation_start, testing_start=testing_start)",
                "true_label": "",
                "top5_preds": [
                    "integrating datetime tools with pandas for time series",
                    "formatting datetimes as strings",
                    "working with pandas series indexed by datetime",
                    "join two dataframes along rows",
                    "split a dataframe into a testing"
                ]
            },
            {
                "code": "model1 = Sequential(conn, model_table='lstm_rnn')\nmodel1.add(InputLayer(std='STD'))\nmodel1.add(Recurrent(rnn_type='LSTM', output_type='samelength', n=15, reversed_=False))\nmodel1.add(Recurrent(rnn_type='LSTM', output_type='encoding', n=15, reversed_=False))\nmodel1.add(OutputLayer(act='IDENTITY'))\nmodel1.plot_network()",
                "true_label": "",
                "top5_preds": [
                    "tensorflow + keras",
                    "logistic regression using tensorflow",
                    "training a sequential model",
                    "keras sequential model",
                    "scikit learn 4 step modeling pattern"
                ]
            },
            {
                "code": "optimizer = Optimizer(algorithm=AdamSolver(learning_rate=0.01), mini_batch_size=32, seed=1234, max_epochs=50)\n                           \nseq_spec  = Sequence(**train_tbl.sequence_opt)",
                "true_label": "",
                "top5_preds": [
                    "tensorflow + keras",
                    "scikit learn",
                    "the scikit learn interface",
                    "training a sequential model",
                    "fit on training"
                ]
            },
            {
                "code": "result = model1.fit(train_tbl, valid_table=valid_tbl, optimizer=optimizer, sequence=seq_spec, **train_tbl.inputs_target)\nmodel1.plot_training_history()",
                "true_label": "",
                "top5_preds": [
                    "tensorflow + keras",
                    "logistic regression using tensorflow",
                    "load table in pandas",
                    "training a sequential model",
                    "what is scikit learn?"
                ]
            },
            {
                "code": "result = model1.predict(test_tbl)\nresulttbl = model1.valid_res_tbl",
                "true_label": "",
                "top5_preds": [
                    "test the model for accuracy",
                    "import polynomial features from sklearn",
                    "using the model for prediction",
                    "load table in pandas",
                    "tensorflow + keras"
                ]
            },
            {
                "code": "import datetime\nfrom swat import *\nfrom dlpy import Model, Sequential, TimeseriesTable\nfrom dlpy.layers import * \nfrom dlpy.applications import *\nfrom dlpy.model import Optimizer, AdamSolver, Sequence, DLPyDict\nfrom dlpy.timeseries import plot_timeseries\n%matplotlib inline\n\nconn = CAS('hostname', your-port-number)\ndata_client_path = './datasources/durham_v2.csv'",
                "true_label": "",
                "top5_preds": [
                    "load table in pandas",
                    "polynomial regression with sklearn",
                    "import polynomial features from sklearn",
                    "linear regression of many variables",
                    "formatting datetimes as strings"
                ]
            },
            {
                "code": "durham_tbl = TimeseriesTable.from_localfile(conn, data_client_path)",
                "true_label": "",
                "top5_preds": [
                    "load table in pandas",
                    "read text file point",
                    "running a local postgres database",
                    "getting data from the internet",
                    "reading in and sampling from the data"
                ]
            },
            {
                "code": "durham_tbl.head()",
                "true_label": "",
                "top5_preds": [
                    "load table in pandas",
                    "loading a csv into a dataframe",
                    "line plots show the trend of a numerical variable over time",
                    "convert text data into vector",
                    "formatting datetimes as strings"
                ]
            },
            {
                "code": "durham_tbl.datetime.dtype",
                "true_label": "",
                "top5_preds": [
                    "transform the date column as a datetime type",
                    "convert date to datetime format",
                    "find data type of each column",
                    "working with pandas series indexed by datetime",
                    "integrating datetime tools with pandas for time series"
                ]
            },
            {
                "code": "figure1 = plot_timeseries(resulttbl, 'datetime', 'T_MAX', label='Actual', xdate_format='%d-%b-%Y:%H', figsize=(12, 8), \n                        xlabel='Datetime', ylabel='Temperature', linewidth=2, title='Durham Temperature Forecast')\n\nfigure2 = plot_timeseries(resulttbl, 'datetime', '_DL_Pred_', label='Predicted', figure = figure1, linestyle='--', color='red',\n                        linewidth=2)\n",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "plotting time series with pandas",
                    "pandas plotting",
                    "line plots show the trend of a numerical variable over time",
                    "ploting out data with box plots"
                ]
            },
            {
                "code": "model1 = Sequential(conn, model_table='lstm_rnn')\nmodel1.add(InputLayer(std='STD'))\nmodel1.add(Recurrent(rnn_type='LSTM', output_type='samelength', n=15, reversed_=False))\nmodel1.add(Recurrent(rnn_type='LSTM', output_type='encoding', n=15, reversed_=False))\nmodel1.add(OutputLayer(act='IDENTITY'))\nmodel1.plot_network()",
                "true_label": "",
                "top5_preds": [
                    "tensorflow + keras",
                    "logistic regression using tensorflow",
                    "training a sequential model",
                    "keras sequential model",
                    "scikit learn 4 step modeling pattern"
                ]
            }
        ],
        [
            {
                "code": "import pods\nimport pylab as plt\n%matplotlib inline",
                "true_label": "",
                "top5_preds": [
                    "trend lines in pyplot",
                    "plot using matplotlib",
                    "plotting in python",
                    "matplotlib",
                    "timing, numpy, plotting"
                ]
            },
            {
                "code": "data = pods.datasets.airline_delay() ",
                "true_label": "",
                "top5_preds": [
                    "formatting datetimes as strings",
                    "load table in pandas",
                    "convert data from string to float",
                    "from dictionary to dataframe",
                    "transform the date column as a datetime type"
                ]
            },
            {
                "code": "data['X'].shape\ndata['Y'].shape",
                "true_label": "",
                "top5_preds": [
                    "plot multidimensional data in two dimensions",
                    "numpy",
                    "what is scikit learn?",
                    "scipy",
                    "equally spaced numbers on a grid"
                ]
            },
            {
                "code": "data['Xtest'].shape\ndata['Ytest'].shape",
                "true_label": "",
                "top5_preds": [
                    "plot multidimensional data in two dimensions",
                    "what is scikit learn?",
                    "numpy",
                    "scipy",
                    "equally spaced numbers on a grid"
                ]
            },
            {
                "code": "print(data['citation'])",
                "true_label": "",
                "top5_preds": [
                    "retrieving data from html page",
                    "loading json in python",
                    "getting data from the internet",
                    "importing data with numpy",
                    "data given as a dictionary"
                ]
            },
            {
                "code": "print(data['info'])\nprint()\nprint(data['details'])",
                "true_label": "",
                "top5_preds": [
                    "getting data from the internet",
                    "retrieving data from html page",
                    "loading json in python",
                    "get a positive integer from a user",
                    "data given as a dictionary"
                ]
            }
        ],
        [
            {
                "code": "import ROOT",
                "true_label": "",
                "top5_preds": [
                    "convert list to numpy array",
                    "import polynomial features from sklearn",
                    "creating a tree diagram",
                    "equally spaced numbers on a grid",
                    "convert date to datetime format"
                ]
            },
            {
                "code": "h = ROOT.TH1F(\"h\", \"My Notebook Histo;x;#\", 64, -4, 4)",
                "true_label": "",
                "top5_preds": [
                    "trend lines in pyplot",
                    "how to change the style of individual lines",
                    "line plots show the trend of a numerical variable over time",
                    "creating a tree diagram",
                    "plot using matplotlib"
                ]
            },
            {
                "code": "from random import gauss\nnumbers = [gauss(0., 1.) for _ in range(1000)]\nnumbers",
                "true_label": "",
                "top5_preds": [
                    "sum all the numbers in a list",
                    "multiply all the numbers in a list",
                    "pick a random integer using the random module",
                    "random variates",
                    "use numpy to generate a random number"
                ]
            },
            {
                "code": "for i in numbers: h.Fill(i)",
                "true_label": "",
                "top5_preds": [
                    "how to change the style of individual lines",
                    "sum all the numbers in a list",
                    "equally spaced numbers on a grid",
                    "create an array of linearly spaced points",
                    "create an array of integers"
                ]
            },
            {
                "code": "h.SetLineColor(ROOT.kBlue)\nh.SetFillColor(ROOT.kBlue)\nc = ROOT.TCanvas()\nh.Draw()\nc.Draw()",
                "true_label": "",
                "top5_preds": [
                    "how to change the color of a plot",
                    "how to change the style of individual lines",
                    "trend lines in pyplot",
                    "how to change the size of a plot",
                    "add edges in graph"
                ]
            }
        ],
        [
            {
                "code": "# the function is here as a reminder, since it is already defined from the code above\na = 10\n\ndef my_function(argument):\n    cube = argument ** 3\n    print(cube)\n    print('a: {}'.format(a))\n\nmy_function(4)\nprint(cube)",
                "true_label": "",
                "top5_preds": [
                    "defining a function",
                    "define a function",
                    "detect the number of local variables declared in a function",
                    "python functions",
                    "strings as function arguments"
                ]
            },
            {
                "code": "# we slightly changed the function from before\n# instead of displaying cube in the command line,\n# it now returns the vaule of cube to the code\ndef my_function(argument):\n    cube = argument ** 3\n    \n    # here, we return cube\n    return cube",
                "true_label": "",
                "top5_preds": [
                    "define a function",
                    "get a positive integer from a user",
                    "plot the function",
                    "the command line",
                    "strings as function arguments"
                ]
            },
            {
                "code": "# define a variable\nx = 10\n\n# pass the variable to a function,\n# and save its return value in a variable\nwhat_we_got_back = my_function(x)\n\n# check the result\nprint(what_we_got_back)",
                "true_label": "",
                "top5_preds": [
                    "get a positive integer from a user",
                    "assign to a variable",
                    "what is a string?",
                    "fit a polynomial",
                    "detect the number of local variables declared in a function"
                ]
            },
            {
                "code": "# a simple polynomial\ndef f(x):\n    # note: we also can return the result\n    # directly, without saving it to a \n    # variable first\n    result = 2 * x**2 + 4 * x + 10\n    return result\n\nx = 10\ncalculate = f(x)\n\nprint(calculate)",
                "true_label": "",
                "top5_preds": [
                    "fit a polynomial",
                    "test whether a number is positive",
                    "likelihood of the binomial distribution",
                    "likelihood of the binomial",
                    "polynomial regression"
                ]
            },
            {
                "code": "# a function that could write emails\ndef print_greeting(person):\n\n    # we can return any value; it doesn't need to be in\n    # a variable first.\n    return 'Dear Prof {},\\nI would like to do a PhD with you.\\n'\\\n          .format(person)\n    \nemail_body = 'very convincing text'    \n    \nstatement1 = print_greeting('Bodenschatz') + email_body\nstatement2 = print_greeting('Tilgner')\nstatement3 = print_greeting('Grubmueller')\n    ",
                "true_label": "",
                "top5_preds": [
                    "displaying the data",
                    "get a positive integer from a user",
                    "fit a polynomial",
                    "likelihood of the binomial",
                    "email header"
                ]
            },
            {
                "code": "print(statement1)\nprint(statement2)\nprint(statement3)",
                "true_label": "",
                "top5_preds": [
                    "creating a tree diagram",
                    "how to change the style of individual lines",
                    "formatting datetimes as strings",
                    "detect the number of local variables declared in a function",
                    "add edges in graph"
                ]
            },
            {
                "code": "# a function, which prints a help text\ndef print_help():\n    \n    # note: the function does not have an argument\n    print('''*** important keyboard shortcuts: ***\n             edit mode - ENTER\n             command mode - ESC\n             cell to markdown - m\n             cell to code - y''')\n    \nprint_help()",
                "true_label": "",
                "top5_preds": [
                    "the command line",
                    "displaying the data",
                    "plot the function",
                    "helper function to print vector",
                    "getting data from the internet"
                ]
            },
            {
                "code": "# a function with two arguments\ndef lunch(main, side):\n    \n    # this function only prints a message    \n    print('today for lunch there is {} with {} as a side'\\\n          .format(main, side))\n    \n",
                "true_label": "",
                "top5_preds": [
                    "create a line plot",
                    "create a scatter plot",
                    "create a bar chart",
                    "plot the function",
                    "the command line"
                ]
            },
            {
                "code": "lunch('schnitzel','potatoes')\nlunch('curry','rice')\n\n# this function does accept numbers as arguments\n# the result doesn't make a lot of sense though...\nlunch(3, 'apple')",
                "true_label": "",
                "top5_preds": [
                    "strings as function arguments",
                    "test whether a number is positive",
                    "detect the number of local variables declared in a function",
                    "sum all the numbers in a list",
                    "what is a string?"
                ]
            },
            {
                "code": "lunch('potatoes','schnitzel')",
                "true_label": "",
                "top5_preds": [
                    "strings as function arguments",
                    "formatting datetimes as strings",
                    "fit a polynomial",
                    "what is a string?",
                    "convert a tuple to a dictionary"
                ]
            },
            {
                "code": "lunch('rice', 'schnitzel')",
                "true_label": "",
                "top5_preds": [
                    "strings as function arguments",
                    "fit a polynomial",
                    "formatting datetimes as strings",
                    "convert categorical variables",
                    "what is a string?"
                ]
            },
            {
                "code": "# This function takes name, surname and age of a person\n# and then prints a short description of the person.\ndef describe_person(first_name, surname, age):\n\n    # Note: title() makes a string begin with a capital letter\n    print(\"First name: {}\".format(first_name.title()))\n    print(\"Surname: {}\".format(surname.title()))\n    print(\"Age: {}\\n\".format(age))\n\ndescribe_person('jana', 'lasser', 26)\ndescribe_person('nina', 'merz', 32)\ndescribe_person('simon', 'mueller', 68)",
                "true_label": "",
                "top5_preds": [
                    "info on the data set",
                    "displaying the data",
                    "create a data dictionary",
                    "print the name of all the columns",
                    "describe each distribution"
                ]
            },
            {
                "code": "describe_person(26, 'jana', 'lasser')",
                "true_label": "",
                "top5_preds": [
                    "get the names of all the tables in the database",
                    "loading json in python",
                    "accessing databases via web apis",
                    "predicting a categorical response",
                    "strings as function arguments"
                ]
            },
            {
                "code": "# This function displays a message to \"name\"\n# if \"name\" is given, if not, the message is\n# addressed to 'everyone' instead (default case)\ndef thank_you(name='everyone'):\n    print(\"\\nYou are doing good work, {}!\".format(name))\n    \nthank_you('Bianca')\nthank_you('Katrin')\nthank_you()",
                "true_label": "",
                "top5_preds": [
                    "formatting datetimes as strings",
                    "get a positive integer from a user",
                    "write a python function",
                    "displaying the data",
                    "what is a string?"
                ]
            },
            {
                "code": "sum(['a','b'])",
                "true_label": "",
                "top5_preds": [
                    "sum all the numbers in a list",
                    "find the length of a tuple",
                    "sum with nan",
                    "the sum product algorithm",
                    "add an item in a tuple"
                ]
            },
            {
                "code": "# this is the header of the function\n# in which we define its name and  \n# the arguments it takes\ndef my_function(argument):\n    \n    # this is the body of the function\n    # in which the actions are defined\n    cube = argument ** 3\n    print(cube)\n    \ndef square(argument):\n    squar = argument ** 2\n    print(squar)\n# thus we have two functions:\n# one which takes an argument, cubes it and prints the cube\n# and one which does the same for the square",
                "true_label": "",
                "top5_preds": [
                    "fit a polynomial",
                    "pi by means of the arithmetic geometric mean",
                    "anonymous functions and lambdas",
                    "strings as function arguments",
                    "define a function"
                ]
            },
            {
                "code": "square(10)",
                "true_label": "",
                "top5_preds": [
                    "sum all the numbers in a list",
                    "integer multiplication",
                    "test whether a number is positive",
                    "fit a polynomial",
                    "pi by means of the arithmetic geometric mean"
                ]
            },
            {
                "code": "my_function(10)",
                "true_label": "",
                "top5_preds": [
                    "detect the number of local variables declared in a function",
                    "fit a polynomial",
                    "create a lambda function",
                    "equally spaced numbers on a grid",
                    "optimal value of k for dataset"
                ]
            },
            {
                "code": "my_function(3)\nblubb = 10\nmy_function(blubb)",
                "true_label": "",
                "top5_preds": [
                    "detect the number of local variables declared in a function",
                    "assign to a variable",
                    "using lambda functions",
                    "create a lambda function",
                    "strings as function arguments"
                ]
            },
            {
                "code": "x = 3\n# call the function we defined with x as an argument\nmy_function(x)",
                "true_label": "",
                "top5_preds": [
                    "detect the number of local variables declared in a function",
                    "define a function",
                    "strings as function arguments",
                    "defining a function",
                    "fit a polynomial"
                ]
            },
            {
                "code": "# set the value of y\ny = 4\n\n# call our function with y as the argument\nmy_function(y)\n\n# ceck whether the value of y changed\nprint('Value of y: {}'.format(y))",
                "true_label": "",
                "top5_preds": [
                    "what is a string?",
                    "detect the number of local variables declared in a function",
                    "assign to a variable",
                    "using lambda functions",
                    "test whether a number is positive"
                ]
            },
            {
                "code": "word = 'hello'\nprint(word)",
                "true_label": "",
                "top5_preds": [
                    "create a list of all words",
                    "what is a string?",
                    "sum all the numbers in a list",
                    "get a positive integer from a user",
                    "add an item in a tuple"
                ]
            },
            {
                "code": "numbers = [1, 2, 3, 4]\nsumme = sum(numbers)\n\nprint(summe)",
                "true_label": "",
                "top5_preds": [
                    "sum all the numbers in a list",
                    "multiply all the numbers in a list",
                    "add an item in a tuple",
                    "get a positive integer from a user",
                    "the sum product algorithm"
                ]
            },
            {
                "code": "# define a variable\nx = 10\n\n# pass the variable to a function,\n# and save its return value in a variable\nwhat_we_got_back = my_function(x)\n\n# check the result\nprint(what_we_got_back)",
                "true_label": "",
                "top5_preds": [
                    "get a positive integer from a user",
                    "assign to a variable",
                    "what is a string?",
                    "fit a polynomial",
                    "detect the number of local variables declared in a function"
                ]
            }
        ],
        [
            {
                "code": "## Use this and additional cells to collect all of the trip times as a list ##\n## and then use pyplot functions to generate a histogram of trip times.     ##\n#This function will also seperate Customer and Subsriber Duration\ndef create_plot_sub_cust_data(filename):\n    data_sub_new = []\n    data_cust_new = []\n    with open(filename, 'r') as f_in:\n        #reusing this code to get the total trips\n        # set up csv reader object\n        reader = csv.DictReader(f_in)\n  \n        # export duration data into var to plot\n        for row in reader:\n            if row['user_type'] == 'Subscriber' or row['user_type'] == 'Registered':\n                data_sub_new.append(float(row['duration']))\n            else:\n                data_cust_new.append(float(row['duration']))\n        return(data_cust_new, data_sub_new)\n\n#I looked up Numpy, wow this would have saved me some math earlier.\ndef build_my_plots(city, file):\n    data_cust_new, data_sub_new = create_plot_sub_cust_data(data_file)\n    custmedian = np.median(data_cust_new)\n    custmean = np.mean(data_cust_new)\n    submedian = np.median(data_sub_new)\n    submean = np.mean(data_sub_new)\n    subs = plt.hist(data_sub_new, range=[1,75])\n    custs = plt.hist(data_cust_new, range=[1,75])\n    plt.title('Distribution of Trip Durations {}'.format(city))\n    plt.xticks()\n    plt.legend(('Subscribers', 'Customers') )\n    plt.xlabel('Duration (m)')\n    plt.show(subs, custs)\n    pprint('{} median customer trip duration is {}'.format(city,custmedian))\n    pprint('{} mean customer trip duration is {}'.format(city,custmean))\n    pprint('{} median Subscriber trip duration is {}'.format(city,submedian))\n    pprint('{} mean Subscriber trip duration is {}'.format(city,submean))",
                "true_label": "",
                "top5_preds": [
                    "plot the data",
                    "plot past data",
                    "plot the function",
                    "get the data",
                    "plot the training"
                ]
            },
            {
                "code": "data_file = './data/Washington-2016-Summary.csv'\ncity = 'Washington'\nbuild_my_plots(city,data_file)\n    \n    \n    \ndata_file = './data/NYC-2016-Summary.csv'\ncity = 'NYC'\nbuild_my_plots(city,data_file)\n\ndata_file = './data/Chicago-2016-Summary.csv'\ncity = 'Chicago'\nbuild_my_plots(city,data_file)\n\n\n",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "plot using pandas plotting",
                    "pandas plotting",
                    "load table in pandas",
                    "student create plots for examples"
                ]
            },
            {
                "code": "## Use this and additional cells to answer Question 5. ##\n#Big thanks to the #t1-office-hours slack channel for the bin_edges suggestion\n\nbin_edges = [0,5,10,15.20,25,30,35,40,45,50,55,60,65,70,75]\ndata_file = './data/Washington-2016-Summary.csv'\n#plt.hist(create_histo_data(data_file), range=[0,75], rwidth=.5)\nplt.hist(create_histo_data(data_file), range=[0,75], bins=bin_edges)\nplt.title('Distribution of Trip Durations Washington')\nplt.xticks()\nplt.xlabel('Duration (m)')\nplt.show()\n\n\ndata_file = './data/NYC-2016-Summary.csv'\n\nplt.hist(create_histo_data(data_file), range=[1,75], bins=bin_edges)\nplt.title('Distribution of Trip Durations NYC')\nplt.xlabel('Duration (m)')\nplt.show()\n\ndata_file = './data/Chicago-2016-Summary.csv'\n\nplt.hist(create_histo_data(data_file), range=[1,75], bins=bin_edges)\nplt.title('Distribution of Trip Durations Chicago')\nplt.xlabel('Duration (m)')\nplt.show()",
                "true_label": "",
                "top5_preds": [
                    "line plots show the trend of a numerical variable over time",
                    "ploting out data with box plots",
                    "integrating datetime tools with pandas for time series",
                    "equally spaced numbers on a grid",
                    "plot histogram"
                ]
            },
            {
                "code": "#Function to Grab all subscribers and their data for NYC and Chicago\nfrom collections import defaultdict \n\ndef trip_day_time(day, filename):\n    \"\"\"\n    This function reads in a file with trip data and reports the day of the week and the time of the trip.\n    \"\"\"\n    date_data = {}\n    with open(filename, 'r') as f_in:\n        #reusing this code to get the total trips per hour for each day\n        # set up csv reader object\n        reader = csv.DictReader(f_in)\n                      \n        hours_d =  {'0' : 0,'1' : 0,'2' : 0,'3' : 0,'4' : 0,'5' : 0,'6' : 0,'7' : 0,'8' : 0,'9' : 0,'10' : 0,'11' : 0,'12' : 0,'13' : 0,'14' : 0,'15' : 0,'16' : 0,'17' : 0,'17' : 0,'18' : 0,'19' : 0,'20' : 0,'21' : 0,'22' : 0,'23' : 0,}\n        for row in reader:\n            if  row['day_of_week'] == day and row['user_type'] == 'Subscriber' or row['user_type'] == 'Registered':\n                hours_d[row['hour']] += 1\n            \n            \n        return(hours_d)",
                "true_label": "",
                "top5_preds": [
                    "convert date to datetime format",
                    "getting data from the internet",
                    "get the data",
                    "parse time and visibility from json",
                    "download and inspect the twitter samples dataset"
                ]
            },
            {
                "code": "#Grab all Subscibers for NYC and Chicago\n#Plot their time of trip against the day of the week.\ndata_file_NYC = './data/NYC-2016-Summary.csv'\ndata_file_Chicago = './data/Chicago-2016-Summary.csv'\ndata_file_Washington = './data/Washington-2016-Summary.csv'\n#date_NYC = trip_day_time(data_file_NYC)\n#date_Chicago = trip_day_time(data_file_Chicago)\n#date_Washington = trip_day_time(data_file_Washington)",
                "true_label": "",
                "top5_preds": [
                    "line plots show the trend of a numerical variable over time",
                    "convert date to datetime format",
                    "importing data with pandas",
                    "importing data with numpy",
                    "line plot with a dataframe"
                ]
            },
            {
                "code": "#Create some Visualization magic.\n#Big pyplot help using some forums from stackoverflow, especially the idea to use range(len()) to get the right x axis.\nimport matplotlib.pyplot as plt\ndef create_bar_plot(day_of_week, city):\n    if city == 'NYC':\n        data_file_city = data_file_NYC\n    elif city == 'Chicago':\n        data_file_city = data_file_Chicago\n    elif city == 'Washington':\n        data_file_city = data_file_Washington\n    else:\n        print('Bad City')\n    date_func = trip_day_time(day_of_week, data_file_city)\n    plt.title(day_of_week +' in ' + city)\n    plt.xlabel('Hours (24 Hour Clock)')\n    plt.ylabel('Bike Trips at x hour')\n    plt.bar(range(len(date_func)), date_func.values(), align='center')\n    plt.xticks(range(len(date_func)), date_func.keys())\n    plt.show()",
                "true_label": "",
                "top5_preds": [
                    "create a bar chart",
                    "plotting in python",
                    "matplotlib",
                    "plot using matplotlib",
                    "pandas plotting"
                ]
            },
            {
                "code": "city = 'NYC'\ncreate_bar_plot('Monday', city)\ncreate_bar_plot('Tuesday', city)\ncreate_bar_plot('Wednesday', city)\ncreate_bar_plot('Thursday', city)\ncreate_bar_plot('Friday', city)\ncreate_bar_plot('Saturday', city)\ncreate_bar_plot('Sunday', city)\n\n",
                "true_label": "",
                "top5_preds": [
                    "create a bar chart",
                    "plotting in python",
                    "trend lines in pyplot",
                    "plot using matplotlib",
                    "pandas plotting"
                ]
            },
            {
                "code": "city = 'Chicago'\ncreate_bar_plot('Monday', city)\ncreate_bar_plot('Tuesday', city)\ncreate_bar_plot('Wednesday', city)\ncreate_bar_plot('Thursday', city)\ncreate_bar_plot('Friday', city)\ncreate_bar_plot('Saturday', city)\ncreate_bar_plot('Sunday', city)",
                "true_label": "",
                "top5_preds": [
                    "create a bar chart",
                    "plotting in python",
                    "trend lines in pyplot",
                    "pandas plotting",
                    "plot using matplotlib"
                ]
            },
            {
                "code": "# load library\nimport matplotlib.pyplot as plt\n\n# this is a 'magic word' that allows for plots to be displayed\n# inline with the notebook. If you want to know more, see:\n# http://ipython.readthedocs.io/en/stable/interactive/magics.html\n%matplotlib inline \n\n# example histogram, data taken from bay area sample\ndata = [ 7.65,  8.92,  7.42,  5.50, 16.17,  4.20,  8.98,  9.62, 11.48, 14.33,\n        19.02, 21.53,  3.90,  7.97,  2.62,  2.67,  3.08, 14.40, 12.90,  7.83,\n        25.12,  8.30,  4.93, 12.43, 10.60,  6.17, 10.88,  4.78, 15.15,  3.53,\n         9.43, 13.32, 11.72,  9.85,  5.22, 15.10,  3.95,  3.17,  8.78,  1.88,\n         4.55, 12.68, 12.38,  9.78,  7.63,  6.45, 17.38, 11.90, 11.52,  8.63,]\nplt.hist(data)\nplt.title('Distribution of Trip Durations')\nplt.xlabel('Duration (m)')\nplt.show()",
                "true_label": "",
                "top5_preds": [
                    "plot using matplotlib",
                    "pandas plotting",
                    "plot using pandas plotting",
                    "trend lines in pyplot",
                    "pandas plotting documentation"
                ]
            },
            {
                "code": "## Use this and additional cells to collect all of the trip times as a list ##\n## and then use pyplot functions to generate a histogram of trip times.     ##\ndef create_histo_data(filename):\n    data_new = []\n    with open(filename, 'r') as f_in:\n        #reusing this code to get the total trips\n        # set up csv reader object\n        reader = csv.DictReader(f_in)\n  \n        # export duration data into var to plot\n        for row in reader:\n            data_new.append(float(row['duration']))   \n        return(data_new)\n    \n\ndata_file = './data/Washington-2016-Summary.csv'\n#plt.hist(create_histo_data(data_file), range=[0,75], rwidth=.5)\nplt.hist(create_histo_data(data_file), range=[0,75])\nplt.title('Distribution of Trip Durations Washington')\nplt.xticks()\nplt.xlabel('Duration (m)')\nplt.show()\n\n\ndata_file = './data/NYC-2016-Summary.csv'\n\nplt.hist(create_histo_data(data_file), range=[1,75])\nplt.title('Distribution of Trip Durations NYC')\nplt.xlabel('Duration (m)')\nplt.show()\n\ndata_file = './data/Chicago-2016-Summary.csv'\n\nplt.hist(create_histo_data(data_file), range=[1,75])\nplt.title('Distribution of Trip Durations Chicago')\nplt.xlabel('Duration (m)')\nplt.show()\n\n\n",
                "true_label": "",
                "top5_preds": [
                    "load table in pandas",
                    "trend lines in pyplot",
                    "read numbers until and print their mean and standard deviation without using a list",
                    "line plot with a dataframe",
                    "getting data from the internet"
                ]
            },
            {
                "code": "## import all necessary packages and functions.\nimport csv # read and write csv files\nimport numpy as np\nfrom datetime import datetime # operations to parse dates\nfrom pprint import pprint # use to print data structures like dictionaries in\n                          # a nicer way than the base print function.",
                "true_label": "",
                "top5_preds": [
                    "importing data with numpy",
                    "import polynomial features from sklearn",
                    "formatting datetimes as strings",
                    "convert date to datetime format",
                    "equally spaced numbers on a grid"
                ]
            },
            {
                "code": "def print_first_point(filename):\n    \"\"\"\n    This function prints and returns the first data point (second row) from\n    a csv file that includes a header row.\n    \"\"\"\n    # print city name for reference\n    city = filename.split('-')[0].split('/')[-1]\n    print('\\nCity: {}'.format(city))\n    \n    with open(filename, 'r') as f_in:\n        ## TODO: Use the csv library to set up a DictReader object. ##\n        ## see https://docs.python.org/3/library/csv.html           ##\n        trip_reader = csv.DictReader(f_in)\n        \n        ## TODO: Use a function on the DictReader object to read the     ##\n        ## first trip from the data file and store it in a variable.     ##\n        ## see https://docs.python.org/3/library/csv.html#reader-objects ##\n        first_trip = next(trip_reader)\n        \n        ## TODO: Use the pprint library to print the first trip. ##\n        ## see https://docs.python.org/3/library/pprint.html     ##\n        #second_row = first_trip[1]\n        pprint(first_trip)\n    # output city name and first trip for later testing\n    return (city, first_trip)\n\n# list of files for each city\ndata_files = ['./data/NYC-CitiBike-2016.csv',\n              './data/Chicago-Divvy-2016.csv',\n              './data/Washington-CapitalBikeshare-2016.csv',]\n\n# print the first trip from each file, store in dictionary\nexample_trips = {}\nfor data_file in data_files:\n    city, first_trip = print_first_point(data_file)\n    example_trips[city] = first_trip",
                "true_label": "",
                "top5_preds": [
                    "read the dataset point",
                    "read data point",
                    "read text file point",
                    "read images point",
                    "getting data from the internet"
                ]
            },
            {
                "code": "def duration_in_mins(datum, city):\n    \"\"\"\n    Takes as input a dictionary containing info about a single trip (datum) and\n    its origin city (city) and returns the trip duration in units of minutes.\n    \n    Remember that Washington is in terms of milliseconds while Chicago and NYC\n    are in terms of seconds. \n    \n    HINT: The csv module reads in all of the data as strings, including numeric\n    values. You will need a function to convert the strings into an appropriate\n    numeric type when making your transformations.\n    see https://docs.python.org/3/library/functions.html\n    \"\"\"\n    \n    \n    if city == 'NYC':\n        datum = int(datum['tripduration'])\n        duration = datum / 60\n        #print(duration)\n    elif city == 'Chicago':\n        #pprint(datum)\n        datum = int(datum['tripduration'])\n        duration = datum / 60\n        #print(duration)\n    else:\n        #pprint(datum)\n        datum = int(datum['Duration (ms)'])\n        duration = (datum / 1000) /60\n        #print(duration)\n    return duration\n\n\n# Some tests to check that your code works. There should be no output if all of\n# the assertions pass. The `example_trips` dictionary was obtained from when\n# you printed the first trip from each of the original data files.\ntests = {'NYC': 13.9833,\n         'Chicago': 15.4333,\n         'Washington': 7.1231}\n\nfor city in tests:\n    assert abs(duration_in_mins(example_trips[city], city) - tests[city]) < .001",
                "true_label": "",
                "top5_preds": [
                    "trips by day hour mapper",
                    "trips by day hour reducer",
                    "trips by hour reducer",
                    "calculate distance of event and station",
                    "trips by hour mapper"
                ]
            },
            {
                "code": "def time_of_trip(datum, city):\n    \"\"\"\n    Takes as input a dictionary containing info about a single trip (datum) and\n    its origin city (city) and returns the month, hour, and day of the week in\n    which the trip was made.\n    \n    Remember that NYC includes seconds, while Washington and Chicago do not.\n    \n    HINT: You should use the datetime module to parse the original date\n    strings into a format that is useful for extracting the desired information.\n    see https://docs.python.org/3/library/datetime.html#strftime-and-strptime-behavior\n    \"\"\"\n    \n    if city == 'NYC':\n        #pprint(datum['starttime'])\n        date_time_obj = datetime.strptime(datum['starttime'], \"%m/%d/%Y %H:%M:%S\")\n        month = int(datetime.strftime(date_time_obj,\"%m\"))\n        hour = int(datetime.strftime(date_time_obj,\"%H\"))\n        day_of_week = str(datetime.strftime(date_time_obj,\"%A\"))\n        #print(month, hour, day_of_week)\n    elif city == 'Chicago':\n        #pprint(datum['starttime'])\n        date_time_obj = datetime.strptime(datum['starttime'], \"%m/%d/%Y %H:%M\")\n        month = int(datetime.strftime(date_time_obj,\"%m\"))\n        hour = int(datetime.strftime(date_time_obj,\"%H\"))\n        day_of_week = str(datetime.strftime(date_time_obj,\"%A\"))\n        #print(month, hour, day_of_week)\n    else:\n        #pprint(datum['Start date'])\n        date_time_obj = datetime.strptime(datum['Start date'], \"%m/%d/%Y %H:%M\")\n        month = int(datetime.strftime(date_time_obj,\"%m\"))\n        hour = int(datetime.strftime(date_time_obj,\"%H\"))\n        day_of_week = str(datetime.strftime(date_time_obj,\"%A\"))\n        #print(month, hour, day_of_week)\n    \n    return (month, hour, day_of_week)\n\n\n# Some tests to check that your code works. There should be no output if all of\n# the assertions pass. The `example_trips` dictionary was obtained from when\n# you printed the first trip from each of the original data files.\ntests = {'NYC': (1, 0, 'Friday'),\n         'Chicago': (3, 23, 'Thursday'),\n         'Washington': (3, 22, 'Thursday')}\n\nfor city in tests:\n    assert time_of_trip(example_trips[city], city) == tests[city]",
                "true_label": "",
                "top5_preds": [
                    "trips by day hour mapper",
                    "trips by day hour reducer",
                    "calculate absolute time of the first arrivals at the station",
                    "to_tuple",
                    "transform the date column as a datetime type"
                ]
            },
            {
                "code": "def type_of_user(datum, city):\n    \"\"\"\n    Takes as input a dictionary containing info about a single trip (datum) and\n    its origin city (city) and returns the type of system user that made the\n    trip.\n    \n    Remember that Washington has different category names compared to Chicago\n    and NYC. \n    \"\"\"\n    #print(city)\n    if city == 'NYC':\n        #pprint(datum['usertype'])\n        user_type = datum['usertype']\n    elif city == 'Chicago':\n        #pprint(datum['usertype'])\n        user_type = datum['usertype']\n    else:\n        #pprint(datum['Member Type'])\n        user_type = datum['Member Type']\n    \n    return user_type\n\n\n# Some tests to check that your code works. There should be no output if all of\n# the assertions pass. The `example_trips` dictionary was obtained from when\n# you printed the first trip from each of the original data files.\ntests = {'NYC': 'Customer',\n         'Chicago': 'Subscriber',\n         'Washington': 'Registered'}\n\nfor city in tests:\n    assert type_of_user(example_trips[city], city) == tests[city]",
                "true_label": "",
                "top5_preds": [
                    "get a positive integer from a user",
                    "info on the data set",
                    "convert integer or float data",
                    "import data",
                    "transform the date column as a datetime type"
                ]
            },
            {
                "code": "def condense_data(in_file, out_file, city):\n    \"\"\"\n    This function takes full data from the specified input file\n    and writes the condensed data to a specified output file. The city\n    argument determines how the input file will be parsed.\n    \n    HINT: See the cell below to see how the arguments are structured!\n    \"\"\"\n    \n    with open(out_file, 'w') as f_out, open(in_file, 'r') as f_in:\n        # set up csv DictWriter object - writer requires column names for the\n        # first row as the \"fieldnames\" argument\n        out_colnames = ['duration', 'month', 'hour', 'day_of_week', 'user_type']        \n        trip_writer = csv.DictWriter(f_out, fieldnames = out_colnames)\n        trip_writer.writeheader()\n        \n        ## TODO: set up csv DictReader object ##\n        trip_reader = csv.DictReader(f_in)\n        \n        # collect data from and process each row\n        for row in trip_reader:\n            # set up a dictionary to hold the values for the cleaned and trimmed\n            # data point\n            \n            user_type = type_of_user(row, city)\n            duration = duration_in_mins(row, city)\n            month, hour, day_of_week = time_of_trip(row, city)\n            #print(month)\n            \n            new_point = {'duration': duration, 'month': month, 'hour': hour, 'day_of_week': day_of_week,'user_type': user_type}\n            #pprint(new_point)\n            trip_writer.writerow(new_point) \n\n            ## TODO: use the helper functions to get the cleaned data from  ##\n            ## the original data dictionaries.                              ##\n            ## Note that the keys for the new_point dictionary should match ##\n            ## the column names set in the DictWriter object above.         ##\n            \n\n            ## TODO: write the processed information to the output file.     ##\n            ## see https://docs.python.org/3/library/csv.html#writer-objects ##\n            \n            ",
                "true_label": "",
                "top5_preds": [
                    "reading in the files",
                    "helpers to read in dataset",
                    "import data",
                    "data import and inspection",
                    "getting data from the internet"
                ]
            },
            {
                "code": "# Run this cell to check your work\ncity_info = {'Washington': {'in_file': './data/Washington-CapitalBikeshare-2016.csv',\n                            'out_file': './data/Washington-2016-Summary.csv'},\n             'Chicago': {'in_file': './data/Chicago-Divvy-2016.csv',\n                         'out_file': './data/Chicago-2016-Summary.csv'},\n             'NYC': {'in_file': './data/NYC-CitiBike-2016.csv',\n                     'out_file': './data/NYC-2016-Summary.csv'}}\n\nfor city, filenames in city_info.items():\n    condense_data(filenames['in_file'], filenames['out_file'], city)\n    print_first_point(filenames['out_file'])",
                "true_label": "",
                "top5_preds": [
                    "remove null values from county, category, and category name",
                    "remove redundant columns vol sold gal and county no",
                    "using json to find your location",
                    "getting data from the internet",
                    "postgres sql lab"
                ]
            },
            {
                "code": "def number_of_trips(filename):\n    \"\"\"\n    This function reads in a file with trip data and reports the number of\n    trips made by subscribers, customers, and total overall.\n    \"\"\"\n    with open(filename, 'r') as f_in:\n        # set up csv reader object\n        reader = csv.DictReader(f_in)\n        \n        # initialize count variables\n        n_subscribers = 0\n        n_customers = 0\n        \n        # tally up ride types\n        for row in reader:\n            if row['user_type'] == 'Subscriber' or row['user_type'] == 'Registered':\n                n_subscribers += 1\n            else:\n                n_customers += 1\n        \n        # compute total number of rides\n        n_total = n_subscribers + n_customers\n        subs_perc = 100* n_subscribers / n_total\n        \n        # return tallies as a tuple\n        return(n_subscribers, n_customers, n_total, subs_perc)",
                "true_label": "",
                "top5_preds": [
                    "download and inspect the twitter samples dataset",
                    "sum all the numbers in a list",
                    "to_tuple",
                    "read table",
                    "reading in the files"
                ]
            },
            {
                "code": "## Modify this and the previous cell to answer Question 4a. Remember to run ##\n## the function on the cleaned data files you created from Question 3.      ##\n\ndata_file = './examples/BayArea-Y3-Summary.csv'\nprint(\"Subscribers, Customers, Total, Percent Subcribers\")\nprint(number_of_trips(data_file))",
                "true_label": "",
                "top5_preds": [
                    "read numbers until and print their mean and standard deviation without using a list",
                    "reading in the files",
                    "get a positive integer from a user",
                    "predicting test data",
                    "add an item in a tuple"
                ]
            },
            {
                "code": "data_file = './data/NYC-2016-Summary.csv'\nprint(\"Subscribers, Customers, Total, Percent Subcribers\")\nprint(number_of_trips(data_file))\n\n",
                "true_label": "",
                "top5_preds": [
                    "sum all the numbers in a list",
                    "read numbers until and print their mean and standard deviation without using a list",
                    "predicting test data",
                    "line plots show the trend of a numerical variable over time",
                    "add an item in a tuple"
                ]
            },
            {
                "code": "data_file = './data/Chicago-2016-Summary.csv'\nprint(\"Subscribers, Customers, Total, Percent Subcribers\")\nprint(number_of_trips(data_file))",
                "true_label": "",
                "top5_preds": [
                    "sum all the numbers in a list",
                    "read numbers until and print their mean and standard deviation without using a list",
                    "predicting test data",
                    "line plots show the trend of a numerical variable over time",
                    "add an item in a tuple"
                ]
            },
            {
                "code": "data_file = './data/Washington-2016-Summary.csv'\nprint(\"Subscribers, Customers, Total, Percent Subcribers\")\nprint(number_of_trips(data_file))",
                "true_label": "",
                "top5_preds": [
                    "sum all the numbers in a list",
                    "predicting test data",
                    "read numbers until and print their mean and standard deviation without using a list",
                    "add an item in a tuple",
                    "remove duplicates from a list"
                ]
            },
            {
                "code": "## Use this and additional cells to answer Question 4b.                 ##\n##                                                                      ##\n## HINT: The csv module reads in all of the data as strings, including  ##\n## numeric values. You will need a function to convert the strings      ##\n## into an appropriate numeric type before you aggregate data.          ##\n## TIP: For the Bay Area example, the average trip length is 14 minutes ##\n## and 3.5% of trips are longer than 30 minutes.                        ##\ndef avg_trip_length(filename):\n    \"\"\"\n    This function reads in a file with trip data and reports the number of\n    trips made by subscribers, customers, and total overall.\n    \"\"\"\n    with open(filename, 'r') as f_in:\n        #reusing this code to get the total trips\n        # set up csv reader object\n        reader = csv.DictReader(f_in)\n        \n        # initialize count variables\n        n_subscribers = 0\n        n_customers = 0\n        tot_trip = 0\n        long_trips = 0\n        short_trips = 0\n        sub_long_trip = 0\n        cust_long_trip = 0\n        sub_tot_trip = 0\n        cust_tot_trip = 0\n        \n        # tally up ride types\n        for row in reader:\n            if row['user_type'] == 'Subscriber' or row['user_type'] == 'Registered':\n                n_subscribers += 1\n            else:\n                n_customers += 1\n            # now find the duration stats\n            if float(row['duration']) > 30:\n                long_trips += 1\n                tot_trip += float(row['duration'])\n            else:\n                short_trips += 1\n                tot_trip += float(row['duration'])\n            if float(row['duration']) > 30 and row['user_type'] == 'Subscriber' or row['user_type'] == 'Registered':\n                sub_long_trip += 1\n                sub_tot_trip += float(row['duration'])\n            else:\n                cust_long_trip += 1\n            if row['user_type'] == 'Subscriber' or row['user_type'] == 'Registered':\n                sub_tot_trip += float(row['duration'])\n            else:\n                cust_tot_trip += float(row['duration'])\n        \n        # compute total number of rides\n        n_total = n_subscribers + n_customers\n        \n        #Find the average duration and number of long and short trips\n        percent_short = 100* short_trips / n_total\n        percent_long = 100* long_trips / n_total\n        avg_trip = tot_trip / n_total\n        avg_cust_trip = cust_tot_trip / n_customers\n        if n_subscribers != 0:\n            avg_subs_trip = sub_tot_trip / n_subscribers\n        else:\n            avg_subs_trip = 0\n        # return my math\n        data_dump = {'avg trip': avg_trip,\n                     'percent short': percent_short,\n                     'Total Long': long_trips,\n                     'percent long': percent_long,\n                     'avg customer trip': avg_cust_trip,\n                     'avg subscriber trip': avg_subs_trip,\n                     'Number Subsribers': n_subscribers,\n                     'Number of Subcribers Long Trips': sub_long_trip,\n                     'Number Customers': n_customers,\n                     'Number of Customer Long Trips': cust_long_trip,\n                     'Overall Total': n_total\n                    }\n        return(data_dump)\n",
                "true_label": "",
                "top5_preds": [
                    "filling the mask",
                    "getting data from the internet",
                    "answer a question with a graph",
                    "range of feature",
                    "the algebraic connectivity"
                ]
            },
            {
                "code": "data_file = './data/Washington-2016-Summary.csv'\npprint(\"Washington\")\n#print(\"Average Trip, Percent Less than 30min, Percent over 30min, Average Customer Trip Length, Subs, Customers, Total\")\npprint(avg_trip_length(data_file))\n\ndata_file = './data/NYC-2016-Summary.csv'\npprint(\"NYC\")\n#print(\"Average Trip, Percent Less than 30min, Percent over 30min, Average Customer Trip Length, Subs, Customers, Total\")\npprint(avg_trip_length(data_file))\n\ndata_file = './data/Chicago-2016-Summary.csv'\npprint(\"Chicago\")\n#print(\"Average Trip, Percent Less than 30min, Percent over 30min, Average Customer Trip Length, Subs, Customers, Total\")\npprint(avg_trip_length(data_file))",
                "true_label": "",
                "top5_preds": [
                    "read numbers until and print their mean and standard deviation without using a list",
                    "formatting datetimes as strings",
                    "convert date to datetime format",
                    "sum all the numbers in a list",
                    "line plots show the trend of a numerical variable over time"
                ]
            },
            {
                "code": "city = 'Chicago'\ncreate_bar_plot('Monday', city)\ncreate_bar_plot('Tuesday', city)\ncreate_bar_plot('Wednesday', city)\ncreate_bar_plot('Thursday', city)\ncreate_bar_plot('Friday', city)\ncreate_bar_plot('Saturday', city)\ncreate_bar_plot('Sunday', city)",
                "true_label": "",
                "top5_preds": [
                    "create a bar chart",
                    "plotting in python",
                    "trend lines in pyplot",
                    "pandas plotting",
                    "plot using matplotlib"
                ]
            }
        ],
        [
            {
                "code": "import pandas as pd\nimport matplotlib.pyplot as plt\nimport os\nfrom mpl_toolkits.basemap import Basemap\nimport warnings\nwarnings.filterwarnings('ignore')\n%matplotlib inline",
                "true_label": "",
                "top5_preds": [
                    "matplotlib",
                    "plot using matplotlib",
                    "equally spaced numbers on a grid",
                    "line plot with a dataframe",
                    "create an array of linearly spaced points"
                ]
            },
            {
                "code": "# create an executable shell command from array of sql sub strings\ndef bq_builder(strs,outfile,legacy_sql=True):\n    \n    # prefix\n    query_str = \"bq query\"\n    \n    # legacy sql\n    if(legacy_sql):\n        query_str += \" --use_legacy_sql=TRUE\"\n    else:\n        query_str += \" --use_legacy_sql=FALSE\"\n    \n    # formatting\n    query_str += \" --format=csv\"\n    query_str += \" --max_rows=10000\"\n    \n    # sql string\n    query_str += \" \\\"\"\n    for substr in strs:\n        query_str += \" \"\n        query_str += substr\n    query_str += \" \\\"\"\n    \n    # redirect ouptut\n    query_str += \" > \"\n    query_str += outfile\n    \n    # returns executable python\n    return(query_str)",
                "true_label": "",
                "top5_preds": [
                    "sql aliases",
                    "store the sources in a database",
                    "function to_binary",
                    "the command line",
                    "make pipeline"
                ]
            },
            {
                "code": "q00_strs = [\"SELECT HOUR(trips.start_date) AS start_hour,\",\n            \"trips.subscriber_type,\"\n            \"COUNT(trips.trip_id) AS num_trips\",\n            \"FROM [bigquery-public-data:san_francisco.bikeshare_trips] AS trips\",\n            \"WHERE DAYOFWEEK(trips.start_date) BETWEEN 2 AND 6\",\n            \"GROUP BY start_hour, trips.subscriber_type\",\n            \"ORDER BY start_hour, trips.subscriber_type ASC\"]\nq00_out = \"q00.csv\"\nq00_cmd = bq_builder(q00_strs,outfile=q00_out,legacy_sql=True)\nexit_stat = os.system(q00_cmd)",
                "true_label": "",
                "top5_preds": [
                    "formatting datetimes as strings",
                    "parse time and visibility from json",
                    "get the names of all the tables in the database",
                    "getting data from the internet",
                    "sqlalchemy, sqlite, and dates"
                ]
            },
            {
                "code": "q00_res=pd.read_csv(q00_out)\nq00_pivot = q00_res.pivot(index='start_hour', columns='trips_subscriber_type', values='num_trips')\nq00_pivot.plot.bar(stacked=True);",
                "true_label": "",
                "top5_preds": [
                    "plotting time series with pandas",
                    "line plots show the trend of a numerical variable over time",
                    "line plot with a dataframe",
                    "using a dataframe and matplotlib commands",
                    "create a one column dataframe with the values of a series"
                ]
            },
            {
                "code": "q01_strs = [\"SELECT trips.start_station_id AS a_id,\",\n            \"trips.start_station_name AS a_name,\",\n            \"trips.end_station_id AS b_id,\",\n            \"trips.end_station_name AS b_name,\",\n            \"COUNT(trips.trip_id) AS num_trips\",\n            \"FROM [bigquery-public-data:san_francisco.bikeshare_trips] AS trips\",\n            \"WHERE DAYOFWEEK(trips.start_date) BETWEEN 2 AND 6 AND\",\n            \"HOUR(trips.start_date) BETWEEN 7 AND 9\",\n            \"AND trips.subscriber_type='Subscriber'\"\n            \"GROUP BY a_id, a_name, b_id, b_name\"]\nq01_out = \"q01.csv\"\nq01_cmd = bq_builder(q01_strs,outfile=q01_out,legacy_sql=True)\nexit_stat = os.system(q01_cmd)\nq01_res=pd.read_csv(q01_out)",
                "true_label": "",
                "top5_preds": [
                    "formatting datetimes as strings",
                    "get the names of all the tables in the database",
                    "load table in pandas",
                    "convert date to datetime format",
                    "read table"
                ]
            },
            {
                "code": "q02_strs = [\"SELECT trips.start_station_id AS b_id,\",\n            \"trips.start_station_name AS b_name,\",\n            \"trips.end_station_id AS a_id,\",\n            \"trips.end_station_name AS a_name,\",\n            \"COUNT(trips.trip_id) AS num_trips\",\n            \"FROM [bigquery-public-data:san_francisco.bikeshare_trips] AS trips\",\n            \"WHERE DAYOFWEEK(trips.start_date) BETWEEN 2 AND 6 AND\",\n            \"HOUR(trips.start_date) BETWEEN 16 AND 18\",\n            \"AND trips.subscriber_type='Subscriber'\"\n            \"GROUP BY a_id, a_name, b_id, b_name\"]\nq02_out = \"q02.csv\"\nq02_cmd = bq_builder(q02_strs,outfile=q02_out,legacy_sql=True)\nexit_stat = os.system(q02_cmd)\nq02_res=pd.read_csv(q02_out)",
                "true_label": "",
                "top5_preds": [
                    "get the names of all the tables in the database",
                    "formatting datetimes as strings",
                    "load table in pandas",
                    "equally spaced numbers on a grid",
                    "convert date to datetime format"
                ]
            },
            {
                "code": "commute_keys = ['a_id', 'a_name', 'b_id', 'b_name']\ncommutes = pd.concat([q01_res,q02_res])\ncommutes = commutes.groupby(commute_keys)['num_trips'].sum()\ntop_commutes = commutes.nlargest(25)\ntop_commutes = pd.DataFrame(top_commutes).reset_index()\ncommutes = pd.DataFrame(commutes).reset_index()\n\ntop_commutes.head(5)",
                "true_label": "",
                "top5_preds": [
                    "predicting a categorical response",
                    "remove duplicates from a list",
                    "find data type of each column",
                    "load table in pandas",
                    "join two dataframes along rows"
                ]
            },
            {
                "code": "# get \"a\" station coordinates\nq03_strs = [\"SELECT station_id, latitude, longitude\",\n            \"FROM [bigquery-public-data:san_francisco.bikeshare_stations];\"]\nq03_out = \"q03.csv\"\nq03_cmd = bq_builder(q03_strs,outfile=q03_out,legacy_sql=True)\nexit_stat = os.system(q03_cmd)",
                "true_label": "",
                "top5_preds": [
                    "running a local postgres database",
                    "postgres sql lab",
                    "accessing databases via web apis",
                    "connect to a remote database",
                    "running blast with apache spark"
                ]
            },
            {
                "code": "q03_res=pd.read_csv(q03_out)",
                "true_label": "",
                "top5_preds": [
                    "join two dataframes along rows",
                    "load table in pandas",
                    "join two dataframes along columns",
                    "loading a csv into a dataframe",
                    "integrating datetime tools with pandas for time series"
                ]
            },
            {
                "code": "top_commutes = pd.merge(top_commutes,\n                        q03_res,\n                        how='left',\n                        left_on='a_id',\n                        right_on='station_id')\ntop_commutes = top_commutes.rename(columns={\"latitude\": \"a_lat\", \"longitude\": \"a_lon\"})\ntop_commutes = top_commutes.drop(\"station_id\",axis=1)",
                "true_label": "",
                "top5_preds": [
                    "join two dataframes along rows",
                    "join two dataframes along columns",
                    "create a dataframe by joining series by column",
                    "when arithmetic operations are performed between differently indexed time series pandas will automatically align on dates",
                    "using a dataframe and matplotlib commands"
                ]
            },
            {
                "code": "top_commutes = pd.merge(top_commutes,\n                        q03_res,\n                        how='left',\n                        left_on='b_id',\n                        right_on='station_id')\ntop_commutes = top_commutes.rename(columns={\"latitude\": \"b_lat\", \"longitude\": \"b_lon\"})\ntop_commutes = top_commutes.drop(\"station_id\",axis=1)",
                "true_label": "",
                "top5_preds": [
                    "join two dataframes along rows",
                    "join two dataframes along columns",
                    "create a dataframe by joining series by column",
                    "when arithmetic operations are performed between differently indexed time series pandas will automatically align on dates",
                    "using a dataframe and matplotlib commands"
                ]
            },
            {
                "code": "# first define a transverse mercator projection centered on the bay area\nmap_width_m = 30 * 1000\nmap_height_m = 30 * 1000\nfig_width = 10\nfig = plt.figure(figsize=[fig_width, fig_width * map_height_m / float(map_width_m)])\nm = Basemap(ellps='WGS84',\n            projection='tmerc',\n            lon_0=-122.4, \n            lat_0=37.79,\n            width=map_width_m, \n            height=map_height_m,\n            resolution='h',\n            area_thresh=10)\n\nm.drawcoastlines()\nm.drawcountries()\nm.fillcontinents()\n\n# plot a stations\na_lon = list(top_commutes['a_lon'])\na_lat = list(top_commutes['a_lat'])\nx,y = m(a_lon, a_lat)\nm.plot(x, y, 'bo', markersize=8)\n\n# plot b stations\nb_lon = list(top_commutes['b_lon'])\nb_lat = list(top_commutes['b_lat'])\nx,y = m(b_lon, b_lat)\nm.plot(x, y, 'ro', markersize=8)\n\nplt.suptitle(\"Popular Commute Origins (blue) and Destinations (red)\")\nplt.show()",
                "true_label": "",
                "top5_preds": [
                    "matplotlib",
                    "equally spaced numbers on a grid",
                    "plot using matplotlib",
                    "create an array of linearly spaced points",
                    "create a basic map"
                ]
            },
            {
                "code": "# count all trips in the trips table\nq04_strs = [\"SELECT COUNT(trips.trip_id)\",\n            \"FROM [bigquery-public-data:san_francisco.bikeshare_trips] AS trips\"]\nq04_out = \"q04.csv\"\nq04_cmd = bq_builder(q04_strs,outfile=q04_out,legacy_sql=True)\nexit_stat = os.system(q04_cmd)\nq04_res=pd.read_csv(q04_out)",
                "true_label": "",
                "top5_preds": [
                    "postgres sql lab",
                    "running a local postgres database",
                    "accessing databases via web apis",
                    "sql aliases",
                    "collecting search results"
                ]
            },
            {
                "code": "# display breakdown of commutes to other trips\ncount_commutes = q01_res[\"num_trips\"].sum() + q02_res[\"num_trips\"].sum()\ncount_trips = q04_res[\"f0_\"][0]\npd.DataFrame({\"Total Trips\":[count_trips],\"Total Commutes\":[count_commutes],\"Proportion Commutes\":[count_commutes/count_trips]})",
                "true_label": "",
                "top5_preds": [
                    "predicting a categorical response",
                    "from dictionary to dataframe",
                    "line plots show the trend of a numerical variable over time",
                    "relationships between dataframes",
                    "add an item in a tuple"
                ]
            },
            {
                "code": "q06_strs = [\"SELECT AVG(TIMESTAMP_DIFF(trips.end_date,trips.start_date,MINUTE)) AS diff_avg,\",\n            \"COUNT(trips.trip_id) AS num_trips,\",\n            \"EXTRACT(HOUR FROM trips.start_date) AS start_hour\",\n            \"FROM `bigquery-public-data.san_francisco.bikeshare_trips` AS trips\",\n            \"WHERE EXTRACT(DAYOFWEEK FROM trips.start_date) BETWEEN 2 AND 6\",\n            \"GROUP BY start_hour\",\n            \"ORDER BY start_hour ASC;\"]\nq06_out = \"q06.csv\"\nq06_cmd = bq_builder(q06_strs,outfile=q06_out,legacy_sql=True)\n#exit_stat = os.system(q06_cmd)",
                "true_label": "",
                "top5_preds": [
                    "formatting datetimes as strings",
                    "convert date to datetime format",
                    "parse time and visibility from json",
                    "convert a tuple to a string",
                    "transform the date column as a datetime type"
                ]
            },
            {
                "code": "q07_strs = [\"SELECT AVG(TIMESTAMP_DIFF(trips.end_date,trips.start_date,MINUTE)) AS diff_avg,\",\n            \"COUNT(trips.trip_id) AS num_trips,\",\n            \"EXTRACT(HOUR FROM trips.start_date) AS start_hour\",\n            \"FROM `bigquery-public-data.san_francisco.bikeshare_trips` AS trips\",\n            \"WHERE ( EXTRACT(DAYOFWEEK FROM trips.start_date)=1 OR EXTRACT(DAYOFWEEK FROM trips.start_date)=7 )\",\n            \"GROUP BY start_hour\",\n            \"ORDER BY start_hour ASC;\"]\nq07_out = \"q07.csv\"\nq07_cmd = bq_builder(q07_strs,outfile=q07_out,legacy_sql=False)\n#exit_stat = os.system(q07_cmd)",
                "true_label": "",
                "top5_preds": [
                    "formatting datetimes as strings",
                    "convert date to datetime format",
                    "parse time and visibility from json",
                    "trips by day hour mapper",
                    "transform the date column as a datetime type"
                ]
            },
            {
                "code": "q06_res=pd.read_csv(q06_out)\nq06_res = q06_res.set_index(keys=['start_hour'])\nq07_res=pd.read_csv(q07_out)\nq07_res = q07_res.set_index(keys=['start_hour'])",
                "true_label": "",
                "top5_preds": [
                    "loading a csv into a dataframe",
                    "join two dataframes along rows",
                    "convert date to datetime format",
                    "from dictionary to dataframe",
                    "formatting datetimes as strings"
                ]
            },
            {
                "code": "# weekday plot\nax = q06_res.plot(kind=\"bar\",subplots=True,legend=None);\nax[0].set_xlabel(\"Hour\")\nax[0].set_ylabel(\"Minutes\")\nax[0].set_title(\"Weekday Duration\")\nax[1].set_xlabel(\"Hour\")\nax[1].set_ylabel(\"Number of Trips\")\nax[1].set_title(\"Weekday Volume\")",
                "true_label": "",
                "top5_preds": [
                    "plotting time series with pandas",
                    "use pandas to make a bar chart",
                    "line plot with a dataframe",
                    "pandas plotting",
                    "plot using pandas plotting"
                ]
            },
            {
                "code": "# weekend plot\nax = q07_res.plot(kind=\"bar\",subplots=True,legend=None);\nax[0].set_xlabel(\"Hour\")\nax[0].set_ylabel(\"Minutes\")\nax[0].set_title(\"Weekend Duration\")\nax[1].set_xlabel(\"Hour\")\nax[1].set_ylabel(\"Number of Trips\")\nax[1].set_title(\"Weekend Volume\")",
                "true_label": "",
                "top5_preds": [
                    "plotting time series with pandas",
                    "use pandas to make a bar chart",
                    "ploting out data with box plots",
                    "line plot with a dataframe",
                    "pandas plotting"
                ]
            },
            {
                "code": "# count all trips in the trips table\nq08_strs = [\"SELECT COUNT(status.bikes_available) AS no_bikes,\",\n            \"station.name,\",\n            \"status.station_id,\",\n            \"station.latitude,\",\n            \"station.longitude\",\n            \"FROM [bigquery-public-data:san_francisco.bikeshare_status] AS status\",\n            \"LEFT JOIN [bigquery-public-data:san_francisco.bikeshare_stations] AS station\",\n            \"ON status.station_id = station.station_id\",\n            \"WHERE status.bikes_available=0\",\n            \"GROUP BY station.name, status.station_id, station.latitude, station.longitude\",\n            \"ORDER BY no_bikes DESC\",\n            \"LIMIT 10;\"]\nq08_out = \"q08.csv\"\nq08_cmd = bq_builder(q08_strs,outfile=q08_out,legacy_sql=True)\nexit_stat = os.system(q08_cmd)",
                "true_label": "",
                "top5_preds": [
                    "getting data from the internet",
                    "get a positive integer from a user",
                    "load table in pandas",
                    "get the names of all the tables in the database",
                    "sql LIKE operator"
                ]
            }
        ],
        [
            {
                "code": "import numpy as np\nfrom IPython.display import display, Markdown, Latex",
                "true_label": "",
                "top5_preds": [
                    "importing data with numpy",
                    "timing, numpy, plotting",
                    "equally spaced numbers on a grid",
                    "numpy",
                    "using python, ipython,"
                ]
            },
            {
                "code": "def sigmoid(x, derivative=False):\n  return x * (1-x) if derivative else 1 /(1 + np.exp(-x))",
                "true_label": "",
                "top5_preds": [
                    "the dot",
                    "use the sigmoid function as a model point",
                    "covariance",
                    "plot the function",
                    "graph"
                ]
            },
            {
                "code": "X = [[1, 0, 1, 0],\n     [1, 0, 1, 1],\n     [0, 1, 0, 1]]\nY = [[1, 1, 0]]\n\nobserved_data = np.array(X)\nactual_dependent = np.array(Y)\nprint(observed_data)\nprint(actual_dependent)",
                "true_label": "",
                "top5_preds": [
                    "numpy",
                    "scipy",
                    "predicting a categorical response",
                    "predicting a continuous response using linear regression",
                    "ridge regression with polynomial features on a grid"
                ]
            },
            {
                "code": "input_shape = np.shape(observed_data)\nprint(input_shape)\nprint(\"(Number of Rows, No. of Features)\")",
                "true_label": "",
                "top5_preds": [
                    "what is the number of observations in each dataset?",
                    "import polynomial features from sklearn",
                    "what is the number of columns in the dataset?",
                    "what is the number of observations in the dataset?",
                    "numpy"
                ]
            },
            {
                "code": "np.random.seed(666)\n\nweights_h1 = np.around(np.random.rand(input_shape[1], input_shape[0]),2)\n\n#We need 1 bias for each data point in the layer\nbias_h1 = np.around(np.random.rand(1, input_shape[0]),2)\nprint(\"Weights - Hidden Layer 1\")\nprint(weights_h1)\nprint(\"Bias - Hidden Layer 1\")\nprint(bias_h1)\n",
                "true_label": "",
                "top5_preds": [
                    "polynomial regression with sklearn",
                    "numpy",
                    "scikit learn",
                    "predicting a continuous response using linear regression",
                    "tensorflow + keras"
                ]
            },
            {
                "code": "output_shape = np.shape(actual_dependent)",
                "true_label": "",
                "top5_preds": [
                    "import polynomial features from sklearn",
                    "matrix addition and scalar matrix multiplication",
                    "numpy",
                    "polynomial regression with sklearn",
                    "logistic regression using tensorflow"
                ]
            },
            {
                "code": "weights_out = np.around(np.random.rand(output_shape[1], output_shape[0]),2)\nbias_out = np.around(np.random.rand(1, output_shape[0]),2)\nprint(\"Weights - Output\")\nprint(weights_out)\nprint(\"Bias - Output\")\nprint(bias_out)",
                "true_label": "",
                "top5_preds": [
                    "numpy",
                    "matrix addition and scalar matrix multiplication",
                    "resampling with weights",
                    "computing the covariance matrix",
                    "non negative matrix factorization"
                ]
            },
            {
                "code": "delta_h1 = np.dot(error_h1, slope_hidden_layer)",
                "true_label": "",
                "top5_preds": [
                    "scipy",
                    "matrix addition and scalar matrix multiplication",
                    "numpy",
                    "predicting a continuous response using linear regression",
                    "polynomial regression with sklearn"
                ]
            },
            {
                "code": "delta_h1",
                "true_label": "",
                "top5_preds": [
                    "formatting datetimes as strings",
                    "convert date to datetime format",
                    "the mean of difference of variables",
                    "line plots show the trend of a numerical variable over time",
                    "integrating datetime tools with pandas for time series"
                ]
            },
            {
                "code": "learning_rate = 0.1",
                "true_label": "",
                "top5_preds": [
                    "tensorflow + keras",
                    "what is scikit learn?",
                    "scikit learn",
                    "logistic regression using tensorflow",
                    "polynomial regression with sklearn"
                ]
            },
            {
                "code": "weights_out =  weights_out + np.dot(hidden_layer_activations.T , delta_output) * learning_rate",
                "true_label": "",
                "top5_preds": [
                    "tensorflow + keras",
                    "scikit learn",
                    "resampling with weights",
                    "polynomial regression with sklearn",
                    "logistic regression using tensorflow"
                ]
            },
            {
                "code": "weights_out",
                "true_label": "",
                "top5_preds": [
                    "resampling with weights",
                    "predicting a categorical response",
                    "calculating the mean of a vector with nans",
                    "creating polynomial features",
                    "computing the covariance when there are nan s"
                ]
            },
            {
                "code": "weights_h1 = weights_h1 + np.dot(observed_data.T, delta_h1) * learning_rate",
                "true_label": "",
                "top5_preds": [
                    "scikit learn",
                    "resampling with weights",
                    "scipy",
                    "predicting a continuous response using linear regression",
                    "linear regression of many variables"
                ]
            },
            {
                "code": "weights_h1",
                "true_label": "",
                "top5_preds": [
                    "matrix addition and scalar matrix multiplication",
                    "resampling with weights",
                    "creating polynomial features",
                    "scipy",
                    "scikit learn"
                ]
            },
            {
                "code": "hidden_layer_input = np.around(np.dot(observed_data, weights_h1) + bias_h1,2)",
                "true_label": "",
                "top5_preds": [
                    "matrix addition and scalar matrix multiplication",
                    "tensorflow + keras",
                    "scikit learn",
                    "numpy",
                    "predicting a continuous response using linear regression"
                ]
            },
            {
                "code": "hidden_layer_input",
                "true_label": "",
                "top5_preds": [
                    "tensorflow + keras",
                    "reducing noise in input data",
                    "import polynomial features from sklearn",
                    "equally spaced numbers on a grid",
                    "what is scikit learn?"
                ]
            },
            {
                "code": "hidden_layer_activations = np.around(sigmoid(hidden_layer_input),2)",
                "true_label": "",
                "top5_preds": [
                    "polynomial regression with sklearn",
                    "scikit learn",
                    "matrix addition and scalar matrix multiplication",
                    "tensorflow + keras",
                    "scikit learn 4 step modeling pattern"
                ]
            },
            {
                "code": "hidden_layer_activations",
                "true_label": "",
                "top5_preds": [
                    "tensorflow + keras",
                    "generating names with recurrent neural networks",
                    "scikit learn 4 step modeling pattern",
                    "what is scikit learn?",
                    "import polynomial features from sklearn"
                ]
            },
            {
                "code": "delta_output = np.around(slope_output_activation * error,2)",
                "true_label": "",
                "top5_preds": [
                    "predicting a continuous response using linear regression",
                    "create an array of linearly spaced points",
                    "ridge regression with one predictor on a grid",
                    "ridge regression with polynomial features on a grid",
                    "fit a polynomial"
                ]
            },
            {
                "code": "delta_output",
                "true_label": "",
                "top5_preds": [
                    "formatting datetimes as strings",
                    "the mean of difference of variables",
                    "equally spaced numbers on a grid",
                    "matrix addition and scalar matrix multiplication",
                    "integrating datetime tools with pandas for time series"
                ]
            },
            {
                "code": "error_h1 = np.around(np.dot(delta_output, weights_out.T),2)",
                "true_label": "",
                "top5_preds": [
                    "matrix addition and scalar matrix multiplication",
                    "numpy",
                    "using k nearest neighbor for imputing missing data",
                    "scipy",
                    "predicting a continuous response using linear regression"
                ]
            },
            {
                "code": "error_h1",
                "true_label": "",
                "top5_preds": [
                    "setup and re introduction to python",
                    "formatting datetimes as strings",
                    "convert date to datetime format",
                    "postgres sql lab",
                    "convert binary to hexadecimal"
                ]
            },
            {
                "code": "output_layer_input = np.dot(hidden_layer_activations, weights_out) + bias_out\noutput_layer_activation =  np.around(sigmoid(output_layer_input),2)",
                "true_label": "",
                "top5_preds": [
                    "matrix addition and scalar matrix multiplication",
                    "numpy",
                    "scikit learn",
                    "polynomial regression with sklearn",
                    "scipy"
                ]
            },
            {
                "code": "output_layer_activation",
                "true_label": "",
                "top5_preds": [
                    "tensorflow + keras",
                    "logistic regression using tensorflow",
                    "import polynomial features from sklearn",
                    "what is scikit learn?",
                    "classification with a cnn"
                ]
            },
            {
                "code": "error = actual_dependent.T - output_layer_activation",
                "true_label": "",
                "top5_preds": [
                    "tensorflow + keras",
                    "logistic regression using tensorflow",
                    "matrix addition and scalar matrix multiplication",
                    "polynomial regression with sklearn",
                    "predicting a continuous response using linear regression"
                ]
            },
            {
                "code": "error",
                "true_label": "",
                "top5_preds": [
                    "formatting datetimes as strings",
                    "convert date to datetime format",
                    "fit a polynomial",
                    "get a positive integer from a user",
                    "getting data from the internet"
                ]
            },
            {
                "code": "slope_output_activation = np.around(sigmoid(output_layer_activation, derivative=True),2)",
                "true_label": "",
                "top5_preds": [
                    "create an array of linearly spaced points",
                    "equally spaced numbers on a grid",
                    "predicting a continuous response using linear regression",
                    "polynomial regression with sklearn",
                    "scipy"
                ]
            },
            {
                "code": "slope_output_activation",
                "true_label": "",
                "top5_preds": [
                    "equally spaced numbers on a grid",
                    "create an array of linearly spaced points",
                    "tensorflow + keras",
                    "predicting a continuous response using linear regression",
                    "import polynomial features from sklearn"
                ]
            },
            {
                "code": "slope_hidden_layer = np.around(sigmoid(hidden_layer_activations, derivative=True),2)",
                "true_label": "",
                "top5_preds": [
                    "create an array of linearly spaced points",
                    "equally spaced numbers on a grid",
                    "predicting a continuous response using linear regression",
                    "scipy",
                    "polynomial regression with sklearn"
                ]
            },
            {
                "code": "slope_hidden_layer",
                "true_label": "",
                "top5_preds": [
                    "equally spaced numbers on a grid",
                    "create an array of linearly spaced points",
                    "counting triangles in a social network",
                    "import polynomial features from sklearn",
                    "find slope"
                ]
            },
            {
                "code": "error_h1 = np.around(np.dot(delta_output, weights_out.T),2)",
                "true_label": "",
                "top5_preds": [
                    "matrix addition and scalar matrix multiplication",
                    "numpy",
                    "using k nearest neighbor for imputing missing data",
                    "scipy",
                    "predicting a continuous response using linear regression"
                ]
            }
        ],
        [
            {
                "code": "%matplotlib nbagg\nax = ut.plotSetup3d(-2,2,-2,2,-200,200)\n# try columns of X with large coefficients, or not\nax.plot(X[:,13],X[:,7],'ro',zs=y,markersize=4);",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "pandas plotting",
                    "plot using matplotlib",
                    "matplotlib",
                    "line plots show the trend of a numerical variable over time"
                ]
            },
            {
                "code": "print('Confidence Intervals: {}'.format(results.conf_int()))\nprint('Parameters: {}'.format(results.params))",
                "true_label": "",
                "top5_preds": [
                    "fit a polynomial",
                    "predicting a categorical response",
                    "check accuracy / score for a logistic classifier",
                    "predicting a continuous response using linear regression",
                    "ridge regression with polynomial features on a grid"
                ]
            },
            {
                "code": "CIs = results.conf_int()\nnotSignificant = (CIs[:,0] < 0) & (CIs[:,1] > 0)\nnotSignificant",
                "true_label": "",
                "top5_preds": [
                    "computing the covariance when there are nan s",
                    "predicting a categorical response",
                    "find data type of each column",
                    "check accuracy / score for a logistic classifier",
                    "chi square test of feature"
                ]
            },
            {
                "code": "Xsignif = X[:,~notSignificant]\nXsignif.shape",
                "true_label": "",
                "top5_preds": [
                    "numpy",
                    "computing the covariance when there are nan s",
                    "non negative matrix factorization",
                    "calculating the mean of a vector with nans",
                    "transform categorical data into binary features"
                ]
            },
            {
                "code": "model = sm.OLS(y, Xsignif)\nresults = model.fit()\nprint(results.summary())",
                "true_label": "",
                "top5_preds": [
                    "fit a logistic regression model using statsmodels using logistic regression formula in patsy",
                    "using logistic regression instead",
                    "predicting a continuous response using linear regression",
                    "polynomial regression with sklearn",
                    "using statsmodels, fit an ols regression"
                ]
            },
            {
                "code": "ca = pd.read_table(\"data/cal_housing.data\", sep=',')\n# may be from here: http://www.dcc.fc.up.pt/~ltorgo/Regression/cal_housing.html\n# Block groups in California from 1990 Census.\n# medianIncome is given as log\nattributes = ['longitude',\n            'latitude',\n            'housingMedianAge',\n            'totalRooms',\n            'totalBedrooms',\n            'population',\n            'households',\n            'medianIncome',\n            'medianHouseValue']\n\nca.columns = attributes\n\nca.info()\nca.head(10)",
                "true_label": "",
                "top5_preds": [
                    "load table in pandas",
                    "loading a csv into a dataframe",
                    "importing data with numpy",
                    "relationships between dataframes",
                    "import polynomial features from sklearn"
                ]
            },
            {
                "code": "%matplotlib inline\nX_CA_H = ca[['longitude','latitude','housingMedianAge','totalRooms',\n             'totalBedrooms','population','households','medianIncome']]\nprint('Complete dataset shape is {}'.format(X_CA_H.shape))\nprint('Sample median house values:')\nprint(ca.medianHouseValue.head())\ny_CA_H = ca.medianHouseValue;\nplt.scatter(range(len(y_CA_H)), y_CA_H, c=\"slategray\", alpha=0.3, linewidths=0.2)\nplt.xlabel('Samples in Order')\nplt.ylabel('Median House Value');",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "plot multidimensional data in two dimensions",
                    "pandas plotting",
                    "equally spaced numbers on a grid",
                    "dataframe methods"
                ]
            },
            {
                "code": "%matplotlib nbagg\nsl.hide_code_in_slideshow()\nax = ut.plotSetup3d(-7,7,-7,7,-10,10)\nv = [4.0,4.0,2.0]\nu = [-4.0,3.0,1.0]\n# plotting the span of v\nut.plotSpan3d(ax,u,v,'Green')\nnpts = 50\n# set locations of points that fall within x,y\n# xc = -7.0 + 14.0 * np.random.random(npts)\n# yc = -7.0 + 14.0 * np.random.random(npts)\n# A = np.array([u,v]).T\n# project these points onto the plane\n# P = A.dot(np.linalg.inv(A.T.dot(A))).dot(A.T)\n# coords = P.dot(np.array([xc,yc,np.zeros(npts)]))\n# coords[2] += np.random.randn(npts)\n_ = ax.plot(coords[0],coords[1],'ro',zs=coords[2],markersize=4)\n# plt.show()",
                "true_label": "",
                "top5_preds": [
                    "plot using matplotlib",
                    "matplotlib",
                    "plot multidimensional data in two dimensions",
                    "create a scatter plot",
                    "plotting in python"
                ]
            },
            {
                "code": "X, y = datasets.make_regression(n_samples=100, n_features=20, n_informative=5, bias=0.1, noise=30, random_state=1)\nprint(X.shape, y.shape)",
                "true_label": "",
                "top5_preds": [
                    "polynomial regression with sklearn",
                    "import polynomial features from sklearn",
                    "ridge regression with polynomial features on a grid",
                    "linear regression of many variables",
                    "ridge regression with one predictor on a grid"
                ]
            },
            {
                "code": "model = sm.OLS(y, X)\nresults = model.fit()\nprint(results.summary())",
                "true_label": "",
                "top5_preds": [
                    "predicting a continuous response using linear regression",
                    "using statsmodels, fit an ols regression",
                    "fit a logistic regression model using statsmodels using logistic regression formula in patsy",
                    "fit a polynomial",
                    "run a logistic regression using statsmodels api"
                ]
            },
            {
                "code": "ca = pd.read_table(\"data/cal_housing.data\", sep=',')\n# may be from here: http://www.dcc.fc.up.pt/~ltorgo/Regression/cal_housing.html\n# Block groups in California from 1990 Census.\n# medianIncome is given as log\nattributes = ['longitude',\n            'latitude',\n            'housingMedianAge',\n            'totalRooms',\n            'totalBedrooms',\n            'population',\n            'households',\n            'medianIncome',\n            'medianHouseValue']\n\nca.columns = attributes\n\nca.info()\nca.head(10)",
                "true_label": "",
                "top5_preds": [
                    "load table in pandas",
                    "loading a csv into a dataframe",
                    "importing data with numpy",
                    "relationships between dataframes",
                    "import polynomial features from sklearn"
                ]
            }
        ],
        [
            {
                "code": "from smartdoc15_ch1 import Models",
                "true_label": "",
                "top5_preds": [
                    "import polynomial features from sklearn",
                    "what is scikit learn?",
                    "load table in pandas",
                    "how to change the style of individual lines",
                    "loading json in python"
                ]
            },
            {
                "code": "m = Models(data_home=\"/data/competitions/2015-ICDAR-smartdoc/challenge1/99-computable-version-2017-test\",\n           download_if_missing=False)",
                "true_label": "",
                "top5_preds": [
                    "load table in pandas",
                    "download and inspect the twitter samples dataset",
                    "read the dataset",
                    "import the dataset",
                    "requirements for working with data in scikit learn"
                ]
            },
            {
                "code": "type(m)",
                "true_label": "",
                "top5_preds": [
                    "numpy point",
                    "convert list to numpy array",
                    "creating a simple numpy array",
                    "remove duplicates from a list",
                    "sum all the numbers in a list"
                ]
            },
            {
                "code": "m = Models(data_home=\"/data/competitions/2015-ICDAR-smartdoc/challenge1/99-computable-version-2017-test\",\n           download_if_missing=False,\n           variant=Models.VARIANT_04_CORRECTED)",
                "true_label": "",
                "top5_preds": [
                    "download and inspect the twitter samples dataset",
                    "read the dataset",
                    "load table in pandas",
                    "import the dataset",
                    "read the dataset point"
                ]
            },
            {
                "code": "(Models.VARIANT_01_ORIGINAL,\nModels.VARIANT_02_EDITED,\nModels.VARIANT_03_CAPTURED,\nModels.VARIANT_04_CORRECTED,\nModels.VARIANT_05_SCALED33,)",
                "true_label": "",
                "top5_preds": [
                    "range of feature",
                    "import polynomial features from sklearn",
                    "the mean of difference of variables",
                    "implementing bag of words in scikit learn",
                    "list of categories"
                ]
            },
            {
                "code": "len(m)",
                "true_label": "",
                "top5_preds": [
                    "sum all the numbers in a list",
                    "convert list to numpy array",
                    "equally spaced numbers on a grid",
                    "matching metacharacters literally",
                    "convert date to datetime format"
                ]
            },
            {
                "code": "m0 = m[0]\nm0",
                "true_label": "",
                "top5_preds": [
                    "numpy",
                    "creating a simple numpy array",
                    "convert list to numpy array",
                    "the mean of difference of variables",
                    "pi by means of the arithmetic geometric mean"
                ]
            },
            {
                "code": "type(m0)",
                "true_label": "",
                "top5_preds": [
                    "create an array of zeros",
                    "numpy point",
                    "import polynomial features from sklearn",
                    "calculating the mean of a vector with nans",
                    "creating a simple numpy array"
                ]
            },
            {
                "code": "m0[\"image_path\"], m0[\"model_cat\"], m0[\"model_name\"], m0[\"model_id\"]",
                "true_label": "",
                "top5_preds": [
                    "from dictionary to dataframe",
                    "import polynomial features from sklearn",
                    "load table in pandas",
                    "loading json in python",
                    "obtaining metadata from crossref"
                ]
            },
            {
                "code": "m0_image = m0.read_image()\nm0_image.shape",
                "true_label": "",
                "top5_preds": [
                    "import polynomial features from sklearn",
                    "numpy",
                    "scikit image panorama",
                    "working with image data cnns",
                    "reading and writing binary files"
                ]
            },
            {
                "code": "m0_image_color_resize = m0.read_image(color=True, scale_factor=0.5)\nm0_image_color_resize.shape",
                "true_label": "",
                "top5_preds": [
                    "scikit image panorama",
                    "projection onto the new feature space",
                    "working with image data cnns",
                    "import polynomial features from sklearn",
                    "creating a simple numpy array"
                ]
            },
            {
                "code": "m.model_ids",
                "true_label": "",
                "top5_preds": [
                    "import polynomial features from sklearn",
                    "what is scikit learn?",
                    "tensorflow + keras",
                    "implementing bag of words in scikit learn",
                    "load table in pandas"
                ]
            },
            {
                "code": "m.modeltype_ids",
                "true_label": "",
                "top5_preds": [
                    "import polynomial features from sklearn",
                    "load table in pandas",
                    "tensorflow + keras",
                    "from dictionary to dataframe",
                    "what is scikit learn?"
                ]
            },
            {
                "code": "m.unique_model_ids",
                "true_label": "",
                "top5_preds": [
                    "import polynomial features from sklearn",
                    "from dictionary to dataframe",
                    "what is scikit learn?",
                    "implementing bag of words in scikit learn",
                    "load table in pandas"
                ]
            }
        ],
        [
            {
                "code": "f = open(\"US_births_1994-2003_CDC_NCHS.csv\", \"r\")\nUS_births_raw = f.read()\nUS_births_raw",
                "true_label": "",
                "top5_preds": [
                    "convert date to datetime format",
                    "read numbers until and print their mean and standard deviation without using a list",
                    "reading in the files",
                    "importing data with numpy",
                    "loading a csv into a dataframe"
                ]
            },
            {
                "code": "import pandas as pd\nmovies = pd.read_csv(\"fandango_score_comparison.csv\")\nmovies",
                "true_label": "",
                "top5_preds": [
                    "importing data with pandas",
                    "importing data with numpy",
                    "loading a csv into a dataframe",
                    "convert data from string to float",
                    "load table in pandas"
                ]
            },
            {
                "code": "import matplotlib.pyplot as plt\n%matplotlib inline\n\nplt.hist(movies['Fandango_Stars'])\nplt.show()",
                "true_label": "",
                "top5_preds": [
                    "plot using matplotlib",
                    "plot using pandas plotting",
                    "plotting in python",
                    "plotting time series with pandas",
                    "plot histogram"
                ]
            },
            {
                "code": "raw_split = US_births_raw.split(\"\\n\")\nraw_split[0:10]",
                "true_label": "",
                "top5_preds": [
                    "formatting datetimes as strings",
                    "split it using tabs",
                    "python data type list",
                    "convert date to datetime format",
                    "retrieving data from html page"
                ]
            },
            {
                "code": "import numpy\nFandango_mean = movies['Fandango_Stars'].mean()\nMetacritic_mean = movies['Metacritic_norm_round'].mean()\n\nFandango_median = movies['Fandango_Stars'].median()\nMetacritic_median = movies['Metacritic_norm_round'].median()\n\nFandango_STD = numpy.std(movies['Fandango_Stars'])\nMetacritic_STD = numpy.std(movies['Metacritic_norm_round'])\n\nprint(Fandango_mean, Metacritic_mean, Fandango_median, Metacritic_median, Fandango_STD, Metacritic_STD)\n\n",
                "true_label": "",
                "top5_preds": [
                    "predicting a categorical response",
                    "calculating the mean of a vector with nans",
                    "convert data from string to float",
                    "line plots show the trend of a numerical variable over time",
                    "use numpy to generate an array of random numbers sampled from a standard normal distribution"
                ]
            },
            {
                "code": "def read_csv(read_file):\n    string_file = open(read_file).read()\n    raw_split = string_file.split(\"\\n\")\n    string_list = raw_split[1:len(raw_split)]\n    final_list = []\n    for string in string_list:\n        int_fields = []\n        string_fields = string.split(\",\")\n        for value in string_fields:\n            int_fields.append(int(value))\n        final_list.append(int_fields)\n    return(final_list)\n\ncdc_list = read_csv(\"US_births_1994-2003_CDC_NCHS.csv\")\ncdc_list[0:10]\n    ",
                "true_label": "",
                "top5_preds": [
                    "reading in the files",
                    "read the dataset",
                    "read table",
                    "helpers to read in dataset",
                    "download and inspect the twitter samples dataset"
                ]
            },
            {
                "code": "def month_births(int_list):\n    births_per_month = {}\n    for values in int_list:\n        month = values[1]\n        births = values[4]\n        if month in births_per_month:\n            births_per_month[month] = births_per_month[month] + births\n        else:\n            births_per_month[month] = births\n    return(births_per_month)\n\ncdc_month_births =  month_births(cdc_list)\ncdc_month_births",
                "true_label": "",
                "top5_preds": [
                    "sum all the numbers in a list",
                    "get a positive integer from a user",
                    "from boolean to integer indices",
                    "create a list of retweet count and status tuples",
                    "calculate absolute time of the first arrivals at the station"
                ]
            },
            {
                "code": "plt.scatter(x = movies['Metacritic_norm_round'], y = movies['Fandango_Stars'])\nplt.show()\n\nmovies['fm_diff'] = abs(movies['Metacritic_norm_round'] - movies['Fandango_Stars'])\nmovies.sort('fm_diff', ascending = False)\nprint(movies.head(5))",
                "true_label": "",
                "top5_preds": [
                    "line plots show the trend of a numerical variable over time",
                    "ploting out data with box plots",
                    "predicting a categorical response",
                    "plotting time series with pandas",
                    "line plot with a dataframe"
                ]
            },
            {
                "code": "from scipy import stats\n\nr_value, x = stats.pearsonr(movies['Fandango_Stars'], movies['Metacritic_norm_round'])\n\nslope, intercept, r_value, p_value, std_err = stats.linregress(movies['Metacritic_norm_round'], movies['Fandango_Stars'])\n\npred_y = slope*3.0 + intercept\n\nprint(slope, intercept, r_value, p_value, std_err)",
                "true_label": "",
                "top5_preds": [
                    "predicting a categorical response",
                    "predicting a continuous response using linear regression",
                    "ridge regression with polynomial features on a grid",
                    "ridge regression with one predictor on a grid",
                    "fit a polynomial"
                ]
            },
            {
                "code": "pred_y2 = slope*4.0 + intercept\npred_y0 = intercept\npred_y5 = slope*5.0 + intercept\ny = [pred_y0, pred_y5]\nx = [0.0, 5.0]\nplt.scatter(x = movies['Metacritic_norm_round'], y = movies['Fandango_Stars'])\nplt.plot(x,y)\nplt.xlabel('Metacritic')\nplt.ylabel('Fandango')\nplt.show",
                "true_label": "",
                "top5_preds": [
                    "plot using matplotlib",
                    "line plot with a dataframe",
                    "predicting a categorical response",
                    "line plots show the trend of a numerical variable over time",
                    "ploting out data with box plots"
                ]
            }
        ],
        [
            {
                "code": "from pprint import pprint\nimport random",
                "true_label": "",
                "top5_preds": [
                    "remove duplicates from a list",
                    "formatting datetimes as strings",
                    "pick a random integer using the random module",
                    "equally spaced numbers on a grid",
                    "numpy point"
                ]
            },
            {
                "code": "random.seed = 123",
                "true_label": "",
                "top5_preds": [
                    "pick a random integer using the random module",
                    "find maximum and the minimum value in a set",
                    "equally spaced numbers on a grid",
                    "ridge regression with one predictor on a grid",
                    "optimal value of k for dataset"
                ]
            },
            {
                "code": "Gym_locations = [\"reddit.com\", \"amazon.com\", \"twitter.com\", \"linkedin.com\", \"ebay.com\", \"netflix.com\", \"sporcle.com\", \"stackoverflow.com\",\"github.com\",\"quora.com\"]",
                "true_label": "",
                "top5_preds": [
                    "using json to find your location",
                    "load table in pandas",
                    "getting data from the internet",
                    "postgres sql lab",
                    "import polynomial features from sklearn"
                ]
            },
            {
                "code": "GymsToVisit = 2\n\nfor i in range(GymsToVisit):\n    Nasrudin.VisitGym(Gym_locations[random.randint(0,len(Gym_locations)-1)])",
                "true_label": "",
                "top5_preds": [
                    "attributes of geometries points",
                    "trajectory optimization for under actuated robots",
                    "getting data from the internet",
                    "import polynomial features from sklearn",
                    "traffic sign classification with keras"
                ]
            },
            {
                "code": "print \"Nasrudin's Info\"\npprint (Nasrudin.info())\nprint \"...\"\nprint \"Player List\"\npprint (PlayerList)",
                "true_label": "",
                "top5_preds": [
                    "print",
                    "getting data from the internet",
                    "sum all the numbers in a list",
                    "get a positive integer from a user",
                    "python data type list"
                ]
            },
            {
                "code": "charmander = {\n    \n                1 : {\n                        'name' : 'charmander',\n                        'type' : 'fire',\n                        'hp' : 39,\n                        'attack' : 52,\n                        'defense' : 43,\n                        'special_attack' : 60,\n                        'special_defense' : 50,\n                        'speed' : 65\n                    } \n            }",
                "true_label": "",
                "top5_preds": [
                    "create a scatter plot",
                    "getting data from the internet",
                    "chart mark types",
                    "chart mark",
                    "list of categories"
                ]
            },
            {
                "code": "def filtered_pokedex(filterlist=filter_options, pokedex_data=pd_comp ):\n    filteredpokemon = []\n   \n    \n    \n    for pokemon in pokedex_data[1::]:\n        criteriaspassed = 0\n        for attribute in filterlist:\n             # get the index number from the label's row.\n            try:\n                index = pokedex_data[0].index(attribute)\n            except:\n                print attribute, \"attribute is incorrect\"\n                return []\n            #debug\n            try:\n                compare =float(filterlist[attribute])\n            except:\n                compare=filterlist[attribute]\n            #print attribute, compare, \"is compared with\", pokemon[1], pokedex_data[0][index],pokedex_data[0].index(attribute), pokemon[index]\n            \n            if type(compare) == float or type(compare) ==int:\n                if compare <= pokemon[index]:             \n                    criteriaspassed +=1\n                    #print 'criteriapassed', criteriaspassed\n            else:\n                if compare == (pokemon[index]):\n                    criteriaspassed +=1\n                    #print 'criteriapassed', criteriaspassed\n            \n        #If passed all criteria, append this pokemon into the filteredpokemon list\n        \n        if criteriaspassed >= len(filterlist.keys()):\n            filteredpokemon.append(pokemon)\n    return filteredpokemon\n    ",
                "true_label": "",
                "top5_preds": [
                    "exclude entries by condition",
                    "helpers to preprocess dataset",
                    "making predictions for the testing data",
                    "collect them in a list print the elements backwards zero not included",
                    "predictions"
                ]
            },
            {
                "code": "pprint (filtered_pokedex(filter_options))",
                "true_label": "",
                "top5_preds": [
                    "filling the mask",
                    "fit a polynomial",
                    "find maximum and the minimum value in a set",
                    "builtin methods defined on stream / trace",
                    "exclude entries by condition"
                ]
            },
            {
                "code": "TotalAttributes = [ info[3] for info in pd_comp[1::] ]",
                "true_label": "",
                "top5_preds": [
                    "find data type of each column",
                    "load table in pandas",
                    "relationships between dataframes",
                    "what is pandas?",
                    "loading a csv into a dataframe"
                ]
            },
            {
                "code": "import numpy as np\nPopulation_mean = np.mean(TotalAttributes)\nPopulation_std = np.std(TotalAttributes)\n\nprint \"Population mean is\", Population_mean, \"\\n\",\"Population_std is\",Population_std",
                "true_label": "",
                "top5_preds": [
                    "the mean of difference of variables",
                    "predicting a categorical response",
                    "calculating the mean of a vector with nans",
                    "numpy",
                    "use numpy to generate an array of random numbers sampled from a standard normal distribution"
                ]
            },
            {
                "code": "squirtle = {\n    \n                2 : {\n                        'name' : 'squirtle',\n                        'type' : 'water',\n                        'hp' : 44,\n                        'attack' : 48,\n                        'defense' : 65,\n                        'special_attack' : 50,\n                        'special_defense' : 64,\n                        'speed' : 43\n                    } \n            }",
                "true_label": "",
                "top5_preds": [
                    "get a positive integer from a user",
                    "getting data from the internet",
                    "data given as a dictionary",
                    "twitter api access",
                    "convert text data into vector"
                ]
            },
            {
                "code": "bulbasaur = {\n    \n                3 : {\n                        'name' : 'bulbasaur',\n                        'type' : 'poison',\n                        'hp' : 45,\n                        'attack' : 49,\n                        'defense' : 49,\n                        'special_attack' : 65,\n                        'special_defense' : 65,\n                        'speed' : 45\n                    } \n            }",
                "true_label": "",
                "top5_preds": [
                    "data given as a dictionary",
                    "create a data dictionary",
                    "postgres sql lab",
                    "function to find dbZ given Pr radar equation",
                    "get a positive integer from a user"
                ]
            },
            {
                "code": "Pokedex.update(bulbasaur)\nPokedex.update(squirtle)\nPokedex.update(charmander)",
                "true_label": "",
                "top5_preds": [
                    "symbolic computation with polynomials",
                    "getting data from the internet",
                    "get a positive integer from a user",
                    "add members in a set",
                    "find maximum and the minimum value in a set"
                ]
            },
            {
                "code": "pprint (Pokedex)",
                "true_label": "",
                "top5_preds": [
                    "add an item in a tuple",
                    "python data type list",
                    "formatting datetimes as strings",
                    "attribute access",
                    "loading json in python"
                ]
            },
            {
                "code": "players ={}\nplayers.update({Nasrudin.info()['player_id']:Nasrudin.info()})\npprint (players)",
                "true_label": "",
                "top5_preds": [
                    "data given as a dictionary",
                    "from dictionary to dataframe",
                    "twitter api access",
                    "loading json in python",
                    "using json to find your location"
                ]
            },
            {
                "code": "players = {}\nplayers = PlayerList\npprint (players)",
                "true_label": "",
                "top5_preds": [
                    "sum all the numbers in a list",
                    "loading json in python",
                    "add string to list using append",
                    "add an item in a tuple",
                    "convert list to numpy array"
                ]
            },
            {
                "code": "Gary = player ('Gary Strong Flavour',2) #Instaed of using the random number generator, we use 2 for the player id argument\npprint (Gary.info())",
                "true_label": "",
                "top5_preds": [
                    "get a positive integer from a user",
                    "getting data from the internet",
                    "add an item in a tuple",
                    "pick a random integer using the random module",
                    "formatting datetimes as strings"
                ]
            },
            {
                "code": "Gary.VisitGym('alcatraz')\nGary.VisitGym('pacific_beach')\nGary.AddPlayTime(100)\n# Just to prove that it works\nprint \"\"\nprint \"Gary's Information\"\npprint (Gary.info())",
                "true_label": "",
                "top5_preds": [
                    "get a positive integer from a user",
                    "importing data with numpy",
                    "add an item in a tuple",
                    "getting data from the internet",
                    "importing functions"
                ]
            },
            {
                "code": "pd_comp = [map(lambda x: float(x) if x.isdigit() else x, List) for List in [row.replace('\"',\"\").split(\",\") for row in raw_pd.replace(\",,\", \",-1,\").split(\"\\n\") ]]",
                "true_label": "",
                "top5_preds": [
                    "formatting datetimes as strings",
                    "convert data from string to float",
                    "find data type of each column",
                    "convert integer or float data",
                    "pandas apply"
                ]
            },
            {
                "code": "pprint (pd_comp)",
                "true_label": "",
                "top5_preds": [
                    "formatting datetimes as strings",
                    "relationships between dataframes",
                    "join two dataframes along rows",
                    "convert date to datetime format",
                    "equally spaced numbers on a grid"
                ]
            },
            {
                "code": "def PokedictGenerator(parsedpd=pd_comp):\n    \n    #The labels\n    label = parsedpd[0][1::]\n    #remove the PokedexNumber labe with slicing\n    \n    \n    #The Data\n    data = parsedpd[1::]\n    \n    #The main dictionary is initialized here\n    Pokedexdict = {}\n    \n    #The original Pokedex values do not contain the PokeDexNumber as a constituent of the values.\n    # We will have to pop it out and use it as the key.\n    for pokemoninfo in data:\n        \n        #This is the dictionary to contain the pokemon stats\n        Pokemondict = { }\n        PokemonVariants = {}\n        #Get the Pokedex Number \n        PokeNumber = pokemoninfo[0]\n        \n        #We now zip the data with the labels to create the dictionary\n        Pokemondict.update( {key:value for key,value in zip(label,pokemoninfo[1::])})\n        \n        #since there are different pokemons with the same PokedexNumber, we will have to create another layer\n        variant =1 #this will work as a sub-Pokemon ID\n        #check if the pokemon has a variant\n        if PokeNumber in Pokedexdict:\n            \n            #Variants of this pokemon exists\n            while variant in Pokedexdict[PokeNumber]: #Variant already registered, so we increase the sub-index number by 1\n                \n                variant += 1\n            Pokedexdict[PokeNumber][variant] = Pokemondict\n            \n        \n            #We then add this dictionary of dictionaries into the PokedexDict\n        else:\n            PokemonVariants[variant] = Pokemondict\n            Pokedexdict.update({PokeNumber:PokemonVariants})\n        \n    #returns the finished dictionary\n    return Pokedexdict\n        \n    ",
                "true_label": "",
                "top5_preds": [
                    "create a data dictionary",
                    "making predictions for the testing data",
                    "data given as a dictionary",
                    "predictive distribution",
                    "predict on validation"
                ]
            },
            {
                "code": "pprint (PokedictGenerator())",
                "true_label": "",
                "top5_preds": [
                    "remove duplicates from a list",
                    "find maximum and the minimum value in a set",
                    "generator tests",
                    "optimal value of k for dataset",
                    "create a python dictionary"
                ]
            },
            {
                "code": "visitedgyms = [players[player]['player_name'] + \" has visited \" + gym for player in players for gym in Gym_locations if gym in players[player]['gyms_visited'] ]\nprint (\"\\n\".join(visitedgyms))",
                "true_label": "",
                "top5_preds": [
                    "create a list of all words",
                    "add an item in a tuple",
                    "using json to find your location",
                    "vectorize words in movie reviews",
                    "detect the number of local variables declared in a function"
                ]
            },
            {
                "code": "def PokemonPower(ID, pokedex = Pokedex):\n    if ID in pokedex:\n    \n        #Make it case insensitive\n        #Create dummy lists that has all keys standardized to lower case, zip them back into a dictionary\n        #via list comprehension\n        \n        dummypokedexID = {key:value for key,value in zip([k.lower() for k in Pokedex[ID]],[k for k in Pokedex[ID].values()])}\n        \n        try:\n    \n            AggregatePower = dummypokedexID['attack'] + dummypokedexID['defense'] + dummypokedexID['special_attack'] + dummypokedexID['special_defense']\n        except:\n        #error fix in the case it starts using no underscores for the special stats later on.\n            AggregatePower = dummypokedexID['attack'] + dummypokedexID['defense'] + dummypokedexID['specialattack'] + dummypokedexID['specialdefense']\n        return AggregatePower\n    else:\n        print ID, \"pokemon not in Pokedex\"\n        return []\n        ",
                "true_label": "",
                "top5_preds": [
                    "predict on test set",
                    "get a positive integer from a user",
                    "predictive distribution",
                    "likelihood of the binomial distribution",
                    "parse a single incident entry"
                ]
            },
            {
                "code": "def PlayerPower(player_id, player_datastructure = players,pokedex_dict = Pokedex ):\n    \n    if player_id in player_datastructure:\n        \n        #A for loop to sum all the pokemon's powers\n        \n        player_power = 0 #initiate the variable\n        for pokemon in player_datastructure[player_id]['player_pokemon']:\n            \n            #calls the Pokemon Power function and then adds the return value into player_power\n            player_power += PokemonPower(pokemon,pokedex_dict)\n              \n        print str(player_datastructure[player_id]['player_name']) + \"'s power is\", str(player_power)+\".\"\n        #returns the final value\n        return player_power\n        \n    else:\n        print \"player\",player_id, \"does not exist!\"\n        return []\n    ",
                "true_label": "",
                "top5_preds": [
                    "calculate the mean yellow cards given per team",
                    "read the dataset point",
                    "find the angle of attack for a given lift coefficient",
                    "get a positive integer from a user",
                    "draw"
                ]
            },
            {
                "code": "# Code to read in pokedex info\nraw_pd = ''\npokedex_file = 'pokedex_basic.csv'\nwith open(pokedex_file, 'r') as f:\n    raw_pd = f.read()\n    \n# the pokedex string is assigned to the raw_pd variable",
                "true_label": "",
                "top5_preds": [
                    "read text file point",
                    "loading json in python",
                    "what is scikit learn?",
                    "getting data from the internet",
                    "line plots show the trend of a numerical variable over time"
                ]
            },
            {
                "code": "PlayerList = {} #Player List as  Dictionary\nPokedex={} #Pokemon List which we will load the list of pokemons inside. Is a Dictionary within a dictionary\nGym_locations = []",
                "true_label": "",
                "top5_preds": [
                    "data given as a dictionary",
                    "add an item in a tuple",
                    "loading json in python",
                    "importing data with numpy",
                    "load table in pandas"
                ]
            },
            {
                "code": "class player(object): \n   \n    #The required variables are created and set here to the default values. With proper data types.\n    def __init__(self,player_name ,player_id):\n        \"\"\"The player_id can be automed within the class itself but instead I've segregated it into another function\n        in case one wants a specific player_id in the future, e.g an admin wants player id = 1\"\"\" \n    \n        self.player_name = str(player_name) \n        self.player_id= int(player_id) \n        self.time_played = 0.0\n        self.player_pokemon = {}  \n        self.gyms_visited = []\n            \n        #Adds this player into the player List\n        global PlayerList \n        PlayerList [self.player_id] = self.player_name\n    \n    # Now we set some methods that player objects can perform.\n    \n    def info(self):\n        \"\"\"Returns Information about the player as a dictionary\"\"\"\n        ''' Also updates the player info into the PlayerList Dictionary( for the purpose of this project)'''\n        \n        #Create List of Information\n        PokemonTrainer = {'player_id':self.player_id, 'player_name':self.player_name, 'time_played':self.time_played,'player_pokemon': self.player_pokemon,'gyms_visited': self.gyms_visited}\n        #update the PlayerList\n        PlayerList.update({self.player_id:PokemonTrainer})\n        return PokemonTrainer\n    \n    #This functions adds a pokemon into the list of pokemons the player have.\n    def Pokemon(self,pokemon, pokedex = Pokedex, add=True):\n        \n        '''Pokemon is added via it's index number'''\n        ''' By default, this will add a pokemon, add can be set to false to remove pokemon'''\n        ''' The pokedex input is used to specify where the pokedex is.'''\n             \n        #Adds pokemon through the index \n        \n        #Check whether add = true\n        if add == True:\n            try:\n                self.player_pokemon.update({pokemon:pokedex[pokemon]})\n                message = \"added to\"\n            except:\n                return 'Pokemon not recognized'    \n        elif add ==False:\n            try:\n                self.player_pokemon.pop(pokemon)\n                message = \"removed from\"\n            except:\n                return 'Pokemon not recognized'  \n        else:\n            print \"'add' variable is not a boolean\" \n            #this will prevent it from giving the output message when\n            return []\n\n        #Output messages\n        #updates the PlayerList\n        self.info()\n        try:\n            print pokedex[pokemon]['Name'], \"has been\",message, self.player_name + \"'s\", \"list of pokemons\" \n        except:\n            print pokedex[pokemon]['name'], \"has been\",message, self.player_name + \"'s\", \"list of pokemons\" \n        \n                         \n\n    def VisitGym(self, gym, gym_locations=Gym_locations):\n        \"\"\"Player visits gym, the gym is added to the list of gyms visited\"\"\"\n        ''' A gym can be added into the list more than once if it was visited numerous times'''\n        \n        #output message\n        GymName = gym\n        \n        \n        if type (gym) == str:\n            self.gyms_visited.append(gym)\n        else:\n            try:\n                self.gyms_visited.append(gym_locations[gym])\n                GymName = gym_locations[gym]\n            except:\n                print str(gym) + \" index is not in the Gym_locations list\"\n                return []\n        #updates the PlayerList\n        self.info()\n        print str(self.player_name) + \" visits the \" + str(GymName) + \" gym\"\n    \n    def AddPlayTime(self, time):\n        \"\"\"Adds Play time into the player's stats\"\"\"\n        self.time_played += time\n        playtime_hours = self.time_played/3600.0\n        \n        #updates the PlayerList\n        self.info()\n        print self.player_name,\"has played for\",time,\"seconds\"\n        print \"Total play time is\",self.time_played,\"hours\"\n    \n    \n        \n        \n\n    \n",
                "true_label": "",
                "top5_preds": [
                    "load table in pandas",
                    "assign to a variable",
                    "get a positive integer from a user",
                    "attributes of geometries points",
                    "summarize attributes by class"
                ]
            },
            {
                "code": "def RandomID():\n        #generate random number\n        generating = True\n        while generating == True:\n            \n            randomstring = random.randint(100000000,999999999)\n            \n        #checks whether randomstring already exists in player database\n            if not randomstring in PlayerList:\n                #This will exit the while loop\n                generating = False\n        return randomstring\n",
                "true_label": "",
                "top5_preds": [
                    "create the next generation",
                    "getting data from the internet",
                    "generate some sample data",
                    "create a graph",
                    "create an array of linearly spaced points"
                ]
            },
            {
                "code": "new_pd = raw_pd.split(\"\\n\")\n",
                "true_label": "",
                "top5_preds": [
                    "formatting datetimes as strings",
                    "join two dataframes along rows",
                    "convert text data into vector",
                    "loading a csv into a dataframe",
                    "importing data with numpy"
                ]
            },
            {
                "code": "fixed_pd =[]\nfor rows in new_pd:\n    \n    rows = rows.replace('\"',\"\")\n    #split the row\n    rows = rows.split(\",\")\n    \n    NewRow =[]\n    for element in rows:\n        #convert numeric values in cells into float\n        try:\n            element = float(element)\n        except:\n            element = element\n        #Make this a new row consisting of elements\n        NewRow.append(element)\n    #append this new row into the list of lists, fixed_pd\n    fixed_pd.append(NewRow)\n",
                "true_label": "",
                "top5_preds": [
                    "convert data from string to float",
                    "convert text data into vector",
                    "from dictionary to dataframe",
                    "convert columns",
                    "convert list to numpy array"
                ]
            },
            {
                "code": "pprint (fixed_pd)",
                "true_label": "",
                "top5_preds": [
                    "equally spaced numbers on a grid",
                    "formatting datetimes as strings",
                    "from dictionary to dataframe",
                    "convert date to datetime format",
                    "line plot with a dataframe"
                ]
            },
            {
                "code": "pprint (players)",
                "true_label": "",
                "top5_preds": [
                    "add an item in a tuple",
                    "sum all the numbers in a list",
                    "equally spaced numbers on a grid",
                    "formatting datetimes as strings",
                    "remove duplicates from a list"
                ]
            },
            {
                "code": "pprint (PokedictGenerator()[6])",
                "true_label": "",
                "top5_preds": [
                    "remove duplicates from a list",
                    "find maximum and the minimum value in a set",
                    "predicting a categorical response",
                    "optimal value of k for dataset",
                    "get a positive integer from a user"
                ]
            },
            {
                "code": "# Only filter based on parameters passed\nfilter_options = {\n    'Attack':   25,\n    'Defense':  30,\n    'Type':     'Electric'\n}",
                "true_label": "",
                "top5_preds": [
                    "optimal value of k for dataset",
                    "find maximum and the minimum value in a set",
                    "fit a polynomial",
                    "predicting a categorical response",
                    "accessing twitter"
                ]
            },
            {
                "code": "Nasrudin = player(\"Nasrudin Salim\",RandomID())",
                "true_label": "",
                "top5_preds": [
                    "get a positive integer from a user",
                    "add an item in a tuple",
                    "modeling in social sciences",
                    "getting data from the internet",
                    "assign to a variable"
                ]
            },
            {
                "code": "pprint (Nasrudin.info())",
                "true_label": "",
                "top5_preds": [
                    "getting data from the internet",
                    "get a positive integer from a user",
                    "what is a string?",
                    "retrieving data from html page",
                    "what is scikit learn?"
                ]
            },
            {
                "code": "print \"Gary's visited Gyms\"\npprint (Gary.info()['gyms_visited'])\nprint \"...\"\nprint \"Nasrudin's visited Gyms\"\npprint (Nasrudin.info()['gyms_visited'])",
                "true_label": "",
                "top5_preds": [
                    "getting data from the internet",
                    "remove duplicates from a list",
                    "print",
                    "importing data with numpy",
                    "sum all the numbers in a list"
                ]
            },
            {
                "code": "loopcount = 0\nfor gym in Gym_locations:\n    for player in players:\n        loopcount += 1\n        if gym in players[player]['gyms_visited']:\n            print players[player]['player_name'],\"has visited\", gym\n            \n    ",
                "true_label": "",
                "top5_preds": [
                    "find the most common words",
                    "getting data from the internet",
                    "trajectory optimization for under actuated robots",
                    "add edges in graph",
                    "detect the number of local variables declared in a function"
                ]
            },
            {
                "code": "print loopcount",
                "true_label": "",
                "top5_preds": [
                    "detect the number of local variables declared in a function",
                    "sum all the numbers in a list",
                    "line plots show the trend of a numerical variable over time",
                    "assign to a variable",
                    "check a list is empty or not"
                ]
            },
            {
                "code": "TSD = 3 * Population_std",
                "true_label": "",
                "top5_preds": [
                    "line plots show the trend of a numerical variable over time",
                    "use numpy to generate an array of random numbers sampled from a standard normal distribution",
                    "integrating datetime tools with pandas for time series",
                    "linear regression of many variables",
                    "ridge regression with one predictor on a grid"
                ]
            },
            {
                "code": "Outlier = TSD + Population_mean\n",
                "true_label": "",
                "top5_preds": [
                    "predicting a categorical response",
                    "computing the mean together with the covariance",
                    "calculating the mean of a vector with nans",
                    "the mean of difference of variables",
                    "sampling from the gaussian process prior"
                ]
            },
            {
                "code": "FindOutlier = {\n    'Total': Outlier\n    \n}\nBroken = filtered_pokedex(FindOutlier)\npprint (Broken)",
                "true_label": "",
                "top5_preds": [
                    "remove duplicates from a list",
                    "predicting a categorical response",
                    "find the repeated items of a tuple",
                    "what is conditional probability good for?",
                    "find maximum and the minimum value in a set"
                ]
            },
            {
                "code": "pprint (PlayerList)",
                "true_label": "",
                "top5_preds": [
                    "sum all the numbers in a list",
                    "add an item in a tuple",
                    "add string to list using append",
                    "python data type list",
                    "remove duplicates from a list"
                ]
            },
            {
                "code": "def rarity(pokemonID,Pokedex = pd_comp):\n    TotalAttributes = [ info[3] for info in Pokedex[1::] ]\n    mean = np.mean(TotalAttributes)\n    std = np.std(TotalAttributes)\n    \n    PokemonTotal = Pokedex[pokemonID][3]\n    difference = abs(PokemonTotal - mean)\n    mlt = difference / std\n   # print mlt\n    interval = mean / std\n   # print interval\n    probabiity_std = 0.5 / interval\n   #print probabiity_std\n    \n    \n    #Check if higher or lower than mean\n    if PokemonTotal >= mean:\n        Probability = 0.5 - (probabiity_std * mlt)\n    else:\n        Probability = 0.5 + (probabiity_std * mlt)\n    return Probability\n    ",
                "true_label": "",
                "top5_preds": [
                    "info on the data set",
                    "predicting a categorical response",
                    "calculate distance of event and station",
                    "calculate the mean yellow cards given per team",
                    "find data type of each column"
                ]
            },
            {
                "code": "rarity(1)",
                "true_label": "",
                "top5_preds": [
                    "anonymous functions and lambdas",
                    "test whether a number is positive",
                    "get a positive integer from a user",
                    "pi by means of the arithmetic geometric mean",
                    "polynomial/rational function simplification"
                ]
            },
            {
                "code": "import matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()",
                "true_label": "",
                "top5_preds": [
                    "use seaborn",
                    "line plot with a dataframe",
                    "visualizing with seaborn",
                    "plot using matplotlib",
                    "plotting time series with pandas"
                ]
            },
            {
                "code": "plt.hist(TotalAttributes,bins=30)\n",
                "true_label": "",
                "top5_preds": [
                    "line plots show the trend of a numerical variable over time",
                    "plotting time series with pandas",
                    "line plot with a dataframe",
                    "predicting a categorical response",
                    "ploting out data with box plots"
                ]
            },
            {
                "code": "plt.show()",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "equally spaced numbers on a grid",
                    "line plots show the trend of a numerical variable over time",
                    "create an array of linearly spaced points",
                    "ploting out data with box plots"
                ]
            },
            {
                "code": "PokemonTotals = []\nPokemonProbability =[]\nfor pokemons in range(1,len(pd_comp)):\n    \n    PokemonTotals.append( pd_comp[pokemons][3])\n    PokemonProbability.append(rarity(pokemons))\n\n\nplt.plot(PokemonTotals,PokemonProbability, marker='.',linestyle='None')\n\n\n\nplt.show()",
                "true_label": "",
                "top5_preds": [
                    "predicting a categorical response",
                    "sum all the numbers in a list",
                    "likelihood of the binomial distribution",
                    "line plots show the trend of a numerical variable over time",
                    "predicting test data"
                ]
            }
        ],
        [
            {
                "code": "pylab.rcParams['figure.figsize'] = (10.0, 8.0)\nxgb.plot_importance(xgb_clf);",
                "true_label": "",
                "top5_preds": [
                    "plot using matplotlib",
                    "plot the function",
                    "likelihood of the binomial distribution",
                    "pandas plotting",
                    "pandas plotting documentation"
                ]
            },
            {
                "code": "predictions = xgb_clf.predict_proba(x_val)\nfalse_predictions = predictions[:, 0]\ntrue_predictions = predictions[:, 1]\n\nplt.figure()\nplt.title(\"Validation set class probability distributions\")\n\nplt.hist(false_predictions, bins = 10, color = 'r', label = 'Low consumption', alpha = 0.7)\nplt.hist(true_predictions, bins = 10, color = 'c', label = 'High consumption', alpha = 0.7)\nplt.legend();\nplt.axvline(0.5, linestyle = 'dashed')",
                "true_label": "",
                "top5_preds": [
                    "predicting a categorical response",
                    "ploting out data with box plots",
                    "likelihood of the binomial distribution",
                    "line plot with a dataframe",
                    "ridge regression with polynomial features on a grid"
                ]
            },
            {
                "code": "def std_array(random_search_res):\n    return np.array([np.std(x) for x in np.array(random_search_res.grid_scores_)[:, 2]]).astype('f')\n\ndef plot_std(scores, std, color):\n    plt.fill_between(np.arange(250), scores + std, scores - std, alpha=0.2, facecolor = color)\n\nxgb_scores = np.array(xgb_random_search.grid_scores_)[:, 1].astype('f')\ncart_scores = np.array(cart_random_search.grid_scores_)[:, 1].astype('f')\nrf_scores = np.array(rf_random_search.grid_scores_)[:, 1].astype('f')\nxgb_std = std_array(xgb_random_search)\ncart_std = std_array(cart_random_search)\nrf_std = std_array(rf_random_search)\n\nplt.figure()\nplt.title(\"Randomized parameter search score\")\n\nplt.plot(xgb_scores, label = 'XGBoost', color = 'r', alpha = 0.7)\nplot_std(xgb_scores, xgb_std, 'g')\nplt.plot(cart_scores, label = 'Random Forest', color = 'm', alpha = 0.7)\nplot_std(cart_scores, cart_std, 'g')\nplt.plot(rf_scores, label = 'CART', color = 'c', alpha = 0.7)\nplot_std(rf_scores, rf_std, 'g')\nplt.legend(loc = 4)",
                "true_label": "",
                "top5_preds": [
                    "create an array of linearly spaced points",
                    "use numpy to generate an array of random numbers sampled from a standard normal distribution",
                    "line plots show the trend of a numerical variable over time",
                    "predicting a categorical response",
                    "ridge regression with one predictor on a grid"
                ]
            },
            {
                "code": "plt.figure()\nplt.title(\"Validation scores\")\n\nval_scores = [xgb_val_score, rf_val_score, cart_val_score]\nlabels = ['XGBoost', 'Random Forest', 'CART']\nx = np.arange(3)\nplt.scatter(\n    x, val_scores, marker = 'o', c = ['r', 'm', 'c'], s = 100)\n\nfor label, x, y in zip(labels, x, val_scores):\n    plt.annotate(\n        label, \n        xy = (x, y), xytext = (-20, 20),\n        textcoords = 'offset points', ha = 'right', va = 'bottom',\n        bbox = dict(boxstyle = 'round,pad=0.5', fc = 'yellow', alpha = 0.5),\n        arrowprops = dict(arrowstyle = '->', connectionstyle = 'arc3,rad=0'))",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "ploting out data with box plots",
                    "line plots show the trend of a numerical variable over time",
                    "equally spaced numbers on a grid",
                    "create a scatter plot"
                ]
            },
            {
                "code": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nfrom scipy import stats\nfrom sklearn import cross_validation\nfrom pandas.tools.plotting import scatter_matrix\nfrom IPython.display import display\n\nimport pylab\n",
                "true_label": "",
                "top5_preds": [
                    "equally spaced numbers on a grid",
                    "line plot with a dataframe",
                    "import polynomial features from sklearn",
                    "ridge regression with polynomial features on a grid",
                    "polynomial regression with sklearn"
                ]
            },
            {
                "code": "%matplotlib inline\nplt.style.use('ggplot')\npd.options.display.mpl_style = 'default'\nstudent_mat = pd.read_csv(\"./data/student-mat.csv\", sep = \";\")\nstudent_por = pd.read_csv(\"./data/student-por.csv\", sep = \";\")",
                "true_label": "",
                "top5_preds": [
                    "plot using pandas plotting",
                    "pandas plotting",
                    "plot using matplotlib",
                    "using a dataframe and matplotlib commands",
                    "load table in pandas"
                ]
            },
            {
                "code": "display(stats.ks_2samp(student_mat['Walc'], student_por['Walc']))\ndisplay(stats.ks_2samp(student_mat['Dalc'], student_por['Dalc']))",
                "true_label": "",
                "top5_preds": [
                    "importing data with numpy",
                    "convert text data into vector",
                    "convert data from string to float",
                    "predicting a categorical response",
                    "line plot with a dataframe"
                ]
            },
            {
                "code": "display(student_por.shape)\ndisplay(student_mat.shape)",
                "true_label": "",
                "top5_preds": [
                    "import polynomial features from sklearn",
                    "numpy",
                    "equally spaced numbers on a grid",
                    "visualizing uncertainty",
                    "timing, numpy, plotting"
                ]
            },
            {
                "code": "# TODO: Dalc + Walc processing\ndef process_alc(data):\n    result = data\n    result['alc'] = data.apply(lambda row: ((row['Dalc'] * 5.0) + (row['Walc'] * 2.0)) / 7, axis = 1)\n    result.drop(['Dalc', 'Walc'], inplace = True, axis = 1)\n    return result\n\nprocess_alc(student_mat);\nprocess_alc(student_por);",
                "true_label": "",
                "top5_preds": [
                    "collecting and analysing alm data",
                    "get the data",
                    "summarize the data",
                    "read featurecounts and apply transformations",
                    "interpreting the coefficients"
                ]
            },
            {
                "code": "student_mat.head(1)",
                "true_label": "",
                "top5_preds": [
                    "import polynomial features from sklearn",
                    "get the sum of all the columns in mat",
                    "what is scikit learn?",
                    "tensorflow + keras",
                    "scikit learn"
                ]
            },
            {
                "code": "students = pd.concat([student_mat, student_por]).groupby([\"school\",\n                                                          \"sex\",\n                                                          \"age\",\n                                                          \"address\",\n                                                          \"famsize\",\n                                                          \"Pstatus\",\n                                                          \"Medu\",\n                                                          \"Fedu\",\n                                                          \"Mjob\",\n                                                          \"Fjob\",\n                                                          \"reason\",\n                                                          \"nursery\",\n                                                          \"internet\"]).mean().reset_index()\n\nstudents['alc'] = students['alc'].apply(np.rint)\nstudents.shape",
                "true_label": "",
                "top5_preds": [
                    "load table in pandas",
                    "create a dataframe by joining series by column",
                    "find data type of each column",
                    "from dictionary to dataframe",
                    "loading a csv into a dataframe"
                ]
            },
            {
                "code": "students.hist(figsize=(20, 20));",
                "true_label": "",
                "top5_preds": [
                    "trend lines in pyplot",
                    "line plots show the trend of a numerical variable over time",
                    "plotting time series with pandas",
                    "ploting out data with box plots",
                    "line plot with a dataframe"
                ]
            },
            {
                "code": "scatter_matrix(students, diagonal = 'hist', figsize=(20, 20));",
                "true_label": "",
                "top5_preds": [
                    "create a scatter plot",
                    "visualize the scatterplot of x",
                    "plot multidimensional data in two dimensions",
                    "counting triangles in a social network",
                    "equally spaced numbers on a grid"
                ]
            },
            {
                "code": "students_transformed = students\nstudents_transformed['male'] = students['sex'] == \"M\"\nstudents_transformed['rural'] = students['address'] == \"R\"\nstudents_transformed['big_family'] = students['famsize'] == 'GT3'\nstudents_transformed['parents_together'] = students['Pstatus'] == \"T\"\nstudents_transformed['studies_less'] = students['studytime'] < 3\nstudents_transformed['more_failures'] = students['failures'] >= 2\nstudents_transformed['bad_relationships'] = students['famrel'] <= 2\nstudents_transformed['more_free_time'] = students['freetime'] > 3\nstudents_transformed['goes_out_more'] = students['goout'] > 4\nstudents_transformed['bad_health'] = students['health'] <= 2\nstudents_transformed['high_absences'] = students['absences'] > (students['absences'].std() * 2)\nstudents_transformed['drinker'] = students['alc'] >= 3\nstudents_transformed['mothers_low_edu'] = students['Medu'] <= 3\nstudents_transformed['fathers_low_edu'] = students['Fedu'] <= 3\nstudents_transformed['more_than_18'] = students['age'] > 18\nstudents_transformed['long_road'] = students['traveltime'] >= 3\n\nsum_grade = students['G1'] + students['G2'] + students['G3']\nmean_grade = (sum_grade) / 3 \nstudents_transformed['low_grade'] = mean_grade <= (mean_grade.mean() + mean_grade.std())\n\nstudents_transformed.drop(['sex', \n                           'address', \n                           'famsize', \n                           'Pstatus', \n                           'studytime', \n                           'failures', \n                           'famrel', \n                           'freetime', \n                           'goout', \n                           'health',\n                           'absences',\n                           'alc',\n                           'G1',\n                            'G2',\n                            'G3',\n                           'Medu',\n                           'Fedu',\n                           'age',\n                           'traveltime'], axis = 1, inplace = True)",
                "true_label": "",
                "top5_preds": [
                    "from dictionary to dataframe",
                    "convert data from string to float",
                    "convert text data into vector",
                    "data given as a dictionary",
                    "get a positive integer from a user"
                ]
            },
            {
                "code": "students_transformed.hist(figsize=(20, 20));",
                "true_label": "",
                "top5_preds": [
                    "line plots show the trend of a numerical variable over time",
                    "trend lines in pyplot",
                    "plotting time series with pandas",
                    "line plot with a dataframe",
                    "ploting out data with box plots"
                ]
            },
            {
                "code": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nfrom scipy import stats\nfrom sklearn import cross_validation\nfrom pandas.tools.plotting import scatter_matrix\nfrom IPython.display import display\n\nimport pylab",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "equally spaced numbers on a grid",
                    "import polynomial features from sklearn",
                    "ridge regression with polynomial features on a grid",
                    "polynomial regression with sklearn"
                ]
            }
        ],
        [
            {
                "code": "SUPPORT_THRESHOLD = 1.9 # To avoid the mistake of using > instead of >=\nCONFIDENCE_THRESHOLD = 0.599999\n\ndataset = \"\"\"HotDogs,\tBuns,\tKetchup\t\nHotDogs,\tBuns\t\nHotDogs,\tCoke,\tChips\t\nChips,\tCoke\t\nChips,\tKetchup\t\nHotDogs,\tCoke,\tChips\t\"\"\".replace(\"\\t\", \"\")\n\ntransactions = []\nitems = {} # dictionary of itesm and a list of  transactions they a p\n\n# Problem would have been easier if I'd ised objects\nfrom collections import namedtuple\nItemset = namedtuple('Itemset', 'items transactions hv support')\n\n# Output for cell in CSV file\ndef symbol(transaction):\n    return [item if item in transaction else '?' for item in items.keys()]\n    \n\nfor i, line in enumerate(dataset.split(\"\\n\"),start=1):\n    transaction = set(line.split(',')) # items in each line\n    for item in transaction:\n        l = items.get(item,[])\n        l.append(str(i))\n        items[item] = l\n        \n    transactions.append(transaction)\n    \nprint \"T\", transactions\nprint \"I\", items\n \n# Create CSV\nprint \",\".join(items.keys())\nfor t in transactions:\n    print \",\".join(symbol(t))\n",
                "true_label": "",
                "top5_preds": [
                    "optimal value of k for dataset",
                    "equally spaced numbers on a grid",
                    "check accuracy / score for a logistic classifier",
                    "predicting a categorical response",
                    "find maximum and the minimum value in a set"
                ]
            },
            {
                "code": "def join_items(A, B):\n    # find the new items\n    diff = A.items.symmetric_difference(B.items)\n    \n    # should be 2 new items e. {1,2,3,4} + {2,3,4,5}\n    # {2,3,4} is common and {1,5} is difference\n    if not len(diff) == 2: return None\n    \n    # find common transactions\n    transactions = A.transactions & B.transactions\n    \n    # check the Itemset has enough support\n    # this replaces pruning where we would have had to\n    # check each proper subset of both A and B\n    # we can do this either by carrying the transactions\n    # or creating a dictionary but I chose this way\n    # because from Big Data Management this would count\n    if not len(transactions) >= SUPPORT_THRESHOLD: return None\n    \n    items = A.items | B.items\n    \n    # sort the items so that they can be hashed\n    values = list(items)\n    values.sort()\n    \n    return Itemset(items = items, transactions = transactions, hv = \"\".join(values), support=len(transactions) )",
                "true_label": "",
                "top5_preds": [
                    "join two dataframes along rows",
                    "join two dataframes along columns",
                    "returns a new list with unique elements of the first list",
                    "most common words",
                    "combine two dataframes into one"
                ]
            }
        ],
        [
            {
                "code": "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore')\n%matplotlib inline",
                "true_label": "",
                "top5_preds": [
                    "matplotlib",
                    "plot using matplotlib",
                    "line plot with a dataframe",
                    "equally spaced numbers on a grid",
                    "calculating the mean of a vector with nans"
                ]
            },
            {
                "code": "mov = pd.read_csv('https://raw.githubusercontent.com/peterkoebel/Project-Movie-Sales/master/Movie-Sales.csv', encoding = 'latin1')",
                "true_label": "",
                "top5_preds": [
                    "convert text data into vector",
                    "importing data with numpy",
                    "convert data from string to float",
                    "loading a csv into a dataframe",
                    "importing data with pandas"
                ]
            },
            {
                "code": "mov.head()",
                "true_label": "",
                "top5_preds": [
                    "convert text data into vector",
                    "calculating the mean of a vector with nans",
                    "scipy",
                    "import polynomial features from sklearn",
                    "line plots show the trend of a numerical variable over time"
                ]
            },
            {
                "code": "mov.describe()",
                "true_label": "",
                "top5_preds": [
                    "calculating the mean of a vector with nans",
                    "line plots show the trend of a numerical variable over time",
                    "line plot with a dataframe",
                    "import polynomial features from sklearn",
                    "equally spaced numbers on a grid"
                ]
            },
            {
                "code": "mov.info()",
                "true_label": "",
                "top5_preds": [
                    "equally spaced numbers on a grid",
                    "create an array of linearly spaced points",
                    "calculating the mean of a vector with nans",
                    "convert text data into vector",
                    "add edges in graph"
                ]
            },
            {
                "code": "mov.Studio.unique()",
                "true_label": "",
                "top5_preds": [
                    "calculating the mean of a vector with nans",
                    "find maximum and the minimum value in a set",
                    "convert text data into vector",
                    "import polynomial features from sklearn",
                    "implementing bag of words in scikit learn"
                ]
            },
            {
                "code": "mov.Genre.unique()",
                "true_label": "",
                "top5_preds": [
                    "calculating the mean of a vector with nans",
                    "import polynomial features from sklearn",
                    "find data type of each column",
                    "find maximum and the minimum value in a set",
                    "importing data with numpy"
                ]
            },
            {
                "code": "mov2 = mov[(mov.Genre == 'action') | (mov.Genre == 'adventure') | (mov.Genre == 'animation') | (mov.Genre == 'comedy') | (mov.Genre == 'drama')]",
                "true_label": "",
                "top5_preds": [
                    "calculating the mean of a vector with nans",
                    "scipy",
                    "numpy",
                    "import polynomial features from sklearn",
                    "what is scikit learn?"
                ]
            },
            {
                "code": "mov3 = mov2[(mov2.Studio == 'Buena Vista Studios') | (mov2.Studio == 'Fox') | (mov2.Studio == 'Paramount Pictures') | (mov2.Studio == 'Sony') | (mov2.Studio == 'Universal') | (mov2.Studio == 'WB')]",
                "true_label": "",
                "top5_preds": [
                    "calculating the mean of a vector with nans",
                    "find maximum and the minimum value in a set",
                    "vectorize words in movie reviews",
                    "linear regression of many variables",
                    "import polynomial features from sklearn"
                ]
            },
            {
                "code": "print (mov3.Genre.unique())\nprint (mov3.Studio.unique())\nprint (len(mov3))",
                "true_label": "",
                "top5_preds": [
                    "remove duplicates from a list",
                    "import polynomial features from sklearn",
                    "how many different items appear in the dataset?",
                    "find data type of each column",
                    "calculating the mean of a vector with nans"
                ]
            }
        ],
        [
            {
                "code": "import os\nimport cv2\nimport numpy as np\nimport collections\nimport pandas as pd\nfrom extract_features import *\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nfrom sklearn.svm import LinearSVC\nfrom sklearn.utils import shuffle\nfrom sklearn import svm, grid_search\nfrom sklearn.externals import joblib\nfrom moviepy.editor import VideoFileClip\nfrom scipy.ndimage.measurements import label\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.cross_validation import train_test_split\n\n%matplotlib inline\n%load_ext autoreload\n# %reload_ext autoreload\n%autoreload 2",
                "true_label": "",
                "top5_preds": [
                    "import polynomial features from sklearn",
                    "polynomial regression with sklearn",
                    "what is scikit learn?",
                    "use sklearn kfold",
                    "ridge regression with polynomial features on a grid"
                ]
            },
            {
                "code": "def extract_features(imgs, cspace='RGB', orient=9, \n                        pix_per_cell=8, cell_per_block=2, hog_channel=0):\n    # Create a list to append feature vectors to\n    features = []\n    # Iterate through the list of images\n    for file in imgs:\n        # Read in each one by one\n        image = mpimg.imread(file)\n        # apply color conversion if other than 'RGB'\n        if cspace != 'RGB':\n            if cspace == 'HSV':\n                feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n            elif cspace == 'LUV':\n                feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2LUV)\n            elif cspace == 'HLS':\n                feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2HLS)\n            elif cspace == 'YUV':\n                feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2YUV)\n            elif cspace == 'YCrCb':\n                feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2YCrCb)\n        else: feature_image = np.copy(image)      \n\n        # Call get_hog_features() with vis=False, feature_vec=True\n        if hog_channel == 'ALL':\n            hog_features = []\n            for channel in range(feature_image.shape[2]):\n                hog_features.append(get_hog_features(feature_image[:,:,channel], \n                                    orient, pix_per_cell, cell_per_block, \n                                    vis=False, feature_vec=True))\n            hog_features = np.ravel(hog_features)        \n        else:\n            hog_features = get_hog_features(feature_image[:,:,hog_channel], orient, \n                        pix_per_cell, cell_per_block, vis=False, feature_vec=True)\n        # Append the new feature vector to the features list\n        features.append(hog_features)\n    # Return list of feature vectors\n    return features",
                "true_label": "",
                "top5_preds": [
                    "transform categorical data into binary features",
                    "separate features and labels",
                    "calculate and store features in database",
                    "read images point",
                    "import polynomial features from sklearn"
                ]
            },
            {
                "code": "car_list = glob.glob('datasets/vehicles/**/*.png')\nncar_list = glob.glob('datasets/non-vehicles/**/*.png')\nprint(len(car_list), len(ncar_list))",
                "true_label": "",
                "top5_preds": [
                    "sum all the numbers in a list",
                    "read numbers until and print their mean and standard deviation without using a list",
                    "line plot with a dataframe",
                    "convert list to numpy array",
                    "equally spaced numbers on a grid"
                ]
            },
            {
                "code": "colorspace = 'YUV' # Can be RGB, HSV, LUV, HLS, YUV, YCrCb\norient = 11\npix_per_cell = 16\ncell_per_block = 2\nhog_channel = 'ALL' # Can be 0, 1, 2, or \"ALL\"\n\ncar_features = extract_features(car_list, cspace=colorspace, orient=orient, \n                        pix_per_cell=pix_per_cell, cell_per_block=cell_per_block, \n                        hog_channel=hog_channel)\nnotcar_features = extract_features(ncar_list, cspace=colorspace, orient=orient, \n                        pix_per_cell=pix_per_cell, cell_per_block=cell_per_block, \n                        hog_channel=hog_channel)\n\nX = np.vstack((car_features, notcar_features)).astype(np.float64) \n\ny = np.hstack((np.ones(len(car_features)), np.zeros(len(notcar_features))))\n\n# Split to train and test sets\nrand_state = np.random.randint(0, 100)\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=rand_state)",
                "true_label": "",
                "top5_preds": [
                    "import polynomial features from sklearn",
                    "equally spaced numbers on a grid",
                    "scikit image panorama",
                    "using principal component analysis to plot in two dimensions",
                    "ridge regression with polynomial features on a grid"
                ]
            },
            {
                "code": "parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]}\nsvr = svm.SVC()\nclf = grid_search.GridSearchCV(svr, parameters)\nclf.fit(X_train, y_train)\n\nprint(\"The best choice of parameter: {}\".format(clf.best_params_))",
                "true_label": "",
                "top5_preds": [
                    "one class svm fitting and estimates",
                    "polynomial regression with sklearn",
                    "predicting a continuous response using linear regression",
                    "ridge regression with polynomial features on a grid",
                    "using logistic regression instead"
                ]
            }
        ],
        [
            {
                "code": "# import libraries\n\nimport pandas as pd\nimport numpy as np\nfrom matplotlib import pyplot as plt\n%matplotlib inline\nfrom scipy import stats",
                "true_label": "",
                "top5_preds": [
                    "timing, numpy, plotting",
                    "pandas plotting",
                    "plot using matplotlib",
                    "line plot with a dataframe",
                    "line plots show the trend of a numerical variable over time"
                ]
            },
            {
                "code": "# read data file \n\nMortgageListings = pd.read_csv(\"MortgageListings_Redfin_05312017.csv\")\nMortgageListings.head()",
                "true_label": "",
                "top5_preds": [
                    "loading a csv into a dataframe",
                    "importing data with pandas",
                    "importing data with numpy",
                    "load table in pandas",
                    "convert text data into vector"
                ]
            },
            {
                "code": "MortgageListings.columns",
                "true_label": "",
                "top5_preds": [
                    "load table in pandas",
                    "find data type of each column",
                    "import polynomial features from sklearn",
                    "loading a csv into a dataframe",
                    "change type of column"
                ]
            },
            {
                "code": "MortgageListings.dtypes",
                "true_label": "",
                "top5_preds": [
                    "calculating the mean of a vector with nans",
                    "import polynomial features from sklearn",
                    "convert text data into vector",
                    "find data type of each column",
                    "importing data with numpy"
                ]
            },
            {
                "code": "print(MortgageListings.isnull().any())",
                "true_label": "",
                "top5_preds": [
                    "check a list is empty or not",
                    "calculating the mean of a vector with nans",
                    "load table in pandas",
                    "find data type of each column",
                    "import polynomial features from sklearn"
                ]
            },
            {
                "code": "merged3_MortgageListings = pd.merge(merged2_MortgageListings, OccupancyStatus, how='left',\n        left_on='ZIP', right_on='Id2')",
                "true_label": "",
                "top5_preds": [
                    "join two dataframes along rows",
                    "join two dataframes along columns",
                    "create a dataframe by joining series by column",
                    "combine two dataframes into one",
                    "importing data with pandas"
                ]
            },
            {
                "code": "merged3_MortgageListings['% Vacant'].astype(np.float)",
                "true_label": "",
                "top5_preds": [
                    "convert data from string to float",
                    "create a one column dataframe with the values of a series",
                    "line plot with a dataframe",
                    "line plots show the trend of a numerical variable over time",
                    "using pandas"
                ]
            },
            {
                "code": "MeanIncome = pd.read_csv(\"MeanIncome_AFASC_2011_2015.csv\")\nMeanIncome.head()",
                "true_label": "",
                "top5_preds": [
                    "loading a csv into a dataframe",
                    "importing data with pandas",
                    "load table in pandas",
                    "importing data with numpy",
                    "working with pandas series indexed by datetime"
                ]
            },
            {
                "code": "merged4_MortgageListings = pd.merge(merged3_MortgageListings, MeanIncome, how='left',\n        left_on='ZIP', right_on='Id2')",
                "true_label": "",
                "top5_preds": [
                    "join two dataframes along rows",
                    "join two dataframes along columns",
                    "combine two dataframes into one",
                    "create a dataframe by joining series by column",
                    "create a one column dataframe with the values of a series"
                ]
            },
            {
                "code": "sns.jointplot(x=\"% Bachelors\", y=\"PRICE\", data=merged4_MortgageListings, kind = 'reg', size = 7)\nplt.show()",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "plotting time series with pandas",
                    "predicting a categorical response",
                    "using a dataframe and matplotlib commands",
                    "plot using pandas plotting"
                ]
            },
            {
                "code": "sns.jointplot(x=\"Unemployment Rate\", y=\"PRICE\", data=merged4_MortgageListings, kind = 'reg', size = 7)\nplt.show()",
                "true_label": "",
                "top5_preds": [
                    "plotting time series with pandas",
                    "line plot with a dataframe",
                    "using a dataframe and matplotlib commands",
                    "plot using pandas plotting",
                    "predicting a categorical response"
                ]
            },
            {
                "code": "sns.jointplot(x=\"Mean Travel Time\", y=\"PRICE\", data=merged4_MortgageListings, kind = 'reg', size = 7)\nplt.show()",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "plotting time series with pandas",
                    "using a dataframe and matplotlib commands",
                    "plot using pandas plotting",
                    "pandas plotting"
                ]
            },
            {
                "code": "MortgageListings.describe()",
                "true_label": "",
                "top5_preds": [
                    "predicting a categorical response",
                    "importing data with pandas",
                    "formatting datetimes as strings",
                    "find maximum and the minimum value in a set",
                    "importing data with numpy"
                ]
            },
            {
                "code": "print(MortgageListings.isnull().sum())",
                "true_label": "",
                "top5_preds": [
                    "load table in pandas",
                    "calculating the mean of a vector with nans",
                    "find data type of each column",
                    "sum all the numbers in a list",
                    "check a list is empty or not"
                ]
            },
            {
                "code": "MortgageListings.dropna(inplace=True, subset=['SQUARE FEET','YEAR BUILT','BATHS'])\nMortgageListings",
                "true_label": "",
                "top5_preds": [
                    "importing data with pandas",
                    "using pandas",
                    "create a one column dataframe with the values of a series",
                    "importing data with numpy",
                    "load table in pandas"
                ]
            },
            {
                "code": "MortgageListings['BATHS'].astype(np.int64)",
                "true_label": "",
                "top5_preds": [
                    "convert data from string to float",
                    "convert text data into vector",
                    "importing data with numpy",
                    "integrating datetime tools with pandas for time series",
                    "working with pandas series indexed by datetime"
                ]
            },
            {
                "code": "EducationalAttainment['% Bachelors'].astype(np.float)",
                "true_label": "",
                "top5_preds": [
                    "convert data from string to float",
                    "convert integer or float data",
                    "find data type of each column",
                    "convert text data into vector",
                    "convert categorical variables"
                ]
            },
            {
                "code": "merged_MortgageListings = pd.merge(MortgageListings, EducationalAttainment, how='left',\n        left_on='ZIP', right_on='Id2')\n\nmerged_MortgageListings.head()",
                "true_label": "",
                "top5_preds": [
                    "create a dataframe by joining series by column",
                    "join two dataframes along rows",
                    "importing data with pandas",
                    "create a one column dataframe with the values of a series",
                    "join two dataframes along columns"
                ]
            },
            {
                "code": "EconomicIndicators = pd.read_csv(\"EconomicIndicators_AFASC_2011_2015.csv\")\nEconomicIndicators.head()",
                "true_label": "",
                "top5_preds": [
                    "loading a csv into a dataframe",
                    "importing data with pandas",
                    "working with pandas series indexed by datetime",
                    "load table in pandas",
                    "convert date to datetime format"
                ]
            },
            {
                "code": "merged2_MortgageListings = pd.merge(merged_MortgageListings, EconomicIndicators, how='left',\n        left_on='ZIP', right_on='Id2')",
                "true_label": "",
                "top5_preds": [
                    "join two dataframes along rows",
                    "join two dataframes along columns",
                    "combine two dataframes into one",
                    "create a dataframe by joining series by column",
                    "create a one column dataframe with the values of a series"
                ]
            },
            {
                "code": "merged2_MortgageListings['Unemployment Rate'].astype(np.float)",
                "true_label": "",
                "top5_preds": [
                    "using pandas",
                    "create a one column dataframe with the values of a series",
                    "working with pandas series indexed by datetime",
                    "importing data with pandas",
                    "line plot with a dataframe"
                ]
            },
            {
                "code": "OccupancyStatus = pd.read_csv(\"OccupancyStatus_AFACS_2011_2015.csv\")\nOccupancyStatus.head()",
                "true_label": "",
                "top5_preds": [
                    "loading a csv into a dataframe",
                    "importing data with pandas",
                    "load table in pandas",
                    "pandas regex",
                    "working with pandas series indexed by datetime"
                ]
            },
            {
                "code": "sns.jointplot(x=\"% Vacant\", y=\"PRICE\", data=merged4_MortgageListings, kind = 'reg', size = 7)\nplt.show()",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "plotting time series with pandas",
                    "using a dataframe and matplotlib commands",
                    "predicting a categorical response",
                    "plot using pandas plotting"
                ]
            },
            {
                "code": "import matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nfrom scipy.stats import norm\nfrom sklearn.preprocessing import StandardScaler\nfrom scipy import stats\nimport warnings\nwarnings.filterwarnings('ignore')\n%matplotlib inline",
                "true_label": "",
                "top5_preds": [
                    "fit a polynomial",
                    "scipy",
                    "polynomial regression with sklearn",
                    "scikit learn",
                    "import polynomial features from sklearn"
                ]
            },
            {
                "code": "# histogram\nsns.distplot(MortgageListings['PRICE'], kde = False, color = 'b', hist_kws={'alpha': 0.5})",
                "true_label": "",
                "top5_preds": [
                    "visualize the distribution histogram of x using sns distplot",
                    "line plot with a dataframe",
                    "distribution plot",
                    "pandas plotting",
                    "pandas plotting documentation"
                ]
            },
            {
                "code": "## Density plot\nsns.kdeplot(MortgageListings['PRICE'], shade=True);",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "line plots show the trend of a numerical variable over time",
                    "plot using pandas plotting",
                    "pandas plotting",
                    "predicting a categorical response"
                ]
            },
            {
                "code": "sns.jointplot(x=\"SQUARE FEET\", y=\"PRICE\", data=MortgageListings, kind = 'reg', size = 7)\nplt.show()",
                "true_label": "",
                "top5_preds": [
                    "plotting time series with pandas",
                    "using a dataframe and matplotlib commands",
                    "line plot with a dataframe",
                    "plot using pandas plotting",
                    "pandas plotting"
                ]
            },
            {
                "code": "sns.jointplot(x=\"BEDS\", y=\"PRICE\", data=MortgageListings, kind = 'reg', size = 7)\nplt.show()",
                "true_label": "",
                "top5_preds": [
                    "plotting time series with pandas",
                    "line plot with a dataframe",
                    "plot using pandas plotting",
                    "using a dataframe and matplotlib commands",
                    "pandas plotting"
                ]
            },
            {
                "code": "sns.jointplot(x=\"BATHS\", y=\"PRICE\", data=MortgageListings, kind = 'reg', size = 7)\nplt.show()",
                "true_label": "",
                "top5_preds": [
                    "plotting time series with pandas",
                    "line plot with a dataframe",
                    "plot using pandas plotting",
                    "using a dataframe and matplotlib commands",
                    "pandas plotting"
                ]
            },
            {
                "code": "sns.jointplot(x=\"YEAR BUILT\", y=\"PRICE\", data=MortgageListings, kind = 'reg', size = 7)\nplt.show()",
                "true_label": "",
                "top5_preds": [
                    "plotting time series with pandas",
                    "line plot with a dataframe",
                    "using a dataframe and matplotlib commands",
                    "plot using pandas plotting",
                    "pandas plotting"
                ]
            },
            {
                "code": "corrmat = MortgageListings.corr()\nf, ax = plt.subplots(figsize=(8, 5))\nsns.heatmap(corrmat, vmax=.8, square=True);",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "create a scatter plot",
                    "heatmap with time",
                    "predicting a categorical response",
                    "pandas plotting"
                ]
            },
            {
                "code": "#saleprice correlation matrix\nk = 15 #number of variables for heatmap\ncols = corrmat.nlargest(k, 'PRICE')['PRICE'].index\ncm = np.corrcoef(MortgageListings[cols].values.T)\nsns.set(font_scale=1.25)\nhm = sns.heatmap(cm, cbar=True, annot=True, square=True, fmt='.2f', annot_kws={'size': 10}, yticklabels=cols.values, xticklabels=cols.values)\nplt.show()",
                "true_label": "",
                "top5_preds": [
                    "predicting a categorical response",
                    "heatmap",
                    "heatmap with time",
                    "line plot with a dataframe",
                    "using a dataframe and matplotlib commands"
                ]
            },
            {
                "code": "#box plot bedrooms/saleprice\nvar = 'BEDS'\ndata = pd.concat([MortgageListings['PRICE'], MortgageListings[var]], axis=1)\nf, ax = plt.subplots(figsize=(8, 12))\nfig = sns.boxplot(x=var, y=\"PRICE\", data=data)\nfig.axis(ymin=0, ymax=40000000);",
                "true_label": "",
                "top5_preds": [
                    "ploting out data with box plots",
                    "using a dataframe and matplotlib commands",
                    "plot using pandas plotting",
                    "line plot with a dataframe",
                    "box plot"
                ]
            },
            {
                "code": "#box plot yearbuilt/saleprice\nvar = 'YEAR BUILT'\ndata = pd.concat([MortgageListings['PRICE'], MortgageListings[var]], axis=1)\nf, ax = plt.subplots(figsize=(24, 18))\nfig = sns.boxplot(x=var, y=\"PRICE\", data=data)\nfig.axis(ymin=0, ymax=40000000);",
                "true_label": "",
                "top5_preds": [
                    "ploting out data with box plots",
                    "using a dataframe and matplotlib commands",
                    "plot using pandas plotting",
                    "line plot with a dataframe",
                    "create box plots"
                ]
            },
            {
                "code": "sns.jointplot(x=\"Mean Income\", y=\"PRICE\", data=merged4_MortgageListings, kind = 'reg', size = 7)\nplt.show()",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "plotting time series with pandas",
                    "using a dataframe and matplotlib commands",
                    "predicting a categorical response",
                    "ploting out data with box plots"
                ]
            },
            {
                "code": "merged4_MortgageListings.dropna(inplace=True, subset=['SQUARE FEET', 'BATHS', 'BEDS', 'YEAR BUILT', 'LATITUDE', 'LONGITUDE',\n                    '% Bachelors', 'Unemployment Rate', 'Mean Income', '% Vacant'])\nprint(merged4_MortgageListings.isnull().sum())",
                "true_label": "",
                "top5_preds": [
                    "create a one column dataframe with the values of a series",
                    "create a dataframe by joining series by column",
                    "create dataframe with given values",
                    "join two dataframes along rows",
                    "dataframe methods"
                ]
            },
            {
                "code": "from sklearn.linear_model import LinearRegression\nfrom sklearn.cross_validation import train_test_split\nfrom sklearn.metrics import mean_squared_error\n\nfeature_col1 = ['SQUARE FEET', 'BATHS', 'BEDS', 'YEAR BUILT', 'LATITUDE', 'LONGITUDE', '% Bachelors'\n                       , 'Unemployment Rate', '% Vacant', 'Mean Income']\n\nX = merged4_MortgageListings\ny = merged4_MortgageListings['PRICE']\n\nX_train, X_test, y_train, y_test = train_test_split(X[feature_col1], y, test_size=0.2)\n\nmodel = LinearRegression()\n\nmodel.fit(X_train, y_train)\n\ny_pred = model.predict(X_test)\nprint(np.sqrt(metrics.mean_squared_error(y_test, y_pred)))",
                "true_label": "",
                "top5_preds": [
                    "what is scikit learn?",
                    "import polynomial features from sklearn",
                    "use sklearn kfold",
                    "scikit learn",
                    "predicting on sample validation data"
                ]
            },
            {
                "code": "from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.cross_validation import train_test_split\nfrom sklearn.metrics import mean_squared_error\n\nfeature_col1 = ['SQUARE FEET', 'BATHS', 'BEDS', 'YEAR BUILT', 'LATITUDE', 'LONGITUDE', '% Bachelors'\n                       , 'Unemployment Rate', '% Vacant', 'Mean Income']\n\nX = merged4_MortgageListings\ny = merged4_MortgageListings['PRICE']\n\nX_train, X_test, y_train, y_test = train_test_split(X[feature_col1], y, test_size=0.2)\n\nmodel_R = RandomForestRegressor(n_estimators=100, min_samples_leaf=10, random_state=1)\nmodel_R.fit(X_train, y_train)\n\npredictions = model_R.predict(X_test)\nprint(np.sqrt(metrics.mean_squared_error(y_test, y_pred)))",
                "true_label": "",
                "top5_preds": [
                    "what is scikit learn?",
                    "import polynomial features from sklearn",
                    "use sklearn kfold",
                    "scikit learn",
                    "implementing bag of words in scikit learn"
                ]
            },
            {
                "code": "sns.jointplot(x=\"YEAR BUILT\", y=\"PRICE\", data=MortgageListings, kind = 'reg', size = 7)\nplt.show()",
                "true_label": "",
                "top5_preds": [
                    "plotting time series with pandas",
                    "line plot with a dataframe",
                    "using a dataframe and matplotlib commands",
                    "plot using pandas plotting",
                    "pandas plotting"
                ]
            }
        ],
        [
            {
                "code": "df1.groupby('YEAR')['TOTAL_PAYMENT'].sum().plot()",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "plotting time series with pandas",
                    "pandas plotting",
                    "plot using pandas plotting",
                    "line plots show the trend of a numerical variable over time"
                ]
            },
            {
                "code": "df['AGREEMENT_REQUIRED_NEW_POSITIONS']",
                "true_label": "",
                "top5_preds": [
                    "working with pandas series indexed by datetime",
                    "create a one column dataframe with the values of a series",
                    "create a dataframe by joining series by column",
                    "find maximum and the minimum value in a set",
                    "using getint and ispositive rewrite get_pos_integer"
                ]
            },
            {
                "code": "df[df['AGREEMENT_REQUIRED_NEW_POSITIONS'].notnull()].shape\n#261 times",
                "true_label": "",
                "top5_preds": [
                    "selecting specific columns in a dataframe",
                    "delete column by name",
                    "find data type of each column",
                    "create dataframe with given values",
                    "create a one column dataframe with the values of a series"
                ]
            },
            {
                "code": "df['AGREEMENT_REQUIRED_NEW_POSITIONS'].value_counts().head(5)",
                "true_label": "",
                "top5_preds": [
                    "create a one column dataframe with the values of a series",
                    "create a dataframe by joining series by column",
                    "working with pandas series indexed by datetime",
                    "pandas apply",
                    "predicting a categorical response"
                ]
            },
            {
                "code": "import numpy as np\ndf.loc[df.AGREEMENT_REQUIRED_NEW_POSITIONS.isnull(), 'required_new_position'] = np.nan\ndf.loc[df.AGREEMENT_REQUIRED_NEW_POSITIONS.str.contains(\"^Yes\") & df.AGREEMENT_REQUIRED_NEW_POSITIONS.notnull(), 'required_new_position'] = True\ndf.loc[df.AGREEMENT_REQUIRED_NEW_POSITIONS.str.contains(\"^No\") & df.AGREEMENT_REQUIRED_NEW_POSITIONS.notnull(), 'required_new_position'] = False",
                "true_label": "",
                "top5_preds": [
                    "create dataframe with given values",
                    "line plot with a dataframe",
                    "convert integer or float data",
                    "pandas apply",
                    "using a dataframe and matplotlib commands"
                ]
            },
            {
                "code": "df['required_new_position'].value_counts()",
                "true_label": "",
                "top5_preds": [
                    "create a one column dataframe with the values of a series",
                    "line plot with a dataframe",
                    "find maximum and the minimum value in a set",
                    "find data type of each column",
                    "in pandas"
                ]
            },
            {
                "code": "df.loc[df.AGREEMENT_REQUIRED_NEW_POSITIONS.str.contains(\"^Yes\") & df.AGREEMENT_REQUIRED_NEW_POSITIONS.notnull(), 'new_position'] = df['AGREEMENT_REQUIRED_NEW_POSITIONS'].astype(str).str.extract('(^Yes.)(.+)')[1]",
                "true_label": "",
                "top5_preds": [
                    "pandas regex",
                    "convert integer or float data",
                    "pandas apply",
                    "convert data from string to float",
                    "using a dataframe and matplotlib commands"
                ]
            },
            {
                "code": "df[df.new_position == \" Compliance Officer\"]",
                "true_label": "",
                "top5_preds": [
                    "create a one column dataframe with the values of a series",
                    "create dataframe with given values",
                    "line plot with a dataframe",
                    "select every row after a specific row",
                    "create a dataframe by joining series by column"
                ]
            },
            {
                "code": "df[df['new_position'].notnull() & df['new_position'].str.contains(\"Compliance\")]",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "concordance: words that co-occur with a word of interest",
                    "find data type of each column",
                    "formatting datetimes as strings",
                    "find all by term in field in case insensitive way"
                ]
            },
            {
                "code": "import pandas as pd \n\ndf = pd.read_csv(\"cpr-data.csv\")\ndf.head()",
                "true_label": "",
                "top5_preds": [
                    "loading a csv into a dataframe",
                    "importing data with pandas",
                    "load table in pandas",
                    "read text file point",
                    "pandas regex"
                ]
            },
            {
                "code": "df.shape",
                "true_label": "",
                "top5_preds": [
                    "find data type of each column",
                    "dataframe methods",
                    "line plot with a dataframe",
                    "what is the type of the columns?",
                    "selecting specific columns in a dataframe"
                ]
            },
            {
                "code": "df.dtypes",
                "true_label": "",
                "top5_preds": [
                    "find data type of each column",
                    "convert date to datetime format",
                    "load table in pandas",
                    "convert categorical variables",
                    "what is the type of the columns?"
                ]
            },
            {
                "code": "pd.set_option('display.max_columns', 65)",
                "true_label": "",
                "top5_preds": [
                    "load table in pandas",
                    "line plot with a dataframe",
                    "displaying the data",
                    "formatting datetimes as strings",
                    "find maximum and the minimum value in a set"
                ]
            },
            {
                "code": "pd.set_option('display.max_rows', 100)",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "load table in pandas",
                    "find maximum and the minimum value in a set",
                    "formatting datetimes as strings",
                    "pandas plotting"
                ]
            },
            {
                "code": "pd.options.display.float_format = '{:,.2f}'.format\ndf['TOTAL_PAYMENT'].describe()",
                "true_label": "",
                "top5_preds": [
                    "convert date to datetime format",
                    "convert data from string to float",
                    "pandas plotting",
                    "formatting datetimes as strings",
                    "plotting time series with pandas"
                ]
            },
            {
                "code": "df['TOTAL_PAYMENT'].describe()",
                "true_label": "",
                "top5_preds": [
                    "formatting datetimes as strings",
                    "convert date to datetime format",
                    "create a one column dataframe with the values of a series",
                    "working with pandas series indexed by datetime",
                    "plotting time series with pandas"
                ]
            },
            {
                "code": "df1.groupby('YEAR')['TOTAL_PAYMENT'].sum()",
                "true_label": "",
                "top5_preds": [
                    "create a dataframe by joining series by column",
                    "load table in pandas",
                    "join two dataframes along rows",
                    "create a one column dataframe with the values of a series",
                    "line plot with a dataframe"
                ]
            },
            {
                "code": "df[df['new_position'].notnull() & df['new_position'].str.contains(\"Compliance\")]['PRIMARY_CRIME_CODE'].value_counts()",
                "true_label": "",
                "top5_preds": [
                    "find data type of each column",
                    "line plot with a dataframe",
                    "concordance: words that co-occur with a word of interest",
                    "create a one column dataframe with the values of a series",
                    "create a dataframe by joining series by column"
                ]
            },
            {
                "code": "df['FORFEITURE_DISGORGEMENT'].head(2)",
                "true_label": "",
                "top5_preds": [
                    "load table in pandas",
                    "dataframe methods",
                    "line plot with a dataframe",
                    "using a dataframe and matplotlib commands",
                    "what is scikit learn?"
                ]
            },
            {
                "code": "df['FINE'].head(2)",
                "true_label": "",
                "top5_preds": [
                    "line plot with a dataframe",
                    "create a one column dataframe with the values of a series",
                    "find maximum and the minimum value in a set",
                    "load table in pandas",
                    "create dataframe with given values"
                ]
            },
            {
                "code": "df['DISPOSITION_TYPE'].value_counts()",
                "true_label": "",
                "top5_preds": [
                    "find data type of each column",
                    "create a one column dataframe with the values of a series",
                    "convert text data into vector",
                    "convert categorical variables",
                    "create a dataframe by joining series by column"
                ]
            },
            {
                "code": "import matplotlib.pyplot as plt\n%matplotlib inline\ndf['DISPOSITION_TYPE'].value_counts(ascending = True).plot(kind = 'barh',)",
                "true_label": "",
                "top5_preds": [
                    "pandas plotting",
                    "plot histogram",
                    "plot using pandas plotting",
                    "pandas plotting documentation",
                    "line plot with a dataframe"
                ]
            },
            {
                "code": "df['TOTAL_PAYMENT'].value_counts().head(15).plot(kind = 'barh')",
                "true_label": "",
                "top5_preds": [
                    "line plots show the trend of a numerical variable over time",
                    "plotting time series with pandas",
                    "pandas plotting",
                    "plot using pandas plotting",
                    "line plot with a dataframe"
                ]
            },
            {
                "code": "df['TOTAL_PAYMENT'].value_counts(ascending = False)",
                "true_label": "",
                "top5_preds": [
                    "predicting a categorical response",
                    "sorting data",
                    "create a one column dataframe with the values of a series",
                    "create a dataframe by joining series by column",
                    "transform year column"
                ]
            },
            {
                "code": "df1 = df[['COMPANY','DISPOSITION_TYPE','TOTAL_PAYMENT','DATE']]",
                "true_label": "",
                "top5_preds": [
                    "join two dataframes along rows",
                    "convert date to datetime format",
                    "load table in pandas",
                    "line plot with a dataframe",
                    "join two dataframes along columns"
                ]
            },
            {
                "code": "df1.shape",
                "true_label": "",
                "top5_preds": [
                    "find data type of each column",
                    "dataframe methods",
                    "create a one column dataframe with the values of a series",
                    "selecting specific columns in a dataframe",
                    "create a dataframe by joining series by column"
                ]
            },
            {
                "code": "df1['YEAR'] = df1['DATE'].astype(str).str.extract('(\\d{4})(.)(\\d{2})(.)(\\d{2})')[0]\ndf1.head()",
                "true_label": "",
                "top5_preds": [
                    "convert date to datetime format",
                    "pandas regex",
                    "loading a csv into a dataframe",
                    "transform the date column as a datetime type",
                    "working with pandas series indexed by datetime"
                ]
            },
            {
                "code": "df1['YEAR'].astype(float)",
                "true_label": "",
                "top5_preds": [
                    "convert date to datetime format",
                    "working with pandas series indexed by datetime",
                    "convert data from string to float",
                    "transform year column",
                    "create a one column dataframe with the values of a series"
                ]
            },
            {
                "code": "df1['YEAR'].astype(float).hist()",
                "true_label": "",
                "top5_preds": [
                    "plotting time series with pandas",
                    "line plots show the trend of a numerical variable over time",
                    "convert date to datetime format",
                    "integrating datetime tools with pandas for time series",
                    "create a one column dataframe with the values of a series"
                ]
            },
            {
                "code": "df1['YEAR'].astype(float)",
                "true_label": "",
                "top5_preds": [
                    "convert date to datetime format",
                    "working with pandas series indexed by datetime",
                    "convert data from string to float",
                    "transform year column",
                    "create a one column dataframe with the values of a series"
                ]
            }
        ],
        [
            {
                "code": "import warnings; warnings.filterwarnings('ignore')\nimport numpy as np\nimport oxyba as ox\nfrom importlib import reload; reload(ox);\nfrom time import perf_counter, process_time\nimport pandas as pd",
                "true_label": "",
                "top5_preds": [
                    "timing, numpy, plotting",
                    "line plots show the trend of a numerical variable over time",
                    "polynomial regression with sklearn",
                    "importing data with numpy",
                    "likelihood of the binomial distribution"
                ]
            },
            {
                "code": "N = 1000000\nnp.random.seed(23)\ndata = np.random.normal(loc=[0.0, 0.0], scale=[1.0, 1.0], size=(N,2))",
                "true_label": "",
                "top5_preds": [
                    "use numpy to generate an array of random numbers sampled from a standard normal distribution",
                    "create an array of linearly spaced points",
                    "optimal value of k for dataset",
                    "predicting a categorical response",
                    "random variates"
                ]
            },
            {
                "code": "data = ox.rand_bivar(data, .5)",
                "true_label": "",
                "top5_preds": [
                    "ridge regression with one predictor on a grid",
                    "use numpy to generate a random number",
                    "numpy point",
                    "ridge regression with polynomial features on a grid",
                    "integrating datetime tools with pandas for time series"
                ]
            },
            {
                "code": "rho,_ = ox.corr(data)\nrho = rho[0][1]\nprint(\"Beta1 coefficient is expected to be: \", rho)",
                "true_label": "",
                "top5_preds": [
                    "numpy",
                    "principal component analysis with random data",
                    "correlation matrix",
                    "co variance matrix",
                    "correlation analysis"
                ]
            },
            {
                "code": "y = data[:,0]\nX = np.c_[np.ones((len(y),1)), data[:,1]]",
                "true_label": "",
                "top5_preds": [
                    "numpy",
                    "scipy",
                    "ridge regression with polynomial features on a grid",
                    "create an array of linearly spaced points",
                    "numpy point"
                ]
            },
            {
                "code": "print(ox.linreg_ridge_gd(y,X, 5.0))",
                "true_label": "",
                "top5_preds": [
                    "ridge regression with one predictor on a grid",
                    "ridge regression with polynomial features on a grid",
                    "linear regression of many variables",
                    "polynomial regression with sklearn",
                    "using logistic regression instead"
                ]
            },
            {
                "code": "for a in ('CG', 'BFGS', 'Newton-CG', 'L-BFGS-B', 'TNC', 'SLSQP'):\n    beta = ox.linreg_ridge_gd(y,X, 5.0, algorithm=a)\n    print(beta, a)",
                "true_label": "",
                "top5_preds": [
                    "ridge regression with one predictor on a grid",
                    "ridge regression with polynomial features on a grid",
                    "linear regression of many variables",
                    "fit a polynomial",
                    "form of linear regression"
                ]
            },
            {
                "code": "print(ox.linreg_ridge_lu(y,X, 5.0))",
                "true_label": "",
                "top5_preds": [
                    "ridge regression with one predictor on a grid",
                    "ridge regression with polynomial features on a grid",
                    "linear regression of many variables",
                    "polynomial regression with sklearn",
                    "fit a polynomial"
                ]
            },
            {
                "code": "print(ox.linreg_ols_lu(y,X))",
                "true_label": "",
                "top5_preds": [
                    "ridge regression with polynomial features on a grid",
                    "ridge regression with one predictor on a grid",
                    "linear regression of many variables",
                    "polynomial regression with sklearn",
                    "linear regression with statsmodels and scikit learn"
                ]
            },
            {
                "code": "trials = 100\nbench = list()\nfor a in ('CG', 'BFGS', 'Newton-CG', 'L-BFGS-B', 'TNC', 'SLSQP'):\n    sh,sc = perf_counter(), process_time();\n    for _ in range(trials):\n        beta = ox.linreg_ridge_gd(y,X, 5.0, algorithm=a);\n        beta = None;\n    eh,ec = perf_counter(), process_time()\n    bench.append( [a, eh-sh, ec-sc] )    \n    print('Perf: {0:.4f} | Proc: {1:.4f} | {2:s}'.format(eh-sh, ec-sc, a))",
                "true_label": "",
                "top5_preds": [
                    "ridge regression with one predictor on a grid",
                    "ridge regression with polynomial features on a grid",
                    "fit a polynomial",
                    "line plots show the trend of a numerical variable over time",
                    "equally spaced numbers on a grid"
                ]
            },
            {
                "code": "sh,sc = perf_counter(), process_time();\nfor _ in range(trials):\n    beta = ox.linreg_ridge_lu(y,X, 5.0);\n    beta = None;\neh,ec = perf_counter(), process_time()\nbench.append( ['Ridge LU', eh-sh, ec-sc] ) \nprint('Perf: {0:.4f} | Proc: {1:.4f} | {2:s}'.format(eh-sh, ec-sc, 'Ridge LU'))",
                "true_label": "",
                "top5_preds": [
                    "ridge regression with one predictor on a grid",
                    "fit a polynomial",
                    "ridge regression with polynomial features on a grid",
                    "likelihood of the binomial distribution",
                    "line plots show the trend of a numerical variable over time"
                ]
            },
            {
                "code": "sh,sc = perf_counter(), process_time();\nfor _ in range(trials):\n    beta = ox.linreg_ols_lu(y,X);\n    beta = None;\neh,ec = perf_counter(), process_time()\nbench.append( ['OLS LU', eh-sh, ec-sc] ) \nprint('Perf: {0:.4f} | Proc: {1:.4f} | {2:s}'.format(eh-sh, ec-sc, 'OLS LU'))",
                "true_label": "",
                "top5_preds": [
                    "fit a polynomial",
                    "likelihood of the binomial distribution",
                    "likelihood of the binomial",
                    "ridge regression with one predictor on a grid",
                    "gradient based stochastic optimization"
                ]
            }
        ],
        [
            {
                "code": "SELECT DISTINCT business_id\nFROM category\nWHERE category IN(\n'Acai Bowls',\n'Afghan',\n'African',\n'Alsatian',\n'American (New)',\n'American (Traditional)',\n'Arabian',\n'Argentine',\n'Armenian',\n'Asian Fusion',\n'Bagels',\n'Baguettes',\n'Bakeries',\n'Bangladeshi',\n'Bar Crawl',\n'Barbeque',\n'Bars',\n'Bavarian',\n'Beach Bars',\n'Bed & Breakfast',\n'Beer Bar',\n'Beer Garden',\n'Beer Gardens',\n'Beer Hall',\n'Beer Tours',\n'Belgian',\n'Bistros',\n'Brasseries',\n'Brazilian',\n'Breakfast & Brunch',\n'Breweries',\n'Brewpubs',\n'British',\n'Bubble Tea',\n'Buffets',\n'Bulgarian',\n'Burgers',\n'Burmese',\n'Cafes',\n'Cajun/Creole',\n'Cambodian',\n'Canadian (New)',\n'Cantonese',\n'Caribbean',\n'Caterers',\n'Cheesesteaks',\n'Chicken Shop',\n'Chicken Wings',\n'Chinese',\n'Chocolatiers & Shops',\n'Churros',\n'Cideries',\n'Cigar Bars',\n'Cocktail Bars',\n'Coffee & Tea',\n'Coffee Roasteries',\n'Coffeeshops',\n'Colombian',\n'Comfort Food',\n'Conveyor Belt Sushi',\n'Creperies',\n'Cuban',\n'Cupcakes',\n'Curry Sausage',\n'Custom Cakes',\n'Czech',\n'Czech/Slovakian',\n'Delicatessen',\n'Delis',\n'Desserts',\n'Dim Sum',\n'Diners',\n'Do-It-Yourself Food',\n'Dominican',\n'Donuts',\n'Drive-Thru Bars',\n'Eastern European',\n'Eastern German',\n'Eatertainment',\n'Egyptian',\n'Empanadas',\n'Ethnic Food',\n'Falafel',\n'Farmers Market',\n'Farms',\n'Fast Food',\n'Filipino',\n'Fischbroetchen',\n'Fish & Chips',\n'Flatbread',\n'Fondue',\n'Food',\n'Food Court',\n'Food Trucks',\n'French',\n'Fruits & Veggies',\n'Gastropubs',\n'Gelato',\n'Georgian',\n'German',\n'Gluten-Free',\n'Greek',\n'Guamanian',\n'Haitian',\n'Halal',\n'Hawaiian',\n'Himalayan/Nepalese',\n'Honduran',\n'Honey',\n'Hong Kong Style Cafe',\n'Hookah Bars',\n'Hot Dogs',\n'Hot Pot',\n'Hotel bar',\n'Hungarian',\n'Iberian',\n'Ice Cream & Frozen Yogurt',\n'Imported Food',\n'Indian',\n'Indonesian',\n'International',\n'Irish',\n'Irish Pub',\n'Italian',\n'Izakaya',\n'Japanese',\n'Japanese Curry',\n'Juice Bars & Smoothies',\n'Kebab',\n'Kombucha',\n'Korean',\n'Kosher',\n'Laotian',\n'Latin American',\n'Lebanese',\n'Live/Raw Food',\n'Lounges',\n'Macarons',\n'Malaysian',\n'Mediterranean',\n'Mexican',\n'Middle Eastern',\n'Milkshake Bars',\n'Minho',\n'Modern European',\n'Mongolian',\n'Moroccan',\n'New Mexican Cuisine',\n'Nicaraguan',\n'Nightlife',\n'Noodles',\n'Pakistani',\n'Palatine',\n'Pan Asian',\n'Parent Cafes',\n'Pasta Shops',\n'Patisserie/Cake Shop',\n'Persian/Iranian',\n'Peruvian',\n'Pita',\n'Pizza',\n'Poke',\n'Polish',\n'Pop-Up Restaurants',\n'Popcorn Shops',\n'Portuguese',\n'Poutineries',\n'Pretzels',\n'Pub Food',\n'Pubs',\n'Puerto Rican',\n'Ramen',\n'Rest Stops',\n'Restaurants',\n'Rotisserie Chicken',\n'Russian',\n'Salad',\n'Salvadoran',\n'Sandwiches',\n'Scandinavian',\n'Schnitzel',\n'Scottish',\n'Seafood',\n'Senegalese',\n'Serbo Croatian',\n'Shanghainese',\n'Sicilian',\n'Signature Cuisine',\n'Singaporean',\n'Slovakian',\n'Smokehouse',\n'Soba',\n'Soul Food',\n'Soup',\n'South African',\n'Southern',\n'Spanish',\n'Specialty Food',\n'Sports Bars',\n'Sri Lankan',\n'Steakhouses',\n'Sugar Shacks',\n'Supper Clubs',\n'Sushi Bars',\n'Swabian',\n'Swiss Food',\n'Syrian',\n'Szechuan',\n'Tacos',\n'Taiwanese',\n'Tapas/Small Plates',\n'Tea Rooms',\n'Tempura',\n'Teppanyaki',\n'Tex-Mex',\n'Thai',\n'Tiki Bars',\n'Tonkatsu',\n'Traditional Chinese Medicine',\n'Traditional Norwegian',\n'Trinidadian',\n'Turkish',\n'Tuscan',\n'Udon',\n'Ukrainian',\n'Vegan',\n'Vegetarian',\n'Venezuelan',\n'Vietnamese',\n'Waffles',\n'Whiskey Bars',\n'Wraps'\n) INTO OUTFILE '/tmp/food_businesses.csv'\nFIELDS TERMINATED BY ','\nENCLOSED BY '\"'\nLINES TERMINATED BY '\\n';\n\n\n\n",
                "true_label": "",
                "top5_preds": [
                    "exploring the database with sql",
                    "sql LIKE operator",
                    "get the names of all the tables in the database",
                    "sqlalchemy, sqlite, and dates",
                    "find all by term in field in case insensitive way"
                ]
            },
            {
                "code": "%matplotlib inline\nimport os\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport ast\nimport unicodedata as ud\nfrom langdetect import detect\npd.options.display.max_rows = 9999\nplt.style.use('dark_background')",
                "true_label": "",
                "top5_preds": [
                    "trend lines in pyplot",
                    "pandas plotting",
                    "plot using matplotlib",
                    "line plot with a dataframe",
                    "load table in pandas"
                ]
            },
            {
                "code": "reviews = pd.read_csv('./data/review.csv',\n                      usecols=['useful','text','date','stars','business_id'])\nreviews.head()\n",
                "true_label": "",
                "top5_preds": [
                    "loading a csv into a dataframe",
                    "load table in pandas",
                    "importing data with pandas",
                    "find data type of each column",
                    "formatting datetimes as strings"
                ]
            },
            {
                "code": "def parse_bytes(field):\n    \"\"\" Convert string represented in Python byte-string literal syntax into a\n    decoded character string. Other field types returned unchanged.\n    https://stackoverflow.com/questions/47741235/how-to-read-bytes-object-from-csv\n    \"\"\"\n    result = field\n    try:\n        result = ast.literal_eval(field)\n    finally:\n        return result.decode('utf-8') if isinstance(result, bytes) else field",
                "true_label": "",
                "top5_preds": [
                    "convert integer or float data",
                    "transform the date column as a datetime type",
                    "check out the type of the columns",
                    "find data type of each column",
                    "read data point"
                ]
            },
            {
                "code": "#cleanup\nreviews['date'] = pd.to_datetime(pd.Series([date[2:-1] for date in reviews['date']]))\nreviews['text'] = pd.Series([parse_bytes(t) for t in reviews['text']])\nreviews['length'] = reviews['text'].apply(len)\nreviews['business_id'] = pd.Series([parse_bytes(t) for t in reviews['business_id']])",
                "true_label": "",
                "top5_preds": [
                    "formatting datetimes as strings",
                    "transform the date column as a datetime type",
                    "convert date to datetime format",
                    "convert data from string to float",
                    "working with pandas series indexed by datetime"
                ]
            },
            {
                "code": "useful_thres = 5",
                "true_label": "",
                "top5_preds": [
                    "optimal value of k for dataset",
                    "equally spaced numbers on a grid",
                    "predicting a categorical response",
                    "filling the mask",
                    "get a positive integer from a user"
                ]
            },
            {
                "code": "rests = pd.read_csv('./data/food_businesses.csv')\nrests['isfood'] = 1\nreviews = pd.merge(reviews,rests,how='left')\ndel rests",
                "true_label": "",
                "top5_preds": [
                    "in pandas",
                    "relationships between dataframes",
                    "importing data with pandas",
                    "select every row after a specific row",
                    "join two dataframes along rows"
                ]
            },
            {
                "code": "reviews = pd.merge(reviews,\n    (reviews.\n     groupby(['business_id']).\n     size().\n     reset_index().\n     rename(columns={0:'business_review_count'})\n    ),how='left'\n    )",
                "true_label": "",
                "top5_preds": [
                    "create a dataframe by joining series by column",
                    "from dictionary to dataframe",
                    "create a list of retweet count and status tuples",
                    "transform year column",
                    "relationships between dataframes"
                ]
            },
            {
                "code": "reviews.head()",
                "true_label": "",
                "top5_preds": [
                    "formatting datetimes as strings",
                    "tensorflow + keras",
                    "sqlalchemy, sqlite, and dates",
                    "get a positive integer from a user",
                    "shortcut principal component analysis in scikit learn"
                ]
            },
            {
                "code": "print(reviews.agg({'date':['min','max']}))",
                "true_label": "",
                "top5_preds": [
                    "formatting datetimes as strings",
                    "sqlalchemy, sqlite, and dates",
                    "integrating datetime tools with pandas for time series",
                    "working with pandas series indexed by datetime",
                    "multiple aggregations for different columns"
                ]
            },
            {
                "code": "print(\nreviews.\n    assign(month=reviews.date.map(lambda dt: dt.replace(day=1))).\n    groupby(['month']).\n    size()\n)",
                "true_label": "",
                "top5_preds": [
                    "transform the date column as a datetime type",
                    "convert date to datetime format",
                    "formatting datetimes as strings",
                    "sqlalchemy, sqlite, and dates",
                    "working with pandas series indexed by datetime"
                ]
            },
            {
                "code": "dt = pd.to_datetime('2007-01-01')\npercentuseful=(\n(reviews.loc[reviews['date'] >= dt].\n assign(isuseful = reviews.useful >= useful_thres).\n groupby(['date','isuseful']).\n size().\n reset_index().\n set_index('date').\n rename(columns={0: \"count\"})\n).merge(\n (reviews.loc[reviews['date'] >= dt].\n     assign(isuseful = reviews.useful >= useful_thres).\n     groupby(['date']).\n     size().\n     to_frame().\n     rename(columns={0:'totcount'})\n ), left_index=True,right_index=True\n).assign(percent = lambda x: x['count']/x['totcount']).\nquery('isuseful')\n)\nplt.title(\"Percent of Reviews with at Least 5 Useful Votes\"+\n         \"\\nred lines indicate date range used\")\npercentuseful['percent'].plot()\nplt.axvline(x=pd.to_datetime('2012-01-01'), color='r')\nplt.axvline(x=pd.to_datetime('2017-12-08'), color='r')\n",
                "true_label": "",
                "top5_preds": [
                    "in pandas",
                    "predicting a categorical response",
                    "formatting datetimes as strings",
                    "integrating datetime tools with pandas for time series",
                    "line plot with a dataframe"
                ]
            },
            {
                "code": "(reviews.\nassign(isuseful=(reviews.useful >= useful_thres)*1).\ngroupby(['stars']).\nagg({'isuseful':['size','sum','mean']}).\n loc[:,'isuseful'].\n loc[:,'mean']\n).plot.bar()\nplt.title(\"Percent of Reviews with at Least 5 Useful Votes by Number of Stars\")",
                "true_label": "",
                "top5_preds": [
                    "predicting a categorical response",
                    "line plot with a dataframe",
                    "calculate average by group",
                    "ploting out data with box plots",
                    "calculating the mean of a vector with nans"
                ]
            },
            {
                "code": "b\"\\xe5\\xbd\\xb9\\xe3\\x81\\xab\\xe7\\xab\\x8b\\xe3\\x81\\xa4\\xe6\\x97\\xa5\\xe3\\x81\\x8c\\xe6\\x9d\\xa5\\xe3\\x82\\x8b\\xe3\\x81\\x8b\\xe3\\x82\\x8f\\xe3\\x81\\x8b\\xe3\\x82\\x8a\\xe3\\x81\\xbe\\xe3\\x81\\x9b\\xe3\\x82\\x93\\xe3\\x81\\x8c\\xe3\\x80\\x81\\n\\xe3\\x82\\xa8\\xe3\\x83\\x87\\xe3\\x82\\xa3\\xe3\\x83\\xb3\\xe3\\x83\\x90\\xe3\\x83\\xa9\\xe9\\xa7\\x85\\xe3\\x81\\xae\\xe9\\x9b\\xbb\\xe8\\xbb\\x8a\\xe3\\x81\\xae\\xe9\\xa7\\x85\\xe3\\x81\\xaf\\xe3\\x81\\x93\\xe3\\x81\\x93\\xe3\\x81\\xaa\\xe3\\x81\\xae\\xe3\\x81\\xa7\\xe3\\x81\\x99\\xe3\\x81\\x8c\\xe3\\x80\\x81\\n\\xe3\\x82\\xa2\\xe3\\x83\\x8a\\xe3\\x82\\xa6\\xe3\\x83\\xb3\\xe3\\x82\\xb9\\xe3\\x81\\xa7\\xe3\\x82\\xa8\\xe3\\x83\\x87\\xe3\\x82\\xa3\\xe3\\x83\\xb3\\xe3\\x83\\x90\\xe3\\x83\\xa9\\xe3\\x82\\xa6\\xe3\\x82\\xa7\\xe3\\x83\\x90\\xe3\\x83\\xaa\\xe3\\x83\\xbc\\xe3\\x81\\xa3\\xe3\\x81\\xa6\\xe9\\xa2\\xa8\\xe3\\x81\\xab\\xe8\\x81\\x9e\\xe3\\x81\\x93\\xe3\\x81\\x88\\xe3\\x82\\x8b\\xe3\\x81\\xae\\xe3\\x81\\xa7\\xe3\\x81\\x88\\xe3\\x81\\xa3\\xef\\xbc\\x81\\xe3\\x81\\x93\\xe3\\x81\\x93\\xe3\\x82\\xa8\\xe3\\x83\\x87\\xe3\\x82\\xa3\\xe3\\x83\\xb3\\xe3\\x83\\x90\\xe3\\x83\\xa9\\xe9\\xa7\\x85\\xe3\\x81\\xa7\\xe3\\x81\\x82\\xe3\\x81\\xa3\\xe3\\x81\\xa6\\xe3\\x82\\x8b\\xe3\\x81\\xae\\xe3\\x81\\xa8\\xe4\\xbd\\x95\\xe5\\x9b\\x9e\\xe3\\x81\\x8b\\xe9\\xa9\\x9a\\xe3\\x81\\x8d\\xe3\\x81\\xbe\\xe3\\x81\\x97\\xe3\\x81\\x9f\\xe3\\x80\\x82\\n\\n\\xe3\\x82\\xa8\\xe3\\x83\\x87\\xe3\\x82\\xa3\\xe3\\x83\\xb3\\xe3\\x83\\x90\\xe3\\x83\\xa9\\xe3\\x82\\xa6\\xe3\\x82\\xa7\\xe3\\x83\\x90\\xe3\\x83\\xaa\\xe3\\x83\\xbc\\xe9\\xa7\\x85\\xe3\\x81\\x8c\\xe3\\x82\\xac\\xe3\\x82\\xa4\\xe3\\x83\\x89\\xe3\\x83\\x96\\xe3\\x83\\x83\\xe3\\x82\\xaf\\xe3\\x81\\xaa\\xe3\\x81\\xa9\\xe3\\x81\\xab\\xe3\\x81\\xaf\\xe3\\x82\\xa8\\xe3\\x83\\x87\\xe3\\x82\\xa3\\xe3\\x83\\xb3\\xe3\\x83\\x90\\xe3\\x83\\xa9\\xe9\\xa7\\x85\\xe3\\x81\\xab\\xe3\\x81\\xaa\\xe3\\x81\\xa3\\xe3\\x81\\xa6\\xe3\\x82\\x8b\\xe3\\x81\\xae\\xe3\\x81\\xa7\\xe5\\xa4\\xa7\\xe4\\xb8\\x88\\xe5\\xa4\\xab\\xe3\\x81\\xa7\\xe3\\x81\\x99\\xe3\\x80\\x82\\xe6\\x81\\x90\\xe3\\x82\\x89\\xe3\\x81\\x8f\\xe3\\x80\\x82\\xe8\\xbf\\x91\\xe3\\x81\\x8f\\xe3\\x81\\xae\\xe3\\x83\\x98\\xe3\\x82\\xa4\\xe3\\x83\\x9e\\xe3\\x83\\xbc\\xe3\\x82\\xb1\\xe3\\x83\\x83\\xe3\\x83\\x88\\xe9\\xa7\\x85\\xe3\\x81\\x8b\\xe3\\x82\\x89\\xe3\\x81\\x93\\xe3\\x81\\xae\\xe9\\xa7\\x85\\xe3\\x81\\xbe\\xe3\\x81\\xa7\\xe3\\x81\\xaf\\xe6\\xad\\xa9\\xe3\\x81\\x84\\xe3\\x81\\xa6\\xe3\\x82\\x82\\xe6\\xa5\\xbd\\xe3\\x81\\x97\\xe3\\x82\\x81\\xe3\\x82\\x8b\\xe9\\x81\\x93\\xe3\\x81\\xab\\xe3\\x81\\xaa\\xe3\\x81\\xa3\\xe3\\x81\\xa6\\xe3\\x81\\xbe\\xe3\\x81\\x99\\xe3\\x82\\x88\\xe3\\x80\\x82\\n\\n\\xe6\\x81\\x90\\xe3\\x82\\x89\\xe3\\x81\\x8f\\xe3\\x80\\x81\\xe5\\xa4\\x9a\\xe5\\x88\\x86\\xe3\\x80\\x81\\xe3\\x82\\xa8\\xe3\\x83\\x87\\xe3\\x82\\xa3\\xe3\\x83\\xb3\\xe3\\x83\\x90\\xe3\\x83\\xa9\\xe3\\x82\\xa6\\xe3\\x82\\xa7\\xe3\\x83\\x90\\xe3\\x83\\xaa\\xe3\\x83\\xbc\\xe9\\xa7\\x85\\xe3\\x81\\x8c\\xe3\\x81\\x82\\xe3\\x81\\xaa\\xe3\\x81\\x9f\\xe3\\x81\\xae\\xe3\\x81\\x8a\\xe3\\x82\\x8a\\xe3\\x81\\x9f\\xe3\\x81\\x84\\xe3\\x82\\xa8\\xe3\\x83\\x87\\xe3\\x82\\xa3\\xe3\\x83\\xb3\\xe3\\x83\\x90\\xe3\\x83\\xa9\\xe9\\xa7\\x85\\xe3\\x81\\xa0\\xe3\\x81\\xa8\\xe6\\x80\\x9d\\xe3\\x81\\x84\\xe3\\x81\\xbe\\xe3\\x81\\x99\\xe3\\x80\\x82\\n\\n\\xe5\\xbf\\xb5\\xe3\\x81\\xae\\xe3\\x81\\x9f\\xe3\\x82\\x81\\xe7\\xa2\\xba\\xe8\\xaa\\x8d\\xe3\\x81\\x97\\xe3\\x81\\xa6\\xe3\\x81\\x8f\\xe3\\x81\\xa0\\xe3\\x81\\x95\\xe3\\x81\\x84\\xe3\\x81\\xadw\".decode('utf-8')",
                "true_label": "",
                "top5_preds": [
                    "formatting datetimes as strings",
                    "convert binary to hexadecimal",
                    "convert date to datetime format",
                    "loading json in python",
                    "matching metacharacters literally"
                ]
            },
            {
                "code": "# cut to date range\nreviews = reviews.loc[\n    (reviews.date>=pd.to_datetime('2012-01-01')) &\n    (reviews.date<=pd.to_datetime('2017-12-08'))\n           ].assign(isuseful=(reviews.useful >= useful_thres)*1)",
                "true_label": "",
                "top5_preds": [
                    "integrating datetime tools with pandas for time series",
                    "formatting datetimes as strings",
                    "transform the date column as a datetime type",
                    "working with pandas series indexed by datetime",
                    "when arithmetic operations are performed between differently indexed time series pandas will automatically align on dates"
                ]
            },
            {
                "code": "def lang_detector(review):\n    try:\n        return detect(review)\n    except: # if lang cant be detected, probably isnt english\n        return ''",
                "true_label": "",
                "top5_preds": [
                    "getting data from the internet",
                    "get a positive integer from a user",
                    "download and inspect the twitter samples dataset",
                    "function get_version",
                    "convert integer or float data"
                ]
            },
            {
                "code": "# cut to reviews that are english\n# this takes a VERY long time\nreviews = reviews.loc[reviews['text'].apply(lang_detector)=='en']",
                "true_label": "",
                "top5_preds": [
                    "load table in pandas",
                    "polynomial regression with sklearn",
                    "what is scikit learn?",
                    "vectorize words in movie reviews",
                    "import polynomial features from sklearn"
                ]
            },
            {
                "code": "np.random.seed(42)\n\n# cut useful and not into separate datasets\nuseful_reviews = reviews.loc[reviews.isuseful == 1]\nreviews = reviews.loc[reviews.isuseful == 0]\n\n# shuffle\nuseful_reviews = useful_reviews.sample(frac=1).reset_index(drop=True)\nreviews = reviews.sample(frac=1).reset_index(drop=True)\n\n# get counts for 80-20 split\nnum_useful = useful_reviews.shape[0]\nnum_useful_train = round(.8 * num_useful)\n\nprint('# useful reviews:', num_useful)\nprint('use',num_useful_train,'for training')\n\n# train-test split\nuseful_reviews_train = useful_reviews.loc[0:num_useful_train-1]\nuseful_reviews_test = useful_reviews.loc[num_useful_train:]\nnon_useful_reviews_train = reviews.loc[0:num_useful_train-1]\nnon_useful_reviews_test = reviews.loc[num_useful_train:num_useful-1]\ndel reviews\ndel useful_reviews\nprint(non_useful_reviews_train.shape[0],'nonuseful reviews for training')\n\nX_train = pd.concat([useful_reviews_train,non_useful_reviews_train])\ndel useful_reviews_train\ndel non_useful_reviews_train\n\nX_test = pd.concat([useful_reviews_test,non_useful_reviews_test])\ndel useful_reviews_test\ndel non_useful_reviews_test\n\nprint(\"X_train shape\",X_train.shape)\nprint(\"X_test shape\",X_test.shape)",
                "true_label": "",
                "top5_preds": [
                    "predicting a categorical response",
                    "ploting out data with box plots",
                    "optimal value of k for dataset",
                    "use numpy to generate a random number",
                    "equally spaced numbers on a grid"
                ]
            },
            {
                "code": "X_train.to_pickle('./data/training_dat_eng_wrest_andbct.pkl')\nX_test.to_pickle('./data/test_dat_eng_wrest_andbct.pkl')",
                "true_label": "",
                "top5_preds": [
                    "what is scikit learn?",
                    "logistic regression using tensorflow",
                    "import polynomial features from sklearn",
                    "load table in pandas",
                    "polynomial regression with sklearn"
                ]
            }
        ],
        [
            {
                "code": "import cntk as C\nimport numpy as np\nimport math\nnp.set_printoptions(precision=4)\n\nfeatures = C.input_variable(3)\nlabel = C.input_variable(2)\nz = C.layers.Sequential([C.layers.Dense(4, activation=C.relu), C.layers.Dense(2)])(features)",
                "true_label": "",
                "top5_preds": [
                    "import polynomial features from sklearn",
                    "polynomial regression with sklearn",
                    "scikit learn",
                    "predicting a categorical response",
                    "classification with a cnn"
                ]
            },
            {
                "code": "sgd_learner_m = C.sgd(z.parameters, lr = 0.5, minibatch_size = C.learners.IGNORE)\nsgd_learner_s2 = C.sgd(z.parameters, lr = 0.5, minibatch_size = 2)",
                "true_label": "",
                "top5_preds": [
                    "tensorflow + keras",
                    "polynomial regression with sklearn",
                    "scikit learn",
                    "what is scikit learn?",
                    "import polynomial features from sklearn"
                ]
            },
            {
                "code": "def inspect_update(learner, actual_minibatch_size, count=1):\n    # Save current parameter values\n    old_values = [p.value for p in learner.parameters]\n    # Set current parameter values to all 0\n    for p in learner.parameters:\n        p.value = 0 * p.value\n    # create all-ones gradients, and associate the sum of gradients over \n    # the number of samples in the minibatch with the parameters\n    gradients_sum = {p: np.zeros_like(p.value) \n                     + 1.0 * actual_minibatch_size for p in learner.parameters}    \n    # do 'count' many updates\n    for i in range(count):\n        # note that CNTK learner's update function consumes \n        # sum of gradients over the samples in a minibatch\n        learner.update(gradients_sum, actual_minibatch_size)\n    ret_values = [p.value for p in learner.parameters]\n    # Restore values\n    for p, o in zip(learner.parameters, old_values):\n        p.value = o\n    return ret_values",
                "true_label": "",
                "top5_preds": [
                    "read the dataset",
                    "download and inspect the twitter samples dataset",
                    "the scikit learn interface",
                    "read the dataset point",
                    "summarize the data"
                ]
            },
            {
                "code": "print('\\nper minibatch:\\n', inspect_update(sgd_learner_m, actual_minibatch_size=2))",
                "true_label": "",
                "top5_preds": [
                    "getting data from the internet",
                    "read numbers until and print their mean and standard deviation without using a list",
                    "what is scikit learn?",
                    "scikit learn",
                    "optimal value of k for dataset"
                ]
            },
            {
                "code": "print('\\nper 2 samples: \\n', inspect_update(sgd_learner_s2, actual_minibatch_size=2))",
                "true_label": "",
                "top5_preds": [
                    "what is scikit learn?",
                    "scikit learn",
                    "tensorflow + keras",
                    "scipy",
                    "getting data from the internet"
                ]
            },
            {
                "code": "print('\\nper minibatch:\\n', inspect_update(sgd_learner_m, actual_minibatch_size=10))",
                "true_label": "",
                "top5_preds": [
                    "getting data from the internet",
                    "read numbers until and print their mean and standard deviation without using a list",
                    "what is scikit learn?",
                    "scikit learn",
                    "optimal value of k for dataset"
                ]
            },
            {
                "code": "print('\\nper 2 samples: \\n', inspect_update(sgd_learner_s2, actual_minibatch_size=10))",
                "true_label": "",
                "top5_preds": [
                    "what is scikit learn?",
                    "scikit learn",
                    "getting data from the internet",
                    "tensorflow + keras",
                    "scipy"
                ]
            },
            {
                "code": "momentum = 0.9672161004820059\nminibatch_size = 10\nlr_schedule = C.learning_parameter_schedule(1, minibatch_size=C.learners.IGNORE)\nug_schedule = C.learning_parameter_schedule(1/(1-momentum), minibatch_size=C.learners.IGNORE)\n\nm_schedule = C.momentum_schedule(momentum) #minibatch_size=C.learners.IGNORE\nt_schedule = C.momentum_schedule(momentum, minibatch_size=minibatch_size)\n#t_schedule is equivalent to the legacy API: (see the legacy interfaces section below for details)\n#       t_schedule = C.momentum_as_time_constant_schedule(300)\n\nmsgd = C.momentum_sgd(z.parameters, lr_schedule, m_schedule, unit_gain=False)\ntsgd = C.momentum_sgd(z.parameters, lr_schedule, t_schedule, unit_gain=False)\nusgd = C.momentum_sgd(z.parameters, ug_schedule, m_schedule, unit_gain=True)\n\nprint(inspect_update(msgd, minibatch_size, 5)[0][0])\nprint(inspect_update(tsgd, minibatch_size, 5)[0][0])\nprint(inspect_update(usgd, minibatch_size, 5)[0][0])",
                "true_label": "",
                "top5_preds": [
                    "using logistic regression instead",
                    "fit a polynomial",
                    "sampling from the gaussian process prior",
                    "polynomial regression with sklearn",
                    "scikit learn"
                ]
            },
            {
                "code": "mb_size = 32\n\nlr_schedule = C.learning_parameter_schedule(1, minibatch_size=C.learners.IGNORE)\nt_schedule = C.momentum_schedule(0.971, minibatch_size=C.learners.IGNORE) \n\ntsgd = C.momentum_sgd(z.parameters, lr_schedule, t_schedule, unit_gain=False)\n\nadadelta  = C.adadelta(z.parameters, lr_schedule, 0.999, 1e-6)\nadagrad   = C.adagrad(z.parameters, lr_schedule)\nadam      = C.adam(z.parameters, lr_schedule, t_schedule, unit_gain=False)\nadamax    = C.adam(z.parameters, lr_schedule, t_schedule, unit_gain=False, adamax=True)\nfsadagrad = C.fsadagrad(z.parameters, lr_schedule, t_schedule, unit_gain=False)\nrmsprop   = C.rmsprop(z.parameters, lr_schedule, gamma=0.999, inc=1.0+1e-9, dec=1.0-1e-9, max=np.inf, min=1e-30)\n\nnum_steps = 30\nprint('adadelta :', inspect_update(adadelta, mb_size, num_steps)[0][0])\nprint('adagrad  :', inspect_update(adagrad, mb_size, num_steps)[0][0])\nprint('adam     :', inspect_update(adam, mb_size, num_steps)[0][0])\nprint('adamax   :', inspect_update(adamax, mb_size, num_steps)[0][0])\nprint('fsadagrad:', inspect_update(fsadagrad, mb_size, num_steps)[0][0])\nprint('rmsprop  :', inspect_update(rmsprop, mb_size, num_steps)[0][0])\n\nadadelta_schedule = C.learning_parameter_schedule(1004, minibatch_size=C.learners.IGNORE)\nadadelta_tuned  = C.adadelta(z.parameters, adadelta_schedule, 0.999, 1e-6)\nprint('adadelta2:', inspect_update(adadelta_tuned, mb_size, num_steps)[0][0])",
                "true_label": "",
                "top5_preds": [
                    "polynomial regression with sklearn",
                    "optimal value of k for dataset",
                    "using logistic regression instead",
                    "scikit learn",
                    "sampling from the gaussian process prior"
                ]
            },
            {
                "code": "def my_rmsprop(parameters, gradients):\n    rho = 0.999\n    lr = 0.01\n    # We use the following accumulator to store the moving average of every squared gradient\n    accumulators = [C.constant(1e-6, shape=p.shape, dtype=p.dtype) for p in parameters]\n    update_funcs = []\n    for p, g, a in zip(parameters, gradients, accumulators):\n        # We declare that `a` will be replaced by an exponential moving average of squared gradients\n        # The return value is the expression rho * a + (1-rho) * g * g \n        accum_new = C.assign(a, rho * a + (1-rho) * g * g)\n        # This is the rmsprop update. \n        # We need to use accum_new to create a dependency on the assign statement above. \n        # This way, when we run this network both assigns happen.\n        update_funcs.append(C.assign(p, p - lr * g / C.sqrt(accum_new)))\n    return C.combine(update_funcs)\n\nmy_learner = C.universal(my_rmsprop, z.parameters)\nprint(inspect_update(my_learner, 10, 2)[0][0])",
                "true_label": "",
                "top5_preds": [
                    "fit the vectorizer and svd",
                    "compute covariance matrix",
                    "fit a polynomial",
                    "build a linear regression model to predict mpi",
                    "co variance matrix"
                ]
            },
            {
                "code": "class MySgd(C.UserLearner):\n\n    def __init__(self, parameters, lr_schedule):\n        super(MySgd, self).__init__(parameters, lr_schedule, as_numpy=False)\n\n        self.new_parameter = {}\n        self.grad_input = {}\n\n        self.sample_count_input = C.input_variable((), name='count')\n\n        lr = lr_schedule[0]  # assuming constant learning rate\n        eta = lr / self.sample_count_input\n\n        # we need one graph per parameter shape\n        for param in parameters:\n            p_shape = param.shape\n            self.grad_input[p_shape] = C.input_variable(p_shape)\n            self.new_parameter[p_shape] = param - eta * self.grad_input[p_shape]\n\n    def update(self, gradient_values, training_sample_count, sweep_end):\n        for p, g in gradient_values.items():\n            new_p = self.new_parameter[p.shape]\n            grad_input = self.grad_input[p.shape]\n\n            data = {\n                    self.sample_count_input: np.asarray(training_sample_count),\n                    grad_input: g\n                    }\n            result = new_p.eval(data, as_numpy=False)\n            shape = result.shape\n\n            # result has the shape of a complete minibatch, but contains\n            # only one tensor, which we want to write to p. This means, we\n            # have to slice off the leading dynamic axis.\n            static_tensor = result.data.slice_view([0]*len(shape), shape[1:])\n            p.set_value(static_tensor)\n        return True\n    \nmb_size = 64\nlr_schedule = C.learning_parameter_schedule(1, minibatch_size=C.learners.IGNORE)\nmy_sgd = MySgd(z.parameters, lr_schedule)\n\ndef inspect_user_learner_update(learner, mbsize, count):\n    # user defined learner parameters are of type C.cntk_py.Parameter which is not nice to work with\n    # we copy them out to easy_parameters and update their __class__ attribute to be C.Parameter \n    easy_parameters = [p for p in learner.parameters()]\n    for p in easy_parameters: \n        p.__class__ = C.Parameter\n    old_values = [p.value for p in easy_parameters]\n    for p in easy_parameters:\n        p.value = 0 * p.value\n    updates = {p: p.value + 1 for p in easy_parameters}\n    for i in range(count):\n        learner.update(updates, np.float32(mbsize), sweep_end=False)\n    ret_values = [p.value for p in easy_parameters]\n    for p, o in zip(easy_parameters, old_values):\n        p.value = o\n    return ret_values\n\nprint(inspect_user_learner_update(my_sgd, mb_size, 10)[0][0])",
                "true_label": "",
                "top5_preds": [
                    "the scikit learn interface",
                    "fit the vectorizer and svd",
                    "import polynomial features from sklearn",
                    "create the vectorizer",
                    "import the dataset"
                ]
            },
            {
                "code": "lr_schedule_m = C.learning_rate_schedule(0.5, C.UnitType.minibatch)\nlr_schedule_s = C.learning_rate_schedule(0.5, C.UnitType.sample)\n\nsgd_learner_m = C.sgd(z.parameters, lr_schedule_m)\nsgd_learner_s = C.sgd(z.parameters, lr_schedule_s)",
                "true_label": "",
                "top5_preds": [
                    "polynomial regression with sklearn",
                    "tensorflow + keras",
                    "import polynomial features from sklearn",
                    "fit a polynomial",
                    "resampling and frequency conversion"
                ]
            },
            {
                "code": "print('\\nunit = minibatch\\n', inspect_update(sgd_learner_m, actual_minibatch_size=2))",
                "true_label": "",
                "top5_preds": [
                    "tensorflow + keras",
                    "what is scikit learn?",
                    "read numbers until and print their mean and standard deviation without using a list",
                    "getting data from the internet",
                    "scikit learn"
                ]
            },
            {
                "code": "print('\\nunit = sample\\n', inspect_update(sgd_learner_s, actual_minibatch_size=2))",
                "true_label": "",
                "top5_preds": [
                    "what is scikit learn?",
                    "tensorflow + keras",
                    "scikit learn",
                    "getting data from the internet",
                    "get a positive integer from a user"
                ]
            },
            {
                "code": "mb_size = 10\ntime_constant = 300\nmomentum = math.exp(-mb_size/time_constant)\n\nprint('time constant for momentum of 0.967... = ', mb_size/math.log(1/momentum))\nprint('momentum for time constant of 300      = ', math.exp(-mb_size/time_constant))",
                "true_label": "",
                "top5_preds": [
                    "pi by means of the arithmetic geometric mean",
                    "formatting datetimes as strings",
                    "resampling and frequency conversion",
                    "sum all the numbers in a list",
                    "likelihood of the binomial distribution"
                ]
            }
        ]
    ]
}