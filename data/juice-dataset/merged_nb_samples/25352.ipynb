{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ba56b92",
   "metadata": {},
   "source": [
    "<div id=\"toc\"></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f1312b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "$.getScript('https://kmahelona.github.io/ipython_notebook_goodies/ipython_notebook_toc.js')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8998449",
   "metadata": {},
   "source": [
    "# Goal\n",
    "\n",
    "The goal of this work is to create methods in `bicorr.py` that will enable the following capabilities in analyzing `bicorr_hist_master`.\n",
    "\n",
    "Issues:  \n",
    "1) Change the time bins to be more coarse  \n",
    "2) Normalizing the counts in each bin so that the magnitude in each bin is approximately the same regardless of the time bin width\n",
    "\n",
    "Start by importing relevant packages and some data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acda6867",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors\n",
    "import inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8095ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the bicorr.py functions I have already developed\n",
    "sys.path.append('../scripts')\n",
    "\n",
    "import bicorr as bicorr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8280ca2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa5cf60",
   "metadata": {},
   "source": [
    "Import data from the following folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7076dc69",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir('../analysis/Cf072115_to_Cf072215b/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cac0e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_bhm, dt_bin_edges, note = bicorr.load_sparse_bhm(r'../analysis/Cf072115_to_Cf072215b/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ec222b",
   "metadata": {},
   "outputs": [],
   "source": [
    "det_df = bicorr.load_det_df('../meas_info/det_df_pairs_angles.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176975d6",
   "metadata": {},
   "source": [
    "I'm going to work with the positive `bhm` only and not perform a background subtraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dac4ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "bhm = bicorr.revive_sparse_bhm(sparse_bhm, det_df, dt_bin_edges)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcdefcdf",
   "metadata": {},
   "source": [
    "Save the `bicorr_hist_plot` for coarsening later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51080b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "bhp = bicorr.build_bhp(bhm, dt_bin_edges, print_flag=True)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ceff986",
   "metadata": {},
   "source": [
    "# Issue 1: Make time binning more coarse on `bhm`\n",
    "\n",
    "In some instances, there are not enough counts in each histogram to see smooth features, and therefore it is beneficial to make the time bins more coarse (change the time bin width from 0.25 ns to 1 ns, for example).\n",
    "\n",
    "Here I will write a function that performs that task based on a specified factor $C$ by which to coarsen the time bin width. If a histogram with time bin width 0.25 ns is coarsend by a factor $C=4$, then the resulting histogram will have time bin widths of $0.25*4$ ns $= 1$ ns.\n",
    "\n",
    "## Generate coarse matrix\n",
    "\n",
    "What is the shape and bin width of the original matrix?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923bc062",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = bhm.shape\n",
    "print('Dimensions of bicorr_hist_master: ', bhm.shape)\n",
    "\n",
    "dt_bin_width = dt_bin_edges[1]-dt_bin_edges[0]\n",
    "print('Width of time bin in (ns): ', dt_bin_width)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2082ccd5",
   "metadata": {},
   "source": [
    "What will be the shape of the final matrix?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f27590",
   "metadata": {},
   "outputs": [],
   "source": [
    "C = 4\n",
    "\n",
    "# Preallocate coarse matrix\n",
    "bhm_coarse = np.zeros((shape[0],shape[1],int(shape[2]/C),int(shape[3]/C)))\n",
    "\n",
    "# Calculate new dt_bin_edges\n",
    "dt_bin_edges_coarse = dt_bin_edges[0::C]\n",
    "dt_bin_width_coarse = dt_bin_edges_coarse[1]-dt_bin_edges_coarse[0]\n",
    "\n",
    "print('Dimensions of bicorr_hist_master_coarse: ', bhm_coarse.shape)\n",
    "print('Width of coarse time bin in (ns): ', dt_bin_width_coarse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b50dcd",
   "metadata": {},
   "source": [
    "To fill the histogram, I need to sum over a range of values in `bicorr_hist_master`. If the coarsening factor is $C=4$, then the corresponding bin indices are:\n",
    "\n",
    "Index in `bicorr_hist_master_coarse` --> Indices in `bicorr_hist_master`...  \n",
    "\n",
    "0 --> (0-3)  \n",
    "1 --> (4-7)  \n",
    "2 --> (8-11 )  \n",
    "3 --> (12-15)  \n",
    "4 --> (16-19)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645eed05",
   "metadata": {},
   "source": [
    "But in python, to select data at indices $0-3$, for instance, you must use the index range `[0:4]`, so the indices that you call will be even simpler.\n",
    "\n",
    "For an index $i$ in `bicorr_hist_master_coarse`, the corresponding starting and ending bin indices in `bicorr_hist_master` given factor $C$ are:\n",
    "\n",
    "Starting index: `C*i`  \n",
    "Final index:    `C*(i+1)`  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be250e1e",
   "metadata": {},
   "source": [
    "Loop through all of the bins in `bicorr_hist_master_coarse` and fill them by summing the corresponding bins in `bicorr_hist_master`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65dc66d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for bin1 in np.arange(0,bhm_coarse.shape[2]):\n",
    "    for bin2 in np.arange(0,bhm_coarse.shape[3]):\n",
    "        bhm_coarse[:,:,bin1,bin2] = np.sum(bhm[:,:,C*bin1:C*(bin1+1),C*bin2:C*(bin2+1)],axis=(2,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd95863",
   "metadata": {},
   "source": [
    "## Plot original and coarse matrices\n",
    "\n",
    "Plot the two distributions to compare them. Start with all events across all detectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1059497a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.pcolormesh(dt_bin_edges, dt_bin_edges, np.sum(bhm,axis=(0,1)), norm = matplotlib.colors.LogNorm())\n",
    "plt.xlabel('$\\Delta t_1$ (ns)')\n",
    "plt.ylabel('$\\Delta t_2$ (ns)')\n",
    "plt.title('Bicorr_hist_master with 0.25 ns bin width')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d71c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.pcolormesh(dt_bin_edges_coarse, dt_bin_edges_coarse, np.sum(bhm_coarse,axis=(0,1)), norm = matplotlib.colors.LogNorm())\n",
    "plt.xlabel('$\\Delta t_1$ (ns)')\n",
    "plt.ylabel('$\\Delta t_2$ (ns)')\n",
    "plt.title('Bicorr_hist_master_coarse with 1.0 ns bin width')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28baddb6",
   "metadata": {},
   "source": [
    "## Functionalize it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c7e8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(inspect.getsource(bicorr.coarsen_bhm))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671b3cdb",
   "metadata": {},
   "source": [
    "Try it out- make an even coarser matrix with 4 ns bins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1124920",
   "metadata": {},
   "outputs": [],
   "source": [
    "bhm_4ns, dt_bin_edges_4ns = bicorr.coarsen_bhm(bhm,dt_bin_edges,16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba00db01",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.pcolormesh(dt_bin_edges_4ns, dt_bin_edges_4ns, np.sum(bhm_4ns,axis=(0,1)), norm = matplotlib.colors.LogNorm())\n",
    "plt.xlabel('$\\Delta t_1$ (ns)')\n",
    "plt.ylabel('$\\Delta t_2$ (ns)')\n",
    "plt.title('bhm_coarse with 4.0 ns bin width')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332d313b",
   "metadata": {},
   "source": [
    "# Issue 2: Make time binning more coarse on `bhp`\n",
    "\n",
    "In some cases I will already have `bhp` constructed, and I want to coarsen that instead of starting from `bhm`. Follow the same steps. \n",
    "\n",
    "## Generate `bhp_coarse`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8e6169",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = bhp.shape\n",
    "print('Dimensions of bicorr_hist_plot: ', bhp.shape)\n",
    "\n",
    "dt_bin_width = dt_bin_edges[1]-dt_bin_edges[0]\n",
    "print('Width of time bin in (ns): ', dt_bin_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b7f7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "C = 4\n",
    "\n",
    "# Preallocate coarse matrix\n",
    "bhp_coarse = np.zeros((int(shape[0]/C),int(shape[1]/C)))\n",
    "\n",
    "# Calculate new dt_bin_edges\n",
    "dt_bin_edges_coarse = dt_bin_edges[0::C]\n",
    "dt_bin_width_coarse = dt_bin_edges_coarse[1]-dt_bin_edges_coarse[0]\n",
    "\n",
    "print('Dimensions of bicorr_hist_plot_coarse: ', bhp_coarse.shape)\n",
    "print('Width of coarse time bin in (ns): ', dt_bin_width_coarse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deae253c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for bin1 in np.arange(0,bhp_coarse.shape[0]):\n",
    "    for bin2 in np.arange(0,bhp_coarse.shape[1]):\n",
    "        bhp_coarse[bin1,bin2] = np.sum(bhp[C*bin1:C*(bin1+1),C*bin2:C*(bin2+1)],axis=(0,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4fc310",
   "metadata": {},
   "source": [
    "## Plot original and coarse `bhp`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e38aa2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bicorr.bicorr_plot(bhp, dt_bin_edges, show_flag = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d5034c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bicorr.bicorr_plot(bhp_coarse, dt_bin_edges_coarse, show_flag = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfe356b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(inspect.getsource(bicorr.coarsen_bhp))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8beb1f",
   "metadata": {},
   "source": [
    "## Plot it directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6141a886",
   "metadata": {},
   "outputs": [],
   "source": [
    "bicorr.bicorr_plot(bhp,dt_bin_edges,show_flag = True, title='Original')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25281ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "bicorr.bicorr_plot(bicorr.coarsen_bhp(bhp,dt_bin_edges,4)[0],\n",
    "                   bicorr.coarsen_bhp(bhp,dt_bin_edges,4)[1],\n",
    "                   show_flag = True, title='Coarsen with C = 4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0bb43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bicorr.bicorr_plot(bicorr.coarsen_bhp(bhp,dt_bin_edges,16)[0],\n",
    "                   bicorr.coarsen_bhp(bhp,dt_bin_edges,16)[1],\n",
    "                   show_flag = True, title='Coarsen with C = 16')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d74c4f",
   "metadata": {},
   "source": [
    "# Issue 3: Normalize the counts\n",
    "\n",
    "When looking at these distributions in terms of number of counts, there are several issues that make it difficult to make comparisons between plots. These include the following points:\n",
    "\n",
    "* With finer time bin width, there are fewer counts per bin. You will notice above that the scale on the color bar starts at over $10^4$ for 0.25 ns bins, goes above $10^5$ for 1 ns bins, and then above $10^6$ for 4 ns bins. This makes sense because the number of counts in each bin is increasing roughly with $C^2$ as the counts over a range of bins are combined. \n",
    "* So far in this analysis we have only generated plots for all detector pairs, but later we will generate this histogram for subsets of detector pairs based on the angle between detectors. Thus, a subset with fewer detector pairs would have fewer counts in each bin than a subset with more detector pairs.\n",
    "* Also, some of the measurements were taken for longer measurement times, so that there are more fission events in the measurement, and therefore we would expect more counts.\n",
    "* Finally, we will eventually compare these bicorrelation plots between measurement and simulation, so we need units that can be fairly compared between the two. \n",
    "\n",
    "To deal with this, we will normalize the number of counts in each bin of the histogram to the following things:\n",
    "\n",
    "* Number of fission events\n",
    "* Number of detector pairs\n",
    "* Area of pixel in time-squared units"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75084cbf",
   "metadata": {},
   "source": [
    "## Units \n",
    "\n",
    "These values will change for each measurement, but the information related to the number of fissions that I have is:\n",
    "\n",
    "* fission rate in [fissions/s]\n",
    "* measurement length in [s]\n",
    "\n",
    "I can multiply these together to get the total number of fissions during the time of the measurement. Working with values from the `Cf072115-Cf072215b` measurement..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a77fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fission_rate = 2.9498e+05 # fissions/s\n",
    "meas_length = 7440 # sec\n",
    "num_fissions = fission_rate * meas_length\n",
    "print(num_fissions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8ef38c",
   "metadata": {},
   "source": [
    "For the number of detector pairs, I can take the length of the array `pair_is` that I pass into `bicorr.build_bicorr_hist_plot`. `pair_is` contains an array of the indices of the selected detector pairs in `bicorr_hist_master`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10132f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_is = det_df.index.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4c47bb",
   "metadata": {},
   "source": [
    "Lastly, we need to calculate the size of the bin width in two-dimensional space. For example, the data in a bin of size 0.25 ns x 0.25 ns should be inflated by a factor of 16 (or divided by 1/16) in order to be compared to the data in a bin of size 1 ns x 1 ns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9534b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the time-binning\n",
    "time_bin_width = dt_bin_edges[1]-dt_bin_edges[0]\n",
    "time_norm_factor = np.power(time_bin_width,2) # Units of ns^2\n",
    "print(time_bin_width, time_norm_factor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19353b63",
   "metadata": {},
   "source": [
    "## Calculate the normalization factor\n",
    "\n",
    "Ultimately, the normalization factor is the product of these four values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68c12f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_factor = num_fissions * len(pair_is) * time_norm_factor\n",
    "print(norm_factor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec86aa18",
   "metadata": {},
   "source": [
    "Try it now for the coarser bin widths and see if the two norm_factors differ by a factor of 16."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda661fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_factor_coarse = num_fissions * len(pair_is) * time_norm_factor_coarse\n",
    "print(norm_factor_coarse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce8b112",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(norm_factor_coarse / norm_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b59fe14",
   "metadata": {},
   "outputs": [],
   "source": [
    "C**2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6dcf12f",
   "metadata": {},
   "source": [
    "Does this add up? The number of counts will be divided by the normalization factor. The coarser measurements should be divided by a greater value, therefore `norm_factor_coarse > norm_factor`. So it checks out."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801bbf77",
   "metadata": {},
   "source": [
    "## Compare normal and coarse plots after normalization\n",
    "\n",
    "The colorbar scale on the two plots should be the same after normalization for any time bin width.\n",
    "\n",
    "To normalize, divide the `bicorr_hist_plot` (summed `bicorr_hist_matrix`) matrix by `norm_factor`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ea4687",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.pcolormesh(dt_bin_edges, dt_bin_edges, np.divide(np.sum(bhm,axis=(0,1)),norm_factor), norm = matplotlib.colors.LogNorm())\n",
    "plt.xlabel('$\\Delta t_1$ (ns)')\n",
    "plt.ylabel('$\\Delta t_2$ (ns)')\n",
    "plt.title('bhm with 0.25 ns bin width, normalized')\n",
    "plt.axes().set_aspect('equal')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71347ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.pcolormesh(dt_bin_edges_coarse, dt_bin_edges_coarse, np.divide(np.sum(bhm_coarse,axis=(0,1)),norm_factor_coarse), norm = matplotlib.colors.LogNorm())\n",
    "plt.xlabel('$\\Delta t_1$ (ns)')\n",
    "plt.ylabel('$\\Delta t_2$ (ns)')\n",
    "plt.title('Bicorr_hist_master_coarse with 1.0 ns bin width, normalized')\n",
    "plt.axes().set_aspect('equal')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c28cced",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_bin_width_4ns = dt_bin_edges_4ns[1]-dt_bin_edges_4ns[0]\n",
    "time_norm_factor_4ns = np.power(time_bin_width_4ns,2) # Units of ns^2\n",
    "norm_factor_4ns = num_fissions * len(pair_is) * time_norm_factor_4ns\n",
    "\n",
    "plt.pcolormesh(dt_bin_edges_4ns, dt_bin_edges_4ns, np.divide(np.sum(bhm_4ns,axis=(0,1)),norm_factor_4ns), norm = matplotlib.colors.LogNorm())\n",
    "plt.xlabel('$\\Delta t_1$ (ns)')\n",
    "plt.ylabel('$\\Delta t_2$ (ns)')\n",
    "plt.title('Bicorr_hist_master_coarse with 4.0 ns bin width, normalized')\n",
    "plt.axes().set_aspect('equal')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24c68b7",
   "metadata": {},
   "source": [
    "The 4 ns range is lower than the other two ranges. Why? This plot will have more data in each bin, but will be less susceptible to small fluctuations. For example, if there is a localized peak in the finer mesh plot, the average of those counts is lower, and the coarsened distribution will be representative of the average. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4269dfc",
   "metadata": {},
   "source": [
    "## Confirm accuracy of normalization with variable `pair_is` and `type_is`\n",
    "\n",
    "Change the number of detector pairs in each plot and verify that the normalization accounts for that. Work with the data binned to 1 ns time bins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6583ffc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_bin_width_coarse = dt_bin_edges_coarse[1]-dt_bin_edges_coarse[0]\n",
    "time_norm_factor_coarse = np.power(time_bin_width_coarse,2) # Units of ns^2\n",
    "print(time_bin_width_coarse, time_norm_factor_coarse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d8e981",
   "metadata": {},
   "source": [
    "Start with all events and detector pairs for reference"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
