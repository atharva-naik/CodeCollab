{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88b7604b",
   "metadata": {},
   "source": [
    "# News Headline Analysis\n",
    "\n",
    "In this project we're analyzing news headlines written by two journalists – a **finance** reporter from the Business Insider, and a **celebrity** reporter from the Huffington post – to find similarities and differences between the ways that these authors write headlines for their news articles and blog posts. Our selected reporters are:\n",
    "\n",
    "- Akin Oyedele the Business Insider who covers market updates; and\n",
    "- Carly Ledbetter from the Huffington Post who mainly writes about celebrities.\n",
    "\n",
    "### Approach\n",
    "\n",
    "We're initially going to collect and parse news headlines from each of the authors in order to obtain a parse tree. Then we're going to extract certain information from these parse trees that are indicative of the overall structure of the headline.\n",
    "\n",
    "Next, we will define a simple sequence similarity metric to compare any pair of headlines quantitatively, and we will apply the same method to all of the headlines we've gathered for each author, to find out how similar each pair of headlines is.\n",
    "\n",
    "Finally, we're going to use K-Means and tSNE to produce a visual map of all the headlines, where we can see the similarities and the differences between the two authors more clearly.\n",
    "\n",
    "### Data\n",
    "\n",
    "For this project we've gathered 700 headlines for each author using the [AYLIEN News API](https://newsapi.aylien.com) which we're going to analyze using Python. You can obtain the Pickled data files directly from the GitHub repository, or by using [the data collection notebook](https://github.com/AYLIEN/headline_analysis/blob/master/data-collection.ipynb) that we've prepared for this project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427fc796",
   "metadata": {},
   "source": [
    "### A primer on parse trees\n",
    "\n",
    "In linguistics, a parse tree is a rooted tree that represents the syntactic structure of a sentence, according to some pre-defined grammar.\n",
    "\n",
    "For a simple sentence like \"The cat sat on the mat\", a parse tree might look like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84fdc1b",
   "metadata": {},
   "source": [
    "![The cat sat on the mat](https://raw.githubusercontent.com/AYLIEN/headline_analysis/master/parsetree.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18cc1666",
   "metadata": {},
   "source": [
    "We're going to use the [Pattern library](http://www.clips.ua.ac.be/pages/pattern-en#tree) for Python to parse the headlines and create parse trees for them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7daf13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pattern.en import parsetree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7ace3b",
   "metadata": {},
   "source": [
    "Let's see an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0b7625",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = parsetree('The cat sat on the mat.')\n",
    "for sentence in s:\n",
    "    for chunk in sentence.chunks:\n",
    "        print chunk.type, [(w.string, w.type) for w in chunk.words]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b67b35",
   "metadata": {},
   "source": [
    "### Loading the data\n",
    "\n",
    "Let's load the Pickled data file for the first author (Akin Oyedele) which contains 700 headlines, and let's see an example of what a headline might look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7c59e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cPickle as pickle\n",
    "author1 = pickle.load( open( \"author1.p\", \"rb\" ) )\n",
    "author1[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8afbf933",
   "metadata": {},
   "source": [
    "### Parsing the data\n",
    "\n",
    "Now that we have all the headlines for the first author loaded, we're going to analyze them, create parse trees for each headline, and store them together with some basic information about the headline in the same object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e24b23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "author1[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7fafcee",
   "metadata": {},
   "source": [
    "Let's see what the numeric attributes for headlines written by this author look like. We're going to use [Pandas](http://pandas.pydata.org/) for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d355131d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df1 = pd.DataFrame.from_dict(author1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79f3e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effe8c81",
   "metadata": {},
   "source": [
    "From this information, we're going to extract the chunk type sequence of each headline (i.e. the first level of the parse tree) and use it as an indicator of the overall structure of the headline. So in the above example, we would extract and use the following sequence of chunk types in our analysis:\n",
    "\n",
    "```\n",
    "['NP', 'PP', 'NP', 'VP']\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7a5496",
   "metadata": {},
   "source": [
    "### Similarity\n",
    "\n",
    "We have loaded all the headlines written by the first author, and created and stored their parse trees. Next, we need to find a similarity metric that given two chunk type sequences, tells us how similar these two headlines are, from a structural perspective. \n",
    "\n",
    "For that we're going to use the SequenceMatcher class of difflib, which produces a similarity score between 0 and 1 for any two sequences (Python lists):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f7d741",
   "metadata": {},
   "outputs": [],
   "source": [
    "import difflib\n",
    "print \"Similarity scores for...\\n\"\n",
    "print \"Two identical sequences: \", difflib.SequenceMatcher(None,[\"A\",\"B\",\"C\"],[\"A\",\"B\",\"C\"]).ratio()\n",
    "print \"Two similar sequences: \", difflib.SequenceMatcher(None,[\"A\",\"B\",\"C\"],[\"A\",\"B\",\"D\"]).ratio()\n",
    "print \"Two completely different sequences: \", difflib.SequenceMatcher(None,[\"A\",\"B\",\"C\"],[\"X\",\"Y\",\"Z\"]).ratio()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a3d6bc",
   "metadata": {},
   "source": [
    "Now let's see how that works with our chunk type sequences, for two randomly selected headlines from the first author:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac08192",
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = author1[3][\"title_chunks\"]\n",
    "v2 = author1[1][\"title_chunks\"]\n",
    "\n",
    "print v1, v2, difflib.SequenceMatcher(None,v1,v2).ratio()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2aaa1f",
   "metadata": {},
   "source": [
    "### Pair-wise similarity matrix for the headlines\n",
    "\n",
    "We're now going to apply the same sequence similarity metric to all of our headlines, and create a 700x700 matrix of pairwise similarity scores between the headlines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84eb4540",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "chunks = [author[\"title_chunks\"] for author in author1]\n",
    "m = np.zeros((700,700))\n",
    "for i, chunkx in enumerate(chunks):\n",
    "    for j, chunky in enumerate(chunks):\n",
    "        m[i][j] = difflib.SequenceMatcher(None,chunkx,chunky).ratio()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6512da8b",
   "metadata": {},
   "source": [
    "### Visualization\n",
    "\n",
    "To make things clearer and more understandable, let's try and put all the headlines written by the first author on a 2d scatter plot, where similarly structured headlines are close together.\n",
    "\n",
    "For that we're going to first use tSNE to reduce the dimensionality of our similarity matrix from 700 down to 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804445a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "tsne_model = TSNE(n_components=2, verbose=1, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c87a687",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = tsne_model.fit_transform(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091beefc",
   "metadata": {},
   "source": [
    "And to add a bit of color to our visualization, let's use K-Means to identify 5 clusters of similar headlines, which we will use in our visualization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c3de1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import MiniBatchKMeans\n",
    "\n",
    "kmeans_model = MiniBatchKMeans(n_clusters=5, init='k-means++', n_init=1, \n",
    "                         init_size=1000, batch_size=1000, verbose=False, max_iter=1000)\n",
    "kmeans = kmeans_model.fit(m)\n",
    "kmeans_clusters = kmeans.predict(m)\n",
    "kmeans_distances = kmeans.transform(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6295780",
   "metadata": {},
   "source": [
    "Finally let's plot the actual chart using [Bokeh](http://bokeh.pydata.org/en/latest/):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b01bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bokeh.plotting as bp\n",
    "from bokeh.models import HoverTool, BoxSelectTool\n",
    "from bokeh.plotting import figure, show, output_notebook\n",
    "\n",
    "colormap = np.array([\n",
    "    \"#1f77b4\", \"#aec7e8\", \"#ff7f0e\", \"#ffbb78\", \"#2ca02c\", \n",
    "    \"#98df8a\", \"#d62728\", \"#ff9896\", \"#9467bd\", \"#c5b0d5\", \n",
    "    \"#8c564b\", \"#c49c94\", \"#e377c2\", \"#f7b6d2\", \"#7f7f7f\", \n",
    "    \"#c7c7c7\", \"#bcbd22\", \"#dbdb8d\", \"#17becf\", \"#9edae5\"\n",
    "])\n",
    "\n",
    "output_notebook()\n",
    "plot_author1 = bp.figure(plot_width=900, plot_height=700, title=\"Author1\",\n",
    "    tools=\"pan,wheel_zoom,box_zoom,reset,hover,previewsave\",\n",
    "    x_axis_type=None, y_axis_type=None, min_border=1)\n",
    "\n",
    "plot_author1.scatter(x=tsne[:,0], y=tsne[:,1],\n",
    "                    color=colormap[kmeans_clusters],\n",
    "                    source=bp.ColumnDataSource({\n",
    "                        \"chunks\": [x[\"title_chunks\"] for x in author1], \n",
    "                        \"title\": [x[\"title\"] for x in author1],\n",
    "                        \"cluster\": kmeans_clusters\n",
    "                    }))\n",
    "\n",
    "hover = plot_author1.select(dict(type=HoverTool))\n",
    "hover.tooltips={\"chunks\": \"@chunks (title: \\\"@title\\\")\", \"cluster\": \"@cluster\"}\n",
    "show(plot_author1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee10edc",
   "metadata": {},
   "source": [
    "The above interactive chart shows a number of dense groups of headlines, as well as some sparse ones. Some of the dense groups that stand out more are:\n",
    "\n",
    "- The **NP, VP** group on the left, which typically consists of short, snappy stock update headlines such as \"Viacom is crashing\";\n",
    "- The **VP, NP** group on the top right, which is mostly announcement headlines in the \"Here comes the...\" format; and\n",
    "- The **NP, VP, ADJP, PP, VP** group at bottom left, where we have headlines such as \"Industrial production **falls more than expected**\" or \"ADP private payrolls **rise more than expected**\".\n",
    "\n",
    "If you look closely you will find other interesting groups, as well as their similarities/disimilarities when compared to their neighbors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec598824",
   "metadata": {},
   "source": [
    "### Comparing the two authors\n",
    "\n",
    "Finally, let's load the headlines for the second author and see how they compare to the ones from the first one. The steps are quite similar to the above, except this time we're going to calculate the similarity of both sets of headlines and store it in a 1400x1400 matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c11367",
   "metadata": {},
   "outputs": [],
   "source": [
    "author2 = pickle.load( open( \"author2.p\", \"rb\" ) )\n",
    "for story in author2:\n",
    "    story[\"title_length\"] = len(story[\"title\"])\n",
    "    story[\"title_chunks\"] = [chunk.type for chunk in parsetree(story[\"title\"])[0].chunks]\n",
    "    story[\"title_chunks_length\"] = len(story[\"title_chunks\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3dc15e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.from_dict(author2).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "821c74f8",
   "metadata": {},
   "source": [
    "The basic stats don't show a significant difference between the headlines written by the two authors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230dc0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks_joint = [author[\"title_chunks\"] for author in (author1+author2)]\n",
    "m_joint = np.zeros((1400,1400))\n",
    "for i, chunkx in enumerate(chunks_joint):\n",
    "    for j, chunky in enumerate(chunks_joint):\n",
    "        sm=difflib.SequenceMatcher(None,chunkx,chunky)\n",
    "        m_joint[i][j] = sm.ratio()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d0fb3d",
   "metadata": {},
   "source": [
    "Now that we have analyzed the headlines for the second author, let's see how many common patterns exist between the two authors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7775ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "for story in author1:\n",
    "    story[\"title_length\"] = len(story[\"title\"])\n",
    "    story[\"title_chunks\"] = [chunk.type for chunk in parsetree(story[\"title\"])[0].chunks]\n",
    "    story[\"title_chunks_length\"] = len(story[\"title_chunks\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e385b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "set1= [author[\"title_chunks\"] for author in author1]\n",
    "set2= [author[\"title_chunks\"] for author in author2]\n",
    "list_new = [itm for itm in set1 if itm in set2]\n",
    "len(list_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6b4cd4",
   "metadata": {},
   "source": [
    "We observe that about 50% (347/700) of the headlines have a similar structure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4023c8",
   "metadata": {},
   "source": [
    "### Visualization of headlines by the two authors\n",
    "\n",
    "Our approach here is quite similar to what we did for the first author. The only difference is that here we're going to use colors to indicate the _author_ and not the cluster this time (blue for author1 and orange for author2)."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
