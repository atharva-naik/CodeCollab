{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39e16e8b",
   "metadata": {},
   "source": [
    "# Mercari Price Suggestion Challenge\n",
    "\n",
    "For the Kaggle competition \"Mercari Price Suggestion Challenge,\" we were tasked to write code to predict prices. This is my suggestion. There are three steps: \n",
    "\n",
    "1. EDA\n",
    "2. Data Engineering\n",
    "3. Machine Learning\n",
    "\n",
    "The challenge was completed in mid-February of 2018 and I scored among the top 60% of over 2300 sbumission. This was my first ever Kaggle competition. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8b2fe8",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis\n",
    "\n",
    "The data is organized accordingly:\n",
    "\n",
    "- train_id or test_id - the id of the listing\n",
    "- name - the title of the listing\n",
    "- item_condition_id - the condition of the items provided by the seller\n",
    "- category_name - category of the listing\n",
    "- brand_name\n",
    "- price - the price that the item was sold for, also the **target variable**\n",
    "- shipping - 1 if shipping fee is paid by seller and 0 by buyer\n",
    "- item_description - the full description of the item\n",
    "\n",
    "The first natural step is to look at the distribituion of prices.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27252325",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from wordcloud import WordCloud\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import svm\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "test=pd.read_csv(\"C:/Users/Malte/Documents/My repositories/Mercari/test.tsv\",sep=\"\\t\")\n",
    "\n",
    "train=pd.read_csv(\"C:/Users/Malte/Documents/My repositories/Mercari/train.tsv\",sep=\"\\t\")\n",
    "\n",
    "train.fillna(\"\",inplace=True)\n",
    "test.fillna(\"\",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc23b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,(ax) = plt.subplots(1,2,figsize=(10,5))\n",
    "sns.distplot(train[\"price\"],ax=ax[0],axlabel=\"Price Distribution\")\n",
    "sns.distplot(np.log1p(train[\"price\"]),ax=ax[1],axlabel=\"Log1p Price Distribution\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b718e20e",
   "metadata": {},
   "source": [
    "Looking at the price distribution, two observations become clear:\n",
    "\n",
    "1. The bulk of the prices are lower.\n",
    "2. Transforming the prices logarithmically, we can see that that the distribtuion is slightly positively skewed. \n",
    "\n",
    "Let's look at prices now and how they are affected whether shipping is included or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b91540a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x=\"shipping\",y=\"price\",data=train,ci=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ba4255",
   "metadata": {},
   "source": [
    "Shipping does seem to have a slight effect on pricing. \n",
    "\n",
    "What about the condition of the item?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c69097a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x=\"item_condition_id\",y=\"price\",data=train,ci=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c054e467",
   "metadata": {},
   "source": [
    "The item condition does not have the expected effect on prices."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85e7579",
   "metadata": {},
   "source": [
    "We are looking at the item prices in a very broad manner. Let's look at categories in greater detail to gain a deeper understanding. The data comes with uncategorized category names, that is, each category looks like the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118d015d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print train[\"category_name\"][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ea75ad",
   "metadata": {},
   "source": [
    "In order to work with the categories more effectively, we have to change the data to separate the main category and the two subcategories. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2114402",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cat_split(row):\n",
    "    try:\n",
    "        txt1, txt2, txt3 = row.split('/')\n",
    "        return row.split('/')\n",
    "    except:\n",
    "        return (\"No Label\", \"No Label\", \"No Label\")\n",
    "\n",
    "train[\"cat_1\"], train[\"cat_2\"], train[\"cat_3\"] = zip(*train[\"category_name\"].apply(lambda val: cat_split(val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e293d7c1",
   "metadata": {},
   "source": [
    "We can now look at the categories and price differences in greater detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3c251b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(1,1,figsize=(20,10))\n",
    "sns.barplot(x=\"cat_1\",y=\"price\",data=train,ax=ax,ci=None)\n",
    "ax.set(xlabel=\"Main Catgory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ac9259",
   "metadata": {},
   "source": [
    "There does seem to be quite a variety of prices between the categories.\n",
    "\n",
    "Since you can describe each item by putting it into two further subcategories, we are going to look at the types of these subcategories. For both, we will use the ten most occuring labels and display their average price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3475c58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_x_by_mean_price(df,cat,x):\n",
    "    most_freq_items=df[cat].value_counts()\n",
    "    most_freq_items=list(most_freq_items.index[:x])\n",
    "    if \"\" in most_freq_items:\n",
    "        most_freq_items.remove(\"\")\n",
    "    df_top_10=df[df[cat].isin(most_freq_items)]\n",
    "    df_top_10=df_top_10.groupby(cat)\n",
    "    df_top_10_by_price= df_top_10[\"price\"].mean().reset_index()\n",
    "    df_top_10_by_price.sort_values(\"price\",ascending=False,inplace=True)\n",
    "    fig,ax=plt.subplots(figsize=(x+10,10))\n",
    "    ax.set_title(\"Top {} {} by occurence, sorted by mean article value\".format(str(x),cat))\n",
    "    sns.barplot(x=cat,y=\"price\",data=df_top_10_by_price,ax=ax,ci=None)\n",
    "    \n",
    "top_x_by_mean_price(train,\"cat_2\",10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9f7c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_x_by_mean_price(df,cat,x):\n",
    "    most_freq_items=df[cat].value_counts()\n",
    "    most_freq_items=list(most_freq_items.index[:x])\n",
    "    if \"\" in most_freq_items:\n",
    "        most_freq_items.remove(\"\")\n",
    "    df_top_10=df[df[cat].isin(most_freq_items)]\n",
    "    df_top_10=df_top_10.groupby(cat)\n",
    "    df_top_10_by_price= df_top_10[\"price\"].mean().reset_index()\n",
    "    df_top_10_by_price.sort_values(\"price\",ascending=False,inplace=True)\n",
    "    fig,ax=plt.subplots(figsize=(x+10,10))\n",
    "    ax.set_title(\"Top {} {} by occurence, sorted by mean article value\".format(str(x),cat))\n",
    "    sns.barplot(x=cat,y=\"price\",data=df_top_10_by_price,ax=ax,ci=None)\n",
    "    \n",
    "top_x_by_mean_price(train,\"cat_3\",10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "234b9353",
   "metadata": {},
   "source": [
    "Categories definitely play a role, which is why we need to prepare them for our machine learning algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90045b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorizer(df,col):\n",
    "    df[col]=df[col].astype(\"category\")\n",
    "    df[col]=df[col].cat.codes\n",
    "    return df\n",
    "\n",
    "for e in [\"brand_name\",\"cat_1\",\"cat_2\",\"cat_3\"]:\n",
    "    categorizer(train,e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7026eb0f",
   "metadata": {},
   "source": [
    "These kind of platforms also rely on descriptions of their products. Let's take a look first and see whether having descriptions or not makes a difference in price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11cf7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def described(x):\n",
    "    if \"description yet\" in x:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "train[\"has_description\"]=train[\"item_description\"].apply(lambda x: described(x))\n",
    "\n",
    "plt.figure(figsize=(20,15))\n",
    "plt.hist(train[\"price\"].loc[train[\"has_description\"]==True],label=\"Has Description\",bins=60,color=\"blue\",alpha=0.6,range=[0,250])\n",
    "plt.hist(train[\"price\"].loc[train[\"has_description\"]==False],label=\"Does not have Description\",bins=60,alpha=0.6,range=[0,250])\n",
    "plt.legend()\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03977073",
   "metadata": {},
   "source": [
    "The distributions are smiliar, which tells us that there are simply more items without descriptions. Let's look at the lengths of the descriptions now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a08c729",
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"desc_length\"]=train[\"item_description\"].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693d1692",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(\"price\",\"desc_length\",data=train,fit_reg=True,scatter_kws={'alpha':0.3},aspect=1,size=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e32425c",
   "metadata": {},
   "source": [
    "There seems to be a minimal correlation at best. \n",
    "\n",
    "One more thing to examine is the term frequency-inverse document frequency, that is how often a word appears relative to the overall number of words in the document. Another way of looking at it is, how rare a word is. Let's start with a wordcloud first."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
