{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "600ebaa3",
   "metadata": {},
   "source": [
    "# Predicting Diabetes in the Pima People"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4951f304",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pandas for data manipulation\n",
    "import pandas as pd\n",
    "\n",
    "#import data\n",
    "data = pd.read_csv('diabetes.csv')\n",
    "\n",
    "#change float64 values to integers for comparisons to work correctly\n",
    "data.loc[:,['BMI','DiabetesPedigreeFunction']]=data.loc[:,['BMI','DiabetesPedigreeFunction']].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5c08ad",
   "metadata": {},
   "source": [
    "After reviewing the dataset, there were no missing datapoints as None or NaN. However, many of the features are indeed physical attributes and there are many 0 values. With the columns for glucose (concentration in blood), blood pressure, skin thickness, insulin (concentration in blood), BMI (a height and weight measurement), and age I decided if 3 or more of these are 0 in any row then they should be left out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499b7095",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for columns glucose through age, remove rows with 3 or more 0's across those columns\n",
    "data = data.loc[(data.loc[:,'Glucose':'Age']==0).sum(axis=1)<3,:]\n",
    "\n",
    "#split independent and dependent\n",
    "x = data.iloc[:,0:8].values\n",
    "y = data.iloc[:,8].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb43ef4",
   "metadata": {},
   "source": [
    "To prevent a warning when scaling, the x variable will by transformed to float."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f142e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#change all x values to float for imputing and scaling\n",
    "x = x.astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f849e1",
   "metadata": {},
   "source": [
    "Now that the rows with 3 or more 0 values in the aforementioned column are gone, I assumed it to be safe to replace the remaining few 0 values with the sample mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b51ecf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace remaining glucose and skin thickness 0's with the respective mean's\n",
    "from sklearn.preprocessing import Imputer\n",
    "xputer = Imputer(missing_values = 0, strategy = 'mean', axis = 0)\n",
    "xputer = xputer.fit(x[:,[1,3]])\n",
    "x[:,[1,3]] = xputer.transform(x[:,[1,3]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6006390",
   "metadata": {},
   "source": [
    "The data is now ready to be split into training and test sets, then features scaled to build the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8621ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train test split\n",
    "from sklearn.cross_validation import train_test_split\n",
    "xtrain,xtest,ytrain,ytest = train_test_split(x,y,test_size=0.2, random_state=1)\n",
    "\n",
    "\n",
    "#feature scaling x\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "xscaler = StandardScaler()\n",
    "xtrain = xscaler.fit_transform(xtrain)\n",
    "xtest = xscaler.transform(xtest)\n",
    "\n",
    "#fit model\n",
    "from sklearn.svm import SVC\n",
    "classifier = SVC(kernel='linear')\n",
    "classifier.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83d6ade",
   "metadata": {},
   "source": [
    "With the classifier trained, we are ready to make predictions on the test set!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8fa2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict\n",
    "ypred = classifier.predict(xtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4413ab",
   "metadata": {},
   "source": [
    "Using the confusion matrix we can see how will it performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be8eafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(ytest,ypred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700be166",
   "metadata": {},
   "source": [
    "Let's see this as a score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4badec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#single score\n",
    "score = classifier.score(xtest,ytest)\n",
    "print('single score: {0:.2f}%'.format(score*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f5a66e",
   "metadata": {},
   "source": [
    "In this instance the classifier does a very decent job of predicting the outcomes correctly. Now we will see a more realistic score with 5 fold cross validation."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
