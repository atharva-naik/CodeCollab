{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0124aea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from os import path\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.colors\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "import missingno as mn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95915f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.reset_option('display.float_format')\n",
    "\n",
    "my_cmap = ListedColormap(sns.color_palette().as_hex())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86bf7e09",
   "metadata": {},
   "source": [
    "### Import Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e107ae",
   "metadata": {},
   "source": [
    "First, we will import all of our datasets into a single dictionary for convenience:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cceca8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fd = ['..','data','raw']\n",
    "\n",
    "data = {}\n",
    "fn_list = ['orders.csv', 'products.csv', 'order_products__prior.csv', 'order_products__train.csv', 'departments.csv', 'aisles.csv']\n",
    "\n",
    "for fn in fn_list:\n",
    "    fp = path.join(*fd, fn)\n",
    "\n",
    "    with open(file=fp, mode='r', encoding='utf8') as file:\n",
    "        import re\n",
    "        label = re.sub('\\.csv$', '', fn)\n",
    "        data[label] = pd.read_csv(file, encoding='utf8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03340e6b",
   "metadata": {},
   "source": [
    "Checking the size of each dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620051fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in data.items():\n",
    "    print('{}: {} rows, {} columns; {} null values'.format(k, v.shape[0], v.shape[1], v.isnull().sum().sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cfc074a",
   "metadata": {},
   "source": [
    "High volume of data on the mangitude of millions for the order/product tables. Prior data has 32 million records, which may pose problems for performance during evaluation. Worth considering methods of reducing the dimensionality."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c262784",
   "metadata": {},
   "source": [
    "### Null Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7794d23f",
   "metadata": {},
   "source": [
    "Will check to see why we are missing values in the orders table:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24eae3ac",
   "metadata": {},
   "source": [
    "Moving on to the days since prior order column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789ac95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['orders']['days_since_prior_order'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b878d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "\n",
    "ax = sns.distplot(data['orders'].dropna()['days_since_prior_order'], )\n",
    "\n",
    "ax.set_title('Distribution of Days Since Last Order')\n",
    "ax.set_xlabel('Days Since Last Order')\n",
    "ax.set_ylabel('Density')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c3ac8c",
   "metadata": {},
   "source": [
    "We can see that the majority of re-orders happen in the 0-10 day range. Again, we have an unnatural peak at the maximum value of 30 days, suggesting that this value was clipped for larger values. It may be necessary to discount this disproportionate volume of orders at 30 days."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cecd9b5d",
   "metadata": {},
   "source": [
    "Taking a look at the possible changes in mean time intervals between orders and the number of orders placed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b98dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "\n",
    "ax = data['orders'].groupby('order_number')['days_since_prior_order'].mean().plot(label='Mean')\n",
    "ax.fill_between(x = data['orders'].groupby('order_number')['days_since_prior_order'].std().index.values,\n",
    "                 y1 = data['orders'].groupby('order_number')['days_since_prior_order'].mean() - data['orders'].groupby('order_number')['days_since_prior_order'].std(),\n",
    "                 y2 = data['orders'].groupby('order_number')['days_since_prior_order'].mean() + data['orders'].groupby('order_number')['days_since_prior_order'].std(),\n",
    "                 alpha=0.2, label='St. Dev.')\n",
    "\n",
    "ax.set_title('Mean Days Between Orders vs. Order Number')\n",
    "ax.set_xlabel('Order Number')\n",
    "ax.set_ylabel('Days Since Last Order')\n",
    "\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3387893a",
   "metadata": {},
   "source": [
    "The decay in time intervals between orders as well as its standard deviation with increasing order number aligns with the notion that long term customers begin shopping on more regular intervals. This could prove useful in building recommenders specific to the number of orders & timing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d04e848",
   "metadata": {},
   "source": [
    "### Basic Exploration: Order Products (Priors/Train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490829eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a temporary copy for convenience\n",
    "df = data['order_products__prior'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e091a9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277efe38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of orders\n",
    "df['order_id'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a435d195",
   "metadata": {},
   "source": [
    "Taking a look at the number of items per order (i.e. basket size):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126e43fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "\n",
    "ax = data_prior.groupby(['order_number', 'user_id'])['aisle_id'].nunique().unstack().mean(axis=1).plot(cmap=my_cmap)\n",
    "\n",
    "ax.set_title('Number of Aisles Shopped from vs. Order Number')\n",
    "ax.set_xlabel('Order Number')\n",
    "ax.set_ylabel('Mean Number of Aisles in Order')\n",
    "ax.set_ylim(0,8)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07f285e",
   "metadata": {},
   "source": [
    "We a similar trend with aisles, noting again that whilst there is a decrease over increasing order number the change is relatively small. Perhaps a stronger change can be observed at the individual product level:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4ceddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "\n",
    "ax = data_prior.groupby(['order_number', 'user_id'])['product_id'].nunique().unstack().mean(axis=1).plot(cmap=my_cmap)\n",
    "\n",
    "ax.set_title('Number of Unique Products in Order vs. Order Number')\n",
    "ax.set_xlabel('Order Number')\n",
    "ax.set_ylabel('Mean Number of Unique Products in Order')\n",
    "ax.set_ylim(0,12)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa655fa0",
   "metadata": {},
   "source": [
    "We do see a similar weak downward trend, but there is a noticeable bump around 40 order number mark which could be interpreted as customers experimenting with new products before focusing back on a consistent set of purchases. All of these trends are relatively weak however so it is hard to make any hard conclusions.\n",
    "\n",
    "Looking at the reorder rates over time (i.e. order number) may provide a stronger impression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c043ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "\n",
    "ax = data_prior[data_prior['order_number'] > 1].groupby(['order_number', 'user_id'])['reordered'].mean().unstack().mean(axis=1).plot(cmap=my_cmap)\n",
    "\n",
    "ax.set_title('Mean Reorder Rate vs. Order Number')\n",
    "ax.set_xlabel('Order Number')\n",
    "ax.set_ylabel('Mean Reorder Rate')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ebaf47",
   "metadata": {},
   "source": [
    "We can see that starting at around 20 orders user reorder rates stabalize in the 0.7-0.8 range, meaning 70-80% of items ordered are reorders. We do not know if these reorders are consistently the same items, but is still does show us the establishment of a consistent purchase habit beginning at 20 orders. In the context of a recommender system, it may prove useful to prioritize past ordered items more as a customer reaches this mark."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033fae44",
   "metadata": {},
   "source": [
    "To help fill in some of the unknowns with consistent ordering habits, we will take a look at how the set of unique purchases develops as the customer places subsequent orders:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13314ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data = data_prior.drop_duplicates(subset=['user_id', 'product_id']).groupby(['order_number','user_id'])['product_id'].count().unstack().cumsum().bfill()\n",
    "\n",
    "mu = plot_data.mean(axis=1)\n",
    "std = plot_data.std(axis=1)\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "\n",
    "ax = mu.plot()\n",
    "ax.fill_between(std.keys(), mu - std.values, mu + std.values, alpha=0.2)\n",
    "\n",
    "ax.set_ylim(bottom=0)\n",
    "ax.set_title('Cumulative Number of Unique Products Ordered vs. Order Number')\n",
    "ax.set_xlabel('Order Number')\n",
    "ax.set_ylabel('Mean Cumulative Count')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b15a64",
   "metadata": {},
   "source": [
    "It is important to note that in removing duplicates for the cumulative count approach above, values had to be backfilled so there is a certain amount of interpolation and smoothening which has introduced into this view. Regardless, the overall trend should remain true, which we can see shows a gradual decrease in the rate at which new products are ordered. There is an odd peak right at the end of this curve, but this is likely an artifact of the limited number of order data at the largest order numbers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9378fd7",
   "metadata": {},
   "source": [
    "Moving on to distributions of orders over time of day/week, we can perform a few views utilizing violin plots to see if there are some noticeable variations in demand for different departments over the course of the week:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999758fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,7))\n",
    "ax = sns.violinplot(data=data_prior.sample(int(1e5)), x='department', y='order_dow', cut=1, scale='area', bw=0.25)\n",
    "\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=50)\n",
    "ax.set_title('Distribution of Order Times by Department')\n",
    "ax.set_xlabel('Department')\n",
    "ax.set_ylabel('Day of Week')\n",
    "\n",
    "ax.set_yticks(np.arange(0,7,1))\n",
    "ax.set_yticklabels(['Sun', 'Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4a2cb2",
   "metadata": {},
   "source": [
    "We can notice a few variations in peaks between different departments and days of the week. We see the previously observed increases in demand on Sunday and Monday across most departments, and some departments have unique peaks such as \"bulk\" on Wednesday. However, overall this plot is bit difficult to discern between in terms of singling out strong variations so perhaps separating out our weekdays from weekends and analyzing demand by hour proves more useful:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459ae103",
   "metadata": {},
   "source": [
    "Let us see how our non-ID numerical fields are distributed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beae7636",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "data['orders'].drop(['order_id', 'user_id'], axis=1).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918b2505",
   "metadata": {},
   "source": [
    "Worth noting some of the ranges/scales:\n",
    "- order_number: initiates at 1 vs. 0\n",
    "- order_dow: 0-6, unclear if on a Mon-Sun or Sun-Sat schedule.\n",
    "- order_hour_of_day: 0-23 scale (military time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0aaa831",
   "metadata": {},
   "source": [
    "Taking a more intuitive view of distributions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9adb79ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "\n",
    "# Countplot of orders per dow\n",
    "ax = sns.countplot(x=data['orders']['order_dow'], palette='GnBu', edgecolor='k')\n",
    "\n",
    "# Format plot\n",
    "ax.set_title('Count of Orders by Day')\n",
    "ax.set_xlabel('Day of Week')\n",
    "ax.set_ylabel('Count')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9386632",
   "metadata": {},
   "source": [
    "It is still unknown as to whether this scale represent Mon-Sun or Sun-Sat, but perhaps future analysis of purchase behavior can help indicate which is more likely. Initial conjecture based of counts above would be that the largest volume of purchases happen Sunday/Monday versus Monday/Tuesday, but we will ultimately need to see if other data supports this hypothesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17749e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "\n",
    "# Countplot of orders per hour of day\n",
    "ax = sns.countplot(x=data['orders']['order_hour_of_day'], palette='GnBu', edgecolor='k')\n",
    "\n",
    "# Format plot\n",
    "ax.set_title('Count of Orders by Hour of Day')\n",
    "ax.set_xlabel('Hour (0-24)')\n",
    "ax.set_ylabel('Count')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50735acc",
   "metadata": {},
   "source": [
    "Two slights humps in the late morning and afternoon, but as a whole the majority of orders are focused around the 9AM-5PM interval."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5da794",
   "metadata": {},
   "source": [
    "Taking a look at the same distribution split by day:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10161e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(4,2, figsize=[12,12], sharey=True)\n",
    "\n",
    "# Plot orders counts for each dow\n",
    "for dow in range(7):\n",
    "    ax = axs.flatten()[dow]\n",
    "    sns.countplot(x=data['orders'][data['orders']['order_dow'] == dow]['order_hour_of_day'], palette='GnBu', edgecolor='k', ax=ax)\n",
    "    ax.set_title('Day = {}'.format(dow))\n",
    "\n",
    "# delete last subplot (odd number of plots since dow=7)\n",
    "fig.delaxes(axs.flatten()[-1])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd6c632",
   "metadata": {},
   "source": [
    "Days 0 and 6 appear to share a somewhat similar pattern of a single hump in orders towards the afternoon, whereas all other days show the double maximums in the morning/afternoon observed earlier. This could further suggest that day 0 is Sunday (and 6 is Saturday)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a010c2d9",
   "metadata": {},
   "source": [
    "Moving on to orders and users:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a72abc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of basket sizes above 20\n",
    "print(sum(df['order_id'].value_counts() > 20))\n",
    "\n",
    "# % orders with basket sizes above 20\n",
    "print(sum(df['order_id'].value_counts() > 20)/df['order_id'].nunique() * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92b3abe",
   "metadata": {},
   "source": [
    "Fortunately this seems to be limited to just 20 out of our 3+ million orders. Extending our search to basket sizes above 50 yields just over 3,000 orders, which still only comprises 0.1% of our data. Once we reach basket of sizes of 20, however, we start seeing a considerable portion of data (approx. 10%). It may be worth keeping the potential for large basket sizes in consideration, particularly when working with association rules."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477796e0",
   "metadata": {},
   "source": [
    "It is possible that these large basket sizes are a result of certain products beings ordered in large quantities (e.g. 10-20 of the same item being added vs 10-20 unique products):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4161c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count of orders with duplicate product ids\n",
    "sum(df.groupby(['order_id','product_id'])['product_id'].count() > 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515f5181",
   "metadata": {},
   "source": [
    "No orders exist in which the same product is accounted for more than once, indicating that the quantity of an item ordered is not captured."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6e93e1",
   "metadata": {},
   "source": [
    "Moving on to the products purchased:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2681ef32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of unique products present in orders\n",
    "df['product_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8ef0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Purchase counts per individual product\n",
    "df['product_id'].value_counts().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef6c93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of products only purchased once\n",
    "sum(df['product_id'].value_counts() == 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef9c4c80",
   "metadata": {},
   "source": [
    "The majority of products have been purchased less than 100 times across our 3 million orders. Additionally, we have 131 products which have only been purchased once. Making recommendations for products with a limited history of purchase means relying solely on popularity of items will lead to some biased results.\n",
    "\n",
    "We also have some large outliers, with a maximum purchase count of 470k:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4374c001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Products with over 100k purchases\n",
    "sum(df['product_id'].value_counts() > 100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5f1cfe",
   "metadata": {},
   "source": [
    "15 products have been purchased over 100,000 times. We will need to look into what these extremely popular products are once we join this table with the product names."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8242e85c",
   "metadata": {},
   "source": [
    "### Basic Exploration: Products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ce5cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data['products'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69465112",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total number of unique products\n",
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ed2641",
   "metadata": {},
   "source": [
    "Compared to our order table, we can see that almost every product has at least 1 purchase with the exception of 11 items (46777 purchased vs. 49688 on record). Taking a look at what we are missing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec21146",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create temp merged dataframe of products with order counts\n",
    "temp = pd.merge(data['products'], pd.DataFrame(data['order_products__prior'].groupby('product_id')['order_id'].count()).rename(columns={'order_id':'order_count'}), left_on='product_id', right_index=True, how='left').fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb73c45a",
   "metadata": {},
   "source": [
    "Taking a look out the items which were never ordered:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2271f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp[temp['order_count'] == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b903b3d5",
   "metadata": {},
   "source": [
    "Nothing immediately discernable from these items, but we can guess that these are likely niche products. As for the most popular products identified earlier with order counts on the magnitidue of 100k:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9675477",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp.sort_values(by='order_count', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf2af5a",
   "metadata": {},
   "source": [
    "Here we see that produce (fruits/vegetables) are clearly dominating in order counts. We have not taken a focused look at aisle/department counts just yet, but it is already evident that department 4 and aisle 24 are likely to be the most popular and reoccuring."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4c5387",
   "metadata": {},
   "source": [
    "Looking through some of the product names listed above, it is evident hat we have a lot of similar items with slight variations (e.g. bananas vs. bag of organic bananas). If we explore some products sharing the same words/naming:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e6886b",
   "metadata": {},
   "source": [
    "Whilst we have not looked at the aisles just yet, this cleaning effort may also be further complicated if aisle information is also missing. Looking at records missing department and (potentially) not missing aisle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c356b0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aisle ID for missing\n",
    "data['aisles'][data['aisles']['aisle'] == 'missing']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462e501a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of missing departments not missing aisle\n",
    "sum((temp['department'] == 'missing') & (temp['aisle_id'] != 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e035d40f",
   "metadata": {},
   "source": [
    "Every instance of missing department is also missing aisle, so this will at least double the effort required in trying to interpret and assign both correct department and aisles to these items."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b62b57",
   "metadata": {},
   "source": [
    "### Basic Exploration: Aisles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c793ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data['aisles'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8498208",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b235f2b",
   "metadata": {},
   "source": [
    "We have 134 aisles to work with. Performing a similar analysis of order distribution across aisles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab39e30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.merge(data['products'], data['departments'], on='department_id').merge(data['aisles'], on='aisle_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b00568",
   "metadata": {},
   "outputs": [],
   "source": [
    "depts = temp['department'].unique()\n",
    "depts.sort()\n",
    "\n",
    "n_cols = 3\n",
    "n_rows = len(depts)//n_cols\n",
    "fig, axs = plt.subplots(n_rows, n_cols, figsize=(5*n_cols,10*n_cols))\n",
    "\n",
    "for i, dept in enumerate(depts):\n",
    "    mask = temp['department'] == dept\n",
    "    ax = axs.flatten()[i]\n",
    "    temp[mask]['aisle'].value_counts().plot.bar(ax=ax)\n",
    "    ax.set_title('Product Counts: {}'.format(dept.title()))\n",
    "    ax.set_xlabel('Aisle')\n",
    "    ax.set_ylabel('Number of Products')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7afa6194",
   "metadata": {},
   "source": [
    "We will refrain from exploring the details of each aisle in too much depth, but we can at least see that within any department there are typically 1-3 aisles with the largest proportion of products. Repeating the above view with the number of products ordered within each aisle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff3bc60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of basket sizes above 100\n",
    "sum(df['order_id'].value_counts() > 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d23689a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of basket sizes above 50\n",
    "print(sum(df['order_id'].value_counts() > 50))\n",
    "\n",
    "# % orders with basket sizes above 50\n",
    "print(sum(df['order_id'].value_counts() > 50)/df['order_id'].nunique() * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a262ba6b",
   "metadata": {},
   "source": [
    "Out of curiosity we will see how many reorders we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a4aec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['reordered'].value_counts() / df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2dd28e1",
   "metadata": {},
   "source": [
    "Approximeately 59% of the ordered items are reorders. This a good initial indicator that building recommendations of previously ordered items may prove succesful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f89d250",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['orders']['user_id'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a713145b",
   "metadata": {},
   "source": [
    "As mentioned on the Kaggle page, we are working with just over 200,000 users. Looking at the number of orders each user has on record:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ec4123",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['orders']['user_id'].value_counts().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ab94e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "\n",
    "# Distribution of orders per user, default bins = 20\n",
    "ax = sns.distplot(data['orders']['user_id'].value_counts(), kde=False)\n",
    "\n",
    "ax.set_title('Distribution of Order Counts per User')\n",
    "ax.set_xlabel('Number of Orders')\n",
    "ax.set_ylabel('Count')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9b5668",
   "metadata": {},
   "source": [
    "We can see that the number of orders strongly gravitates toward the 4-10 range, with 50% of users having placed 10 orders or less. It should also be noted that order numbers appear to be capped at 100 due to the unnatural peak in volume for the maximum value of 100 orders.\n",
    "\n",
    "Fortunately, with a minimum order count of 4 per user we have at least a basic guarantee of having some information for each user. However, the analysis above is working with the entire 3 datasets so we need to ensure our training (prior) dataset also has enough information per user:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5f68e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['product_name'].str.contains('[Bb]anana')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa60dbf3",
   "metadata": {},
   "source": [
    "In the case of 'Banana', we have 376 products with the word banana. This is not to say that all of these are products are similar or identical - for instance we have banana twin cakes versus bananas peppers which are two rather disparate items. However, there are few instances where there are minor variations of the same concept, or at the very least we see banana prevalent as a flavoring throughout these items. It may be beneficial to explore utilizing common word features to identify favorite tastes, for example in this context finding users who show a strong liking toward banana & banana flavored items to then recommend other items of similar or compatible flavors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa11b04",
   "metadata": {},
   "source": [
    "### Basic Exploration: Department"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a175e758",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data['departments'].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ae6cd2",
   "metadata": {},
   "source": [
    "Departments appear to be a broad categorization of products, with 21 possibilities. Let us first take a look at how many products we have in each department:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4cc8691",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.merge(data['products'], data['departments'], on='department_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac0f822",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "\n",
    "ax = temp.groupby('department')['product_id'].nunique().sort_values(ascending=False).plot.bar()\n",
    "\n",
    "ax.set_title('Number of Products per Department')\n",
    "ax.set_xlabel('Department')\n",
    "ax.set_ylabel('Number of Products')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a9b973",
   "metadata": {},
   "source": [
    "Next let us join this table with our orders to see how purchases are distributed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9124cc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.merge(data['order_products__prior'], data['products'], on='product_id').merge(data['departments'], on='department_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3da2815",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d10437",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "\n",
    "ax = temp['department'].value_counts().sort_values(ascending=False).plot.bar()\n",
    "\n",
    "ax.set_title('Number of Products Ordered per Department')\n",
    "ax.set_xlabel('Department')\n",
    "ax.set_ylabel('Count')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af82e94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# % of orderered items comprising produce or dairy/eggs\n",
    "sum(((temp['department'] == 'produce') | (temp['department'] == 'dairy eggs'))) / temp.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab71a19",
   "metadata": {},
   "source": [
    "Produce and dairy/eggs are clearly the dominating departments, making up 46% of ordered items. Compared to our original product counts per department, we can see that whilst the most products available are in personal care, they actually constitue a small fraction of purchases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a32dfa2",
   "metadata": {},
   "source": [
    "We can try to capture a rough essence of popularity by weighing these purchase counts against the proportion of products available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a186d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "\n",
    "# Plot product order counts per department as fraction of total products available in said department\n",
    "ax = (temp['department'].value_counts().sort_index() / temp.groupby('department')['product_id'].nunique().sort_index()).sort_values(ascending=False).plot.bar()\n",
    "\n",
    "ax.set_title('Weighted Department Popularity')\n",
    "ax.set_xlabel('Department')\n",
    "ax.set_ylabel('Relative Popularity')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60546852",
   "metadata": {},
   "source": [
    "Whilst this view does not necessarily yield much insight with regards to our recommender system approach, it is interesting from a business perspective as to the approximate value/efficiency of stocking certain items. For example, even with the limited selection of produce relative to the number of personal care products, the amount of purchases and visibility of produce items greatly exceeds that of personal care items."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9c6df4",
   "metadata": {},
   "source": [
    "One concern worth noting before proceeding to aisle exploration is the \"missing\" department. Taking a look at some of the items in this department:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a366d9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['orders'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05dc7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['orders'].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4167f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['orders'][data['orders']['order_number'] != 1].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7091abd0",
   "metadata": {},
   "source": [
    "Null values are evidently a result of no prior orders existing. This is not something that necessarily needs to be fixed, but should be kept in mind during analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389095a4",
   "metadata": {},
   "source": [
    "### Basic Exploration: Orders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f7280c",
   "metadata": {},
   "source": [
    "Volume of data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92309168",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = data['orders'][data['orders']['eval_set'] == 'prior'].groupby(['user_id'])['order_id'].count()\n",
    "for i in range(3,11):\n",
    "    n = sum(N >= i)\n",
    "    print('Number of customers with >= {} orders: {} ({:.1f}%)'.format(i, n, n / N.shape[0] * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8581e33e",
   "metadata": {},
   "source": [
    "We can see that at a cut-off of 10 or more orders we are only left with just under 50% of our original set of customers. Considering our large dataset size, however, it may be worthwhile for the sake of performance to limit ourselves to such a minimum. At the very least, the minimum of 5 orders still leaves us with almost 80% of customers to work with. Translating these possibilities to our total number of orders to be processed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1928c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_orders = data['orders'][data['orders']['eval_set'] == 'prior'].groupby(['user_id'])\n",
    "for i in range(3,11):\n",
    "    users = (user_orders['order_id'].count() >= i)\n",
    "    users = users[users==True]\n",
    "    n_orders = data['orders'][(data['orders']['eval_set'] == 'prior') & (data['orders']['user_id'].isin(users.keys()))].shape[0]\n",
    "    print('Number of orders using customers with >= {} orders: {} ({:.1f}%)'.format(i, n_orders, n_orders / data['orders'][data['orders']['eval_set'] == 'prior'].shape[0] * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b4aaff",
   "metadata": {},
   "source": [
    "Whilst a threshold of 10 orders resulted in losing half the customer base, we can see we still utilize over 80% of the orders on record. This somewhat mitigates concerns with potentially choosing such a threshold to reduce the volume of data we are dealing with and improve information available per customer, but at thresholds of 10 orders (and higher) it is still hard to justify losing half of the customer base in evaluation. The ultimate decision as to how much data is excluded will likely come down to performance constraints when modelling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506b5d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 90th percentile for number of purchases per product\n",
    "df['product_id'].value_counts().quantile(0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312a4f2e",
   "metadata": {},
   "source": [
    "As a whole, approximately 90% of products have been purchases 1,000 times or less. Relative to our dataset of 3 million orders, we will need to see how this sparsity translates to our recommendation capabilities. Simplifying products into broader categories may prove necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c1e813",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of products in 'missing' department\n",
    "temp[temp['department']=='missing']['product_name'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5710c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample of 'missing' department products\n",
    "temp[temp['department']=='missing']['product_name'].unique()[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70eadb57",
   "metadata": {},
   "source": [
    "These 'missing' department items do not seem to follow any consistent theme, with a variety of foods and beverages we would expect to find in some of our other department labels. It may be necessary to discard these items from our recommender, at least in scenarios where department is being leveraged in decisioning. Alternatively, we can attempt to assign appropriate labels based off our understanding of department definitions, but this is likely to be a highly manual process of involving the 1255 records. We also do not know if Instacart has intentionally marked these items as missing due to discontinuation of products or other unique circumstances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85128e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.merge(data['order_products__prior'], data['products'], on='product_id').merge(data['departments'], on='department_id').merge(data['aisles'], on='aisle_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7db59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "depts = temp['department'].unique()\n",
    "depts.sort()\n",
    "\n",
    "n_cols = 3\n",
    "n_rows = len(depts)//n_cols\n",
    "fig, axs = plt.subplots(n_rows, n_cols, figsize=(5*n_cols,10*n_cols))\n",
    "\n",
    "for i, dept in enumerate(depts):\n",
    "    mask = temp['department'] == dept\n",
    "    ax = axs.flatten()[i]\n",
    "    (temp[mask]['aisle'].value_counts()).sort_values(ascending=False).plot.bar(ax=ax)\n",
    "    ax.set_title('Order Counts: {}'.format(dept.title()))\n",
    "    ax.set_xlabel('Aisle')\n",
    "    ax.set_ylabel('Number of Products Ordered')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97657e12",
   "metadata": {},
   "source": [
    "As with our departments, the most populated aisles do not necessarily correspond to the most purchased. For example, we can see that sparkling selzer water is much more succesful in terms of purchase quantity versus the number of products available."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac70f79",
   "metadata": {},
   "source": [
    "### Full Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6011f06",
   "metadata": {},
   "source": [
    "Build a dataframe with all 'prior' orders & products:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ff19b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['order_id'].value_counts().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614d4967",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "\n",
    "ax = sns.countplot(df['order_id'].value_counts())\n",
    "\n",
    "ax.set_xticks(np.arange(5,60,5))\n",
    "ax.set_xticklabels(np.arange(5,60,5))\n",
    "ax.set_xlim(right=60)\n",
    "\n",
    "ax.set_title('Distribution of Basket Size')\n",
    "ax.set_xlabel('Basket Size')\n",
    "ax.set_ylabel('Count')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed37f953",
   "metadata": {},
   "source": [
    "Majority of orders fall in the range of 1-10 items per order. It is also worth noting a select few basket sizes reach up to 100+ items (cut off from the graph above):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ae5a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['orders'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c8958e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['orders']['eval_set'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0c45a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['orders']['eval_set'].value_counts()/data['orders'].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a186854a",
   "metadata": {},
   "source": [
    "Prior and train translate to training and validation datasets, respectively. Models will be fit using the prior set, and optimized according performance on the train set. Test is the ultimate testing set for final performance evaluation of our recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e08e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['orders'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3a3fc4",
   "metadata": {},
   "source": [
    "Columns are described as follows:\n",
    "\n",
    "- order_id: unique ID for the order\n",
    "- user_id: unique ID for the user\n",
    "- eval_set: prior/train/test sets, as mentioned above\n",
    "- order_number: sequential order number for a given user (i.e. 1st order, 2nd order, etc.)\n",
    "- order_dow: day of the week on which order was placed\n",
    "- order_hour_of_day: hour of the day in which order was placed\n",
    "- days_since_prior_order: days since last order was placed. Value is NaN if first order (no prior order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4230c274",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['orders'][data['orders']['eval_set'] == 'prior']['user_id'].value_counts().describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696f893f",
   "metadata": {},
   "source": [
    "Our minimum number of orders per user in working with our training dataset is 3. In an ideal world we would want 10-20 observations per user, but we at least have more than 1 record per user (which in itself may contain multiple items ordered) to work with in producing recommendations, somewhat mitigating the cold start problem.\n",
    "\n",
    "Exploring how much of our customer base is available for each level of order quantities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207a8ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prior['product_id'].value_counts().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988df226",
   "metadata": {},
   "outputs": [],
   "source": [
    "npp = data_prior['product_id'].nunique()\n",
    "\n",
    "print('{}/{} products purchased (coverage = {:.2f}%)'.format(npp,data['products'].shape[0], 100*npp/data['products'].shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ab4ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pvc = data_prior['product_id'].value_counts()\n",
    "\n",
    "for i in range(1,11):\n",
    "    n = sum(data_prior['product_id'].value_counts() <= i) + 11\n",
    "    print('Number of products with <= {} purchases: {} ({:.2f}%)'.format(i, n, 100*n/data['products'].shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8db43a",
   "metadata": {},
   "source": [
    "Fortunately, only 11 products out of the 49k have never been purchased. However, we do have a number of products with a relatively sparse purchase history with over 8000 products having only been purchased 10 or fewer times. With respect to the overall set of products available this amounts to 16% of the product inventory having very limited interactions, which will prove challenging when aiming recommending such products."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d50637b",
   "metadata": {},
   "source": [
    "Taking a closer look at the distribution in customer purchases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5f9cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,2, figsize=(12,5))\n",
    "\n",
    "plot_data = data_prior.groupby('user_id')['product_id'].nunique()\n",
    "q_mask = plot_data < plot_data.quantile(.99)\n",
    "\n",
    "sns.distplot(plot_data, ax=axs[0])\n",
    "sns.distplot(plot_data[q_mask], ax=axs[1])\n",
    "\n",
    "for ax in axs:    \n",
    "    ax.set_xlabel('Number of Unique Products Purchased')\n",
    "    ax.set_ylabel('Density')\n",
    "\n",
    "axs[0].set_title('All Data')\n",
    "axs[1].set_title('99th Percentile')\n",
    "    \n",
    "fig.suptitle('Distribution of Unique Product Purchases per Customer')\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2af1d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prior.groupby('user_id')['product_id'].nunique().describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1943f98",
   "metadata": {},
   "source": [
    "In terms of unique products purchased, we seem to peak in range the 20-30 products purchased, with the major concentration of customers falling in the 25-85 range. In other words, we rarely see customers whose buying habits extend beyond a core set of products in this range. This can be interpeted in two ways: on the the one hand customers may be habitual in their purchase habits and prefer sticking to a core set of products they are familiar with (adding challenge to effective recommendations), but alternatively one can also argue that there is great potential to introduce customers to new products and increase coverage assuming they are willing to step outside their comfort zone.\n",
    "\n",
    "Extending this view to a level higher with aisles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbe10e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "\n",
    "ax = sns.distplot(data_prior.groupby('user_id')['aisle_id'].nunique())\n",
    "\n",
    "ax.set_title('Distribution of Aisle Purchases per Customer')\n",
    "ax.set_xlabel('Number of Aisles Purchased From')\n",
    "ax.set_ylabel('Density')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b5ce99",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prior.groupby('user_id')['aisle_id'].nunique().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2612cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['aisles']['aisle_id'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7f1f79",
   "metadata": {},
   "source": [
    "We again see a majroity of customers limiting themselves to a selection of aisles from which they purchase in the 10-40 range. Relative to the total number of aisles (134), this represents a much more diverse range which is to be expected given we are dealing with fewer options. It can still be argued, however, that customers seem to favor a certain selection of aisles in their shopping habits and are less likely to expand or explore all options.\n",
    "\n",
    "Repeating this view with distributions across departments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8310aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "\n",
    "# Plot as bar chart instead since we have a more limited list\n",
    "ax = data_prior.groupby('user_id')['department_id'].nunique().value_counts().sort_index().plot.bar(cmap=my_cmap)\n",
    "\n",
    "ax.set_title('Distribution of Department Purchases per Customer')\n",
    "ax.set_xlabel('Number of Departments Purchased From')\n",
    "ax.set_ylabel('Frequency')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f9470a",
   "metadata": {},
   "source": [
    "With departments we see a significant rightward shift in the distribution. This indicates that whilst for individual products and aisles customers tend to limit themselves to a smaller subset, the variety in departments from which customers shop tends to be more encompassing of all available departmenents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb7dc843",
   "metadata": {},
   "source": [
    "We can continue this analysis of shopping variety/coverage in looking at how purchase variety changes over time (i.e. order number):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d73fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "\n",
    "ax = data_prior.groupby(['order_number', 'user_id'])['department_id'].nunique().unstack().mean(axis=1).plot(cmap=my_cmap)\n",
    "\n",
    "ax.set_title('Number of Departments Shopped from vs. Order Number')\n",
    "ax.set_xlabel('Order Number')\n",
    "ax.set_ylabel('Mean Number of Departments in Order')\n",
    "ax.set_ylim(0,5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b123945f",
   "metadata": {},
   "source": [
    "We see a gradual, albeit relatively small, decrease in the mean number of departments in orders with increasing order numbers, which might suggest that customers hone in on their preferences and \"go-to's\" over time. Repeating this view for aisles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac8b097",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prior = pd.merge(data['orders'], data['order_products__prior'], on='order_id')\\\n",
    "               .merge(data['products'].merge(data['departments'], on='department_id').merge(data['aisles'], on='aisle_id'), on='product_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30886c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prior.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60caf7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prior.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6682a7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,2, figsize=(12,5))\n",
    "\n",
    "plot_data = data_prior['product_id'].value_counts()\n",
    "q_mask = plot_data < plot_data.quantile(.90)\n",
    "\n",
    "sns.distplot(plot_data, ax=axs[0])\n",
    "sns.distplot(plot_data[q_mask], ax=axs[1])\n",
    "\n",
    "for ax in axs:    \n",
    "    ax.set_xlabel('Number of Times Product was Purchased')\n",
    "    ax.set_ylabel('Density')\n",
    "\n",
    "axs[0].set_title('All Data')\n",
    "axs[1].set_title('90th Percentile')\n",
    "    \n",
    "fig.suptitle('Distribution of Product Purchase Counts')\n",
    "    \n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
