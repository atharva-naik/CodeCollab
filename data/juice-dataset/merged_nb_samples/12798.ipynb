{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e63ee7f",
   "metadata": {},
   "source": [
    "# Objective\n",
    "\n",
    "To reduce the number of dimensions of the Amazon food reviews dataset so that we can visualize it using a scatterplot. The plot should ideally distinguish between positive and negative reviews.\n",
    "\n",
    "I'm not building a classification model here. The goal is to apply t-SNE on various vector representation of the text data. I will use these models to vectorize text:\n",
    "\n",
    "\n",
    "*   Bag of Words (Unigram and Bigram)\n",
    "* Tfidf\n",
    "* Doc2Vec\n",
    "* Average W2V\n",
    "* Tfidf weighted W2V\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9f4f8c",
   "metadata": {},
   "source": [
    "As always, let's start by loading the files that we need. I'm working on Google Colab for this Exercise, since my laptop isn't powerful enough to handle the workload.\n",
    "\n",
    "To avoid having to upload data from local disk everytime the environment is disconnected, I'll be using Google Drive to store all the data and pickled models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4977b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/gdrive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5464fc",
   "metadata": {},
   "source": [
    "List files on the drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff54542",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # List all files present on google drive\n",
    "# import os\n",
    "# os.listdir('/gdrive/My Drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ed1f8c",
   "metadata": {},
   "source": [
    "Import needed libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e31e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sbn\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83bd39a4",
   "metadata": {},
   "source": [
    "The raw data is present in the form of a sqlite file. Let's retrieve it from google drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b28d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load sqlite database\n",
    "con = sqlite3.connect(r'/gdrive/My Drive/amazon/database.sqlite')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01671633",
   "metadata": {},
   "source": [
    "Since the aim here is to just visualize the positive and negative reviews, I select only the reviews that aren't neutral. It's a fair assumption that the reviews with score = 3 are neutral. We'll work with reviews that have score either 1,2,4 or 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c23631",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_vector_3k_tsne = tsne.fit_transform(X_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9601996",
   "metadata": {},
   "source": [
    "Shape of the numpy array after reducing the dimensions to two. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e551c143",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_vector_3k_tsne.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d546aa1",
   "metadata": {},
   "source": [
    "Pickle important variables again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6203bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Pickle it first!\n",
    "# import pickle\n",
    "# pickle_file = open('/gdrive/My Drive/amazon/pickled_3k_reviews_tsne_bigram.pkl', 'wb')\n",
    "# pickle.dump(review_vector_3k_tsne, pickle_file)\n",
    "# pickle_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e2d5da",
   "metadata": {},
   "source": [
    "Build dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088c5e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_tsne_3k_array = np.vstack((review_vector_3k_tsne.T, df_np['Score'])).T\n",
    "df_bigram_tsne_3k = pd.DataFrame(bigram_tsne_3k_array, columns=['First Dimension', 'Second Dimension', 'Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43caf47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bigram_tsne_3k.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33af6635",
   "metadata": {},
   "source": [
    "Plot the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293bd1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sbn.FacetGrid(df_bigram_tsne_3k, hue=\"Label\", size=6).map(plt.scatter, 'First Dimension', 'Second Dimension').add_legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c676baba",
   "metadata": {},
   "source": [
    "Unfortunately, using bigrams also does not yield anything useful. Let's look at TFIDF next."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb6b163",
   "metadata": {},
   "source": [
    "### Tfidf\n",
    "\n",
    "Term Frequency Inverse Document Frequency. \n",
    "\n",
    "Let's define the model and fit it to the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d8cd06",
   "metadata": {},
   "source": [
    "There are about half a million reviews in the original data file that are not neautral."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a226cc8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40f75f1",
   "metadata": {},
   "source": [
    "For this exercise, we want score to be a categorical feature.\n",
    "* Mark reviews with rating > 3 as positive\n",
    "* Mark reviews with rating < 3 as negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84257032",
   "metadata": {},
   "outputs": [],
   "source": [
    "m1 =  df['Score'] > 3 \n",
    "m2 =  df['Score'] < 3 \n",
    "\n",
    "df['Score'] = np.select([m1,m2], ['positive','negative'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c933760a",
   "metadata": {},
   "source": [
    "This is an imbalanced dataset. The number of positice reviews is almost 6 times the number of negative reviews!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c336047b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Score.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280c9bbd",
   "metadata": {},
   "source": [
    "Let's change the datatype of Score in our Pandas dataframe to 'Category'. Using Categories instead of the default 'Object' datatype leads to performance improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26581b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Score']=df['Score'].astype('category')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83457313",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aefa3698",
   "metadata": {},
   "source": [
    "Are there any duplicate rows in the dataset?\n",
    "Inspecting the \"Text\" column, we clearly see there are duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406cd0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated('Text').value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd88ff5c",
   "metadata": {},
   "source": [
    "There are also a few anomalies in the data where the HelpfulnessNumerator is greater than the helpfulnessDenominator. \n",
    "\n",
    "* HelpfulnessNumberator = Number of positive reviews\n",
    "* HelpfulnessDenominator = Number of positive reviews + Number of negative reviews\n",
    "\n",
    "Therefore, HelpfulnessDenominator can't be less than HelpfulnessNumerator.  We need to get rid of such erroneous records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9070bad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c21d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2f9dfb",
   "metadata": {},
   "source": [
    "Convert the sparse matrix to a dense numpy matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b660a49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_vector_3k = bigrams.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e90d9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_vector_3k.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "895d9922",
   "metadata": {},
   "source": [
    "Standardize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55d4144",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_scaled = scaler.fit_transform(review_vector_3k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144bacdb",
   "metadata": {},
   "source": [
    "At this point, memory is about to run out so let's store the variable on Google drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abae43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# pickle_file = open('/gdrive/My Drive/amazon/X_scaled_standardized_3k_bigram_bow_nparray.pkl', 'wb')\n",
    "# pickle.dump(X_scaled, pickle_file)\n",
    "# pickle_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448a0264",
   "metadata": {},
   "source": [
    "Load the pickled X_scaled file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87d62b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# file_path = open('/gdrive/My Drive/amazon/X_scaled_standardized_3k_bigram_bow_nparray.pkl', 'rb')\n",
    "# X_scaled = pickle.load(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5329b2b0",
   "metadata": {},
   "source": [
    "Create a t-SNE model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5b094c",
   "metadata": {},
   "source": [
    "Considering how long it takes for a modest computer to run the above code for cleaning data, it's a good idea to store it  on disk for future use. The entire dataframe along with the newly created column \"cleaned_data\" is stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f01207e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Save final cleaned dataframe to the drive.\n",
    "# conn = sqlite3.connect('/gdrive/My Drive/amazon/reviews_cleaned_final.sqlite')\n",
    "# df.to_sql('Reviews', conn)\n",
    "# conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b15bd1",
   "metadata": {},
   "source": [
    "If the environment was disconnected, load the cleaned dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a2306d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conn = sqlite3.connect('/gdrive/My Drive/amazon/reviews_cleaned_final.sqlite')\n",
    "# df = pd.read_sql('select * from Reviews;', conn, index_col='index')\n",
    "# conn.close()\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "698774e3",
   "metadata": {},
   "source": [
    "### Bag of words\n",
    "\n",
    "Let's vectorize the data using the simplest method first: BoW\n",
    "\n",
    "There is class imbalance in our original dataset. The positive reviews are far more than the negative ones. Let's take 1500 positive and 1500 negative samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce58c7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = df['Score'] == 'negative'\n",
    "p = df['Score'] == 'positive'\n",
    "#df_n = df[df['Score']]\n",
    "df_n = df[n][['cleaned_text','Score']][:1500]\n",
    "df_p = df[p][['cleaned_text', 'Score']][:1500]\n",
    "\n",
    "df_np = pd.concat([df_n, df_p])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33dc52ca",
   "metadata": {},
   "source": [
    "Initialize the CountVectorizer class which creates a Bag of Words representation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027b2e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vec = CountVectorizer()\n",
    "final_counts = count_vec.fit_transform(df_np['cleaned_text'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d95dd75",
   "metadata": {},
   "source": [
    "Type of the returned object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c78511",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The type of final_counts is {}'.format(type(final_counts)))\n",
    "print('The shape of the matrix is {}'.format(final_counts.get_shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb27d4d2",
   "metadata": {},
   "source": [
    "Convert the sparse matrix of Bag of Words model to a numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a8de8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_vector_3k = final_counts.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1433af2",
   "metadata": {},
   "source": [
    "Before applying t-SNE, it's necessary that we standardize our data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec409da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(review_vector_3k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc32d5d",
   "metadata": {},
   "source": [
    "Let's see the shape of of standardized data of BoW representation. It contains 3000 rows for 3000 reviews and 7207 dimensions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e411eb",
   "metadata": {},
   "source": [
    "These are some dimensions in the tfidf representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bce2707",
   "metadata": {},
   "outputs": [],
   "source": [
    "features[100:110]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6e2068",
   "metadata": {},
   "source": [
    "Convert the tfidf matrix to a dense numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d00b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_vector_3k_TFIDF=tfidf.toarray()\n",
    "review_vector_3k_TFIDF.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802549ca",
   "metadata": {},
   "source": [
    "Standardize the tfidf data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdcbdd7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9af5eed",
   "metadata": {},
   "source": [
    "Apply t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35323b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "tsne = TSNE(n_components=2, random_state=7, perplexity=45, early_exaggeration = 17, learning_rate = 300, method='exact')\n",
    "review_vector_3k_tsne = tsne.fit_transform(X_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86e33ec",
   "metadata": {},
   "source": [
    "As expected, the newly create data array has 2 dimensions and 3000 reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba73992",
   "metadata": {},
   "source": [
    "Pickle the tsne object to Google Drive."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c549bb",
   "metadata": {},
   "source": [
    "Now apply t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1604c1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "tsne = TSNE(n_components=2, random_state=7, perplexity=40, early_exaggeration = 18, learning_rate = 250, method='exact')\n",
    "\n",
    "review_vector_3k_tsne = tsne.fit_transform(X_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b18ef83",
   "metadata": {},
   "source": [
    "Let's see the shape of the array after reducing the dimensions with t-SNE. It should be 3000 x 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be36607",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(review_vector_3k_tsne.shape)\n",
    "print(review_vector_3k_tsne)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2980f1da",
   "metadata": {},
   "source": [
    "This model took an hour to run. It's a good idea to store it on disk for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d145883",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle_file = open('/gdrive/My Drive/amazon/pickled_3k_reviews_tsne_bow.pkl', 'wb')\n",
    "pickle.dump(review_vector_3k_tsne, pickle_file)\n",
    "pickle_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208bd3e0",
   "metadata": {},
   "source": [
    "Construct a dataframe to help visualize the t-SNE result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c2016a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_tsne_3k_array = np.vstack((review_vector_3k_tsne.T, df_np['Score'])).T\n",
    "df_bow_tsne_3k = pd.DataFrame(bow_tsne_3k_array, columns=['First Dimension', 'Second Dimension', 'Label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2299af5",
   "metadata": {},
   "source": [
    "The following dataframe contains the new dimensions that were created by t-SNE. The original dimensions are lost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea9b5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bow_tsne_3k.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5e4a05",
   "metadata": {},
   "source": [
    "Display a scatter plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8453074",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_sql_query(\"select * from reviews where score <> 3;\", con)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7204cf33",
   "metadata": {},
   "source": [
    "Let's define a couple of handy functions to clean the data and the stemmer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6860f20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "porter = PorterStemmer()\n",
    "lemma = WordNetLemmatizer()\n",
    "\n",
    "def clean_html(sentence, compiled_regex):\n",
    "    cleaned_sentence = re.sub(compiled_regex, ' ', sentence)\n",
    "    return cleaned_sentence\n",
    "\n",
    "def clean_punctuation(sentence):\n",
    "    cleaned_sentence = re.sub(r'[?|!|\\'|\"|#]', r'', sentence)\n",
    "    cleaned_sentence = re.sub(r'[.|,|)|(|\\|/]', r' ', cleaned_sentence)\n",
    "    return cleaned_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b926c6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(stop_words, end='\\n\\n-------------------------\\n\\n')\n",
    "print('Stemmed form of \"Goodness\" is: {}'.format(porter.stem('Goodness')))\n",
    "print('Lemmatized form of \"Goodness\" is: {}'.format(lemma.lemmatize('Goodness')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495d2385",
   "metadata": {},
   "source": [
    "Let's clean the reviews using the functions defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832314ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code for implementing step-by-step the checks mentioned in the pre-processing phase\n",
    "# this code takes a while to run as it needs to run on 500k sentences.\n",
    "i=0\n",
    "str1=' '\n",
    "final_string=[]\n",
    "\n",
    "all_positive_words=[] # store words from +ve reviews here\n",
    "all_negative_words=[] # store words from -ve reviews here.\n",
    "\n",
    "s=''\n",
    "\n",
    "regex_html=re.compile('<.*?>')\n",
    "\n",
    "for review in df['Text'].values:\n",
    "    filtered_sentence=[]\n",
    "    #print(sent);\n",
    "    review=clean_html(review, regex_html) # remove HTMl tags\n",
    "    for w in review.split():\n",
    "        for cleaned_words in clean_punctuation(w).split():\n",
    "            if((cleaned_words.isalpha()) & (len(cleaned_words)>2)):    \n",
    "                if(cleaned_words.lower() not in stop_words):\n",
    "                    s = (porter.stem(cleaned_words.lower())).encode('utf8')\n",
    "                    filtered_sentence.append(s)\n",
    "                    if (df['Score'].values)[i] == 'positive': \n",
    "                        all_positive_words.append(s) #list of all words used to describe positive reviews\n",
    "                    if(df['Score'].values)[i] == 'negative':\n",
    "                        all_negative_words.append(s) #list of all words used to describe negative reviews reviews\n",
    "                else:\n",
    "                    continue\n",
    "            else:\n",
    "                continue \n",
    "    #print(filtered_sentence)\n",
    "    str1 = b\" \".join(filtered_sentence) #final string of cleaned words\n",
    "    #print(\"***********************************************************************\")\n",
    "    \n",
    "    final_string.append(str1)\n",
    "    i+=1\n",
    "\n",
    "df['cleaned_text']=final_string #adding a column of CleanedText which displays the data after pre-processing of the review "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ec3cad",
   "metadata": {},
   "source": [
    "The column \"cleaned_text\" contains the cleaned reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455ca3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components=2, random_state=7, perplexity=45, early_exaggeration = 13, learning_rate = 300, method='exact')\n",
    "\n",
    "review_vector_3k_tsne = tsne.fit_transform(review_vector_3k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606154c4",
   "metadata": {},
   "source": [
    "As expected, the resulting matrix has 2 dimensions which are created using t-SNE, from the original vector generated using Doc2Vec."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c8b07b",
   "metadata": {},
   "source": [
    "Generate a dataframe from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817f057b",
   "metadata": {},
   "outputs": [],
   "source": [
    "d2v_tsne_3k_array = np.vstack((review_vector_3k_tsne.T, df_np['Score'])).T\n",
    "df_d2v_tsne_3k = pd.DataFrame(d2v_tsne_3k_array, columns=['First Dimension', 'Second Dimension', 'Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585ea969",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_d2v_tsne_3k.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b26781",
   "metadata": {},
   "outputs": [],
   "source": [
    "sbn.FacetGrid(df_d2v_tsne_3k, hue=\"Label\", size=6).map(plt.scatter, 'First Dimension', 'Second Dimension').add_legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f514b0d",
   "metadata": {},
   "source": [
    "Not much here, either."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa315f4",
   "metadata": {},
   "source": [
    "### Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925b0527",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd545105",
   "metadata": {},
   "source": [
    "Here, I'm training the model using our own corpus of food reviews. The reason behind not using Google's model trained on google news is - there are several words used in the food reviews that aren't present in the model trained by Google. Creating vectors of reviews using it throws exceptions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49577a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training a Word2Vec model using our own corpus\n",
    "\n",
    "list_of_reviews = []\n",
    "\n",
    "for review in df['cleaned_text'].values:\n",
    "    list_of_reviews.append(review.decode('utf-8').split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07d2391",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['cleaned_text'][0])\n",
    "print('------------------')\n",
    "print(list_of_reviews[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ec2423",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model = gensim.models.Word2Vec(list_of_reviews, min_count=4,size=50,workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af6b672",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = list(w2v_model.wv.vocab)\n",
    "print(len(words))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4f1472",
   "metadata": {},
   "source": [
    "The following result is fascinating. It shows the words which are similar to 'smell'. The list of words printed is amazing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed82d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vec = TfidfVectorizer(ngram_range=(1,1))\n",
    "tfidf = tfidf_vec.fit_transform(df_np['cleaned_text'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e9d5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cce9083",
   "metadata": {},
   "source": [
    "There are 3000 rows as expected and 7207 dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe45d3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = tfidf_vec.get_feature_names()\n",
    "len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b38821",
   "metadata": {},
   "outputs": [],
   "source": [
    "sbn.FacetGrid(df_bow_tsne_3k, hue=\"Label\", size=6).map(plt.scatter, 'First Dimension', 'Second Dimension').add_legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9febef96",
   "metadata": {},
   "source": [
    "The above scatter plot doesn't make any sense. The positive and negative reviews are almost perfectly overlapped. \n",
    "\n",
    "This suggests that the Bag of Words model isn't really good at distinguishing between the two types of reviews."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4207cac",
   "metadata": {},
   "source": [
    "### BoW Bigrams \n",
    "\n",
    "This is an extension to the previous model. We consider bi-grams here instead of uni-grams.\n",
    "\n",
    "First, let's create lists of positive and negative words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d845272",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_positive_words = []\n",
    "\n",
    "for w in df_p['cleaned_text']:\n",
    "    all_positive_words.extend(w.split())\n",
    "#all_positive_words\n",
    "\n",
    "all_negative_words = []\n",
    "\n",
    "for w in df_n['cleaned_text']:\n",
    "    all_negative_words.extend(w.split())\n",
    "#all_negative_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b8351a",
   "metadata": {},
   "source": [
    "Most used words in positive and negative reviews. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde65b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_dist_positive = nltk.FreqDist(all_positive_words)\n",
    "print('Most common positive words: {}'.format(freq_dist_positive.most_common(10)))\n",
    "\n",
    "freq_dist_negative = nltk.FreqDist(all_negative_words)\n",
    "print('Most common negative words: {}'.format(freq_dist_negative.most_common(10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f492b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Bi-grams\n",
    "count_vec = CountVectorizer(ngram_range=(1,2))\n",
    "bigrams = count_vec.fit_transform(df_np['cleaned_text'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60c5be8",
   "metadata": {},
   "source": [
    "The number of bigrams is far more than the unigrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db51609a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "tsne = TSNE(n_components=2, random_state=7, perplexity=40, early_exaggeration = 18, learning_rate = 250, method='exact')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d7794b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['HelpfulnessNumerator'] > df['HelpfulnessDenominator']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9834886e",
   "metadata": {},
   "source": [
    "Let's drop these data points using the drop() method given by pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f89af56",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df[df['HelpfulnessNumerator'] > df['HelpfulnessDenominator']].index.tolist(), axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547e92c9",
   "metadata": {},
   "source": [
    "Verify whether the rows have been dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ccc04fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df [df['HelpfulnessNumerator'] > df['HelpfulnessDenominator']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1968c424",
   "metadata": {},
   "source": [
    "Now, let's drop the reviews which have the same data for the attributes:\n",
    "* UserId\n",
    "* ProfileName\n",
    "* Time\n",
    "* Text\n",
    "\n",
    "These are the reviews for same products, duplicated in the dataset because Amazon considers slight variations of the same product to be different products. i.e. A food item with red color would be different than the same item of green color. We need to drop these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45f841a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle_file = open('/gdrive/My Drive/amazon/avg_w2v_nparray_3kcorpus_50dim.pkl', 'wb')\n",
    "pickle.dump(corpus_vec, pickle_file)\n",
    "pickle_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a4aba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_vec.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7366dfd4",
   "metadata": {},
   "source": [
    "Appply t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d13bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "tsne = TSNE(n_components=2, random_state=7, perplexity=45, early_exaggeration = 13, learning_rate = 250)\n",
    "\n",
    "review_vector_3k_tsne = tsne.fit_transform(corpus_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8ff405",
   "metadata": {},
   "source": [
    "Build a dataframe for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8c64f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_w2v_tsne_3k_array = np.vstack((review_vector_3k_tsne.T, df_np['Score'])).T\n",
    "df_avg_w2v_tsne_3k = pd.DataFrame(avg_w2v_tsne_3k_array, columns=['First Dimension', 'Second Dimension', 'Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c489a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sbn.FacetGrid(df_avg_w2v_tsne_3k, hue=\"Label\", size=6).map(plt.scatter, 'First Dimension', 'Second Dimension').add_legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0980299c",
   "metadata": {},
   "source": [
    "The above result is far from ideal, but it's slightly better than the techniques seen so far. The density of positive points is more in the right side of the map as compared to the left side."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8423a3e",
   "metadata": {},
   "source": [
    "### Tfidf weighted W2V\n",
    "\n",
    "In this representation, each review is made up from the tfidf weighted sum of all the words in a review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f7586b",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_tfidf_weighted_w2v = np.zeros(shape=(50))\n",
    "review_number = 0\n",
    "\n",
    "for review in df_np['cleaned_text'].values:\n",
    "    review_vector_tfidf_weighted = np.zeros(shape=(50))\n",
    "    tfidf_sum = 0\n",
    "    for word in review.decode('utf-8').split():\n",
    "        try:\n",
    "            tfidf_value = review_vector_3k_TFIDF[review_number, features.index(word)]\n",
    "            review_vector_tfidf_weighted += w2v_model.wv[word] * tfidf_value\n",
    "            tfidf_sum += tfidf_value\n",
    "            \n",
    "        except KeyError:\n",
    "            continue\n",
    "    \n",
    "    review_number += 1\n",
    "    \n",
    "    review_vector_tfidf_weighted /= tfidf_sum\n",
    "    corpus_tfidf_weighted_w2v=np.vstack((corpus_tfidf_weighted_w2v,review_vector_tfidf_weighted))\n",
    "    \n",
    "corpus_tfidf_weighted_w2v = np.delete(corpus_tfidf_weighted_w2v, 0, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73411fc7",
   "metadata": {},
   "source": [
    "Shape of the data matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e7b12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle_file = open('/gdrive/My Drive/amazon/pickled_3k_reviews_tsne_tfidf_1gram.pkl', 'wb')\n",
    "pickle.dump(review_vector_3k_tsne, pickle_file)\n",
    "pickle_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2aa134",
   "metadata": {},
   "source": [
    "Construct dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99cb5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_tsne_3k_array = np.vstack((review_vector_3k_tsne.T, df_np['Score'])).T\n",
    "df_tfidf_tsne_3k = pd.DataFrame(tfidf_tsne_3k_array, columns=['First Dimension', 'Second Dimension', 'Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327bf346",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tfidf_tsne_3k.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675abfde",
   "metadata": {},
   "source": [
    "Plot the result of applying t-SNE on tfidf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b35a05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sbn.FacetGrid(df_tfidf_tsne_3k, hue=\"Label\", size=6).map(plt.scatter, 'First Dimension', 'Second Dimension').add_legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d6477c8",
   "metadata": {},
   "source": [
    "The TFIDF model too didn't prove to be of much use here. Let's look at a different technique."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13367aae",
   "metadata": {},
   "source": [
    "### Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420860fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install gensim if not installed\n",
    "\n",
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe4d385",
   "metadata": {},
   "source": [
    "Import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59658838",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models import word2vec\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9f5d34",
   "metadata": {},
   "source": [
    "Define a function that reads each review and converts it into TaggedDocument format needed for training a model using Doc2Vec technique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82002284",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_tfidf_weighted_w2v.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d18ddf",
   "metadata": {},
   "source": [
    "Apply t-SNE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8facd7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "tsne = TSNE(n_components=2, random_state=13, perplexity=50, early_exaggeration = 14, learning_rate = 225)\n",
    "\n",
    "review_vector_3k_tsne = tsne.fit_transform(corpus_tfidf_weighted_w2v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02e008f",
   "metadata": {},
   "source": [
    "The dimensions of the array reduced to 2 as expected."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade0f493",
   "metadata": {},
   "source": [
    "Build a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08cb4cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model.wv.most_similar('smell')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e386efa0",
   "metadata": {},
   "source": [
    "Similarly, words similar to 'bad'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92639b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model.wv.most_similar('bad')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d2d6e46",
   "metadata": {},
   "source": [
    "Calculating the avg W2V representation for each review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c2743c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "corpus_vec = np.zeros(shape=(50))\n",
    "\n",
    "for review in df_np['cleaned_text'].values:\n",
    "    review_vector = np.zeros(shape=(50))\n",
    "    for word in review.decode('utf-8').split():\n",
    "        try:\n",
    "            \n",
    "            review_vector += w2v_model.wv[word]\n",
    "            \n",
    "        except KeyError:\n",
    "            continue\n",
    "    \n",
    "    review_vector /= 50\n",
    "    corpus_vec=np.vstack((corpus_vec,review_vector))    \n",
    "corpus_vec=np.delete(corpus_vec, 0, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978802bb",
   "metadata": {},
   "source": [
    "Again, store the files on Google Drive for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053ab3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(subset={\"UserId\",\"ProfileName\",\"Time\",\"Text\"}, keep = 'first', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50848911",
   "metadata": {},
   "source": [
    "Dropping the duplicate significantly reduces the size of our dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b19dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2637c5a",
   "metadata": {},
   "source": [
    "### Text Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6098bb86",
   "metadata": {},
   "source": [
    "Data collected from the web often contains unrendered HTML tags in them. Let's see if our reviews have them. We are only interested in the 'Text' column, because this is the column that will help us decide if a review is positive or negative. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523567e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_corpus = gensim.utils.simple_preprocess(df_np['cleaned_text'][1])\n",
    "\n",
    "def read_corpus(df_np, tokens_only=False):\n",
    "        for i, review in enumerate(df_np['cleaned_text']):\n",
    "            if tokens_only:\n",
    "                yield gensim.utils.simple_preprocess(review)\n",
    "            else:\n",
    "                # For training data, add tags\n",
    "                yield gensim.models.doc2vec.TaggedDocument(gensim.utils.simple_preprocess(review), [i])\n",
    "\n",
    "train_corpus = list(read_corpus(df_np))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36999a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_corpus[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04375263",
   "metadata": {},
   "source": [
    "Define D2V model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6227bc23",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.doc2vec.Doc2Vec(vector_size=50, min_count=2, epochs=45)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b2b855",
   "metadata": {},
   "source": [
    "Build vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c9602f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build_vocab(train_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5429c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c1b6a4",
   "metadata": {},
   "source": [
    "Train D2V model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d9b40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%time model.train(train_corpus, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88ab9d2",
   "metadata": {},
   "source": [
    "Create a corpus of vector representation of all reviews under consideration, using D2V technique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338af5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_vector_3k = np.zeros((1,50))\n",
    "\n",
    "\n",
    "for review in df_np['cleaned_text']:\n",
    "    arr = np.reshape(model.infer_vector(str(review).split()), (1,-1))\n",
    "    review_vector_3k=np.vstack([review_vector_3k, arr])\n",
    "\n",
    "#model.infer_vector(str(df_np['cleaned_text'][1636]).split())\n",
    "#df_np['cleaned_text'][1637]\n",
    "#df_np['cleaned_text']\n",
    "#np.reshape(model.infer_vector(str(df_np['cleaned_text'][2]).split()), (1,-1)).shape\n",
    "\n",
    "review_vector_3k = np.delete(review_vector_3k, (0), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09dc50c",
   "metadata": {},
   "source": [
    "A vector is generated that has 3000 rows, each for 1 review and 50 dimensions as defined by the vector_size parameter specified when we defined the model above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368d1c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "review_vector_3k = scaler.fit_transform(review_vector_3k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6295c839",
   "metadata": {},
   "source": [
    "Define t-SNE and transform data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bdc15f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "i=0\n",
    "\n",
    "for review in df['Text'].values:\n",
    "    if (len(re.findall('<.*>', review))):\n",
    "            i+=1\n",
    "            r=review"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53562665",
   "metadata": {},
   "source": [
    "How many reviews contain HTML tags?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c52a1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of reviews which contain HTML tags: {}'.format(i), end='\\n\\n------------------\\n\\n')\n",
    "print('Sample review containing HTML tags: {}'.format(r))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c89e3b9",
   "metadata": {},
   "source": [
    "Let's import some text processing libraries we need. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9fc3af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_tfidf_weighted_w2v_tsne_3k_array = np.vstack((review_vector_3k_tsne.T, df_np['Score'])).T\n",
    "df_avg_tfidf_weighted_w2v_tsne_3k = pd.DataFrame(avg_tfidf_weighted_w2v_tsne_3k_array, columns=['First Dimension', 'Second Dimension', 'Label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54bd2551",
   "metadata": {},
   "source": [
    "The tfidf weighted W2V plot is not very different from the plot obtained using the avg. W2V representation. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682179e2",
   "metadata": {},
   "source": [
    "TFIDF values of words in a review"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
