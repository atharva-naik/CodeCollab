{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ffa2ba83",
   "metadata": {},
   "source": [
    "# Detect Enron Poi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c9ac3e",
   "metadata": {},
   "source": [
    "In choosing the features, the following strategy was used:\n",
    "- Start with all features\n",
    "- Run SelectKBest for all features, plot results\n",
    "- Omit features that do not seem to affect the model\n",
    "- Run the model and see the test results\n",
    "\n",
    "Additionally, since the data seemed to have quite a few features compared to the dataset size, PCA was also used:\n",
    "- Run PCA with different amount of components\n",
    "- Run the model and see the test results\n",
    "- Choose the amount of PCA components with the best results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55f8851",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of feature names, handy for plot labeling etc.\n",
    "features_only_list = list(features_list)\n",
    "features_only_list.remove('poi')\n",
    "\n",
    "labels, features = targetFeatureSplit(data)\n",
    "\n",
    "features_train, features_test, labels_train, labels_test = \\\n",
    "    stratifiedShuffleSplit(features, labels)\n",
    "\n",
    "# Get feature importance:\n",
    "importance, selector = getFeatureImportance(features_train, labels_train, features_only_list, k = 8)\n",
    "plt.figure()\n",
    "plotFeatureImportance(importance, features_only_list, plt)\n",
    "plt.show()\n",
    "\n",
    "### First try with all features: \n",
    "print 'P_values of the features:'\n",
    "pprint.pprint([i[2] for i in importance])\n",
    "print '\\n'\n",
    "# Do some hyperparam validation:\n",
    "best_svc, svc_grid_scores = ClassifySVM.gridsearch(features_train, labels_train)\n",
    "\n",
    "# Do fits based on hyperparam validation\n",
    "nbfit = ClassifyNB.train(features_train, labels_train)\n",
    "svmfit = ClassifySVM.train(features_train, labels_train, best_svc)\n",
    "\n",
    "### Probably better to test with precision and recall:\n",
    "print 'Naive bayes:'\n",
    "test_classifier(nbfit, data)\n",
    "print 'SVM:'\n",
    "test_classifier(svmfit, data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d71d286",
   "metadata": {},
   "source": [
    "Already looking at the p-values, there seem to be quite a few variables that are likely to not be good features for the model. It seems that with a confidence interval of 95%, the 8 best features should be used.\n",
    "\n",
    "Lets try with selector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76cec0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Next try with selector\n",
    "selector_train = selector.transform(features_train)\n",
    "\n",
    "# Do some hyperparam validation:\n",
    "best_svc, svc_grid_scores = ClassifySVM.gridsearch(selector_train, labels_train)\n",
    "\n",
    "# Do fits based on hyperparam validation\n",
    "nbfit = ClassifyNB.train(selector_train, labels_train)\n",
    "svmfit = ClassifySVM.train(selector_train, labels_train, best_svc)\n",
    "\n",
    "### Probably better to test with precision and recall:\n",
    "print 'Naive bayes:'\n",
    "test_classifier(nbfit, data)\n",
    "print 'SVM:'\n",
    "test_classifier(svmfit, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3653c36",
   "metadata": {},
   "source": [
    "Quite a bit better, especially with SVM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035cc034",
   "metadata": {},
   "source": [
    "PCA was used the following way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b258014c",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels, features = targetFeatureSplit(data)\n",
    "\n",
    "features_train, features_test, labels_train, labels_test = \\\n",
    "    stratifiedShuffleSplit(features, labels)\n",
    "\n",
    "### Do some PCA\n",
    "pca = PCA.doPCA(features_train, n = 3)\n",
    "transformed_train = pca.transform(features_train)\n",
    "transformed_test = pca.transform(features_test)\n",
    "\n",
    "features_only_list = ['pca'+str(i) for i in range(len(transformed_train[0]))]\n",
    "\n",
    "# Do some hyperparam validation:\n",
    "best_svc, svc_grid_scores = ClassifySVM.gridsearch(transformed_train, labels_train)\n",
    "\n",
    "# Do fits based on hyperparam validation\n",
    "nbfit = ClassifyNB.train(transformed_train, labels_train)\n",
    "svmfit = ClassifySVM.train(transformed_train, labels_train, best_svc)\n",
    "\n",
    "### Probably better to test with precision and recall:\n",
    "print 'Naive bayes:'\n",
    "test_classifier(nbfit, data)\n",
    "print 'SVM:'\n",
    "test_classifier(svmfit, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5ed2b8",
   "metadata": {},
   "source": [
    "PCA yeilded results that are exactly the same as SelectKFeatures."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb94b230",
   "metadata": {},
   "source": [
    "Lets try combining both:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e93199f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import RandomizedPCA\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "pca = RandomizedPCA(n_components=1)\n",
    "selector = SelectKBest(score_func=f_classif, k=1)\n",
    "\n",
    "# Build estimator from PCA and Univariate selection:\n",
    "\n",
    "combined_features = FeatureUnion([(\"pca\", pca), (\"f_classif\", selector)])\n",
    "\n",
    "# Use combined features to transform dataset:\n",
    "combined_train = combined_features.fit(features_train, labels_train).transform(features_train)\n",
    "\n",
    "# Do some hyperparam validation:\n",
    "best_svc, svc_grid_scores = ClassifySVM.gridsearch(combined_train, labels_train)\n",
    "\n",
    "# Do fits based on hyperparam validation\n",
    "nbfit = ClassifyNB.train(combined_train, labels_train)\n",
    "svmfit = ClassifySVM.train(combined_train, labels_train, best_svc)\n",
    "\n",
    "### Probably better to test with precision and recall:\n",
    "print 'Naive bayes:'\n",
    "test_classifier(nbfit, data)\n",
    "print 'SVM:'\n",
    "test_classifier(svmfit, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e242b851",
   "metadata": {},
   "source": [
    "Unsurprisingly, same results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1ec150",
   "metadata": {},
   "source": [
    "Now, the Precision of the model should be bumped to over 0.3 in order to pass the evaluation requirements. To do that, lets organize a new feature.\n",
    "\n",
    "Lets try to get a bit more bang for our buck from the email features. Lets see how a ratio-feature affects the model by organizing the following feature:\n",
    "$$X_{email\\_from\\_poi\\_ratio} = \\frac{X_{from\\_poi\\_to\\_this\\_person}+X_{to\\_poi\\_from\\_this\\_person}}{X_{from\\_messages}+X_{to\\_messages}}$$"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
