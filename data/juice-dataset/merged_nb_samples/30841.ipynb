{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ead56dc7",
   "metadata": {},
   "source": [
    "# This notebook shows how to learn weights for a logistic regression model using gradient ascent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb597778",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import needed libraries\n",
    "import numpy as np\n",
    "import graphlab as gl #The dataset is in SFrame format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c8d4e9",
   "metadata": {},
   "source": [
    "## Load Amazon baby products reviews dataset\n",
    "\n",
    "To download this dataset click [here](https://s3.amazonaws.com/static.dato.com/files/coursera/course-3/amazon_baby_subset.gl.zip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30aa199",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd 'C:\\Users\\Rolex James\\Documents\\MOOCs\\ML Univ of Washington\\Classification\\Resources\\machine-learning-specialization-master\\course-3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c5b0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#I am using a subset of the amazon baby products reviews dataset\n",
    "products = gl.SFrame('amazon_baby_subset.gl/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302904e8",
   "metadata": {},
   "source": [
    "### Exploring the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64cffafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "products.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90eb293c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print 'Number of positive reviews =', len(products[products['sentiment']== 1])\n",
    "print 'Number of negative reviews =', len(products[products['sentiment']== -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e82829",
   "metadata": {},
   "outputs": [],
   "source": [
    "print products.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e9ea1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's look at a single review \n",
    "print products['review'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96a34be",
   "metadata": {},
   "source": [
    "## Apply text cleaning to the review column\n",
    "\n",
    "We will use  the word counts of the 193 most frequent words as the features for each review in the dataset. \n",
    "We will also remove punctuations from the 'review' column of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b5bf35",
   "metadata": {},
   "outputs": [],
   "source": [
    "print important_words[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d56904",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to remove punctuations a string\n",
    "def remove_punctuation(text):\n",
    "    import string\n",
    "    return text.translate(None, string.punctuation) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c4ecf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a column that contains 'clean' reviews\n",
    "products['review_clean'] = products['review'].apply(remove_punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac64086",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's view the products SFrame again\n",
    "products.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64907fb",
   "metadata": {},
   "source": [
    "Next we create columns that contain word counts for each word in the important_words list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed285289",
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in important_words:\n",
    "    products[word] = products['review_clean'].apply(lambda s : s.split().count(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46867fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To run gradient ascent on our data we need to convert it to matrices\n",
    "def get_numpy_data(data_sframe, features, label):\n",
    "    data_sframe['intercept'] = 1\n",
    "    features = ['intercept'] + features\n",
    "    features_sframe = data_sframe[features]\n",
    "    feature_matrix = features_sframe.to_numpy()\n",
    "    label_sarray = data_sframe[label]\n",
    "    label_array = label_sarray.to_numpy()\n",
    "    return(feature_matrix, label_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05fef154",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split data into training and test sets, set seed to ensure reproducibility\n",
    "train, test = products.random_split(.8, seed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73b7b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "print \"Number of reviews in training data: \", train.shape[0]\n",
    "print \"Number of reviews in test data: \", test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdbb839b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_matrix, sentiment_train = get_numpy_data(train, important_words, 'sentiment')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc5165f",
   "metadata": {},
   "source": [
    "### First we write a function to compute conditional probability with logistic link function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37d09f4",
   "metadata": {},
   "source": [
    "Recall that the logistic link function is given by:\n",
    "$$\n",
    "P(y_i = +1 | \\mathbf{x}_i,\\mathbf{w}) = \\frac{1}{1 + \\exp(-\\mathbf{w}^T h(\\mathbf{x}_i))},\n",
    "$$\n",
    "\n",
    "where the feature vector $h(\\mathbf{x}_i)$ represents the word counts of **important_words** in the review  $\\mathbf{x}_i$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f3ffce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_probability(feature_matrix, coefficients):\n",
    "    '''\n",
    "    produces probablistic estimate for P(y_i = +1 | x_i, w).\n",
    "    estimate ranges between 0 and 1.\n",
    "    '''\n",
    "    score = np.dot(feature_matrix, coefficients)\n",
    "    predictions = 1/(1 + np.exp(-score))\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfaa7d86",
   "metadata": {},
   "source": [
    "## Next we need to compute derivative of the log likelihood with respect to a single coefficient\n",
    "\n",
    "This is given by:\n",
    "$$\n",
    "\\frac{\\partial\\ell}{\\partial w_j} = \\sum_{i=1}^N h_j(\\mathbf{x}_i)\\left(\\mathbf{1}[y_i = +1] - P(y_i = +1 | \\mathbf{x}_i, \\mathbf{w})\\right)\n",
    "$$\n",
    "\n",
    "This function accepts two arguments:\n",
    "* `errors` vector containing $\\mathbf{1}[y_i = +1] - P(y_i = +1 | \\mathbf{x}_i, \\mathbf{w})$ for all $i$. This is simply the difference between the true values and our predictions using a given set of weights.\n",
    "* `feature` vector containing $h_j(\\mathbf{x}_i)$  for all $i$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110d7b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_derivative(errors, feature):     \n",
    "    derivative = np.dot(errors, feature)\n",
    "    return derivative"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9604d31",
   "metadata": {},
   "source": [
    "Next we compute the log likelihood for a given set of weights. This helps us to check how well the learning algorithm is doing. For each iteration the log likelihood should increase.\n",
    "\n",
    "The log likelihood equation is given by:\n",
    "$$\\ell\\ell(\\mathbf{w}) = \\sum_{i=1}^N \\Big( (\\mathbf{1}[y_i = +1] - 1)\\mathbf{w}^T h(\\mathbf{x}_i) - \\ln\\left(1 + \\exp(-\\mathbf{w}^T h(\\mathbf{x}_i))\\right) \\Big) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2dda27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_log_likelihood(feature_matrix, sentiment, coefficients):\n",
    "    indicator = (sentiment==+1)\n",
    "    scores = np.dot(feature_matrix, coefficients)\n",
    "    logexp = np.log(1. + np.exp(-scores))\n",
    "    \n",
    "    # Simple check to prevent overflow\n",
    "    mask = np.isinf(logexp)\n",
    "    logexp[mask] = -scores[mask]\n",
    "    \n",
    "    lp = np.sum((indicator-1)*scores - logexp)\n",
    "    return lp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87890e72",
   "metadata": {},
   "source": [
    "## Running Gradient Ascent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57eeed74",
   "metadata": {},
   "source": [
    "The following function takes gradient steps to the optimum (the maximum point of the log likelihood function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ed82d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "\n",
    "def logistic_regression(feature_matrix, sentiment, initial_coefficients, step_size, max_iter):\n",
    "    coefficients = np.array(initial_coefficients) # make sure it's a numpy array\n",
    "    for itr in xrange(max_iter):\n",
    "        predictions = predict_probability(feature_matrix, coefficients)\n",
    "        \n",
    "        # Compute indicator value for (y_i = +1)\n",
    "        indicator = (sentiment==+1)\n",
    "        errors = indicator - predictions\n",
    "        for j in xrange(len(coefficients)): # loop over each coefficient\n",
    "            derivative = feature_derivative(errors, feature_matrix[:,j])\n",
    "            coefficients[j] = coefficients[j] + (step_size * derivative)\n",
    "            \n",
    "        # Check whether log likelihood is increasing\n",
    "        if itr <= 15 or (itr <= 100 and itr % 10 == 0) or (itr <= 1000 and itr % 100 == 0) \\\n",
    "        or (itr <= 10000 and itr % 1000 == 0) or itr % 10000 == 0:\n",
    "            lp = compute_log_likelihood(feature_matrix, sentiment, coefficients)\n",
    "            print 'iteration %*d: log likelihood of observed labels = %.8f' % \\\n",
    "                (int(np.ceil(np.log10(max_iter))), itr, lp)\n",
    "                \n",
    "    return coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98a443e",
   "metadata": {},
   "source": [
    "Running our logistc regression solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64f6f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficients = logistic_regression(train_matrix, sentiment_train, initial_coefficients=np.zeros(194),\n",
    "                                   step_size=1e-7, max_iter=301)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bbcbb0b",
   "metadata": {},
   "source": [
    "As you can see the log likelihood increases after every iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e28b66a",
   "metadata": {},
   "source": [
    "## Making Predictions on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7c793b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert test data to a numpy array\n",
    "test_matrix, sentiment_test = get_numpy_data(test, important_words, 'sentiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3506b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute probability estimates of reviews in test data being positive\n",
    "pred_proba = predict_probability(test_matrix, coefficients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f4b2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict class labels based on probability estimates\n",
    "#Here I am using 0.5 as the probability threshold for predicting the positive class\n",
    "#This is because logit(0) = 0.5\n",
    "pred_labels = np.where(pred_proba >= 0.5, +1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3b3e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#View the first 10 predictions\n",
    "pred_labels[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33443423",
   "metadata": {},
   "source": [
    "Alternatively we can use the scores (i.e. dot product of the coefficients and feature values) for predicting class labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384a13ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_scores = np.dot(test_matrix, coefficients)\n",
    "pred_labels_scores = np.where(pred_scores > 0, +1, -1)\n",
    "pred_labels_scores[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b5427f8",
   "metadata": {},
   "source": [
    "## Measuring accuracy on test data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09cd2130",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mbox{accuracy} = \\frac{\\mbox{# correctly classified data points}}{\\mbox{# total data points}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a197a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_mistakes = len(test) - np.sum(pred_labels == np.array(test['sentiment']))\n",
    "accuracy = np.sum(pred_labels == np.array(test['sentiment'])) / float(len(test))\n",
    "print \"-----------------------------------------------------\"\n",
    "print 'Number of test reviews correctly classified =', len(test) - num_mistakes\n",
    "print 'Number of test reviews incorrectly classified =', num_mistakes\n",
    "print 'Total number of reviews                       =', len(test)\n",
    "print \"-----------------------------------------------------\"\n",
    "print 'Accuracy = %.2f' % accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07905c0",
   "metadata": {},
   "source": [
    "This model does pretty well on the test set. It is better than a majority classifier which would have an accuaracy of about 50%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c9ba5d",
   "metadata": {},
   "source": [
    "## Finally, let's see the words most associated with positive & negative sentiment"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
