{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05b90049",
   "metadata": {},
   "source": [
    "## MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a3015f",
   "metadata": {},
   "source": [
    "### 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0898e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import fashion_mnist\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.optimizers import adam\n",
    "from scipy.misc import toimage #(*)\n",
    "import matplotlib.pylab as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e66941",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3f37f4",
   "metadata": {},
   "source": [
    "### 2. Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3b4972",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "epoch = 1\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89da9898",
   "metadata": {},
   "source": [
    "### 3. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3440fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d5b595",
   "metadata": {},
   "source": [
    "### 4. Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc8352f",
   "metadata": {},
   "outputs": [],
   "source": [
    "im = x_test[6]\n",
    "plt.imshow(im, cmap=plt.get_cmap('gray'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a391fc",
   "metadata": {},
   "source": [
    "### 5. Reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af77cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('shape')\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8bb60c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_RS = x_train.reshape(60000, 28, 28, 1)\n",
    "x_test_RS  = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
    "print(x_train_RS.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22aadd7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_RS = x_train_RS.astype('float32')\n",
    "x_test_RS  = x_test_RS.astype('float32')\n",
    "\n",
    "x_train_RS /= 255\n",
    "x_test_RS  /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f88ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_RS = to_categorical(y_train, num_classes)\n",
    "y_test_RS  = to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0772fd0d",
   "metadata": {},
   "source": [
    "### 6. CNN layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88d3507",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11050ee2",
   "metadata": {},
   "source": [
    "### 7. Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d4d085",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train_RS, y_train_RS, \n",
    "          batch_size=batch_size, epochs=epoch, verbose=1, \n",
    "          validation_data=(x_test_RS, y_test_RS))\n",
    "loss, accuracy = model.evaluate(x_test_RS, y_test_RS, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c58f67d",
   "metadata": {},
   "source": [
    "### 8. Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496fc5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3eeef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"weight.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08f17fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "im = im.reshape(1, 28, 28, 1)\n",
    "im = im.astype('float32')\n",
    "im /= 255\n",
    "predict = model.predict(im)\n",
    "print(predict)\n",
    "print(np.argmax(predict, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf804c3e",
   "metadata": {},
   "source": [
    "### 9. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6da530e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageOps\n",
    "import numpy as np\n",
    "from tempfile import TemporaryFile\n",
    "test_dataset = TemporaryFile()\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac31a49b",
   "metadata": {},
   "source": [
    "### 10. Gray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e424792",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb2gray(rgb):\n",
    "    r, g, b = rgb[:,:,0], rgb[:,:,1], rgb[:,:,2]\n",
    "    gray = 0.2989 * r + 0.5870 * g + 0.1140 * b\n",
    "    return(gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5ee353",
   "metadata": {},
   "outputs": [],
   "source": [
    "im = Image.open('trouser.jpeg')\n",
    "im = im.resize((28,28))\n",
    "im = np.asarray(ImageOps.invert(im))\n",
    "im = rgb2gray(im)\n",
    "plt.imshow(im, cmap=plt.get_cmap('gray'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb9aed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "im = im.reshape(1, 28, 28, 1)\n",
    "im = im.astype('float32')\n",
    "im /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b3e2a9",
   "metadata": {},
   "source": [
    "### 11. Predict"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
