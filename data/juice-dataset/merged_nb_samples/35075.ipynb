{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5eb2811",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed6e1d2",
   "metadata": {},
   "source": [
    "# Initial Data Cleaning and Exploration\n",
    "Code for the initial data cleaning and exploration done before modeling   \n",
    "_Author: Jimmy Charit√©_  \n",
    "_Email: jimmy.charite@gmail.com_  \n",
    "_Date: January 8, 2017_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15a7ad5",
   "metadata": {},
   "source": [
    "## Directory & Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a66b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de024069",
   "metadata": {},
   "source": [
    "The default directory is the code subdirectory. Changing to the main repo directory above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92e8524",
   "metadata": {},
   "source": [
    "Converting the image type variable into numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc8d78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_tab(raw_data,'image_type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c802cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data=raw_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9e10e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data.replace({'image_type': {'nonad.':0,'ad.':1}},inplace=True)\n",
    "clean_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6602a4a8",
   "metadata": {},
   "source": [
    "Converting all other variables into numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7a755f",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data=clean_data.apply(lambda row: pd.to_numeric(row,errors='coerce'))\n",
    "clean_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ccdfa0f",
   "metadata": {},
   "source": [
    "Inspecting the 'Height' feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe7ac47",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data[np.isnan(clean_data.height)==False].height.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65cdba2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "g=sns.distplot(clean_data[np.isnan(clean_data.height)==False].height)\n",
    "g.axes.set_ylim(0,)\n",
    "g.axes.set_xlim(0,)\n",
    "g.axes.set_title('Image Heights\\n',fontsize=20)\n",
    "g.set_xlabel('Height',fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3df2fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "g=sns.distplot(np.log(clean_data[np.isnan(clean_data.height)==False].height))\n",
    "g.axes.set_ylim(0,)\n",
    "g.axes.set_title('Logged Image Heights\\n',fontsize=20)\n",
    "g.set_xlabel('Height',fontsize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9bfe950",
   "metadata": {},
   "source": [
    "Taking the log of the continuous variables can be an optional pipeline step during the model training stage. In theory, many of the parametric models like the logistic classifier benefit from (standardized) approximately symmetric distributions. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8e132e",
   "metadata": {},
   "source": [
    "Inspecting the 'Width' feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23c3cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data[np.isnan(clean_data.width)==False].width.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da00dbd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "g=sns.distplot(clean_data[np.isnan(clean_data.width)==False].width)\n",
    "g.axes.set_ylim(0,)\n",
    "g.axes.set_xlim(0,)\n",
    "g.axes.set_title('Image Widths\\n',fontsize=20)\n",
    "g.set_xlabel('Width',fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dddade6",
   "metadata": {},
   "outputs": [],
   "source": [
    "g=sns.distplot(np.log(clean_data[np.isnan(clean_data.width)==False].width))\n",
    "g.axes.set_ylim(0,)\n",
    "g.axes.set_title('Logged Image Widths\\n',fontsize=20)\n",
    "g.set_xlabel('Width',fontsize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e211574c",
   "metadata": {},
   "source": [
    "Widths are bimodal and there isn't simple transformation to address it. I may experiment with using categorical variables for the width. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ebac365",
   "metadata": {},
   "source": [
    "Inspecting the aspect ratio feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6709b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data['missing_local']=clean_data.local.isnull()\n",
    "clean_data['image_type'].groupby(clean_data['missing_local']).mean()*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71191ac6",
   "metadata": {},
   "source": [
    "The local variable is missing for only 15 observations. Assuming this is representative of the general rate at which it is missing, I will simply impute missing values to '0'. In practice, if the 'local' variable turns out to be an extremely important feature, I would discuss the issue with individuals in the company that fully understand how the data was generated to see if there are smarter imputation approaches available or if the data collection process can be changed to avoid missing information on this variable. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b960c1",
   "metadata": {},
   "source": [
    "## Cleaning and Saving Data for Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63718161",
   "metadata": {},
   "source": [
    "Starting with the raw data, I apply everything I learned from the data exploration to preparing the raw data for modeling. The code below will be re-used in the standalone python script that will be used to make predictions on new raw data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d788f6",
   "metadata": {},
   "source": [
    "### Upload Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "277158a6",
   "metadata": {},
   "source": [
    "Main dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faae020b",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data=pd.read_csv(\"./raw_data/data\",header=None)\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ed39a9",
   "metadata": {},
   "source": [
    "Attach column names "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b51b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names=pd.read_csv(\"./raw_data/column.names.txt\",header=None,\n",
    "                     sep=\":\")\n",
    "col_names.columns=['variable','type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6549447c",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names=pd.concat((col_names,\n",
    "                     pd.DataFrame({'variable':['image_type'],\n",
    "                                   'type':['0,1.'] })),axis=0)\n",
    "col_names=col_names[['variable','type']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9afce975",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data.columns=list(col_names.variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59736834",
   "metadata": {},
   "source": [
    "### Make Numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c3f8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp=raw_data[np.isnan(pd.to_numeric(raw_data.width,errors='coerce'))]['width']\n",
    "np.unique(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10cd88ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp=raw_data[np.isnan(pd.to_numeric(raw_data.aratio,errors='coerce'))]['aratio']\n",
    "np.unique(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec0a668",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp=raw_data[np.isnan(pd.to_numeric(raw_data.local,errors='coerce'))]['local']\n",
    "np.unique(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5470f582",
   "metadata": {},
   "source": [
    "The non-numerical values enter as \"?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6238b2ec",
   "metadata": {},
   "source": [
    "### Inspecting the Continuous Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3420abeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(clean_data)-len(clean_data.dropna(axis=0,how='any'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361804b6",
   "metadata": {},
   "source": [
    "Counting missing instances by variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283548b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp=clean_data.isnull().sum().reset_index()\n",
    "temp.columns=['variable','missing']\n",
    "temp.sort_values(by='missing',inplace=True,ascending=False)\n",
    "temp['percent']=np.round(100*temp['missing']/len(clean_data),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc71743",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp[temp.missing>0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3077e0c2",
   "metadata": {},
   "source": [
    "Missing values in the height, width, and aspect ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b24ceee",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(clean_data[(clean_data.height.isnull()==False) & \n",
    "           (clean_data.width.isnull()==False) &\n",
    "           (clean_data.aratio.isnull()==True) ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bdb37ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(clean_data[(clean_data.height.isnull()==False) & \n",
    "           (clean_data.width.isnull()==True) &\n",
    "           (clean_data.aratio.isnull()==False) ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04974230",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(clean_data[(clean_data.height.isnull()==True) & \n",
    "           (clean_data.width.isnull()==False) &\n",
    "           (clean_data.aratio.isnull()==False) ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b37224f",
   "metadata": {},
   "source": [
    "With the current data, it is not possible to impute missing data in one continuous variable with complete data from the other two continuous variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeac0cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data['missing_aratio']=clean_data.aratio.isnull()\n",
    "clean_data['image_type'].groupby(clean_data['missing_aratio']).mean()*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0c314e",
   "metadata": {},
   "outputs": [],
   "source": [
    "f='image_type ~ missing_aratio'\n",
    "results = smf.glm(formula=f, data=clean_data, \n",
    "                  family=sm.families.Binomial()).fit()\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea62470f",
   "metadata": {},
   "source": [
    "16% of instances with missing aspect ratios are ads and 8% of instances without missing aspect ratios are ads. The difference, in a univariate regression, is statistically significant. \n",
    "\n",
    "In light of the large percent of missing values and the seemingly non-randomness of the missing values with respect to the feature being classified, I will represent the aspect ratio, height, and width as categorical variables with 'missing' being the reference category. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25ef310",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data[np.isnan(clean_data.aratio)==False].aratio.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ceaf1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "g=sns.distplot(clean_data[np.isnan(clean_data.aratio)==False].aratio)\n",
    "g.axes.set_ylim(0,)\n",
    "g.axes.set_xlim(0,)\n",
    "g.axes.set_title('Image Aspect Ratio\\n',fontsize=20)\n",
    "g.set_xlabel('Ratio',fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504b0b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "100*len(clean_data[clean_data.aratio>10])/len(clean_data) #1.25% 10+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dce67cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "g=sns.distplot(np.log(clean_data[np.isnan(clean_data.aratio)==False].aratio))\n",
    "g.axes.set_ylim(0,)\n",
    "g.axes.set_title('Logged Image Aspect Ratio\\n',fontsize=20)\n",
    "g.set_xlabel('Ratio',fontsize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138c5057",
   "metadata": {},
   "source": [
    "Taking the log of the aspect ratio improves the symmetry of the distribution, but it is not approximately normal one. On the non-logged scale, the aspect ratios greater than 10 definitely look like outliers, however, they are still within reason for aspect ratios for images. I created an image with an aspect ratio of 60 to confirm. Dropping outliers may result in an inability to make predictions for certain instances, which isn't always practical. Therefore, initially, I will include algorithms that are robust to outliers before experimenting with removing them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea39e0e",
   "metadata": {},
   "source": [
    "### Inspecting the Binary Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca25e12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_types[data_types.d_type=='object']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a16e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp=raw_data[np.isnan(pd.to_numeric(raw_data.height,errors='coerce'))]['height']\n",
    "np.unique(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36e50ee",
   "metadata": {},
   "source": [
    "Height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34699d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data['height_cat']='height_NaN'\n",
    "raw_data.ix[(raw_data.height>=0) & (raw_data.height<50), 'height_cat']='height_0t50'\n",
    "raw_data.ix[(raw_data.height>=50) & (raw_data.height<100), 'height_cat']='height_50t100'\n",
    "raw_data.ix[(raw_data.height>=100) & (raw_data.height<150), 'height_cat']='height_100t150'\n",
    "raw_data.ix[(raw_data.height>=150) & (raw_data.height<200), 'height_cat']='height_150t200'\n",
    "raw_data.ix[(raw_data.height>=200) & (raw_data.height<250), 'height_cat']='height_200t250'\n",
    "raw_data.ix[(raw_data.height>=250) & (raw_data.height<300), 'height_cat']='height_250t300'\n",
    "raw_data.ix[(raw_data.height>=300) & (raw_data.height<350), 'height_cat']='height_300t350'\n",
    "raw_data.ix[(raw_data.height>=350) & (raw_data.height<400), 'height_cat']='height_350t400'\n",
    "raw_data.ix[(raw_data.height>=400), 'height_cat']='height_400t'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb3cb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "height_cats=pd.get_dummies(raw_data['height_cat'])\n",
    "del height_cats['height_NaN'] #comparison category\n",
    "del raw_data['height_cat']\n",
    "height_cats.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c934cf6",
   "metadata": {},
   "source": [
    "Width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4960b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data['width_cat']='width_NaN'\n",
    "raw_data.ix[(raw_data.width>=0) & (raw_data.width<50), 'width_cat']='width_0t50'\n",
    "raw_data.ix[(raw_data.width>=50) & (raw_data.width<100), 'width_cat']='width_50t100'\n",
    "raw_data.ix[(raw_data.width>=100) & (raw_data.width<150), 'width_cat']='width_100t150'\n",
    "raw_data.ix[(raw_data.width>=150) & (raw_data.width<200), 'width_cat']='width_150t200'\n",
    "raw_data.ix[(raw_data.width>=200) & (raw_data.width<250), 'width_cat']='width_200t250'\n",
    "raw_data.ix[(raw_data.width>=250) & (raw_data.width<300), 'width_cat']='width_250t300'\n",
    "raw_data.ix[(raw_data.width>=300) & (raw_data.width<350), 'width_cat']='width_300t350'\n",
    "raw_data.ix[(raw_data.width>=350) & (raw_data.width<400), 'width_cat']='width_350t400'\n",
    "raw_data.ix[(raw_data.width>=400), 'width_cat']='width_400t'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e0aa0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "width_cats=pd.get_dummies(raw_data['width_cat'])\n",
    "del width_cats['width_NaN'] #comparison category\n",
    "del raw_data['width_cat']\n",
    "width_cats.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27cb58f7",
   "metadata": {},
   "source": [
    "Switching the categorical with binary variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8d146d",
   "metadata": {},
   "outputs": [],
   "source": [
    "del raw_data['height'], raw_data['width'], raw_data['aratio']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3a4555",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data=pd.concat([height_cats,width_cats,aspect_cats,raw_data], axis=1)\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cfbc7af",
   "metadata": {},
   "source": [
    "Without domain knowledge or clear business logic, turning continuous variables into a series of categorical variables is a mix of empiricism and guessing. I inspected the histograms and selected partitions that made sense. This part of the model building process can be refined through iteration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53531e7",
   "metadata": {},
   "source": [
    "### Saving Final Modeling Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db37303",
   "metadata": {},
   "source": [
    "Normally I pickle datasets. However, to make the code more portable, I will save it as a csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97ff4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp=clean_data.mean().reset_index(name='Percent')\n",
    "temp.columns=['Variable','Percent']\n",
    "temp=temp[3:] #remove the continuous ones\n",
    "temp['Percent']=np.round(temp['Percent']*100,2)\n",
    "temp.sort_values(by='Percent',inplace=True,ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1226ca3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b98ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7cea97",
   "metadata": {},
   "outputs": [],
   "source": [
    "g=sns.distplot(temp.Percent)\n",
    "g.axes.set_ylim(0,)\n",
    "g.axes.set_xlim(0,100)\n",
    "g.axes.set_title('Distribution of Sparsity of Binary Variables\\n',fontsize=20)\n",
    "g.set_xlabel('Percent of Affirmative/True Instances',fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6670cd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(temp[temp.Percent<10])/len(temp) #Percent of binary features less than 10% affirmative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d586678",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(temp[temp.Percent<1])/len(temp) #Percent of binary features less than 1% affirmative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bba2175",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(temp[temp.Percent<.1])/len(temp)  #Percent of binary features less than 0.1% affirmative"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7615256",
   "metadata": {},
   "source": [
    "The feature space for the binary variables is sparse: 99% of the binary variables are affirmative less than 10% of the time and 86% are affirmative less than 1% of the time. \n",
    "\n",
    "In addition to using algorithms robust to sparse features, I may experiment with cross-validation driven feature selection (like 'VarianceThreshold')."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27e3f9d",
   "metadata": {},
   "source": [
    "### Inspecting with Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d01c9c1",
   "metadata": {},
   "source": [
    "Rows with all missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9082e189",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(clean_data)-len(clean_data.dropna(axis=0,how='all'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5158127b",
   "metadata": {},
   "source": [
    "Rows with any missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063e0239",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names=pd.read_csv(\"./raw_data/column.names.txt\",header=None,\n",
    "                     sep=\":\")\n",
    "col_names.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f344ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names.columns=['variable','type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c823b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9dd212",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data.columns=list(col_names.variable)\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c365cd51",
   "metadata": {},
   "source": [
    "## Data Quality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23ae045",
   "metadata": {},
   "source": [
    "### Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41371270",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_types=raw_data.dtypes.reset_index()\n",
    "data_types.columns=['variable','d_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaba1de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_tab(data_types,'d_type')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c463a391",
   "metadata": {},
   "source": [
    "All the features will be made numerical."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53aa2037",
   "metadata": {},
   "source": [
    "### Non-Numerical Values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4a1ceb",
   "metadata": {},
   "source": [
    "Non-numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85085cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data.ix[raw_data.local.isnull(), 'local']=0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb17acf4",
   "metadata": {},
   "source": [
    "### Make the Continuous Variables Categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82bfb7d0",
   "metadata": {},
   "source": [
    "Aspect Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c3ba21",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data['aratio_cat']='aratio_NaN'\n",
    "raw_data.ix[(raw_data.aratio>=0) & (raw_data.aratio<2), 'aratio_cat']='aratio_0t2'\n",
    "raw_data.ix[(raw_data.aratio>=2) & (raw_data.aratio<4), 'aratio_cat']='aratio_2t4'\n",
    "raw_data.ix[(raw_data.aratio>=4) & (raw_data.aratio<6), 'aratio_cat']='aratio_4t6'\n",
    "raw_data.ix[(raw_data.aratio>=6) & (raw_data.aratio<8), 'aratio_cat']='aratio_6t8'\n",
    "raw_data.ix[(raw_data.aratio>=8) & (raw_data.aratio<10), 'aratio_cat']='aratio_8t10'\n",
    "raw_data.ix[(raw_data.aratio>=10), 'aratio_cat']='aratio_10t'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d71e049",
   "metadata": {},
   "outputs": [],
   "source": [
    "aspect_cats=pd.get_dummies(raw_data['aratio_cat'])\n",
    "del aspect_cats['aratio_NaN'] #comparison category\n",
    "del raw_data['aratio_cat']\n",
    "aspect_cats.head()"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
