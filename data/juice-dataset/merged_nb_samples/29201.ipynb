{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f12257b",
   "metadata": {},
   "source": [
    "<img src=\"images/skanda.jpg\" width=\"400\"/>\n",
    "<img src=\"images/tf-small.png\" width=\"70\"/>\n",
    "\n",
    "# The Skandapurāṇa project\n",
    "\n",
    "We convert the Skandapurāṇa text to TF. \n",
    "\n",
    "They come from Peter Bisschop's [Skandapurāṇa project](https://www.universiteitleiden.nl/en/research/research-projects/humanities/the-skandapurāṇa-project#tab-1).\n",
    "\n",
    "We used the transliterated and the Devanāgarī representations of the texts as found [here](https://www.universiteitleiden.nl/en/research/research-projects/humanities/the-skandapurāṇa-project#tab-4)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6ede58",
   "metadata": {},
   "source": [
    "## Details of the TF modeling\n",
    "\n",
    "We take the Devanāgarī-character as smallest unit, the slot.\n",
    "Character nodes are called `char`.\n",
    "The unicode representation of a char is stored in the feature `dchar`.\n",
    "\n",
    "If a letter is the last letter of a word, we set its feature `last` to a space,\n",
    "otherwise the empty string.\n",
    "\n",
    "Words are the maximal stretches of Devanāgarī-chars that do not contain a space.\n",
    "Word nodes have node type `word`.\n",
    "\n",
    "The unicode representation of a word is stored in the feature `dword`.\n",
    "\n",
    "The transliteration of a word is stored in the feature `tword`.\n",
    "\n",
    "The top-level sectional unit is the node type `text`, and corresponds to the contents of a single file.\n",
    "\n",
    "Nodes of type `text` have the following features:\n",
    "\n",
    "* `name`: the name of the text. Usually this is just the number, but in some text\n",
    "  some characters are appended to the number;\n",
    "* `number`: the integer corresponding to the first triplet of digits\n",
    "  after the `SP` at the start of each line;\n",
    "* `volume`: as given in the description of the project\n",
    "\n",
    "Texts are subdivided into `verse`s.\n",
    "\n",
    "Nodes of type `verse` have the following features:\n",
    "\n",
    "* `number`: the integer corresponding to the second triplet of digits \n",
    "  after the `SP` at the start of each line.\n",
    "  \n",
    "Verses are subdivided into `line`s.\n",
    "\n",
    "Nodes of type `line` have the following features:\n",
    "\n",
    "* `number`: the integer corresponding to the last digit\n",
    "  after the `SP` at the start of each line.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253f4f8e",
   "metadata": {},
   "source": [
    "# The program"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6bcde1",
   "metadata": {},
   "source": [
    "Import generic Python modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41a9a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, collections\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94869b5d",
   "metadata": {},
   "source": [
    "Here is the import of the Text-Fabric library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d626b7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf.fabric import Fabric\n",
    "from tf.timestamp import Timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8472c891",
   "metadata": {},
   "outputs": [],
   "source": [
    "tm = Timestamp()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b610dbf",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "We use variables to point to the input directories and the output tf directory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537f3ff7",
   "metadata": {},
   "source": [
    "We glean the volume membership from the project description. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2affd11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOLUMES = dict(\n",
    "  I=(1,25),\n",
    "  IIA=(26,30),\n",
    "  IIB=(31,52),\n",
    "  III=(53,69),\n",
    "  S=(167,'s'),\n",
    "  RA=(167, 'ra'),  \n",
    ")\n",
    "RAS = (1,5)\n",
    "\n",
    "# node types\n",
    "\n",
    "TEXT = 'text'\n",
    "VERSE = 'verse'\n",
    "LINE = 'line'\n",
    "WORD = 'word'\n",
    "CHAR = 'char'\n",
    "\n",
    "NODE_TYPES = f'''\n",
    "  {CHAR}\n",
    "  {WORD}\n",
    "  {LINE}\n",
    "  {VERSE}\n",
    "  {TEXT}\n",
    "'''.strip().split()\n",
    "\n",
    "# features\n",
    "\n",
    "OTYPE = 'otype'\n",
    "OSLOTS = 'oslots'\n",
    "VOLUME = 'volume'\n",
    "NAME = 'name'\n",
    "NUMBER = 'number'\n",
    "DWORD = 'dword'\n",
    "TWORD = 'tword'\n",
    "DCHAR = 'dchar'\n",
    "LAST = 'last'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f6c2ec",
   "metadata": {},
   "source": [
    "## File list\n",
    "\n",
    "We generate the list of files in the corpus from the configuration.\n",
    "The result is represented as a list of items, each item is\n",
    "a document number plus document name plus a file name with its transliterated text, plus\n",
    "a file name with its devanagari text.\n",
    "\n",
    "We also map the document names to volume labels.\n",
    "\n",
    "Beyond the numbered texts there a a few special texts: S and RA recensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc5700e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeFileList():\n",
    "  textVolume = {}\n",
    "  texts = []\n",
    "  for (vol, (n, x)) in VOLUMES.items():\n",
    "    if type(x) is int:\n",
    "      for i in range(n, x + 1):\n",
    "        fileStart = f'st{i:>03}'\n",
    "        name = f'{i:>03}'\n",
    "        texts.append((i, name, f'{fileStart}.txt', f'{fileStart}_d.txt'))\n",
    "        textVolume[name] = vol\n",
    "    else:\n",
    "      fileStart = f'st{n:>03}'\n",
    "      if x == 's':\n",
    "        name = f'{n}S'\n",
    "        texts.append((n, name, f'{fileStart}_{x}.txt', f'{fileStart}_{x}_d.txt'))\n",
    "        textVolume[name] = vol\n",
    "      else:\n",
    "        for i in range(RAS[0], RAS[1] + 1):\n",
    "          name = f'{n}RA{i}'\n",
    "          texts.append((n, name, f'{fileStart}_{x}{i}.txt', f'{fileStart}_{x}{i}_d.txt'))\n",
    "          textVolume[name] = vol\n",
    "  return (texts, textVolume)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403c33a7",
   "metadata": {},
   "source": [
    "## Read the corpus files\n",
    "\n",
    "For each text item in the list, we read the associated files from disk.\n",
    "The file contents is chopped up in lines, and the text-containing lines\n",
    "are chopped up in words.\n",
    "\n",
    "All this data is collected in one big data structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f641eee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readText(n, name, transFile, devFile):\n",
    "  good = True\n",
    "  transPath = f'{TRANS}/{transFile}'\n",
    "  devPath = f'{ORIG}/{devFile}'\n",
    "  results = []\n",
    "  for path in (transPath, devPath):\n",
    "    if not os.path.isfile(path):\n",
    "      tm.error(f'{name}: file does not exist: {path}')\n",
    "      good = False\n",
    "      continue\n",
    "    with open(path) as fh:\n",
    "      results.append([\n",
    "        line.rstrip('\\n').split('|', 1)[0].split()\n",
    "        for line in fh\n",
    "        if line.startswith('SP')\n",
    "      ])\n",
    "  return results if good else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594520b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readCorpus(texts):\n",
    "  data = []\n",
    "  tm.indent(reset=True)\n",
    "  tm.info('Reading corpus')\n",
    "  for item in texts:\n",
    "    tm.info(f'\\t{item[1]}')\n",
    "    results = readText(*item)\n",
    "    if results is not None:\n",
    "      data.append((item[0], item[1], *results))\n",
    "  tm.info('Done')\n",
    "  return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b6b7ab",
   "metadata": {},
   "source": [
    "## Proto TF\n",
    "\n",
    "We process the data and compose the feature data for the `oslots` edge feature and\n",
    "the desired node features.\n",
    "\n",
    "In this stage we cannot know the eventual node numbers, so we identify each node by node type and node number within its type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c14fc9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def protoTf(data, textVolume):\n",
    "  curSlot = 0\n",
    "  curWord = 0\n",
    "  curLine = 0\n",
    "  curVerse = 0\n",
    "  curText = 0\n",
    "  edgeFeatures = {\n",
    "    OSLOTS: {},\n",
    "  }\n",
    "  nodeFeatures = {\n",
    "    OTYPE: {},\n",
    "    VOLUME: {},\n",
    "    NAME: {},\n",
    "    NUMBER: {},\n",
    "    DWORD: {},\n",
    "    TWORD: {},\n",
    "    DCHAR: {},\n",
    "    LAST: {},\n",
    "  }\n",
    "\n",
    "  tm.indent(reset=True)\n",
    "  tm.info('Proto TF generation')\n",
    "  for (textNum, textName, transData, devData) in data:\n",
    "    tm.info(f'\\t{textName}')\n",
    "    curText += 1\n",
    "    nodeFeatures[OTYPE][(TEXT, curText)] = TEXT\n",
    "    nodeFeatures[NAME][(TEXT, curText)] = textName\n",
    "    nodeFeatures[NUMBER][(TEXT, curText)] = textNum\n",
    "    nodeFeatures[VOLUME][(TEXT, curText)] = textVolume[textName]\n",
    "    firstTextSlot = curSlot + 1\n",
    "    firstVerseSlot = curSlot + 1\n",
    "    firstLineSlot = curSlot + 1\n",
    "    verseNum = None\n",
    "    lineNum = None\n",
    "    for (i, dLine) in enumerate(devData):\n",
    "      label = dLine[0]\n",
    "      dWords = dLine[1:]\n",
    "      tWords = transData[i][1:]\n",
    "      labelNumbers = label[10:14] if label[2:4] == 'ra' else label[5:9]\n",
    "      thisVerseNum = int(labelNumbers[0:3])\n",
    "      thisLineNum = int(0 if labelNumbers[3] == ':' else labelNumbers[3])\n",
    "      if thisLineNum != lineNum or thisVerseNum != verseNum:\n",
    "        if lineNum is not None:\n",
    "          curLine += 1\n",
    "          nodeFeatures[OTYPE][(LINE, curLine)] = LINE\n",
    "          nodeFeatures[NUMBER][(LINE, curLine)] = lineNum\n",
    "          edgeFeatures[OSLOTS][(LINE, curLine)] = set(range(firstLineSlot, curSlot + 1))\n",
    "          firstLineSlot = curSlot + 1\n",
    "        lineNum = thisLineNum\n",
    "      if thisVerseNum != verseNum:\n",
    "        if verseNum is not None:\n",
    "          curVerse += 1\n",
    "          nodeFeatures[OTYPE][(VERSE, curVerse)] = VERSE\n",
    "          nodeFeatures[NUMBER][(VERSE, curVerse)] = verseNum\n",
    "          edgeFeatures[OSLOTS][(VERSE, curVerse)] = set(range(firstVerseSlot, curSlot + 1))\n",
    "          firstVerseSlot = curSlot + 1\n",
    "        verseNum = thisVerseNum\n",
    "      if thisLineNum != lineNum or thisVerseNum != verseNum:\n",
    "        if lineNum is not None:\n",
    "          curLine += 1\n",
    "          nodeFeatures[OTYPE][(LINE, curLine)] = LINE\n",
    "          nodeFeatures[NUMBER][(LINE, curLine)] = lineNum\n",
    "          edgeFeatures[OSLOTS][(LINE, curLine)] = set(range(firstLineSlot, curSlot + 1))\n",
    "          firstLineSlot = curSlot + 1\n",
    "        lineNum = thisLineNum\n",
    "      for (j, dWord) in enumerate(dWords):\n",
    "        tWord = tWords[j]\n",
    "        curWord += 1\n",
    "        nodeFeatures[OTYPE][(WORD, curWord)] = WORD\n",
    "        nodeFeatures[DWORD][(WORD, curWord)] = dWord\n",
    "        nodeFeatures[TWORD][(WORD, curWord)] = tWord\n",
    "        edgeFeatures[OSLOTS][(WORD, curWord)] = set(range(curSlot + 1, curSlot + 1 + len(dWord)))\n",
    "        for d in dWord:\n",
    "          curSlot += 1\n",
    "          nodeFeatures[OTYPE][(CHAR, curSlot)] = CHAR\n",
    "          nodeFeatures[DCHAR][(CHAR, curSlot)] = d\n",
    "          nodeFeatures[LAST][(CHAR, curSlot)] = ''\n",
    "        nodeFeatures[LAST][(CHAR, curSlot)] = ' '\n",
    "    if verseNum is not None:\n",
    "      curVerse += 1\n",
    "      nodeFeatures[OTYPE][(VERSE, curVerse)] = VERSE\n",
    "      nodeFeatures[NUMBER][(VERSE, curVerse)] = verseNum\n",
    "      edgeFeatures[OSLOTS][(VERSE, curVerse)] = set(range(firstVerseSlot, curSlot + 1))\n",
    "    if lineNum is not None:\n",
    "      curLine += 1\n",
    "      nodeFeatures[OTYPE][(LINE, curLine)] = LINE\n",
    "      nodeFeatures[NUMBER][(LINE, curLine)] = lineNum\n",
    "      edgeFeatures[OSLOTS][(LINE, curLine)] = set(range(firstLineSlot, curSlot + 1))\n",
    "    edgeFeatures[OSLOTS][(TEXT, curText)] = set(range(firstTextSlot, curSlot + 1))\n",
    "  tm.info('Done')\n",
    "  tm.info('Checking whether all slots are contained in a word, line, verse and text')\n",
    "  typeSlots = {}\n",
    "  for ((nType, n), slots) in edgeFeatures[OSLOTS].items():\n",
    "    typeSlots.setdefault(nType, set())\n",
    "    typeSlots[nType] |= slots\n",
    "  for (nType, slots) in typeSlots.items():\n",
    "    minSlot = min(slots)\n",
    "    maxSlot = max(slots)\n",
    "    ok = minSlot == 1 and maxSlot == curSlot and len(slots) == maxSlot\n",
    "    okRep = 'ok' if ok else '!!!'\n",
    "    print(f'{nType:<8}: {len(slots)} elements between {minSlot} - {maxSlot} ({okRep})')\n",
    "  return (nodeFeatures, edgeFeatures)      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228bce3a",
   "metadata": {},
   "source": [
    "## TF features\n",
    "\n",
    "We create real TF feature data, by ordering all nodes into one big sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04ceb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfFeatures(nodeFeaturesProto, edgeFeaturesProto):\n",
    "  errors = set()\n",
    "  nodeTypeSets = {}\n",
    "  for ((otp, n), xtp) in nodeFeaturesProto[OTYPE].items():\n",
    "    if otp != xtp:\n",
    "      errors.add((otp, n, xtp))\n",
    "    nodeTypeSets.setdefault(otp, set()).add(n)\n",
    "  print(f'{len(errors)} inconsistencies')\n",
    "  curOffset = 0\n",
    "  offsets = {}\n",
    "  for otp in NODE_TYPES:\n",
    "    offsets[otp] = curOffset\n",
    "    ns = nodeTypeSets[otp]\n",
    "    minNtp = min(ns)\n",
    "    if minNtp != 1:\n",
    "      print(f'Node type {otp} starts with {minNtp}')\n",
    "    maxNtp = max(ns)\n",
    "    if maxNtp != len(ns):\n",
    "      print(f'Node type {otp} has holes in the sequence: {len(ns)} vs {maxNtp}')\n",
    "    print(f'{otp:<8}: {maxNtp:>6}')\n",
    "    curOffset += maxNtp\n",
    "  nodeFeatures = {}\n",
    "  edgeFeatures = {}\n",
    "  for (feature, data) in nodeFeaturesProto.items():\n",
    "    featureData = {}\n",
    "    for ((ntp, n), value) in data.items():\n",
    "      featureData[n + offsets[ntp]] = value\n",
    "    nodeFeatures[feature] = featureData\n",
    "  for (feature, data) in edgeFeaturesProto.items():\n",
    "    featureData = {}\n",
    "    for ((ntp, n), value) in data.items():\n",
    "      featureData[n + offsets[ntp]] = value\n",
    "    edgeFeatures[feature] = featureData\n",
    "  for (otp, offset) in offsets.items():\n",
    "    print(f'{otp} has offset {offset}')\n",
    "    for i in range(max((offset - 3, 1)), offset + 4):\n",
    "      print(f'{i:>6} is a {nodeFeatures[\"otype\"][i]}')\n",
    "  return (nodeFeatures, edgeFeatures)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cdb67a7",
   "metadata": {},
   "source": [
    "## Main steps\n",
    "\n",
    "Here we execute the main steps, as defined in the functions above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d66bae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "(texts, textVolume) = makeFileList()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f487d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = readCorpus(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6591ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "(nodeFeaturesProto, edgeFeaturesProto) = protoTf(data, textVolume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba220ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "(nodeFeatures, edgeFeatures) = tfFeatures(nodeFeaturesProto, edgeFeaturesProto)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8255d72",
   "metadata": {},
   "source": [
    "# Metadata\n",
    "\n",
    "We supply the necessary metadata for the new features.\n",
    "We also have a few generic fields that will be added to all features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40855ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "metaData = {\n",
    "  '': dict(\n",
    "    createdBy='Peter Bisschop et al.',\n",
    "    convertedBy='Dirk Roorda',\n",
    "    name='Adhyāyas',\n",
    "    title='Skandapurāṇa Project',\n",
    "    source1='http://hum2.leidenuniv.nl/pdf/skandapurana-project/SP_all_devanagari.zip',\n",
    "    source2='http://hum2.leidenuniv.nl/pdf/skandapurana-project/SP_all_transliteration.zip',\n",
    "    provenance='https://www.universiteitleiden.nl/en/research/research-projects/humanities/the-skandapurāṇa-project',\n",
    "    description='volumes I-III of the critical edition of the Skandapurāṇa online',\n",
    "  ),\n",
    "  'otext': {\n",
    "    'sectionFeatures': ','.join((NAME, NUMBER, NUMBER)),\n",
    "    'sectionTypes': ','.join((TEXT, VERSE, LINE)),\n",
    "    'fmt:text-orig-full': f'{{{DCHAR}}}{{{LAST}}}',\n",
    "    'fmt:text-orig-word': f'{{{DWORD}}} ',\n",
    "    'fmt:text-trans-word': f'{{{TWORD}}} ',\n",
    "  },\n",
    "  'name@en': {\n",
    "    'valueType': 'str',\n",
    "    'language': 'english',\n",
    "    'languageCode': 'en',\n",
    "    'languageEnglish': 'English',\n",
    "  },\n",
    "}\n",
    "nodeFeatures['name@en'] = nodeFeatures[NAME]\n",
    "\n",
    "for feat in (OSLOTS, OTYPE, NAME, DWORD, TWORD, DCHAR, LAST, VOLUME):\n",
    "  metaData.setdefault(feat, {})['valueType'] = 'str'\n",
    "for feat in (NUMBER,):\n",
    "  metaData.setdefault(feat, {})['valueType'] = 'int'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c81399",
   "metadata": {},
   "source": [
    "## Save data as TF data set\n",
    "\n",
    "The TF package has a function by which we can save all data that we have composed\n",
    "into a valid TF data set."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
