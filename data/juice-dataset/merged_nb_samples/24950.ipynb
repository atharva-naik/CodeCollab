{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd2f9f15",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Let's perform classifiction with two Neural Networks on the MNIST dataset.\n",
    "\n",
    " - Multi-Layer Perceptron\n",
    " - Convolutional Neural Network\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26cbbef2",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6523bb",
   "metadata": {},
   "source": [
    "## What is MNIST?\n",
    "\n",
    "It's a database of handwritten digits that has a training set of 60.000 examples and a test set of 10.000 examples. The digits have been size-normalized and centered in a fixed-size image.\n",
    "\n",
    "### Import with TensorFlow\n",
    "\n",
    "We will get the dataset directly from the TensorFlow API, so it really doesn't contain images. It contain the transformed-into-arrays images.\n",
    "\n",
    "One-Hot encoding will be used for the labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "293961c5",
   "metadata": {},
   "source": [
    "#### One-Hot\n",
    "<pre>\n",
    "Number representation:    5\n",
    "One-hot encoding:        [5]   [4]    [3]    [2]    [1]    [0]  \n",
    "Array/vector:             1     0      0      0      0      0   \n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0e324c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets('MNIST_data',one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f95b1a4",
   "metadata": {},
   "source": [
    "A fast overview of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0e8952",
   "metadata": {},
   "source": [
    "### Weights and Bias\n",
    "\n",
    "This time, with zeros initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3338384",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Weight Tensor\n",
    "W = tf.Variable(tf.zeros(dtype=tf.float32,shape=[numFeatures,numLabels]))\n",
    "#Bias Tensor\n",
    "b = tf.Variable(tf.zeros(dtype=tf.float32,shape=[numLabels]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8410aa0",
   "metadata": {},
   "source": [
    "Initialize variables (Note that we are in an interactive session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52fc0909",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.global_variables_initializer().run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5021f7c1",
   "metadata": {},
   "source": [
    "### Adding Weights and Biases to input\n",
    "\n",
    "Representation of the operations that are: A matrix multiplication between x (inputs) and W (weights) and posterior biases add\n",
    "\n",
    "<img src=\"https://ibm.box.com/shared/static/88ksiymk1xkb10rgk0jwr3jw814jbfxo.png\" alt=\"HTML5 Icon\" style=\"width:350px;height:306px;\"> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a2b8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mathematical representation of image above\n",
    "tf.matmul(x,W) + b;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a71dca",
   "metadata": {},
   "source": [
    "### Softmax Regression\n",
    "\n",
    "Softmax is an **activation function** that is normally used in classification problems. \n",
    "\n",
    "It \"squashes\" a K-dimensional vector of arbitrary real values to a K-dimensional vector of real values in the range [0, 1] that add up to 1. It generates a distribution of probabilities for the output, for example:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "05e79fe3",
   "metadata": {},
   "source": [
    "0 -->.0.1%  \n",
    "1 -->...2%  \n",
    "2 -->...3%  \n",
    "3 -->...2%  \n",
    "4 -->..12%  \n",
    "5 -->..10%  \n",
    "6 -->..57%\n",
    "7 -->..20%\n",
    "8 -->..55%\n",
    "9 -->..80%  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6094a169",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SoftMax\n",
    "y = tf.nn.softmax(tf.matmul(x,W) + b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95fb480f",
   "metadata": {},
   "source": [
    "Logistic function is used for the binary classification 0/1\n",
    "\n",
    "Softmax function is a generalized type of logistic function that can output a multiclass categorical probabilty distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4e9c43",
   "metadata": {},
   "source": [
    "### Cost function\n",
    "\n",
    "It is a function that is used to **minimize the difference between the right answers and estimated outputs** by the Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b08b21",
   "metadata": {},
   "source": [
    "---\n",
    "**But before let's see what the next functions do**\n",
    "\n",
    "The following code shows an example of cross-entropy for a minibatch of size 2 with 3 possible classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a40a6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "y_gold_test = [[1.0,0.0,0.0],[1.0,0.0,0.0]]\n",
    "\n",
    "\n",
    "output_test = [[0.9,0.1,0.1],[0.9,0.1,0.1]]\n",
    "print('Some good predictions give as a cross-entropy of...: %.3f' % np.mean(-np.sum(y_gold_test * np.log(output_test),1)))\n",
    "\n",
    "output_test = [[0.5,0.2,0.1],[0.4,0.3,0.1]]\n",
    "print('Some bad predictions give as a cross-entropy of...: %.3f' % np.mean(-np.sum(y_gold_test * np.log(output_test),1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1779aaf2",
   "metadata": {},
   "source": [
    "**reduce_sum** computes the sum of elements of **(y_ * tf.log(y))** across second dimension of the tensor, and **reduce_mean** computes the mean of all elements in the tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54714f21",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c338c65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cost function\n",
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y),axis=[1])) \n",
    "train_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(cross_entropy)\n",
    "\n",
    "#axis=1 => The outputs, columns (axis=0 are the observations, rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38aa61e",
   "metadata": {},
   "source": [
    "### Type of optimization: Gradient Descent\n",
    "\n",
    "Configure the optimizer. There are several but Gradient Descent will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32bd55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.5\n",
    "train_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c8099f",
   "metadata": {},
   "source": [
    "### Training batches\n",
    "\n",
    "Train using minibatch Gradient Descent.\n",
    "\n",
    "Gradient Descent will find the **global minimum** but it's **computationally expensive** so minibatches will be used.\n",
    "\n",
    "First, let's take a brief look on the batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7690c430",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = mnist.train.next_batch(50)\n",
    "# print all dictionaries in the list\n",
    "batch_inputs = batch[0]\n",
    "batch_labels = batch[1]\n",
    "\n",
    "print('Batch inputs shape: ',batch_inputs.shape)\n",
    "print('The first image on batch:\\n %s' % batch_inputs[0])\n",
    "print('Batch labels shape: ',batch_labels.shape)\n",
    "print('The label of the first image on batch:\\n %s' %batch_labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda0f894",
   "metadata": {},
   "source": [
    "**Batch summary**\n",
    "\n",
    "It's a tuple where:\n",
    " - batch[0] => Observations\n",
    "  - batch[0][0] => First observation\n",
    " - batch[1] => Labels\n",
    "  - batch[1][0] => First observation label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed4e2087",
   "metadata": {},
   "source": [
    "### Test\n",
    "\n",
    "Let's get some results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d52670",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('For example: The first \"image\" of the dataset:\\n %s' %mnist.train.images[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1579b23f",
   "metadata": {},
   "source": [
    "## Understanding the imported data\n",
    "\n",
    "The imported data can be divided as follow:\n",
    "\n",
    " - Training (mnist.train): Use the given dataset with inputs and related outputs for training of NN.\n",
    "      - 55.000 observations\n",
    "      - mnist.train.images for inputs\n",
    "      - mnist.train.labels for outputs\n",
    " - Validation (mnist.validation): The same as training\n",
    "      - 5.000 observations\n",
    "      - mnist.validation.images for inputs\n",
    "      - mnist.validation.labels for outputs\n",
    " - Test (mnist.test): The model does not have access to this informations prior to the test phase. It is used to evaluate the performance and accuracy of the model.\n",
    "     - 10.000 observations\n",
    "     - mnist.test.images for inputs\n",
    "     - mnist.test.labels for outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c709e26f",
   "metadata": {},
   "source": [
    "# 1st: Multi-Layer Perceptron\n",
    "\n",
    "Simple type of Neural Network to perform classification tasks on the MNIST digits dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40641218",
   "metadata": {},
   "source": [
    "### Interactive session\n",
    "\n",
    "Instead of do all the set-up and then execute a session to evaluate tensors and run operations (as usual) we will use and interactive session to create the code and run on the fly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ba0e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74bb428",
   "metadata": {},
   "source": [
    "### Creating Placeholders\n",
    "\n",
    "Note: The 'shape' argument defines the tensor size by its dimensions\n",
    "\n",
    "**Placeholder 'X':** Represents the input images\n",
    " - Each image is 28 x 28 px -> 784 pixels\n",
    " - 1st dimension: Indicates the **batch size** => None (any size)\n",
    " - 2nd dimension: Indicates the **number of pixels (features in general)** on a single flattened MNIST image => 784 (28*28)\n",
    " \n",
    "**Placeholder 'Y':** Represents the output labels\n",
    " - 10 possible classes (0,1,2,3,4,5,6,7,8,9)\n",
    " - 1st dimension: Indicates the **batch size** => None (any size)\n",
    " - 2nd dimension: Indicates the number of **possible classes** => 10\n",
    " \n",
    "**dtype:**: In general, use tf.float32. The limitation is that some functions only accepts float32 or float64 representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3733908f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training dataset shape:', mnist.train.images.shape)\n",
    "numTrainInstances = mnist.train.images.shape[0]\n",
    "numFeatures = mnist.train.images.shape[1]\n",
    "print('Num instances: %d \\nNum features: %d' %(numTrainInstances,numFeatures))\n",
    "print('Training dataset labels shape:', mnist.train.labels.shape)\n",
    "numLabels = mnist.train.labels.shape[1]\n",
    "print('Num possible classes: %d' %(numLabels))\n",
    "\n",
    "x = tf.placeholder(dtype=tf.float32,shape=[None,numFeatures],name='x_placeholder')\n",
    "y_ = tf.placeholder(dtype=tf.float32,shape=[None,numLabels],name='y_gold_placeholder')"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
