{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "360dd2a3",
   "metadata": {},
   "source": [
    "# Automated Transient Determination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f88544c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function, unicode_literals\n",
    "import time\n",
    "#import os\n",
    "#import glob\n",
    "#import subprocess\n",
    "import numpy as np\n",
    "import math\n",
    "import astropy.io.fits as fits\n",
    "import sys\n",
    "import datetime\n",
    "import ephem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27355e7c",
   "metadata": {},
   "source": [
    "### Here we can add the below process to the existing Transients code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6418461d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creates a segmentation map from the master file. This will be used to generate flag files later.\n",
    "#To tweak the sensitivity of this segmentation map (brightness of objects it identifies for flagging), change\n",
    "#the DETECT_THRESH and ANALYSIS_THRESH values in segmentation.sex, located in the config_files directory.\n",
    "#This file is a temporary file, but the code will not delete it by default, as it can be a useful analysis tool.\n",
    "\n",
    "subprocess.call('sex '+master_file[0]+' -c ./config_files/segmentation.sex -WEIGHT_IMAGE '+master_weight[0], shell=True)\n",
    "subprocess.call('mv ./Processed_Images/Temp/check.fits ./Processed_Images/Temp/segmentation_map_ref.fits', shell=True)\n",
    "master_segmentation = ['./Processed_Images/Temp/segmentation_map_ref.fits']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d11ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This loop creates all the difference images and their respective object, background, and aperture maps.\n",
    "\n",
    "for i in range(0,2):#len(resamps)):\n",
    "    reference=fits.open(master_file[0])\n",
    "    resampled=fits.open(resamps[i])\n",
    "    \n",
    "    #measures the distance from the central WCS pixel to the right and to the bottom of the image, respectively.\n",
    "    resdistx=(resampled[0].header['NAXIS1']-resampled[0].header['CRPIX1'])\n",
    "    resdisty=(resampled[0].header['NAXIS2']-resampled[0].header['CRPIX2'])\n",
    "    \n",
    "    #Creates difference values that represent the start and end pixels of the resampled image on the reference image.\n",
    "    ref_x_start=int(reference[0].header['CRPIX1']-resampled[0].header['CRPIX1'])\n",
    "    ref_y_start=int(reference[0].header['CRPIX2']-resampled[0].header['CRPIX2'])\n",
    "    ref_x_end=int(reference[0].header['CRPIX1']+resdistx)\n",
    "    ref_y_end=int(reference[0].header['CRPIX2']+resdisty)\n",
    "    \n",
    "    #loading files into memory\n",
    "    refimg=pyfits.open(master_file[0])\n",
    "    resimg=pyfits.open(resamps[i])\n",
    "    segimg=pyfits.open(master_segmentation[0])\n",
    "    \n",
    "    #converting to array\n",
    "    D1=refimg[0].data\n",
    "    D2=resimg[0].data\n",
    "    D3=segimg[0].data\n",
    "    \n",
    "    #resizing and scaling pixel values\n",
    "    resize_ref=D1[ref_y_start:ref_y_end,ref_x_start:ref_x_end]\n",
    "    resamp_scaled=D2*resampled[0].header['FLXSCALE']\n",
    "    resize_seg=D3[ref_y_start:ref_y_end,ref_x_start:ref_x_end]\n",
    "    \n",
    "    #doing the subtraction of the reference image from the resampled\n",
    "    out_file=resamp_scaled-resize_ref\n",
    "    \n",
    "    #loading header information from original resampled image. This will be saved into the new images.\n",
    "    head=pyfits.getheader(resamps[i])\n",
    "    \n",
    "    #loads the filename of the resamp image into a variable, then deletes .resamp.fits from the end of it.\n",
    "    #This allows the code to write new files with the same naming format, but different file extension names.\n",
    "    #If your files don't end in .resamp.fits, the -12 will need to be changed to match the number of characters\n",
    "    #in the file extension.\n",
    "    path=os.path.basename(resamps[i])\n",
    "    new_path=path[:-12]\n",
    "    \n",
    "    #saves the final difference file, and the temporary resized segmentation map.\n",
    "    pyfits.writeto(('./Processed_Images/'+new_path+'.difference.fits'), out_file, head)\n",
    "    pyfits.writeto(('./Processed_Images/Temp/temp_segment.fits'), resize_seg, head)\n",
    "    \n",
    "    #produces a flag map from the temporary segmentation map.\n",
    "    subprocess.call('ww -c ./config_files/default.ww -WEIGHT_NAMES '+weights[i]+',./Processed_Images/Temp/temp_segment.fits', shell=True)\n",
    "    \n",
    "    #does the main sextractor run on the subtracted file, producing the object, background, and aperture files.\n",
    "    #this is controlled by default.sex in the config_files directory\n",
    "    subprocess.call('sex ./Processed_Images/'+new_path+'.difference.fits -c ./config_files/default.sex', shell=True)\n",
    "    \n",
    "    #cleans up temporary files and renames background, object, and aperture files. \n",
    "    subprocess.call('rm ./Processed_Images/Temp/temp_segment.fits',shell=True)\n",
    "    subprocess.call('mv ./Processed_Images/check.fits ./Processed_Images/'+new_path+'.background.fits',shell=True)\n",
    "    subprocess.call('mv ./Processed_Images/check2.fits ./Processed_Images/'+new_path+'.object.fits',shell=True)\n",
    "    subprocess.call('mv ./Processed_Images/check3.fits ./Processed_Images/'+new_path+'.apertures.fits',shell=True)\n",
    "    subprocess.call('rm ./Processed_Images/Temp/weight.fits',shell=True)\n",
    "    subprocess.call('rm ./Processed_Images/Temp/flag.fits',shell=True)\n",
    "#Uncomment the next line if you would like the code to automatically clean up the master segmentation map.\n",
    "#subprocess.call('rm ./Processed_Images/Temp/segmentation_map_ref.fits',shell=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eaad4f8",
   "metadata": {},
   "source": [
    "# Begin Brendan's Transient checking script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30bd321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is where the code can be tacked onto the pipeline, after subtracting reference images.\n",
    "# At this point we should have a combined image, with reference subtracted, where the only point sources remaining\n",
    "# (in theory) are transients such as supernovae or asteroids.\n",
    "\n",
    "# This code aims to classify such sources as either known asteroids or anomalies, which can then be manually checked."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8b27a3",
   "metadata": {},
   "source": [
    "### Run SExtractor once more to spot remaining (transient) sources:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbfc818c",
   "metadata": {},
   "source": [
    "Generate list of sources:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5250d9e",
   "metadata": {},
   "source": [
    "## Check against catalogues of known asteroids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95aa7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download latest MPCORB catalogue from:\n",
    "# www.minorplanetcenter.org/iau/MPCORB/MPCORB.DAT\n",
    "\n",
    "# Full list of paramters and how to read the data:\n",
    "# http://www.minorplanetcenter.net/iau/info/MPOrbitFormat.html\n",
    "\n",
    "\n",
    "# and do a manual check using PYEPHEM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7245b915",
   "metadata": {},
   "source": [
    "### Fiddling around with pyephem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12007e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(perihelion_arg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6773aa55",
   "metadata": {},
   "source": [
    "### Define a function to extract the packed Epoch date format given in the MPCORB data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec61c039",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define dictionary of alpha to numbers for MPCORB packed dates translation:\n",
    "# see  <http://www.minorplanetcenter.net/iau/info/PackedDates.html>  for more info.\n",
    "\n",
    "def epoch_convert(date):\n",
    "    \n",
    "    \"Converts the MPCORB Epoch from packed form to a regular YYYYMMDD.DDDD string to be split up and used later.\"\n",
    "    \n",
    "    packeddates = {'1':'1', '2':'2', '3':'3', '4':'4', '5':'5', '6':'6', '7':'7', '8':'8', '9':'9', \\\n",
    "                   '0':'0', 'A':'10', 'B':'11', 'C':'12', 'D':'13', 'E':'14', 'F':'15', 'G':'16', \\\n",
    "                   'H':'17', 'I':'18', 'J':'19', 'K':'20', 'L':'21', 'M':'22', 'N':'23', 'O':'24', \\\n",
    "                   'P':'25', 'Q':'26', 'R':'27', 'S':'28','T':'29', 'U':'30', 'V':'31' \\\n",
    "              }\n",
    "    datestring = list(date[0:5])\n",
    "    datestring2 = \"\"\n",
    "    nums = \"0123456789\"\n",
    "    \n",
    "    # Conditionals to distinguish between packed dates, eg  avoid confusion between 1-Nov (11 1) /\n",
    "    # and 11-Jan (1 11) when compiled back into a string (111). \n",
    "    # We convert all single-digit numeric month/day values to 2-digits (eg 6 --> 06):\n",
    "    \n",
    "    if date[3] in nums and date[4] in nums:\n",
    "        datestring.insert(3,'0')\n",
    "        datestring.insert(5,'0')\n",
    "        for i in range(len(datestring)):\n",
    "            char = packeddates['%s' % datestring[i]]\n",
    "            datestring2 += str(char)\n",
    "        if len(date) > 5:\n",
    "            datestring2 += \".\" + date[5:]\n",
    "        return datestring2 \n",
    "    elif date[3] in nums and date[4] not in nums:\n",
    "        datestring.insert(3,'0')\n",
    "        for i in range(len(datestring)):\n",
    "            char = packeddates['%s' % datestring[i]]\n",
    "            datestring2 += str(char)\n",
    "        if len(date) > 5:\n",
    "            datestring2 += \".\" + date[5:]\n",
    "        return datestring2\n",
    "    elif date[3] not in nums and date[4] in nums:\n",
    "        datestring.insert(4,'0')\n",
    "        for i in range(len(datestring)):\n",
    "            char = packeddates['%s' % datestring[i]]\n",
    "            datestring2 += str(char)\n",
    "        if len(date) > 5:\n",
    "            datestring2 += \".\" + date[5:]\n",
    "        return datestring2\n",
    "    elif date[3] not in nums and date[4] not in nums:\n",
    "        for i in range(len(datestring)):\n",
    "            char = packeddates['%s' % datestring[i]]\n",
    "            datestring2 += str(char)\n",
    "        if len(date) > 5:\n",
    "            datestring2 += \".\" + date[5:]\n",
    "        return datestring2\n",
    "    \n",
    "    print(datestring2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8e8f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = 'K165B5566'\n",
    "test2 = epoch_convert(test1)\n",
    "print(test2)\n",
    "hhh = (int(test2[:4]), int(test2[4:6]), float(test2[6:]))\n",
    "print(hhh)\n",
    "print(ephem.Date(hhh))\n",
    "print('%s' % (test2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c4d279",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = int(test2[:4])\n",
    "b = int(test2[4:6])\n",
    "c = float(test2[6:])\n",
    "print(a, b, c)\n",
    "print(ephem.Date((a, b, c)))\n",
    "print(ephem.Date((2016, 5, 11.2566)))\n",
    "ephem.Date((a, b, c))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2cc05ce",
   "metadata": {},
   "source": [
    "### Load some asteroid parameters into pyephem to test:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef66e11",
   "metadata": {},
   "source": [
    "Required orbital params:\n",
    "\n",
    "Om longitude of the ascending node \n",
    "\n",
    "inc = inclination to the ecliptic (plane of the Earth's orbit)\n",
    "\n",
    "om = argument of perihelion\n",
    "\n",
    "a = semi-major axis, or mean distance from Sun\n",
    "\n",
    "e = eccentricity (0=circle, 0-1=ellipse, 1=parabola)\n",
    "\n",
    "M = mean anomaly (0 at perihelion; increases uniformly with time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915cbed3",
   "metadata": {},
   "source": [
    "## Testing Ephemeris calculation for a real asteroid, Vesta:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1334937",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise a new, blank orbital body and load orbital params:\n",
    "params = MPCORB[2]\n",
    "body = ephem.EllipticalBody()\n",
    "\n",
    "#six required params for Keplerian orbit:\n",
    "# Longitude of ascending node:\n",
    "body._Om = float(params[6])\n",
    "# Inclination:\n",
    "body._inc = float(params[7])\n",
    "# Arg of perihelion\n",
    "body._om = float(params[5])\n",
    "# Mean distance from Sun: ???????????? ACCURATE?? Semi Major Axis, technically.\n",
    "body._a = float(params[10])\n",
    "# Eccentricity:\n",
    "body._e = float(params[8])\n",
    "# Mean anomoly from perihelion:\n",
    "body._M = float(params[4])\n",
    "# Epoch for _M:\n",
    "aster_epoch = epoch_convert('K161D')\n",
    "#body._epoch_M = ephem.Date((int(aster_epoch[:4]), int(aster_epoch[4:6]), float(aster_epoch[6:])))\n",
    "body._epoch_M = ephem.Date((2016, 01, 19))\n",
    "\n",
    "\n",
    "huntsman = ephem.Observer()\n",
    "huntsman.lon = 151.111128\n",
    "huntsman.lat = -33.770281\n",
    "huntsman.elevation = 50\n",
    "huntsman.date = ephem.Date((2016, 11, 26, 0, 0, 0))\n",
    "huntsman.epoch=ephem.J2000\n",
    "#get fits header for date\n",
    "\n",
    "\n",
    "print(body._epoch_M)\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e1041c",
   "metadata": {},
   "outputs": [],
   "source": [
    "body.compute(huntsman)\n",
    "print(body.a_ra, body.a_dec)\n",
    "print(body.g_ra, body.g_dec)\n",
    "print(body.ra, body.dec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240141c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "date1 = ephem.Date((2016, 1, 19, 0, 0, 0))\n",
    "body.compute(date1)\n",
    "print(date1)\n",
    "print(params[21])\n",
    "print('Apparent Topocentric Position:      RA: ' +str(body.ra) +', DEC: '+ str(body.dec))\n",
    "print('Astrometric Geocentric Position:   RA: ' +str(body.a_ra) +', DEC: '+ str(body.a_dec))\n",
    "print('Apparent Geocentric Position:      RA: ' +str(body.g_ra) +', DEC: '+ str(body.g_dec))\n",
    "\n",
    "# Correct values for 19 Jan 2016 0:00:00  as per <ssd.jpl.nasa.gov/horizons.cgi>:\n",
    "# 00 52 10.62 -01 26 01.5       \n",
    " \n",
    "# See what values we get for our data!\n",
    "\n",
    "# This was tested at most recent epoch. Test further away from this to check how fast errors will accumulate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8c23dd",
   "metadata": {},
   "source": [
    "### test reading fits header for pulling date and time of image and store as string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1fe8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "light = '2014-09-21_83F011167_12_light.bdfw.fits'\n",
    "datestr = fits.getheader(light)['DATE']\n",
    "datestr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5cc4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ephem.Date((int(datestr[0:4]), int(datestr[5:7]), int(datestr[8:10]), int(datestr[11:13]), \\\n",
    "                  int(datestr[14:16]), int(datestr[17:19]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2020dd48",
   "metadata": {},
   "source": [
    "### Can use this to calculate day fractionals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d871eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = ephem.Date((2014, 9, 21, 15, 21, 50))\n",
    "print(d.triple())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e503fff3",
   "metadata": {},
   "source": [
    "## Final code to check series of images against MPCORB:"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
