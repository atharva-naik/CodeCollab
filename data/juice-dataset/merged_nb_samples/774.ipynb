{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ba81087",
   "metadata": {},
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#[5.1]-Generate-a-time-series-from-an-IID-Gaussian-random-process.-This-is-a-memory-less,-stationary-series:\" data-toc-modified-id=\"[5.1]-Generate-a-time-series-from-an-IID-Gaussian-random-process.-This-is-a-memory-less,-stationary-series:-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>[5.1] Generate a time series from an IID Gaussian random process. This is a memory-less, stationary series:</a></span><ul class=\"toc-item\"><li><span><a href=\"#(a)-Compute-the-ADF-statistic-on-this-series.-What-is-the-p-value?\" data-toc-modified-id=\"(a)-Compute-the-ADF-statistic-on-this-series.-What-is-the-p-value?-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>(a) Compute the ADF statistic on this series. What is the p-value?</a></span></li><li><span><a href=\"#(b)-Compute-the-cumulative-sum-of-the-observations.-This-is-a-non-stationary-series-w/o-memory.\" data-toc-modified-id=\"(b)-Compute-the-cumulative-sum-of-the-observations.-This-is-a-non-stationary-series-w/o-memory.-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>(b) Compute the cumulative sum of the observations. This is a non-stationary series w/o memory.</a></span><ul class=\"toc-item\"><li><span><a href=\"#(i)-What-is-the-order-of-integration-of-this-cumulative-series?\" data-toc-modified-id=\"(i)-What-is-the-order-of-integration-of-this-cumulative-series?-1.2.1\"><span class=\"toc-item-num\">1.2.1&nbsp;&nbsp;</span>(i) What is the order of integration of this cumulative series?</a></span></li><li><span><a href=\"#(ii)-Compute-the-ADF-statistic-on-this-series.-What-is-the-p-value?\" data-toc-modified-id=\"(ii)-Compute-the-ADF-statistic-on-this-series.-What-is-the-p-value?-1.2.2\"><span class=\"toc-item-num\">1.2.2&nbsp;&nbsp;</span>(ii) Compute the ADF statistic on this series. What is the p-value?</a></span></li></ul></li><li><span><a href=\"#(c)-Differentiate-the-series-twice.-What-is-the-p-value-of-this-over-differentiated-series?\" data-toc-modified-id=\"(c)-Differentiate-the-series-twice.-What-is-the-p-value-of-this-over-differentiated-series?-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>(c) Differentiate the series twice. What is the p-value of this over-differentiated series?</a></span></li></ul></li><li><span><a href=\"#[5.2]-Generate-a-time-series-that-follows-a-sinusoidal-function.-This-is-a-stationary-series-with-memory.\" data-toc-modified-id=\"[5.2]-Generate-a-time-series-that-follows-a-sinusoidal-function.-This-is-a-stationary-series-with-memory.-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>[5.2] Generate a time series that follows a sinusoidal function. This is a stationary series with memory.</a></span><ul class=\"toc-item\"><li><span><a href=\"#(a)-Compute-the-ADF-statistic-on-this-series.-What-is-the-p-value?\" data-toc-modified-id=\"(a)-Compute-the-ADF-statistic-on-this-series.-What-is-the-p-value?-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>(a) Compute the ADF statistic on this series. What is the p-value?</a></span></li><li><span><a href=\"#(b)-Shift-every-observation-by-the-same-positive-value.-Compute-the-cumulative-sum-of-the-observations.-This-is-a-non-stationary-series-with-memory.\" data-toc-modified-id=\"(b)-Shift-every-observation-by-the-same-positive-value.-Compute-the-cumulative-sum-of-the-observations.-This-is-a-non-stationary-series-with-memory.-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>(b) Shift every observation by the same positive value. Compute the cumulative sum of the observations. This is a non-stationary series with memory.</a></span><ul class=\"toc-item\"><li><span><a href=\"#(i)-Compute-the-ADF-statistic-on-this-series.-What-is-the-p-value?\" data-toc-modified-id=\"(i)-Compute-the-ADF-statistic-on-this-series.-What-is-the-p-value?-2.2.1\"><span class=\"toc-item-num\">2.2.1&nbsp;&nbsp;</span>(i) Compute the ADF statistic on this series. What is the p-value?</a></span></li><li><span><a href=\"#(ii)-Apply-an-expanding-window-fracdiff,-with-$\\tau-=-1E-2$.-For-what-minimum-$d$-value-do-you-get-a-p-value-below-$5\\%$?\" data-toc-modified-id=\"(ii)-Apply-an-expanding-window-fracdiff,-with-$\\tau-=-1E-2$.-For-what-minimum-$d$-value-do-you-get-a-p-value-below-$5\\%$?-2.2.2\"><span class=\"toc-item-num\">2.2.2&nbsp;&nbsp;</span>(ii) Apply an expanding window fracdiff, with $\\tau = 1E-2$. For what minimum $d$ value do you get a p-value below $5\\%$?</a></span></li><li><span><a href=\"#(iii)-Apply-FFD-with-$\\tau-=-1E-5$.-For-what-minimum-$d$-value-do-you-get-a-p-value-below-$5\\%$\" data-toc-modified-id=\"(iii)-Apply-FFD-with-$\\tau-=-1E-5$.-For-what-minimum-$d$-value-do-you-get-a-p-value-below-$5\\%$-2.2.3\"><span class=\"toc-item-num\">2.2.3&nbsp;&nbsp;</span>(iii) Apply FFD with $\\tau = 1E-5$. For what minimum $d$ value do you get a p-value below $5\\%$</a></span></li></ul></li></ul></li><li><span><a href=\"#[5.3]-Take-the-series-from-exercise-2.b:\" data-toc-modified-id=\"[5.3]-Take-the-series-from-exercise-2.b:-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>[5.3] Take the series from exercise 2.b:</a></span><ul class=\"toc-item\"><li><span><a href=\"#(a)-Fit-the-series-to-a-sine-function.-What-is-the-R-squared?\" data-toc-modified-id=\"(a)-Fit-the-series-to-a-sine-function.-What-is-the-R-squared?-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>(a) Fit the series to a sine function. What is the R-squared?</a></span></li><li><span><a href=\"#(b)-Apply-FFD$(d=1)$.-Fit-the-series-to-a-sine-function.-What-is-the-R-squared?\" data-toc-modified-id=\"(b)-Apply-FFD$(d=1)$.-Fit-the-series-to-a-sine-function.-What-is-the-R-squared?-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>(b) Apply FFD$(d=1)$. Fit the series to a sine function. What is the R-squared?</a></span></li><li><span><a href=\"#(c)-What-value-of-d-maximizes-the-R-squared-of-a-sinusoidal-fit-on-FFD$(d)$?-Why?\" data-toc-modified-id=\"(c)-What-value-of-d-maximizes-the-R-squared-of-a-sinusoidal-fit-on-FFD$(d)$?-Why?-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>(c) What value of d maximizes the R-squared of a sinusoidal fit on FFD$(d)$? Why?</a></span></li></ul></li><li><span><a href=\"#5.4\" data-toc-modified-id=\"5.4-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>5.4</a></span></li><li><span><a href=\"#5.5\" data-toc-modified-id=\"5.5-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>5.5</a></span><ul class=\"toc-item\"><li><span><a href=\"#(a)-Form-a-new-series-as-a-cumulative-sum-of-log-prices\" data-toc-modified-id=\"(a)-Form-a-new-series-as-a-cumulative-sum-of-log-prices-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>(a) Form a new series as a cumulative sum of log-prices</a></span></li><li><span><a href=\"#(b)-Apply-FFD,-with-$\\tau-=-1E-5$.-Determine-for-what-minimum-$d-\\in-[0,2]$-the-new-series-is-stationary\" data-toc-modified-id=\"(b)-Apply-FFD,-with-$\\tau-=-1E-5$.-Determine-for-what-minimum-$d-\\in-[0,2]$-the-new-series-is-stationary-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>(b) Apply FFD, with $\\tau = 1E-5$. Determine for what minimum $d \\in [0,2]$ the new series is stationary</a></span></li><li><span><a href=\"#(c)-Compute-the-correlation-of-the-fracdiff-series-to-the-original-(untransformed)-series\" data-toc-modified-id=\"(c)-Compute-the-correlation-of-the-fracdiff-series-to-the-original-(untransformed)-series-5.3\"><span class=\"toc-item-num\">5.3&nbsp;&nbsp;</span>(c) Compute the correlation of the fracdiff series to the original (untransformed) series</a></span></li><li><span><a href=\"#(d)-Apply-Engel-Granger-cointegration-test-on-the-original-and-fracdiff-series.-Are-they-cointegrated?-Why?\" data-toc-modified-id=\"(d)-Apply-Engel-Granger-cointegration-test-on-the-original-and-fracdiff-series.-Are-they-cointegrated?-Why?-5.4\"><span class=\"toc-item-num\">5.4&nbsp;&nbsp;</span>(d) Apply Engel-Granger cointegration test on the original and fracdiff series. Are they cointegrated? Why?</a></span></li><li><span><a href=\"#(e)-Apply-a-Jarque-Bera-normality-test-on-the-fracdiff-series.\" data-toc-modified-id=\"(e)-Apply-a-Jarque-Bera-normality-test-on-the-fracdiff-series.-5.5\"><span class=\"toc-item-num\">5.5&nbsp;&nbsp;</span>(e) Apply a Jarque-Bera normality test on the fracdiff series.</a></span></li></ul></li><li><span><a href=\"#5.6-Take-the-fracdiff-series-from-exercise-5\" data-toc-modified-id=\"5.6-Take-the-fracdiff-series-from-exercise-5-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>5.6 Take the fracdiff series from exercise 5</a></span><ul class=\"toc-item\"><li><span><a href=\"#(a)-Apply-a-CUSUM-filter-(Chapter-2),-where-h-is-twice-the-standard-deviation-of-the-series.\" data-toc-modified-id=\"(a)-Apply-a-CUSUM-filter-(Chapter-2),-where-h-is-twice-the-standard-deviation-of-the-series.-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>(a) Apply a CUSUM filter (Chapter 2), where h is twice the standard deviation of the series.</a></span></li><li><span><a href=\"#(b)-Use-the-filtered-timestamps-to-sample-a-features'-matrix.-Use-as-one-of-the-features-the-fracDiff-value.\" data-toc-modified-id=\"(b)-Use-the-filtered-timestamps-to-sample-a-features'-matrix.-Use-as-one-of-the-features-the-fracDiff-value.-6.2\"><span class=\"toc-item-num\">6.2&nbsp;&nbsp;</span>(b) Use the filtered timestamps to sample a features' matrix. Use as one of the features the fracDiff value.</a></span></li><li><span><a href=\"#(c)-Form-labels-using-the-triple-barrier-method,-with-symmetric-horizontal-barriers-of-twice-the-daily-standard-deviation,-and-a-vertical-barrier-of-5-days\" data-toc-modified-id=\"(c)-Form-labels-using-the-triple-barrier-method,-with-symmetric-horizontal-barriers-of-twice-the-daily-standard-deviation,-and-a-vertical-barrier-of-5-days-6.3\"><span class=\"toc-item-num\">6.3&nbsp;&nbsp;</span>(c) Form labels using the triple-barrier method, with symmetric horizontal barriers of <code>twice</code> the daily standard deviation, and a vertical barrier of <code>5</code> days</a></span></li><li><span><a href=\"#(d)-Fit-a-bagging-classifier-of-decision-trees-where:\" data-toc-modified-id=\"(d)-Fit-a-bagging-classifier-of-decision-trees-where:-6.4\"><span class=\"toc-item-num\">6.4&nbsp;&nbsp;</span>(d) Fit a bagging classifier of decision trees where:</a></span><ul class=\"toc-item\"><li><span><a href=\"#(i)-The-observed-features-are-bootstrapped-using-the-sequential-method-from-chapter-4.\" data-toc-modified-id=\"(i)-The-observed-features-are-bootstrapped-using-the-sequential-method-from-chapter-4.-6.4.1\"><span class=\"toc-item-num\">6.4.1&nbsp;&nbsp;</span>(i) The observed features are bootstrapped using the sequential method from chapter 4.</a></span></li><li><span><a href=\"#(ii)-On-each-bootstrapped-sample,-sample-weights-are-determined-using-the-techniques-from-Chapter-4\" data-toc-modified-id=\"(ii)-On-each-bootstrapped-sample,-sample-weights-are-determined-using-the-techniques-from-Chapter-4-6.4.2\"><span class=\"toc-item-num\">6.4.2&nbsp;&nbsp;</span>(ii) On each bootstrapped sample, sample weights are determined using the techniques from Chapter 4</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad1868d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext watermark\n",
    "%watermark\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# import standard libs\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from IPython.display import display\n",
    "from IPython.core.debugger import set_trace as bp\n",
    "from pathlib import PurePath, Path\n",
    "\n",
    "# import python scientific stack\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 100)\n",
    "from dask import dataframe as dd\n",
    "from dask.diagnostics import ProgressBar\n",
    "pbar = ProgressBar()\n",
    "pbar.register()\n",
    "import multiprocessing as mp\n",
    "from multiprocessing import cpu_count \n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import statsmodels.api as sm\n",
    "import numba as nb\n",
    "import math\n",
    "from theano import shared, theano as tt\n",
    "\n",
    "# import visual tools\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import plotnine as pn\n",
    "\n",
    "plt.style.use('seaborn-talk')\n",
    "plt.style.use('bmh')\n",
    "#plt.rcParams['font.family'] = 'DejaVu Sans Mono'\n",
    "plt.rcParams['font.size'] = 9.5\n",
    "plt.rcParams['font.weight'] = 'medium'\n",
    "plt.rcParams['figure.figsize'] = 10,7\n",
    "blue, green, red, purple, gold, teal = sns.color_palette('colorblind', 6)\n",
    "\n",
    "# import util libs\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "import missingno as msno\n",
    "\n",
    "from src.utils.utils import *\n",
    "import src.features.bars as brs\n",
    "import src.features.snippets as snp\n",
    "\n",
    "import copyreg, types\n",
    "copyreg.pickle(types.MethodType,snp._pickle_method,snp._unpickle_method)\n",
    "RANDOM_STATE = 777\n",
    "\n",
    "pdir = get_relative_project_dir('Adv_Fin_ML_Exercises')\n",
    "data_dir = pdir/'data'/'processed'\n",
    "\n",
    "print()\n",
    "%watermark -p pandas,numpy,numba,pymc3,sklearn,statsmodels,scipy,matplotlib,seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970bc87b",
   "metadata": {},
   "source": [
    "# Chapter 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002cad96",
   "metadata": {},
   "source": [
    "## [5.1] Generate a time series from an IID Gaussian random process. This is a memory-less, stationary series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1d8ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "N = 252*10\n",
    "s = pd.Series(np.random.randn(N))\n",
    "s.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "232e8063",
   "metadata": {},
   "source": [
    "### (a) Compute the ADF statistic on this series. What is the p-value?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28897308",
   "metadata": {},
   "outputs": [],
   "source": [
    "adf = lambda s: sm.tsa.stattools.adfuller(s)\n",
    "p_val = lambda s: sm.tsa.stattools.adfuller(s)[1]\n",
    "res = adf(s); p = res[1]\n",
    "res, p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8abacbef",
   "metadata": {},
   "source": [
    "### (b) Compute the cumulative sum of the observations. This is a non-stationary series w/o memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2641ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmsm = pd.Series(s).cumsum()\n",
    "cmsm.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524c2b34",
   "metadata": {},
   "source": [
    "#### (i) What is the order of integration of this cumulative series?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656ed801",
   "metadata": {},
   "outputs": [],
   "source": [
    "slope, intercept, r_value, p_value, std_err = scipy.stats.linregress(yy, res[\"fitfunc\"](xx))\n",
    "r_value**2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c5dd14",
   "metadata": {},
   "source": [
    "### (b) Apply FFD$(d=1)$. Fit the series to a sine function. What is the R-squared?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7c06ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cols = ['adfStat','pVal','lags','nObs','95% conf']#,'corr']\n",
    "#out = pd.DataFrame(columns=cols)\n",
    "df1 = fracDiff(s_,d=1)\n",
    "#df1 = sm.tsa.stattools.adfuller(df0['fake_close'],maxlag=1,regression='c',autolag=None)\n",
    "#out.loc[d]=list(df0[:4])+[df0[4]['5%']]\n",
    "df1.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93748969",
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = df1.index.values\n",
    "yy = df1.values.ravel()\n",
    "\n",
    "res = fit_sin(xx, yy)\n",
    "slope, intercept, r_value, p_value, std_err = scipy.stats.linregress(yy, res[\"fitfunc\"](xx))\n",
    "r_value**2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f42b2c",
   "metadata": {},
   "source": [
    "### (c) What value of d maximizes the R-squared of a sinusoidal fit on FFD$(d)$? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e94bd4",
   "metadata": {},
   "source": [
    "## 5.4\n",
    "\n",
    "Take dollar bar series on E-mini S&P 500 futures. Using the code in Snippet 5.3, for some `d` in `[0,2]`, compute `fracDiff_FFD(fracDiff_FFD(series,d)`. What do you get? Why?\n",
    "\n",
    "Note: for some reason this never finishes computing in my notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878289ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getWeights_FFD(d,thres):\n",
    "    w,k=[1.],1\n",
    "    while True:\n",
    "        w_=-w[-1]/k*(d-k+1)\n",
    "        if abs(w_)<thres:break\n",
    "        w.append(w_);k+=1\n",
    "    return np.array(w[::-1]).reshape(-1,1)\n",
    "\n",
    "#---------------------------------------------------------------------------\n",
    "\n",
    "def fracDiff_FFD(series,d,thres=1e-5):\n",
    "    # Constant width window (new solution)\n",
    "    w = getWeights_FFD(d,thres)\n",
    "    width = len(w)-1\n",
    "    df={}\n",
    "    for name in series.columns:\n",
    "        seriesF, df_=series[[name]].fillna(method='ffill').dropna(), pd.Series()\n",
    "        for iloc1 in range(width,seriesF.shape[0]):\n",
    "            loc0,loc1=seriesF.index[iloc1-width], seriesF.index[iloc1]\n",
    "            test_val = series.loc[loc1,name] # must resample if duplicate index\n",
    "            if isinstance(test_val, (pd.Series, pd.DataFrame)):\n",
    "                test_val = test_val.resample('1m').mean()\n",
    "            if not np.isfinite(test_val).any(): continue # exclude NAs\n",
    "            #print(f'd: {d}, iloc1:{iloc1} shapes: w:{w.T.shape}, series: {seriesF.loc[loc0:loc1].notnull().shape}')\n",
    "            try:\n",
    "                df_.loc[loc1]=np.dot(w.T, seriesF.loc[loc0:loc1])[0,0]\n",
    "            except:\n",
    "                continue\n",
    "        df[name]=df_.copy(deep=True)\n",
    "    df=pd.concat(df,axis=1)\n",
    "    return df \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f75a76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dask_resample(ser, freq='L'):\n",
    "    dds = dd.from_pandas(ser, chunksize=len(ser)//100)\n",
    "    tdf = (dds\n",
    "           .resample(freq)\n",
    "           .mean()\n",
    "           .dropna()\n",
    "          ).compute()\n",
    "    return tdf\n",
    "\n",
    "infp=PurePath(data_dir/'clean_IVE_fut_prices.parquet')\n",
    "df = pd.read_parquet(infp)\n",
    "\n",
    "dv_rs = dask_resample(df, '1s')\n",
    "cprint(dv_rs)\n",
    "\n",
    "dbars = brs.dollar_bar_df(dv_rs, 'dv', 1_000_000)\n",
    "cprint(dbars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e9dae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 0.5\n",
    "sel = dbars[['price']].iloc[:100]\n",
    "#val = fracDiff_FFD(fracDiff_FFD(sel, d), -d) # Never finishes don't run\n",
    "#val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6606b80b",
   "metadata": {},
   "source": [
    "## 5.5 \n",
    "\n",
    "Take the dollar bar series on E-mini S&P 500 futures."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6b7be9",
   "metadata": {},
   "source": [
    "### (a) Form a new series as a cumulative sum of log-prices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b496272",
   "metadata": {},
   "source": [
    "### (c) Form labels using the triple-barrier method, with symmetric horizontal barriers of `twice` the daily standard deviation, and a vertical barrier of `5` days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9897a777",
   "metadata": {},
   "outputs": [],
   "source": [
    "dailyVol = snp.getDailyVol(ftMtx.dbars)\n",
    "t1 = snp.addVerticalBarrier(tEvents, ftMtx.dbars, numDays=5)\n",
    "\n",
    "ptsl = [1,1]\n",
    "#ptsl = [daily]\n",
    "target=dailyVol*2\n",
    "# select minRet\n",
    "minRet = 0.01\n",
    "# get cpu count - 1\n",
    "cpus = cpu_count() - 1\n",
    "events = snp.getEvents(ftMtx.dbars,tEvents,ptsl,target,minRet,cpus,t1=t1)\n",
    "cprint(events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ba2156",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Example\n",
    "close=ftMtx.dbars\n",
    "numCoEvents = snp.mpPandasObj(snp.mpNumCoEvents,('molecule',events.index),                         \n",
    "                              cpus,closeIdx=close.index,t1=events['t1'])\n",
    "numCoEvents = numCoEvents.loc[~numCoEvents.index.duplicated(keep='last')]\n",
    "numCoEvents = numCoEvents.reindex(close.index).fillna(0)\n",
    "out=pd.DataFrame()\n",
    "out['tW'] = snp.mpPandasObj(snp.mpSampleTW,('molecule',events.index),\n",
    "                            cpus,t1=events['t1'],numCoEvents=numCoEvents)\n",
    "cprint(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a33d358",
   "metadata": {},
   "outputs": [],
   "source": [
    "## example ##\n",
    "out['w']=snp.mpPandasObj(snp.mpSampleW,('molecule',events.index),cpus,\n",
    "                         t1=events['t1'],numCoEvents=numCoEvents,close=close)\n",
    "out['w']*=out.shape[0]/out['w'].sum()\n",
    "cprint(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f72136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get labels\n",
    "labels = snp.getBins(events, ftMtx.dbars, t1=t1)\n",
    "#cprint(labels)\n",
    "\n",
    "clean_labels = snp.dropLabels(labels)\n",
    "cprint(clean_labels)\n",
    "print(clean_labels.bin.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801b0136",
   "metadata": {},
   "source": [
    "### (d) Fit a bagging classifier of decision trees where:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5c9df0",
   "metadata": {},
   "source": [
    "#### (i) The observed features are bootstrapped using the sequential method from chapter 4.\n",
    "\n",
    "Note: must use multiprocessing of some kind as seqBootstrap is very slow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe7b0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "@nb.njit\n",
    "def func(arr,i):\n",
    "    col = arr[i]\n",
    "    mask = np.where(col>0)\n",
    "    return np.mean(col[mask])\n",
    "\n",
    "@nb.njit\n",
    "def njit_getAvgUniqueness(indM):\n",
    "    # Average uniqueness from indicator matrix\n",
    "    c=indM.sum(axis=1).reshape(-1,1) # concurrency\n",
    "    u=np.divide(indM,c) # uniqueness\n",
    "    avgU = np.zeros(len(u.T)) # avg. uniqueness\n",
    "    i = 0\n",
    "    for i in range(len(u.T)):\n",
    "        avgU[i] = func(u.T,i)\n",
    "        i+=1\n",
    "    return avgU\n",
    "\n",
    "@nb.jit\n",
    "def jit_seqBootstrap(indM,sLength=None):\n",
    "    # Generate a sample via sequential bootstrap\n",
    "    if sLength is None:sLength=indM.shape[1]\n",
    "    phi=[]\n",
    "    while len(phi)<sLength:\n",
    "        avgU=pd.Series()\n",
    "        for i in indM:\n",
    "            indM_=indM[phi+[i]] # reduce indM\n",
    "            avgU.loc[i]=njit_getAvgUniqueness(indM_.values)[-1]\n",
    "        prob=avgU/avgU.sum() # draw prob\n",
    "        phi+=[np.random.choice(indM.columns,p=prob)]\n",
    "    return phi\n",
    "#------------------------\n",
    "\n",
    "def split_t1(t1, partitions):\n",
    "    return np.array_split(t1, partitions)\n",
    "\n",
    "def mp_func(indM):\n",
    "    # jit funcs about 2x as fast\n",
    "    phi = jit_seqBootstrap(indM)\n",
    "    seqU = njit_getAvgUniqueness(indM[phi].values).mean()\n",
    "    #phi = snp.seqBootstrap(indM)\n",
    "    #seqU= snp.getAvgUniqueness(indM[phi])\n",
    "    return seqU\n",
    "\n",
    "def main_mp(t1, partitions=100, cpus=8):\n",
    "    jobs = []\n",
    "    splits = split_t1(t1,partitions=100)\n",
    "    for part_t1 in splits:\n",
    "        indM = snp.getIndMatrix(part_t1.index, part_t1)\n",
    "        job = {'func':mp_func,'indM':indM}\n",
    "        jobs.append(job)\n",
    "    if cpus==1: out=snp.processJobs_(jobs)\n",
    "    else: out=snp.processJobs(jobs,numThreads=cpus)\n",
    "    return pd.DataFrame(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb89fe04",
   "metadata": {},
   "outputs": [],
   "source": [
    "seqUs = main_mp(t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3da84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "seqUs.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ccb0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get avg uniqueness for bootstrapping\n",
    "avgU = seqUs.mean()[0]\n",
    "avgU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31cff591",
   "metadata": {},
   "source": [
    "#### (ii) On each bootstrapped sample, sample weights are determined using the techniques from Chapter 4\n",
    "\n",
    "Note: alternative implementations are welcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ae6b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "orders = [0, 1, 2, 3, 4]\n",
    "for o in orders:\n",
    "    diff_ = np.diff(cmsm,o)\n",
    "    print('='*27)\n",
    "    print(f'order: {o}, pVal: {p_val(diff_)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a153bb2f",
   "metadata": {},
   "source": [
    "#### (ii) Compute the ADF statistic on this series. What is the p-value?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7fc08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_val(cmsm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1db9a1",
   "metadata": {},
   "source": [
    "### (c) Differentiate the series twice. What is the p-value of this over-differentiated series?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e54a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_ = np.diff(cmsm,2)\n",
    "p_val(diff_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f498592d",
   "metadata": {},
   "source": [
    "## [5.2] Generate a time series that follows a sinusoidal function. This is a stationary series with memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b95532",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "rand = np.random.random(N)\n",
    "\n",
    "idx = np.linspace(0,10, N)\n",
    "s = pd.Series(1*np.sin(2.*idx + .5))\n",
    "s.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7bf601",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_val(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a8c921",
   "metadata": {},
   "source": [
    "### (b) Shift every observation by the same positive value. Compute the cumulative sum of the observations. This is a non-stationary series with memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4644b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_ = (s + 1).cumsum().rename('fake_close').to_frame()\n",
    "s_.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d8c664",
   "metadata": {},
   "source": [
    "#### (i) Compute the ADF statistic on this series. What is the p-value?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bedc211c",
   "metadata": {},
   "outputs": [],
   "source": [
    "adf(s_['fake_close'].dropna()), p_val(s_['fake_close'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c5583e",
   "metadata": {},
   "source": [
    "#### (ii) Apply an expanding window fracdiff, with $\\tau = 1E-2$. For what minimum $d$ value do you get a p-value below $5\\%$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9270c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getWeights(d,size):\n",
    "    # thres>0 drops insignificant weights\n",
    "    w=[1.]\n",
    "    for k in range(1,size):\n",
    "        w_ = -w[-1]/k*(d-k+1)\n",
    "        w.append(w_)\n",
    "    w=np.array(w[::-1]).reshape(-1,1)\n",
    "    return w \n",
    "\n",
    "#getWeights(0.1, s_.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1f6981",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fracDiff(series, d, thres=0.01):\n",
    "    '''\n",
    "    Increasing width window, with treatment of NaNs\n",
    "    Note 1: For thres=1, nothing is skipped\n",
    "    Note 2: d can be any positive fractional, not necessarily\n",
    "        bounded between [0,1]\n",
    "    '''\n",
    "    #1) Compute weights for the longest series\n",
    "    w=getWeights(d, series.shape[0])\n",
    "    #bp()\n",
    "    #2) Determine initial calcs to be skipped based on weight-loss threshold\n",
    "    w_=np.cumsum(abs(w))\n",
    "    w_ /= w_[-1]\n",
    "    skip = w_[w_>thres].shape[0]\n",
    "    #3) Apply weights to values\n",
    "    df={}\n",
    "    for name in series.columns:\n",
    "        seriesF, df_=series[[name]].fillna(method='ffill').dropna(), pd.Series()\n",
    "        for iloc in range(skip, seriesF.shape[0]):\n",
    "            loc=seriesF.index[iloc]\n",
    "            test_val = series.loc[loc,name] # must resample if duplicate index\n",
    "            if isinstance(test_val, (pd.Series, pd.DataFrame)):\n",
    "                test_val = test_val.resample('1m').mean()\n",
    "            if not np.isfinite(test_val).any(): continue # exclude NAs\n",
    "            try:\n",
    "                df_.loc[loc]=np.dot(w[-(iloc+1):,:].T, seriesF.loc[:loc])[0,0]\n",
    "            except:\n",
    "                continue\n",
    "        df[name]=df_.copy(deep=True)\n",
    "    df=pd.concat(df,axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8462632d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['adfStat','pVal','lags','nObs','95% conf']#,'corr']\n",
    "out = pd.DataFrame(columns=cols)\n",
    "for d in np.linspace(0,1,11):\n",
    "    try:\n",
    "        df0 = fracDiff(s_,d)\n",
    "        df0 = sm.tsa.stattools.adfuller(df0['fake_close'],maxlag=1,regression='c',autolag=None)\n",
    "        out.loc[d]=list(df0[:4])+[df0[4]['5%']]\n",
    "    except: \n",
    "        break\n",
    "\n",
    "f,ax=plt.subplots()\n",
    "out['adfStat'].plot(ax=ax, marker='X')\n",
    "ax.axhline(out['95% conf'].mean(),lw=1,color='r',ls='dotted')\n",
    "ax.set_title('min d with thresh=0.01')\n",
    "ax.set_xlabel('d values')\n",
    "ax.set_ylabel('adf stat');\n",
    "display(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ba5a54",
   "metadata": {},
   "source": [
    "#### (iii) Apply FFD with $\\tau = 1E-5$. For what minimum $d$ value do you get a p-value below $5\\%$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea01d5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['adfStat','pVal','lags','nObs','95% conf']#,'corr']\n",
    "out = pd.DataFrame(columns=cols)\n",
    "for d in np.linspace(0,1,11):\n",
    "    try:\n",
    "        df0 = fracDiff(s_,d,thres=1e-5)\n",
    "        df0 = sm.tsa.stattools.adfuller(df0['fake_close'],maxlag=1,regression='c',autolag=None)\n",
    "        out.loc[d]=list(df0[:4])+[df0[4]['5%']]\n",
    "    except Exception as e:\n",
    "        print(f'd: {d}, error: {e}')\n",
    "        continue\n",
    "\n",
    "f,ax=plt.subplots()\n",
    "out['adfStat'].plot(ax=ax, marker='X')\n",
    "ax.axhline(out['95% conf'].mean(),lw=1,color='r',ls='dotted')\n",
    "ax.set_title('min d with thresh=0.0001')\n",
    "ax.set_xlabel('d values')\n",
    "ax.set_ylabel('adf stat');\n",
    "display(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979ae273",
   "metadata": {},
   "source": [
    "## [5.3] Take the series from exercise 2.b:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cfc7e61",
   "metadata": {},
   "source": [
    "### (a) Fit the series to a sine function. What is the R-squared?\n",
    "\n",
    "Note: Is there a simpler way to do this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7100ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## fitting function taken from stackoverflow\n",
    "##   https://stackoverflow.com/questions/16716302/how-do-i-fit-a-sine-curve-to-my-data-with-pylab-and-numpy#16716964\n",
    "import numpy, scipy.optimize\n",
    "\n",
    "def fit_sin(tt, yy):\n",
    "    '''Fit sin to the input time sequence, and return fitting parameters \"amp\", \"omega\", \"phase\", \"offset\", \"freq\", \"period\" and \"fitfunc\"'''\n",
    "    tt = numpy.array(tt)\n",
    "    yy = numpy.array(yy)\n",
    "    ff = numpy.fft.fftfreq(len(tt), (tt[1]-tt[0]))   # assume uniform spacing\n",
    "    Fyy = abs(numpy.fft.fft(yy))\n",
    "    guess_freq = abs(ff[numpy.argmax(Fyy[1:])+1])   # excluding the zero frequency \"peak\", which is related to offset\n",
    "    guess_amp = numpy.std(yy) * 2.**0.5\n",
    "    guess_offset = numpy.mean(yy)\n",
    "    guess = numpy.array([guess_amp, 2.*numpy.pi*guess_freq, 0., guess_offset])\n",
    "\n",
    "    def sinfunc(t, A, w, p, c):  return A * numpy.sin(w*t + p) + c\n",
    "    popt, pcov = scipy.optimize.curve_fit(sinfunc, tt, yy, p0=guess)\n",
    "    A, w, p, c = popt\n",
    "    f = w/(2.*numpy.pi)\n",
    "    fitfunc = lambda t: A * numpy.sin(w*t + p) + c\n",
    "    return {\"amp\": A, \"omega\": w, \"phase\": p, \"offset\": c, \"freq\": f, \"period\": 1./f, \"fitfunc\": fitfunc, \"maxcov\": numpy.max(pcov), \"rawres\": (guess,popt,pcov)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4c0106",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = fit_sin(s_.index.values, s_.values.ravel())\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e514032f",
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = s_.index.values\n",
    "yy = s_.values.ravel()\n",
    "\n",
    "plt.plot(xx, yy, \"-k\", label=\"y\", linewidth=2)\n",
    "#plt.plot(tt, yynoise, \"ok\", label=\"y with noise\")\n",
    "plt.plot(xx, res[\"fitfunc\"](xx), \"r-\", label=\"y fit curve\", linewidth=2)\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788ee15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.log(dbars.price).cumsum()\n",
    "cprint(x)\n",
    "\n",
    "x.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b4cc18",
   "metadata": {},
   "source": [
    "### (b) Apply FFD, with $\\tau = 1E-5$. Determine for what minimum $d \\in [0,2]$ the new series is stationary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb35623",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimal_ffd(ds, t=1e-5):\n",
    "    \n",
    "    cols = ['adfStat','pVal','lags','nObs','95% conf']#,'corr']\n",
    "    out = pd.DataFrame(columns=cols)\n",
    "    \n",
    "    for d in tqdm_notebook(ds):\n",
    "        try:\n",
    "            #dfx = fracDiff(x.to_frame(),d,thres=1e-5)\n",
    "            dfx = fracDiff_FFD(x.to_frame(),d,thres=t)\n",
    "            dfx = sm.tsa.stattools.adfuller(dfx['price'], maxlag=1,regression='c',autolag=None)\n",
    "            out.loc[d]=list(dfx[:4])+[dfx[4]['5%']]\n",
    "        except Exception as e:\n",
    "            print(f'{d} error: {e}')\n",
    "            break\n",
    "    return out\n",
    "\n",
    "#============================================\n",
    "ds = [0.25,0.5,1,1.5,1.8,1.9,1.999,2]\n",
    "thres = 1e-5\n",
    "out = get_optimal_ffd(ds, thres) # takes 15 minutes to run on ~44k points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431f8b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "f,ax=plt.subplots()\n",
    "out['adfStat'].plot(ax=ax, marker=\"X\", markersize=10)\n",
    "ax.axhline(out['95% conf'].mean(),lw=1,color='r',ls='dotted')\n",
    "ax.set_title(f'min d with thresh={thres}')\n",
    "ax.set_xlabel('d values')\n",
    "ax.set_ylabel('adf stat');\n",
    "display(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738cf5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_ffd = out[out.pVal < 0.05].iloc[0].name\n",
    "min_ffd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45237d45",
   "metadata": {},
   "source": [
    "### (c) Compute the correlation of the fracdiff series to the original (untransformed) series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf5db1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfx2 = fracDiff_FFD(x.to_frame(),min_ffd,thres=thres)\n",
    "cprint(dfx2)\n",
    "\n",
    "joined = dfx2.join(x.rename('original'), how='left') \n",
    "joined.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c35b5a9",
   "metadata": {},
   "source": [
    "### (d) Apply Engel-Granger cointegration test on the original and fracdiff series. Are they cointegrated? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f98a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.tsa.stattools.coint(joined.price, joined.original)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac1271c",
   "metadata": {},
   "source": [
    "### (e) Apply a Jarque-Bera normality test on the fracdiff series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ab429e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "stats.jarque_bera(dfx2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5daf82ee",
   "metadata": {},
   "source": [
    "## 5.6 Take the fracdiff series from exercise 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac991ff",
   "metadata": {},
   "source": [
    "### (a) Apply a CUSUM filter (Chapter 2), where h is twice the standard deviation of the series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c34cbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tEvents = snp.getTEvents(dfx2,h=dfx2.std().iat[0]*2)\n",
    "display(tEvents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be55df28",
   "metadata": {},
   "source": [
    "### (b) Use the filtered timestamps to sample a features' matrix. Use as one of the features the fracDiff value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d20833a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbars_feat = dbars.price.loc[tEvents]\n",
    "frac_diff_feat = dfx2.loc[tEvents]\n",
    "ftMtx = (pd.DataFrame()\n",
    "         .assign(dbars=dbars_feat,\n",
    "                 frac_diff_feat=frac_diff_feat)\n",
    "         .drop_duplicates().dropna())\n",
    "cprint(ftMtx)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
