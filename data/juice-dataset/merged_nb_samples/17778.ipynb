{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a1b5614",
   "metadata": {},
   "source": [
    "Tutorials:\n",
    "\n",
    "* https://www.kaggle.com/c/titanic/details/getting-started-with-python\n",
    "* https://www.kaggle.com/c/titanic/details/getting-started-with-python-ii\n",
    "* https://www.dataquest.io/mission/74/getting-started-with-kaggle\n",
    "* https://www.dataquest.io/mission/75/improving-your-submission\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae50c10",
   "metadata": {},
   "source": [
    "While the book provides a good introduction to a variety of topics, we thought another helpful exercise would be to analyze a dataset. Since our textbook omits pandas, we used the exercise to explore pandas as well. All of the tutorials listed above use the [titanic dataset](https://www.kaggle.com/c/titanic/data) from kaggle. The goal is to predict the survivors of the Titanic disaster. There are two datasets that we'll be using for this, train.csv and test.csv. The training set includes whether each passenger survived or not.\n",
    "\n",
    "https://www.kaggle.com/c/titanic/details/getting-started-with-python-ii uses pandas to explore and manipulate data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36619e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# text import is pretty simple\n",
    "titanic = pd.read_csv(\"train.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731cbdd0",
   "metadata": {},
   "source": [
    "You can see that we've read in the dataset using pandas. Pandas uses three data structures: Series, DataFrames, and Panels. Series have a single dimension and must contain all the same data type. DataFrames have two dimensions, which can be thought of as a tabular structure, and contain named columns of potentially different data types. Panels are three-dimensional structures. \n",
    "\n",
    "You can [learn more about data structures](http://pandas.pydata.org/pandas-docs/stable/dsintro.html) through pandas documentation.\n",
    "\n",
    "We look at the data type of the titanic object that we've created with the pandas package. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8678de44",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(titanic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e79302b",
   "metadata": {},
   "source": [
    "Next, we explore the dataset.  A [list of pandas functions](http://pandas.pydata.org/pandas-docs/version/0.15.1/api.html) describes the usage of each function. \n",
    "\n",
    "We look at the `head` attribute for the titanic object. All the attributes a pandas DataFrame can be found by using tab for code completion after the dot operator. Use object.(tab) and then scroll down using the down arrow to see what's available. We can look at the head and tail of the titanic object."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19f896f",
   "metadata": {},
   "source": [
    "### Linear Regression\n",
    "\n",
    "The first prediction uses linear regression to make the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9091d46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "predictors = [\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Embarked\"]\n",
    "\n",
    "# intiailize algorithm class\n",
    "lm = LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e79287a",
   "metadata": {},
   "source": [
    "Next we make our predictions. We initialize it as a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b97162",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "\n",
    "for train, test, in kf:\n",
    "    # create a subset of training rows using the predictors and training indices\n",
    "    train_predictors = (titanic[predictors].iloc[train,:])\n",
    "    # create a variable for index numbers of target variable\n",
    "    train_target = titanic[\"Survived\"].iloc[train]\n",
    "    # create a linear model using the predictor and target variables\n",
    "    lm.fit(train_predictors, train_target)\n",
    "    # now make predictions and store them in our predictions list.\n",
    "    test_predictions = lm.predict(titanic[predictors].iloc[test,:])\n",
    "    predictions.append(test_predictions)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d10d24",
   "metadata": {},
   "source": [
    "Next we figure out our prediction error. Kaggle uses percentage of correct predictions. Each set of predictions is a numpy array so we concatenate them using numpy (since they're numpy arrays). (This is what the tutorial says but I think what they really mean is it's a list and numpy has a lot of nice functions that deal with lists).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7a5f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#type(predictions[1])\n",
    "# type(predictions)\n",
    "# predictions[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d99850e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "predictions = np.concatenate(predictions, axis=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261a6e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# map predictions to outcomes (0 or 1)\n",
    "predictions[predictions > .5] = 1\n",
    "predictions[predictions <= .5] = 0\n",
    "\n",
    "type(predictions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d51cc5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301051d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = sum(predictions[predictions == titanic[\"Survived\"]])/len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf6a049",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4113fba5",
   "metadata": {},
   "source": [
    "### Logistic Regression \n",
    "\n",
    "Prediction accuracy with linear regression was 78.3 %. A model built using logistic regression may do better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197938d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.head(5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80e4a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7fd7553",
   "metadata": {},
   "source": [
    "To see the data types of the columns in the object use `.dtypes`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f41676",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25318612",
   "metadata": {},
   "source": [
    "`object.info()` gives us more metadata, including number of non-null values in each column, the data type of each column, and a summary of the object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086711f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76152d97",
   "metadata": {},
   "source": [
    "If we only want to view the column headers, we can use the .columns attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5b0e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(titanic.columns)\n",
    "print(titanic.columns.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb845d0",
   "metadata": {},
   "source": [
    "We can also look at a summary of data using the .describe() method. This provides summary statistics for each column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15efa60",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(titanic.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8fa20e",
   "metadata": {},
   "source": [
    "Using describe with it's default parameters only gives us the columns with numerical value. We can specify include='all' and it gives us every column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5686f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(titanic.describe(include = 'all'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fdf1379",
   "metadata": {},
   "source": [
    "A [second tutorial from dataquest](https://www.dataquest.io/mission/74/getting-started-with-kaggle) uses the pandas library, and scikit-learn. It cleans up the dataset and runs it through a couple of regression models. \n",
    "\n",
    "We note from the data above that we have some missing values. A count of the variables age and cabin returns fewer than 891 values. The count is of values that aren't null, NA or NAN. We fill in the missing values of the column with the median age. There may be a better way to do this. \n",
    "\n",
    "We select columns using the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23a3c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic[\"Age\"].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137d9104",
   "metadata": {},
   "source": [
    "We can use the .fillna method. This method takes one argument: the value used to replace the missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c09bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic[\"Age\"] = titanic[\"Age\"].fillna(titanic[\"Age\"].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f2b4c2a",
   "metadata": {},
   "source": [
    "Next we need to convert the \"Sex\" column into a numerical value so that python can work with it. It's currently a  string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9faadb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(titanic[\"Sex\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1829028e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(titanic[\"Sex\"].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7509e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.loc[titanic[\"Sex\"] == \"male\", \"Sex\"] = 0\n",
    "titanic.loc[titanic[\"Sex\"] == \"female\", \"Sex\"] = 1\n",
    "\n",
    "# you can also do this like so:\n",
    "#titanic[\"Sex\"] = titanic[\"Sex\"].map( {'female' : 0, 'male' : 1}).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7d526f",
   "metadata": {},
   "source": [
    "Next we need to convert the embarked column. It has a couple of missing values, which we replace with the most common value using the mode method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ba0350",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Why isn't this working?\n",
    "#titanic[\"Embarked\"] = titanic[\"Embarked\"].fillna(titanic[\"Embarked\"].mode())\n",
    "# But this works.\n",
    "titanic[\"Embarked\"] = titanic[\"Embarked\"].fillna(\"S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a046721a",
   "metadata": {},
   "source": [
    "Then we need to look to see what values exist in the Embarked column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a655839c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(titanic[\"Embarked\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4ebc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# printed this value because I was trying to get the mode attribute to work.\n",
    "# index 829 originally contained NaN\n",
    "print(titanic[\"Embarked\"][829])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090be103",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.loc[titanic[\"Embarked\"] == \"S\", \"Embarked\"] = 0\n",
    "titanic.loc[titanic[\"Embarked\"] == \"C\", \"Embarked\"] = 1\n",
    "titanic.loc[titanic[\"Embarked\"] == \"Q\", \"Embarked\"] = 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980a58c3",
   "metadata": {},
   "source": [
    "Now the file is in the right format. Using scikit-learn, create a linear model. There's also this KFold function, which is a [cross-validation](https://en.wikipedia.org/wiki/Cross-validation_(statistics)) implementation. Kfold takes the original sample and randomly partitions it into k equal sized sub-samples. It then uses the each sub-sample as validation against the rest of the dataset. These results are combined to produce a single estimation. A typical approach is to use 10 \"folds.\"\n",
    "\n",
    "We'll use the scikit-learn [KFold function](http://scikit-learn.org/stable/modules/generated/sklearn.cross_validation.KFold.html)\n",
    "\n",
    "This function take the following as parameters:\n",
    "\n",
    "* n: int, the total number of elements \n",
    "* n_folds: int, number of folds, defaults to 3\n",
    "* shuffle: bool, whether to shuffle the data first\n",
    "* random state: , none, int, RandomState, when shuffle = True, int sets seed. If none, us default numpy rng for shuffling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ccd271",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.cross_validation import KFold\n",
    "\n",
    "# the tutorial doesn't use shuffle but sets random state. \n",
    "# the shape attribute returns the dimensionality of the object. Using an index of zero returns the number of rows\n",
    "kf = KFold(titanic.shape[0], n_folds=3, random_state=1)\n",
    "\n",
    "# just curious\n",
    "print(kf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409016c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "logm = linear_model.LogisticRegression(random_state = 1)\n",
    "\n",
    "scores = cross_validation.cross_val_score(logm, titanic[predictors], titanic[\"Survived\"], cv =3)\n",
    "\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979cb7bb",
   "metadata": {},
   "source": [
    "Apply the same changes to the test set as the train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5829e893",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_test = pd.read_csv(\"test.csv\")\n",
    "titanic_test[\"Age\"] = titanic_test[\"Age\"].fillna(titanic[\"Age\"].median())\n",
    "titanic_test[\"Fare\"] = titanic_test[\"Fare\"].fillna(titanic_test[\"Fare\"].median())\n",
    "titanic_test.loc[titanic_test[\"Sex\"] == \"male\", \"Sex\"] = 0 \n",
    "titanic_test.loc[titanic_test[\"Sex\"] == \"female\", \"Sex\"] = 1\n",
    "titanic_test[\"Embarked\"] = titanic_test[\"Embarked\"].fillna(\"S\")\n",
    "\n",
    "titanic_test.loc[titanic_test[\"Embarked\"] == \"S\", \"Embarked\"] = 0\n",
    "titanic_test.loc[titanic_test[\"Embarked\"] == \"C\", \"Embarked\"] = 1\n",
    "titanic_test.loc[titanic_test[\"Embarked\"] == \"Q\", \"Embarked\"] = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1170f4d5",
   "metadata": {},
   "source": [
    "Create File to Submit to Kaggle"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
