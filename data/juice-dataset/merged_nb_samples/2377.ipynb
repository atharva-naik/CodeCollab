{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9840f1bf",
   "metadata": {},
   "source": [
    "# Machine Learning Engineer Nanodegree - Capstone Project\n",
    "## PART 7: Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0516be",
   "metadata": {},
   "source": [
    "**Author:** Giacomo Sarchioni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b11a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Module imports\n",
    "import pickle as pkl\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from roc_chart import ROCChart\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, roc_curve\n",
    "from roc_chart import ROCChart\n",
    "from sklearn.externals import joblib\n",
    "import keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import load_model\n",
    "from scipy.stats import ttest_rel\n",
    "\n",
    "random_seed = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab080d16",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f46465",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load reviews\n",
    "with open('reviews/sentiment_reviews/sentiment.pkl', 'rb') as f:\n",
    "    sentiment_reviews = pkl.load(f)\n",
    "    \n",
    "# Load indexes\n",
    "with open('split_indexes/indexes.pkl', 'rb') as f:\n",
    "    indexes = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c95c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract scores\n",
    "scores = sentiment_reviews.adj_score.values\n",
    "\n",
    "# Extract non-test and test scores\n",
    "non_test_scores = scores[indexes['non_test']]\n",
    "test_scores = scores[indexes['test']]\n",
    "\n",
    "# Extract train and validation scores\n",
    "train_scores = non_test_scores[indexes['train']]\n",
    "val_scores = non_test_scores[indexes['val']]\n",
    "\n",
    "# Transform scores into categorical\n",
    "scores_cat = keras.utils.to_categorical(scores,2)\n",
    "\n",
    "# Extract non-test and test scores\n",
    "non_test_scores_cat = scores_cat[indexes['non_test']]\n",
    "test_scores_cat = scores_cat[indexes['test']]\n",
    "\n",
    "# Extract train and validation scores\n",
    "train_scores_cat = non_test_scores_cat[indexes['train']]\n",
    "val_scores_cat = non_test_scores_cat[indexes['val']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e368b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract parser_zero_reviews \n",
    "parser_zero_reviews = sentiment_reviews.loc[:,'parser_zero'].values\n",
    "\n",
    "# Extract non test parser two reviews and scores\n",
    "non_test_parser_zero_reviews = parser_zero_reviews[indexes['non_test']]\n",
    "test_parser_zero_reviews = parser_zero_reviews[indexes['test']]\n",
    "\n",
    "# Extract train and validation parser-two reviews\n",
    "train_parser_zero_reviews = non_test_parser_zero_reviews[indexes['train']]\n",
    "val_parser_zero_reviews = non_test_parser_zero_reviews[indexes['val']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8bf9680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract parser_one_reviews \n",
    "parser_one_reviews = sentiment_reviews.loc[:,'parser_one'].values\n",
    "\n",
    "# Extract non test parser two reviews and scores\n",
    "non_test_parser_one_reviews = parser_one_reviews[indexes['non_test']]\n",
    "test_parser_one_reviews = parser_one_reviews[indexes['test']]\n",
    "\n",
    "# Extract train and validation parser-two reviews\n",
    "train_parser_one_reviews = non_test_parser_one_reviews[indexes['train']]\n",
    "val_parser_one_reviews = non_test_parser_one_reviews[indexes['val']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0067715d",
   "metadata": {},
   "source": [
    "## Import log reg benchmark model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6936a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load log reg benchmark\n",
    "bmk_log_reg = joblib.load('bmk_models/bmk_log_reg.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08e8bce",
   "metadata": {},
   "source": [
    "## Parse data for deep learning models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b74208",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bmk prediciton on validation set\n",
    "val_bmk_pred = bmk_log_reg.predict(val_parser_one_reviews)\n",
    "\n",
    "# Deep Learning prediction on validation set\n",
    "val_dl_pred = deep_learning_model.predict_classes(padded_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ae94a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print comparison chart\n",
    "comparison_chart = ROCChart(val_scores,\n",
    "                            [val_bmk_pred, val_dl_pred],\n",
    "                            ['Bmk Log Reg', 'Refined Model'],\n",
    "                            'AUC on validation set')\n",
    "comparison_chart.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705fc6b3",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5612b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bmk prediciton on test set\n",
    "test_bmk_pred = bmk_log_reg.predict(test_parser_one_reviews)\n",
    "\n",
    "# Deep Learning prediction on test set\n",
    "test_dl_pred = deep_learning_model.predict_classes(padded_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72bec0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print comparison chart\n",
    "comparison_chart = ROCChart(test_scores,\n",
    "                            [test_bmk_pred, test_dl_pred],\n",
    "                            ['Bmk Log Reg', 'Refined Model'],\n",
    "                            'AUC on test set')\n",
    "comparison_chart.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0ef6c7",
   "metadata": {},
   "source": [
    "## Build Deep Learning classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01260ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dump keras tokeniser\n",
    "with open('final_model/dl_tokeniser.pkl', 'wb') as f:\n",
    "    pkl.dump(keras_tokenizer, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60407c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "class DL_Classifier:\n",
    "    \n",
    "    def __init__(self, tokeniser_path, model_path, num_words=50):\n",
    "        \n",
    "        with open(tokeniser_path, 'rb') as f:\n",
    "            self.tokeniser = pkl.load(f)\n",
    "             \n",
    "        self.model = load_model(model_path)\n",
    "        self.num_words = num_words\n",
    "        \n",
    "    def predict(self, reviews, return_proba=False):\n",
    "        \n",
    "        reviews = self.tokeniser.texts_to_sequences(reviews)\n",
    "        reviews = pad_sequences(reviews, self.num_words, padding='post')\n",
    "        \n",
    "        predictions = self.model.predict(reviews)\n",
    "        \n",
    "        if return_proba:\n",
    "            return predictions\n",
    "        else:\n",
    "            return predictions.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb54c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "DL_model = DL_Classifier('final_model/dl_tokeniser.pkl', 'final_model/dl_final.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e868b733",
   "metadata": {},
   "outputs": [],
   "source": [
    "DL_model.model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0363eca6",
   "metadata": {},
   "source": [
    "## Prediction on some reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd33c567",
   "metadata": {},
   "source": [
    "#### Order of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca9618b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define number words in tokenizer\n",
    "n_words_tokenizer = None\n",
    "\n",
    "# Define max_len for reviews\n",
    "max_len = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8d3e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenise and pad  parser_zero reviews\n",
    "# Import tokeniser\n",
    "keras_tokenizer = Tokenizer(num_words = n_words_tokenizer)\n",
    "\n",
    "keras_tokenizer.fit_on_texts(train_parser_one_reviews)\n",
    "\n",
    "# Tokenise train, val and test parser_zero reviews\n",
    "tokenised_train = keras_tokenizer.texts_to_sequences(train_parser_one_reviews)\n",
    "tokenised_val = keras_tokenizer.texts_to_sequences(val_parser_one_reviews)\n",
    "tokenised_test = keras_tokenizer.texts_to_sequences(test_parser_one_reviews)\n",
    "\n",
    "# Transform reviews into sequences using pad_sequences\n",
    "padded_train = pad_sequences(tokenised_train, maxlen=max_len, padding='post')\n",
    "padded_val = pad_sequences(tokenised_val, maxlen=max_len, padding='post')\n",
    "padded_test = pad_sequences(tokenised_test, maxlen=max_len, padding='post')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f08b52",
   "metadata": {},
   "source": [
    "## Import deep learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e51d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = [\"I bought this product and I found it not to be very good\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365100e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "bmk_log_reg.predict_proba(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3632ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "DL_model.predict(test, return_proba=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fffd8339",
   "metadata": {},
   "source": [
    "#### 10 Test Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d6f75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_reviews = test_parser_zero_reviews[:10]\n",
    "comparison_parser_one = test_parser_one_reviews[:10]\n",
    "comparison_bmk_pred = [int(x) for x in bmk_log_reg.predict(comparison_parser_one)]\n",
    "comparison_dl_pred = DL_model.predict(comparison_parser_one, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfef936",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame({'text' : comparison_reviews, \n",
    "                        'bmk_pred' : comparison_bmk_pred, \n",
    "                        'dl_pred' : comparison_dl_pred, \n",
    "                        'true' : [int(x) for x in test_scores[:10]]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d613dc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8132a2",
   "metadata": {},
   "source": [
    "## Statistical test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f5bc57",
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_learning_model = load_model('final_model/dl_final.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7b6a40",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd15e99d",
   "metadata": {},
   "source": [
    "#### Validation"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
