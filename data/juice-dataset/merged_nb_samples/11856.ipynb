{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "274d9f70",
   "metadata": {},
   "source": [
    "# Data Acquisition and Cleaning\n",
    "The first part of the document presents the work done in order to obtain a usable dataset. Indeed, the Million Song Dataset (MSD) was lackluster regarding song features (danceability, energy, etc), which were all set to 0. That's why we decided to take additional steps to improve this dataset.    \n",
    "In the first part, we import data from the MSD and we decide to keep only some values of interest from this dataset. Next, we query the Spotify API in order to obtain additional information about each song. In the meantime, we also add genre classification for each song from 3 datasets built around the MSD. Finally, we generate a csv which will be our main resource of data for the rest of the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e46f8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "from sqlite3 import Error\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import widgets, interactive\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8f5154",
   "metadata": {},
   "source": [
    "The following function aims at creating a connection to an SQLite database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889f2ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_connection(db_file):\n",
    "    \"\"\" create a database connection to the SQLite database\n",
    "        specified by the db_file\n",
    "    :param db_file: database file\n",
    "    :return: Connection object or None\n",
    "    \"\"\"\n",
    "    try:\n",
    "        conn = sqlite3.connect(db_file)\n",
    "        return conn\n",
    "    except Error as e:\n",
    "        print(e)\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c5ab53",
   "metadata": {},
   "source": [
    "We have a quick look at the columns we have at our disposal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d2093b",
   "metadata": {},
   "outputs": [],
   "source": [
    "database = \"data/track_metadata.db\"\n",
    "conn = create_connection(database)\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"PRAGMA table_info(songs)\")\n",
    "rows = cur.fetchall()\n",
    "print(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411e9967",
   "metadata": {},
   "source": [
    "Request the dataset and put the data in a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14948974",
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute(\"SELECT track_id, song_id, artist_id, duration, artist_hotttnesss, year FROM songs ORDER BY track_id\")\n",
    "rows = cur.fetchall()\n",
    "songs = pd.DataFrame(rows, columns=['track_id', 'song_id', 'artist_id', 'duration', 'artist_hotttnesss', 'year'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effa17cb",
   "metadata": {},
   "source": [
    "The 3 following cells merge our data from genres classification coming from 3 datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfb30d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_corr(pd.concat([df_stage3[['song_hotttnesss']],df_stage3[df_stage3.columns[-17:]]], axis=1), \"datastory/figures/feature/correlationGenre.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac814370",
   "metadata": {},
   "source": [
    "We want know to check if we can train a regressor and extract the feature importances. Here we use a RandomForest like in HW4, but a regressor one this time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5cf711",
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = RandomForestRegressor(n_jobs=-1, n_estimators = 400, verbose=True)\n",
    "\n",
    "df_stage4 = df_stage3.copy()\n",
    "df_stage4 = df_stage4.dropna(axis=0, how='any')\n",
    "df_stage4 = df_stage4[df_stage4.year > 0]\n",
    "df_stage4['nb_genre'] = np.sum(df_stage4.iloc[:, -17:].values, axis=1)  \n",
    "df_stage4 = df_stage4[df_stage4.nb_genre > 0].drop(['nb_genre'], axis=1)\n",
    "\n",
    "train_set = df_stage4.drop(['song_hotttnesss'], axis=1)  \n",
    "\n",
    "train_label = df_stage4.song_hotttnesss\n",
    "\n",
    "regressor.fit(train_set, train_label)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aaae2d2",
   "metadata": {},
   "source": [
    "Let's check the importance per feature, in order to extract some useful insights. \n",
    "\n",
    "Note that we sum the importance of each genre to see what they mean for the whole random forest, as we can sum feature to get the importance of a bag of feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a082bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_sum = 0.0\n",
    "for a, b in sorted(zip(regressor.feature_importances_, train_set.columns), reverse=True):\n",
    "    print(a, \" : \", b)\n",
    "    if b in genres:\n",
    "        genre_sum += a\n",
    "        \n",
    "genre_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ce6678",
   "metadata": {},
   "source": [
    "Note that, with a sum of 0.07, the bagging of the genres has the same importance as the others.\n",
    "\n",
    "It looks like we have some interesting results, but let's create a graph to visualize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a2e000",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance_df = pd.DataFrame({'label': train_set.columns, 'feature_importance' : regressor.feature_importances_})\n",
    "feature_importance_df = feature_importance_df.sort_values('feature_importance', ascending=False).iloc[:13]\n",
    "feature_importance_df.iloc[12] = [genre_sum, 'genre']\n",
    "\n",
    "order = np.flipud(feature_importance_df.sort_values(by='feature_importance').label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56233911",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale=2)\n",
    "fig, ax = plt.subplots(figsize=(20,20))\n",
    "\n",
    "snsplot = sns.barplot(x='feature_importance', y='label', data=feature_importance_df, palette=\"Blues_d\", order=order)\n",
    "\n",
    "snsplot.figure.savefig(\"datastory/figures/feature/RandomForest_feature_importance.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c986ad",
   "metadata": {},
   "source": [
    "It seems that there is a close top 3, followed by most of the features with little difference in importance, and finally key at the end, which is close to half as important as the other ones.    \n",
    "- liveness may indicate that the live songs may be more or less appreciated than the others\n",
    "- the year plays a big role, we'll see that later\n",
    "- duration seems to be quite important too, with very short or very long tracks being less appreciated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e1ecea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scatter(df, y_name, x_name):\n",
    "    sns_plot = sns.lmplot(x=x_name, y=y_name, scatter_kws={\"s\": 2}, line_kws={'color': 'red'}, data=df)\n",
    "    sns_plot.savefig(\"datastory/figures/scatter_feature/scatter_\" + x_name + \".png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd75211f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_correct_feature = df_stage3.dropna(axis=0, how='any').copy()\n",
    "\n",
    "df_with_correct_year = df_stage3[df_stage3.year > 0].copy()\n",
    "\n",
    "df_with_correct_genre = df_stage3.copy()\n",
    "df_with_correct_genre['nb_genre'] = np.sum(df_with_correct_genre.iloc[:, -17:].values, axis=1)  \n",
    "df_with_correct_genre = df_with_correct_genre[df_with_correct_genre.nb_genre > 0].drop(['nb_genre'], axis=1)\n",
    "   \n",
    "print(\"correct feature len: \", len(df_with_correct_feature))\n",
    "print(\"correct year len: \", len(df_with_correct_year))\n",
    "print(\"correct genre len: \", len(df_with_correct_genre))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2d28fa",
   "metadata": {},
   "source": [
    "Let's plot a scatterplot along with a regression between each feature and song_hotttnesss to see if there are any visible links."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b2007b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('final_merge.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a635ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df09bdc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197a851d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.columns.values[0] = 'id'\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f62f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df[(pd.isnull(df.genre1_cd1) == False) | (pd.isnull(df.genre1_cd2) == False) | (pd.isnull(df.genre1_cd2c) == False)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2e4d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_year = df2.groupby(['year']).size().reset_index(name='counts')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86590418",
   "metadata": {},
   "source": [
    "First we check the number of song per year we have in the dataset. As expected we see an increase in the number of songs over the year except for 2010, this is probably because the year 2010 was just ending when the dataset was created and the 2010 songs hadn't had the time to attain their maximum popularity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915cd430",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_year.iloc[1:, :].plot(x='year', y='counts', kind='line')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778d8842",
   "metadata": {},
   "source": [
    "As said before there are not a lot of songs before the 60s, thus we will drop these ones to continue a meaningful analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b533b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2[df2.year > 1960]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60378872",
   "metadata": {},
   "outputs": [],
   "source": [
    "genres = set([])\n",
    "genres_cols = ['genre1_cd2c', 'genre2_cd2c', 'genre1_cd2', 'genre2_cd2', 'genre1_cd1', 'genre2_cd1']\n",
    "for col_name in genres_cols:\n",
    "    genres = genres | set(df2[col_name].unique())\n",
    "print(genres)\n",
    "print(len(genres))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665445e5",
   "metadata": {},
   "source": [
    "As done in feature analysis, we will create a 1-hot encoded matrix using the genres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d4c3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "track_genre_cd1 = pd.read_csv('data/msd_tagtraum_cd1.cls', sep='\\t', names=['track_id', 'genre1_cd1', 'genre2_cd1'])\n",
    "songs = track_genre_cd1.merge(songs, on='track_id', how='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4bc7b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "track_genre_cd1 = pd.read_csv('data/msd_tagtraum_cd2.cls', sep='\\t', names=['track_id', 'genre1_cd2', 'genre2_cd2'])\n",
    "songs = track_genre_cd1.merge(songs, on='track_id', how='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0afdbec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "track_genre_cd1 = pd.read_csv('data/msd_tagtraum_cd2c.cls', sep='\\t', names=['track_id', 'genre1_cd2c', 'genre2_cd2c'])\n",
    "songs = track_genre_cd1.merge(songs, on='track_id', how='right')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c1c126",
   "metadata": {},
   "source": [
    "We take a look at the analysis of the songs from the MSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8e183c",
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_df = adj_df.iloc[:, :-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efca12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "adj = adj_df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b0699c",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = []\n",
    "for i in range(len(adj)):\n",
    "    for j in range(i+1, len(adj)):\n",
    "        edge = {'source_id': i, 'target_id': j, 'stroke_width': adj[i, j]/1000}\n",
    "        edges.append(edge)\n",
    "edges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46eaf22",
   "metadata": {},
   "source": [
    "Computing data points for hotness depending on the different genres. We use a very little random forest to smooth the curves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721e76d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "int(len(list(genres))/3.0 + .5)\n",
    "f, axarr = plt.subplots(int(len(list(genres))/3.0 + .5), 3)\n",
    "f.set_size_inches(15, 20)\n",
    "plt.subplots_adjust(hspace=.4)\n",
    "i = 0\n",
    "all_data = {}\n",
    "\n",
    "# Compute the avg hotness by year for all the data\n",
    "hottness_avg = df2[df2['song_hotttnesss'].notna()].groupby(['year']).mean().reset_index()\n",
    "regr = RandomForestRegressor(n_estimators=10, n_jobs=-1, max_depth= 5)\n",
    "regr.fit(hottness_avg[['year']], hottness_avg['song_hotttnesss'])\n",
    "hottness_predict = regr.predict(np.array(list(range(1960, 2011))).reshape(-1, 1))\n",
    "data = {}\n",
    "data['years'] = list(hottness_avg['year'].astype(str).values)\n",
    "data['hottness'] = list(hottness_avg['song_hotttnesss'].values)\n",
    "data['predict'] = list(hottness_predict)\n",
    "all_data['avg'] = data\n",
    "\n",
    "# Compute it for each genre\n",
    "for genre in genres:\n",
    "    regr = RandomForestRegressor(n_estimators=10, n_jobs=-1, max_depth= 5)\n",
    "    hottness = df2[(df2[genre] == 1) & df2['song_hotttnesss'].notna()].groupby(['year']).mean().reset_index()\n",
    "    hottness = hottness[hottness['song_hotttnesss'] > 0]\n",
    "    regr.fit(hottness[['year']], hottness['song_hotttnesss'])\n",
    "    hottness.plot(x='year', y='song_hotttnesss', kind='scatter', title=genre, ax=axarr[int(i/3), i%3], color='orange')\n",
    "    hottness_predict = regr.predict(np.array(list(range(1960, 2011))).reshape(-1, 1))\n",
    "    axarr[int(i/3), i%3].plot(list(range(1960, 2011)), hottness_predict)\n",
    "    data = {}\n",
    "    data['years'] = list(hottness['year'].astype(str).values)\n",
    "    data['hottness'] = list(hottness['song_hotttnesss'].values)\n",
    "    data['predict'] = list(hottness_predict)\n",
    "    all_data[genre] = data\n",
    "    i+=1\n",
    "f = open('hottness.json','w')\n",
    "f.write(str(all_data))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8736b489",
   "metadata": {},
   "source": [
    "We store the data points for some interesting features evolution over the years depending on the genre of song. We also look at the average values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2230771d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "for col in ['song_hotttnesss', 'duration', 'speechiness', 'acousticness', 'instrumentalness']:\n",
    "    all_data = {}\n",
    "\n",
    "    # Compute the avg hotness by year for all the data\n",
    "    avg = df2[df2[col].notna()].groupby(['year']).mean().reset_index()\n",
    "    regr = RandomForestRegressor(n_estimators=10, n_jobs=-1, max_depth= 5)\n",
    "    regr.fit(hottness_avg[['year']], avg[col])\n",
    "    predict = regr.predict(avg['year'].values.reshape(-1, 1))\n",
    "    data = {}\n",
    "    data['years'] = list(avg['year'].astype(str).values)\n",
    "    data[col] = list(avg[col].values)\n",
    "    data['predict'] = list(predict)\n",
    "    all_data['avg'] = data\n",
    "\n",
    "    # Compute it for each genre\n",
    "    print(\"%s: \" % col)\n",
    "    for genre in genres:\n",
    "        regr = RandomForestRegressor(n_estimators=10, n_jobs=-1, max_depth= 5)\n",
    "        datas = df2[(df2[genre] == 1) & df2[col].notna()]\n",
    "        col_data = datas.groupby(['year']).mean().reset_index()\n",
    "        col_data = col_data[col_data[col] > 0]\n",
    "        regr.fit(col_data[['year']], col_data[col])\n",
    "        predict = regr.predict(hottness_avg['year'].values.reshape(-1, 1))\n",
    "        data = {}\n",
    "        data['years'] = list(hottness['year'].astype(str).values)\n",
    "        data[col] = list(col_data[col].values)\n",
    "        data['predict'] = list(predict)\n",
    "        all_data[genre] = data\n",
    "        i+=1\n",
    "        avg += np.mean(col_data[col].values)\n",
    "        print(\"\\t %s: Nb songs = %d and Avg Value is %f\" % (genre, len(datas), np.mean(data[col])))\n",
    "    f = open('datastory/data/genre_analysis/%s.json' % col,'w')\n",
    "    f.write(str(all_data))\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3215d5a7",
   "metadata": {},
   "source": [
    "# Feature analysis 2004-2009\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ce4d96",
   "metadata": {},
   "source": [
    "We will now concentrate on the years with the most samples, meaning 2004 to 2009, a 5 year period. The analysis / procedure will be the same as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b68f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[(df['year']>2003) & (df['year']<2010)]\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4bcbd5",
   "metadata": {},
   "source": [
    "We remove the useless columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f5d802",
   "metadata": {},
   "source": [
    "We have 17 different genres (nan are unkownn and international is the same as world). To do a meaningful analysis of the genre analysis over the year a minimum amount of songs of the analyzed type must be in the dataset. In the following cells we first replace the nan and replace International by World. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a63bf1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stage1[genres_cols] = df_stage1[genres_cols].fillna('Unknown')\n",
    "df_stage1[genres_cols] = df_stage1[genres_cols].replace('International', 'World')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7902614",
   "metadata": {},
   "source": [
    "Let's just check that we have the shape wanted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992162e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stage1[genres_cols].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce51ca6a",
   "metadata": {},
   "source": [
    "For the moment we have 6 columns for the genres, we would like to see if we can summarize these columns in one or two columns.\n",
    "First we perform a pivot and count the number of different values there are in each column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38415555",
   "metadata": {},
   "outputs": [],
   "source": [
    "genres = set([])\n",
    "genres_cols = ['genre1_cd2c', 'genre2_cd2c', 'genre1_cd2', 'genre2_cd2', 'genre1_cd1', 'genre2_cd1']\n",
    "for col_name in genres_cols:\n",
    "    genres = genres | set(df_stage1[col_name].unique())\n",
    "    df_stage1[col_name] = df_stage1[col_name].astype(str)\n",
    "print(genres)\n",
    "print(len(genres))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446e3beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for genre in list(genres):\n",
    "    df_stage1[genre] = 0\n",
    "    for col_name in genres_cols:\n",
    "        df_stage1.loc[df_stage1[col_name] == genre, genre] = 1\n",
    "df_stage1.drop(columns=['Unknown'], axis=1, inplace=True)\n",
    "genres.remove('Unknown')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80703ef2",
   "metadata": {},
   "source": [
    "Let's make sure we have a hot encoded matrix at the end now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9856cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stage2 = df_stage1.drop(genres_cols, axis=1).copy()\n",
    "df_stage2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce6456a",
   "metadata": {},
   "source": [
    "Now that the matrix is ready, let's see if we can spot something using a simple correlation between the data, especially between song_hotttnesss and the rest of the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5163ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_corr(df, output_file_name):\n",
    "    '''\n",
    "        Plot the correlation matrix of a dataframe\n",
    "        The plot will be triangular with negative values blue and positive values red\n",
    "        Code taken from https://seaborn.pydata.org/examples/many_pairwise_correlations.html\n",
    "        :param df: The dataframe\n",
    "        :type df: DataFrame\n",
    "    '''\n",
    "    sns.set(style=\"white\", font_scale=1.5)\n",
    "\n",
    "    # Compute the correlation matrix\n",
    "    corr = df.corr()\n",
    "\n",
    "    # Generate a mask for the upper triangle\n",
    "    mask = np.zeros_like(corr, dtype=np.bool)\n",
    "    mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "    # Set up the matplotlib figure\n",
    "    f, ax = plt.subplots(figsize=(16, 12))\n",
    "    f.suptitle(\"Correlation heatmap\")\n",
    "\n",
    "    # Generate a custom diverging colormap\n",
    "    cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "\n",
    "    # Draw the heatmap with the mask and correct aspect ratio\n",
    "    snsplot = sns.heatmap(corr, mask=mask, cmap=cmap, center=0,\n",
    "                square=True, linewidths=.5, cbar_kws={\"shrink\": .5})\n",
    "    \n",
    "    snsplot.figure.savefig(output_file_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c101589",
   "metadata": {},
   "source": [
    "A final remark about song year. Most of them are in fact 0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88cceb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stage2[df_stage2.year == 0].year.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45fe20b",
   "metadata": {},
   "source": [
    "Let's remove them for the correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319ed620",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_corr(df_stage2[df_stage2.year != 0][df_stage2.columns[0:-17]], \"datastory/figures/feature/correlationComplete.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd5aa4ff",
   "metadata": {},
   "source": [
    "What do we see here ?\n",
    "\n",
    "1) the value between spotify and MSD on the duration is highly correlated, same for loudness and key, so let's keep the original one \n",
    "\n",
    "2) track_popularity and song_hotttnesss is moderately correlated, thus we will keep the song_hotttnesss\n",
    "\n",
    "3) year of MSD and album release from spotify is absolutely not correlated, so let's keep the one from MSD again\n",
    "\n",
    "4) The acousticness has negative correlation with loudness and energy (which seems logical, as classical music is generally not loud or energetic)\n",
    "\n",
    "5) no feature looks highly, even moderately, correlated to the song_hotttnesss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54dbd324",
   "metadata": {},
   "source": [
    "Let's drop the useless columns again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89fa4597",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stage3 = df_stage2.drop(['album_release', 'track_popularity', 'duration_ms', 'key_y', 'loudness_y', 'tempo_x'], axis=1)\n",
    "df_stage3.rename(columns={'key_x': 'key', 'loudness_x': 'loudness', 'tempo_y': 'tempo'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77a7485",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_corr(df_stage3[df_stage3.year != 0][df_stage3.columns[0:-17]], \"datastory/figures/feature/correlationReduce.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2baefeb",
   "metadata": {},
   "source": [
    "And let's do the same thing for genre only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd63eb78",
   "metadata": {},
   "outputs": [],
   "source": [
    "msd_summary_file = pd.HDFStore(\"data/msd_summary_file.h5\")\n",
    "songs_analysis = msd_summary_file.get('/analysis/songs')\n",
    "songs_analysis.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe05da1",
   "metadata": {},
   "source": [
    "And add the data we find interesting. Indeed a lot of columns in this dataset are empty and cannot be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c55631f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in df_with_correct_feature.columns[:-17]:\n",
    "    if feature != \"year\" and feature != \"song_hotttnesss\":\n",
    "        plot_scatter(df_with_correct_feature, \"song_hotttnesss\", feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f63829d",
   "metadata": {},
   "source": [
    "As it is a linear regression, it really doesn't tell the whole story, but it seems that songs being short, loud, not danceable but energetic and with little acousticness and speechiness are more appreciated. Take that with a grain of salt though.\n",
    "\n",
    "Recent songs seem to also be \"hotter\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9e342e",
   "metadata": {},
   "outputs": [],
   "source": [
    "songs_analysis = songs_analysis[['track_id', 'loudness', 'mode', 'tempo', 'key']]\n",
    "songs = songs_analysis.merge(songs, on='track_id')\n",
    "del(songs_analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb2ba9a",
   "metadata": {},
   "source": [
    "We do the same operation for the metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65611c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "songs_metadata = msd_summary_file.get('/metadata/songs')\n",
    "songs_metadata.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2fe776",
   "metadata": {},
   "outputs": [],
   "source": [
    "songs_metadata = songs_metadata[['song_hotttnesss', 'song_id', 'artist_latitude', 'artist_location', 'artist_longitude']]\n",
    "songs = songs_metadata.merge(songs, on='song_id')\n",
    "del(songs_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe3f384",
   "metadata": {},
   "source": [
    "And we take a look at the data we have gathered until now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e7f142",
   "metadata": {},
   "outputs": [],
   "source": [
    "songs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a268516",
   "metadata": {},
   "source": [
    "In order to gather data from the Spotify API we have some scripts in auxiliary files (stored in the folder spotify_requests_tools). Using these tools, we created two csv 'feature_songs.csv' and 'track_year_popularity.csv' which contain additional information for each song."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09125318",
   "metadata": {},
   "outputs": [],
   "source": [
    "spotify_data = pd.read_csv('data/feature_songs.csv')\n",
    "spotify_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21904cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the unknown values(zeros) by NaN\n",
    "for column in spotify_data.columns:\n",
    "    spotify_data.loc[spotify_data[column] == 0, column] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30aad408",
   "metadata": {},
   "outputs": [],
   "source": [
    "songs2 = songs.merge(spotify_data, how='left', on='song_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015135a8",
   "metadata": {},
   "source": [
    "Again taking a look at the data we have until now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d669e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "songs2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a622c7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "songs2.iloc[1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89aed2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "spotify_year_pop = pd.read_csv('data/track_year_popularity.csv')\n",
    "final_merge = songs2.merge(spotify_year_pop.drop_duplicates(['song_id'], keep='last'), how='left', on='song_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a78130e",
   "metadata": {},
   "source": [
    "Finally we take a look at our data and save them into a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5162a628",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_merge.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0526226d",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_merge.to_csv('final_merge.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f8e885",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_merge.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f98cf8",
   "metadata": {},
   "source": [
    "It seems that we have gained some rows while joining the datasets. This may be due to duplicate IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc11cc8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_merge.loc[2,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f47dc6",
   "metadata": {},
   "source": [
    "# Feature analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45998bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('final_merge.csv')\n",
    "df['song_hotttnesss'] = df['song_hotttnesss'].fillna(0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328f36af",
   "metadata": {},
   "source": [
    "Let's put the dataframe in a good form for the rest of the analysis.\n",
    "\n",
    "First, we remove all useless columns, or the ones which don't make sense to describe a song."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160ef6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stage1 = df.drop(['Unnamed: 0', 'artist_latitude', 'artist_location', 'artist_id', 'artist_longitude', 'song_id', 'track_id', 'artist_hotttnesss', 'mode_x', 'mode_y'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b2ffec",
   "metadata": {},
   "source": [
    "We will need a one hot encoded matrix for genre for future analysis. We need all the genres in a first time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd26fa5",
   "metadata": {},
   "source": [
    "### You will need the ipython extensions / widgets enabled to use the interactive graph below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954081fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_c = df.copy()\n",
    "df_c = df_c[df_c['year']>=1960] #Only take after 1960, as before there are very few samples\n",
    "DECADE = \"Decade\"\n",
    "SINGLE_YEAR = \"Single year\"\n",
    "df_c['artist_hotttnesss'][df_c['artist_hotttnesss']<0]=0 # Clamp the artist hotness as the data is sometimes faulty\n",
    "df_c['artist_hotttnesss'][df_c['artist_hotttnesss']>1]=1\n",
    "decades = widgets.RadioButtons( #Button to select year or decade\n",
    "options=[DECADE,SINGLE_YEAR],value=SINGLE_YEAR, disabled=False, description=\"Year grouping\")\n",
    "year = widgets.BoundedIntText( #Field to select year\n",
    "    value=1960,\n",
    "    min=1960,\n",
    "    max=2010,\n",
    "    step=1,\n",
    "    description='Year:',\n",
    "    disabled=False,\n",
    "    color='black'\n",
    ")\n",
    "def update_year(*args):\n",
    "    \"\"\"\n",
    "    Update the year widget depending on the button value\n",
    "    \"\"\"\n",
    "    if decades.value==SINGLE_YEAR:\n",
    "        year.step=1\n",
    "        year.max=2010\n",
    "        year.description='Year:'\n",
    "    else:\n",
    "        year.step=10\n",
    "        year.value=np.round(year.value/10)*10\n",
    "        year.max=2000\n",
    "        year.description=\"Decade:\"\n",
    "    \n",
    "decades.observe(update_year,'value') #Listener\n",
    "\n",
    "feature = widgets.Dropdown( #Widget to select the feature\n",
    "    options=selected[1:], #Don't take song hotness\n",
    "    value='loudness_x',\n",
    "    description='Feature:',\n",
    ")\n",
    "\n",
    "def save_all_plots():\n",
    "    \"\"\"\n",
    "    Saves all the year stripplots\n",
    "    \"\"\"\n",
    "    for f in selected[1:]:\n",
    "        for year in range(1960, 2011):\n",
    "            plotit(f, year, SINGLE_YEAR)\n",
    "            fig = plt.gcf()\n",
    "            fig.savefig(\"datastory/figures/year_analysis_plots/single_year/\"+f+\"_\"+str(year)+\".png\", bbox_inches='tight')\n",
    "            if year<2010 and year%10==0: #Save the decades too\n",
    "                plotit(f,year,DECADE)\n",
    "                fig = plt.gcf()\n",
    "                fig.savefig(\"datastory/figures/year_analysis_plots/decade/\"+f+\"_\"+str(year)+\"-\"+str(year+10)+\".png\",bbox_inches=\"tight\")\n",
    "            \n",
    "def plotit(feature, year, decades):\n",
    "    df_d = df_c.copy()\n",
    "    plt.clf()\n",
    "    fig = plt.gcf()\n",
    "    fig.set_size_inches(16,16)\n",
    "    decade = decades==DECADE\n",
    "    ax = plt.gca()\n",
    "    if decade:\n",
    "        title = str(year)+\" - \"+str(year+10)\n",
    "    else:\n",
    "        title = str(year)\n",
    "    fig.suptitle(title, y=0.9)\n",
    "    plot_for_year(df_d,feature,year, decade=decade)\n",
    "\n",
    "interactive(plotit,feature=feature, year=year, decades = decades)\n",
    "#save_all_plots()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364f2b00",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "The analysis will be done by decade, as otherwise the values per year jump a lot, and grouping by decade helps to visualize better the evolution of the features (their tendency). To avoid cluttering the notebook, the plots have been saved and examined on the disk (they are also available on the github repository).\n",
    "\n",
    "### Features\n",
    "First off, the features don't seem to influence the song hotness at all (except for the artist hotness obviously), which is a bit of a letdown. The median for each song hotness bin seems to be around the same value, and the distributions the same.\n",
    "\n",
    "### Evolution\n",
    "There are some evolutions through the years / decades though:\n",
    "- The acousticness seems to decrease throughout the years, and the mean acousticness is quite low overall.\n",
    "- The duration increased from the 60s to the 70s, and then stayed at ~250s.\n",
    "- The songs become more and more energetic decade after decade.\n",
    "- The loudness also increases with the decades. The top songs seems to be louder as well.\n",
    "- The valence decreases with the time, and the top songs hang around 0.5 valence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c98d91",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "We can't really see any link between a feature through the years and the song hotness. We also can't, for most of the features, see any real evolution. These problems are maybe due to the selection bias of the MSD."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77dbac9f",
   "metadata": {},
   "source": [
    "# Genre Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e717475",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[genres_cols] = df2[genres_cols].fillna('Unknown')\n",
    "df2[genres_cols] = df2[genres_cols].replace('International', 'World')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8279e20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "genres = set([])\n",
    "genres_cols = ['genre1_cd2c', 'genre2_cd2c', 'genre1_cd2', 'genre2_cd2', 'genre1_cd1', 'genre2_cd1']\n",
    "for col_name in genres_cols:\n",
    "    genres = genres | set(df2[col_name].unique())\n",
    "    df2[col_name] = df2[col_name].astype(str)\n",
    "print(genres)\n",
    "print(len(genres))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8407c90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[genres_cols].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e57fc32",
   "metadata": {},
   "outputs": [],
   "source": [
    "for genre in list(genres):\n",
    "    df2[genre] = 0\n",
    "    for col_name in genres_cols:\n",
    "        df2.loc[df2[col_name] == genre, genre] = 1\n",
    "df2 = df2.drop(columns=['Unknown'])\n",
    "genres.remove('Unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe65503",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['nb_genre'] = np.sum(df2.iloc[:, -17:].values, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22deb25",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['nb_genre'].plot(kind='hist')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fdd037b",
   "metadata": {},
   "source": [
    "So we see that the majority of the songs have 1 or 2 different genres, some also have 3 genres and 4 genres is atypical. We can now drop the 6 columns containing the label genres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595a97ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2.drop(columns=genres_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ae413d",
   "metadata": {},
   "source": [
    "Now for each genre we plot the number of samples per year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7215086f",
   "metadata": {},
   "outputs": [],
   "source": [
    "int(len(list(genres))/3.0 + .5)\n",
    "f, axarr = plt.subplots(int(len(list(genres))/3.0 + .5), 3)\n",
    "f.set_size_inches(15, 20)\n",
    "plt.subplots_adjust(hspace=.4)\n",
    "i = 0\n",
    "all_data = {}\n",
    "for genre in genres:\n",
    "    data_genre = df2[df2[genre] == 1].groupby(['year']).size().reset_index(name='counts')\n",
    "    data_genre.plot(x='year', y='counts', kind='line', title=genre, ax=axarr[int(i/3), i%3])\n",
    "    fig = axarr[int(i/3), i%3].get_figure()\n",
    "    extent = axarr[int(i/3), i%3].get_window_extent().transformed(fig.dpi_scale_trans.inverted())\n",
    "    data = {}\n",
    "    data['years'] = list(data_genre['year'].astype(str).values)\n",
    "    data['count'] = list(data_genre['counts'].values)\n",
    "    all_data[genre] = data\n",
    "    #fig.savefig('figures/%s_distri_year.png' % (genre), bbox_inches=extent.expanded(1.2, 1.15), dpi = 500)\n",
    "    i+=1\n",
    "f = open('counts.json','w')\n",
    "f.write(str(all_data))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308665bf",
   "metadata": {},
   "source": [
    "These plots are useful to see the data we have in our hands. \n",
    "\n",
    "Firstly we observe that most of the music we have is Rock, Pop, Pop_rock, Electronic or Metal. On the opposite, World, Latin, Blues are not very represented. This can be explained either because the dataset is biased or also because some genres are more popular. Indeed Latin music is underrepresented although there is a very large latin culture in the world. These observations could be made more precise by using only the total number of songs for each genre.\n",
    "\n",
    "Secondly these plots allow us to see some trends in the evolution of the music. If we suppose the dataset is not too much biased for the most represented genres, we can make some interesting observations. We can see that punk music suddenly appears in the middle of the 70's. Rock started in the 60's and grows exponentially since this moment. Indeed these plots are useful to tell something about when the genre appears and how it has evolved since this moment. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e6b355",
   "metadata": {},
   "source": [
    "Now we want to look how genres are connected, so let's construct a graph in which nodes are the genre and a connection between two genres appears when a song has both genres. The weight of the connection is given by the number of songs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e569fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_mat_genres = np.zeros([len(genres), len(genres)])\n",
    "genres = list(genres)\n",
    "for i in range(len(genres)):\n",
    "    for j in range(i, len(genres)):\n",
    "        nb_songs = df2[(df2[genres[i]] == 1) & (df2[genres[j]] == 1)].shape[0]\n",
    "        adj_mat_genres[i, j] = nb_songs\n",
    "        adj_mat_genres[j, i] = nb_songs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95c3f69",
   "metadata": {},
   "source": [
    "Computing the informations for drawing the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c8ded1",
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_df[['radius', 'id', 'genre']].T.to_dict().values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c8a2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "a = adj_df[['radius', 'id', 'genre']].T.to_dict().values()\n",
    "list(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7ec1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "genres = set([])\n",
    "genres_cols = ['genre1_cd2c', 'genre2_cd2c', 'genre1_cd2', 'genre2_cd2', 'genre1_cd1', 'genre2_cd1']\n",
    "for col_name in genres_cols:\n",
    "    genres = genres | set(df_stage1[col_name].unique())\n",
    "print(genres)\n",
    "print(len(genres))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747c99cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_scatter(df_with_correct_year, \"song_hotttnesss\", \"year\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6bcddc1",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "We may see tendencies, but we obviously can't tell \"this is needed to make a great song\" or \"that is bad for ratings\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3c55b8",
   "metadata": {},
   "source": [
    "# Year analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38d3164",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "\n",
    "We can see, as expected, that the dataset doesn't have many songs before ~1990. It also stops after 2010 (when the dataset got created). The set is therefore not sampled uniformly on the release date. Indeed, as explained on the MSD website, the dataset was chosen using the most familiar/popular artists / tracks, which explains why older songs are underrepresented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58113788",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_by(df, idx, column, ax=None):\n",
    "    '''\n",
    "        Plot a column (y axis) against an index (x axis)\n",
    "        Will generate a plot matching for each idx value the mean of the column value for this idx.\n",
    "        :param df: The dataframe containing the data\n",
    "        :param idx: The x axis series\n",
    "        :param column: the y axis series\n",
    "        :param ax: A custom axis object to plot on\n",
    "        :type df: DataFrame\n",
    "        :type idx: string\n",
    "        :type column: string\n",
    "        :type ax: Axes\n",
    "    '''\n",
    "    df_c = df.copy()\n",
    "    df_c = df_c[[idx,column]]\n",
    "    if ax == None:\n",
    "        axes = plt.gca()\n",
    "    else:\n",
    "        axes = ax\n",
    "    axes.set_xlabel(idx)\n",
    "    axes.set_ylabel(column)\n",
    "    df_c.groupby([idx]).mean().plot(ax=ax)\n",
    "    \n",
    "def plot_by_year(df, column, ax = None):\n",
    "    '''\n",
    "        Plot a column (y axis) against the year (x axis)\n",
    "        Will generate a plot matching for each year the mean of the column value for this year.\n",
    "        :param df: The dataframe containing the data\n",
    "        :param column: the y axis series\n",
    "        :param ax: A custom axis object to plot on\n",
    "        :type df: DataFrame\n",
    "        :type column: string\n",
    "        :type ax: Axes\n",
    "    '''\n",
    "    plot_by(df,'year',column, ax=ax)\n",
    "    \n",
    "def plot_heatmap_by(df, idx, column, ax = None):\n",
    "    '''\n",
    "        Plot a heatmap using an index (x axis), and a column (y axis)\n",
    "        The color value of the heatmap will be the number of samples for this coordinate.\n",
    "        :param df: The dataframe containing the data\n",
    "        :param idx: the name of the x axis series\n",
    "        :param column: the name of the y axis series\n",
    "        :param ax: A custom axis object to plot on\n",
    "        :type df: DataFrame\n",
    "        :type idx: string\n",
    "        :type column: string\n",
    "        :type ax: Axes\n",
    "    '''\n",
    "    df_c = df.copy()\n",
    "    df_c = df_c[[idx,column]]\n",
    "    if df[column].dtype == np.float or df[column].dtype == np.float64: #Bin the data if needed\n",
    "        bins = np.linspace(df[column].min(),df[column].max(),20)\n",
    "        df_c[column] = pd.cut(df_c[column],bins)\n",
    "    df_c = df_c.dropna()\n",
    "    df_count = pd.DataFrame(df_c.groupby([idx, column]).size().rename('count'))\n",
    "    df_c = df_c.join(df_count, on=[idx,column])\n",
    "    df_c = df_c.reset_index().pivot_table(index=idx, columns=column, values='count', aggfunc='mean')\n",
    "    if ax==None:\n",
    "        axes = plt.gca()\n",
    "    else:\n",
    "        axes = ax\n",
    "    axes.set_xlabel(idx)\n",
    "    axes.set_ylabel(column)\n",
    "    sns.heatmap(df_c, ax=ax, cbar_kws={'label': 'Number of samples'})\n",
    "\n",
    "def plot_heatmap_by_year(df, column, ax=None):\n",
    "    '''\n",
    "        Plot a heatmap using a column (y axis) against the years\n",
    "        The color value of the heatmap will be the number of samples for this coordinate.\n",
    "        :param df: The dataframe containing the data\n",
    "        :param column: the name of the y axis series\n",
    "        :param ax: A custom axis object to plot on\n",
    "        :type df: DataFrame\n",
    "        :type column: string\n",
    "        :type ax: Axes\n",
    "    '''\n",
    "    plot_heatmap_by(df, 'year', column, ax=ax)\n",
    "    \n",
    "def plot_for_year(df, column, year, ax=None, decade=False):\n",
    "    '''\n",
    "        Plot a stripplot (lineplot) of a feature / column for a given year against the song_hotttnesss\n",
    "        The plot will have jitter to better visualize the data\n",
    "        :param df: The dataframe containing the data\n",
    "        :param column: the name of the series\n",
    "        :param year: the year\n",
    "        :param ax: A custom axis object to plot on\n",
    "        :param decade: Whether to consider the whole decade or not\n",
    "        :type df: DataFrame\n",
    "        :type column: string\n",
    "        :type year: int\n",
    "        :type ax: Axes\n",
    "        :type decade: boolean\n",
    "    '''\n",
    "    df_c = df.copy()\n",
    "    if decade:\n",
    "        df_c['year'], bins=pd.cut(df_c['year'],range(1960,2020,10), include_lowest=True, retbins=True)\n",
    "        interval = pd.Interval(year, year+10)\n",
    "        df_c = df_c[interval==df_c['year']]\n",
    "    else:\n",
    "        df_c = df_c[df_c['year']==year]\n",
    "    df_c = df_c[[column, 'song_hotttnesss']]\n",
    "    df_c['song_hotttnesss'], bins = pd.cut(df_c['song_hotttnesss'],np.linspace(0,1,11), retbins=True) #Bin the song hotness\n",
    "    if ax == None:\n",
    "        axes = plt.gca()\n",
    "    else:\n",
    "        axes = ax\n",
    "\n",
    "    axes.set_xlim(df[column].min()-0.1,df[column].max()+0.1)\n",
    "    axes.set_xlabel(column)\n",
    "    axes.set_ylabel(year)\n",
    "    sns.stripplot(x=column, y='song_hotttnesss',data=df_c, jitter=0.5, ax=axes)\n",
    "    axes.invert_yaxis()\n",
    "    min_y = axes.get_ylim()[0]\n",
    "    max_y = axes.get_ylim()[1]\n",
    "    length = max_y-min_y\n",
    "    for hotness in df_c['song_hotttnesss'].unique(): #Plot the mean of each song hotness bin\n",
    "        if type(hotness)==pd.Interval:\n",
    "            median = df_c.loc[df_c['song_hotttnesss']==hotness][column].median()\n",
    "            start = hotness.left\n",
    "            end = hotness.right\n",
    "            axes.plot([median,median], [length*start+min_y, length*end+min_y], color='k', zorder=1000)\n",
    "    \n",
    "    \n",
    "def plot_heatmap_for_year(df, column1, column2, year, ax=None):\n",
    "    '''\n",
    "        Plot a kdeplot of two features / columns for a given year\n",
    "        It will allow to see correlation between the two columns\n",
    "        :param df: The dataframe containing the data\n",
    "        :param column1: the name of the first series\n",
    "        :param column2: the name of the second series\n",
    "        :param year: the year\n",
    "        :param ax: A custom axis object to plot on\n",
    "        :type df: DataFrame\n",
    "        :type column1: string\n",
    "        :type column2: string\n",
    "        :type year: int\n",
    "        :type ax: Axes\n",
    "    '''\n",
    "    df_c = df.copy()\n",
    "    df_c = df_c[df_c['year']==year]\n",
    "    df_c = df_c[[column1, column2]]\n",
    "    df_c = df_c.dropna()\n",
    "    if ax == None:\n",
    "        axes = plt.gca()\n",
    "    else:\n",
    "        axes = ax\n",
    "    axes.set_xlabel(column1)\n",
    "    axes.set_ylabel(column2)\n",
    "    sns.kdeplot(df_c[column1], df_c[column2], cmap=\"Reds\", shade=True, shade_lowest=False, ax=axes)\n",
    "\n",
    "def ceil(x):\n",
    "    '''\n",
    "        Shortcut for np.ceil(x).astype(int)\n",
    "        :param x: the value to ceil\n",
    "        :type x: number\n",
    "        :return: The result of the ceiling as an int\n",
    "        :rtype: int\n",
    "    '''\n",
    "    return np.ceil(x).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa133a5",
   "metadata": {},
   "source": [
    "We select the features which make sense and then plot their evolution through the years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b33dbb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected = ['song_hotttnesss', 'loudness_x', 'mode_x', 'tempo_x', 'key_x', 'duration', 'artist_hotttnesss', 'danceability', 'energy', 'key_y', 'loudness_y', 'mode_y', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo_y', 'duration_ms']\n",
    "selected.sort()\n",
    "\n",
    "n_cols = 4\n",
    "n_rows = ceil(len(selected)/n_cols)\n",
    "fig, ax = plt.subplots(n_rows,n_cols)\n",
    "fig.set_size_inches(20,n_rows*20/n_cols)\n",
    "idx_r = 0\n",
    "idx_c = 0\n",
    "\n",
    "#For each feature, plot the mean of the feature for each year\n",
    "for col in selected:\n",
    "    plot_by_year(df,col,ax=ax[idx_r, idx_c])\n",
    "    if idx_c==n_cols-1:\n",
    "        idx_r+=1\n",
    "        idx_c=0\n",
    "    else:\n",
    "        idx_c+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838be130",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "\n",
    "For most of the data before ~1960, there is a huge variance due to the low number of samples. However, we can still see tendencies for several features.    \n",
    "- Duration : We can see a clear spike (for both duration and duration_ms) around 1960. We suppose that it is due to the apparition and democratization of the vinyl record (more precisely its more modern iteration). This allowed the musicians to store longer musics (which seemed to be a problem before). However, the duration hasn't increased since, probably because the artists and public feel that the current mean duration is the most optimal one.\n",
    "\n",
    "- Acousticness : We see a massive drop through the years. This is surely due to the apparition of the electronic music (acousticness is determined by the absence of electronic instruments).\n",
    "\n",
    "- Loudness : The music seems to get louder and louder. This is probably due to cultural changes (genre, etc).\n",
    "\n",
    "- Energy : The energy also increases along with the loudness.\n",
    "\n",
    "- Song hotness : The hotness seems to spike at around 2010. This may be explained by the algorithm, if it is similar to the one of Spotify, the hotness is hugely influenced by the recency of the music, which explains this result. Otherwise, this may be due to the same problem seen with tempo, mode, etc, which all spike at the end of the graph.\n",
    "\n",
    "- We can drop mode_y, as it is always 1.\n",
    "\n",
    "- We can't really say much about the other values, except that they seem to stay stable through the years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08a84e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cols = 1\n",
    "selected = ['song_hotttnesss', 'loudness_x', 'mode_x', 'tempo_x', 'key_x', 'duration', 'artist_hotttnesss', 'danceability', 'energy', 'key_y', 'loudness_y', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo_y', 'duration_ms']\n",
    "n_rows = ceil(len(selected)/n_cols)\n",
    "fig, ax = plt.subplots(n_rows,n_cols)\n",
    "fig.set_size_inches(20,n_rows*20/n_cols/2) #Trying to find a good aspect\n",
    "fig.tight_layout()\n",
    "plt.subplots_adjust(hspace=0.5)\n",
    "\n",
    "#For each feature, print the heatmap of the feature regarding the year\n",
    "for idx,col in enumerate(selected):\n",
    "    plot_heatmap_by_year(df, col, ax=ax[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec83f19",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "These graphs don't show much, except that most of the samples are recent, as seen earlier (and what feature values those recent years samples have). We could perhaps normalize by year to have a better visualization."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
