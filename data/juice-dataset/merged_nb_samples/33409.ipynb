{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d3162c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import sklearn\n",
    "from sklearn import linear_model\n",
    "from sklearn import preprocessing\n",
    "from sklearn import neighbors\n",
    "from sklearn import ensemble\n",
    "\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "from sklearn.decomposition import PCA \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "import time\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "sns.set_style('white')\n",
    "\n",
    "import plotly\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "plotly.offline.init_notebook_mode(connected=True)\n",
    "plotly.offline.init_notebook_mode() \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3578bcd",
   "metadata": {},
   "source": [
    "# Cancer diagnosis prediction\n",
    "Source http://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Original%29 <br>\n",
    "Challenge: Classification <br>\n",
    "Using set of breast cancer data, create a model to predict breast cancer. Also, what traits are most indicative of whether or not an individual will be diagnosed?\n",
    "\n",
    "# Summary\n",
    "\n",
    "The data contains more bening than malignant information.But only small numbers of na data, that can be drop.There are few outliers. I decided to keep them. When exploring the features with the outcome variable 'CLASS', it becomes obvious that the data for benign findings has most of the time a much smaller variance.<br>\n",
    "I decided to generate two combination feature: One that combines all cell feautures(UniCellSize,UniCellShape,MarginalAdhesion and SingleEpithelialCellSize) and the other combines all nucleus findings(NucleusFeatureSum, BareNuclei, 'BlandChromatin, 'NormalNucleoli'). <br>\n",
    "Random forest, KNN, logistic regression and support vector machines perform equally well on the dataset, with scores of over 0.95. To figure out with features are most valuable for these decision, I analyse the scores when leaving one feature after the other out. The most important features for those four models have a high overlap. Finally, I try to improve the model performance, by only using the 3 top features of all models, but surprisingly this does not improve the scores.\n",
    "\n",
    "\n",
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653adcec",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = pd.read_csv('breast-cancer-wisconsin.data.csv')\n",
    "columnNames = ['id','Clump Thickness','UniCellSize','UniCellShape','MarginalAdhesion','SingleEpithelialCellSize','BareNuclei',\n",
    "               'BlandChromatin','NormalNucleoli','Mitoses','Class']\n",
    "raw.columns=columnNames\n",
    "raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ddee40",
   "metadata": {},
   "source": [
    "# Inspect Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7aab37",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710565e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed98a7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There should only be numeric data here. so I convert the column to numeric.\n",
    "raw['BareNuclei']= pd.to_numeric(raw['BareNuclei'], errors='coerce')\n",
    "raw.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eca7f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check how many values are NA for the target 'Class'\n",
    "print('Sum of missing datapoints for Class', raw['Class'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a80e274",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many missing values are there per column\n",
    "for c in raw.columns:\n",
    "    print(c)\n",
    "    print(raw[c].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1b85af",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(raw.shape)\n",
    "nona=raw.dropna()\n",
    "print(nona.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7258673",
   "metadata": {},
   "source": [
    "Removed 16 rows with NA in BareNuclei."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc95d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Class into from 2= benign and 4 = malignant , into 0= benign and 1= malignant\n",
    "nona['CLASS']= np.where(nona['Class']==2,0,1)\n",
    "data=nona.drop(['Class','id'], axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3e53bc",
   "metadata": {},
   "source": [
    "# Explore Features \n",
    "## Explore variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f88784",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def LOO_Scores(Name,input_df, y,model):\n",
    "rand_forest_class = ensemble.RandomForestClassifier()\n",
    "RFCScores=LOO_Scores('Random Forest Classifier',inputdata, target, rand_forest_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a474ac",
   "metadata": {},
   "source": [
    "## Most important features KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ddf17dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_w = neighbors.KNeighborsClassifier(n_neighbors=5, weights='distance')\n",
    "KNNcores=LOO_Scores('K-nearest Neighbor',inputdata, target, knn_w)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb346a9",
   "metadata": {},
   "source": [
    "## Most important features Logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6dc1a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = linear_model.LogisticRegression(C=1e9)\n",
    "logScores=LOO_Scores('Logistic Regression',inputdata, target, logreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ca9303",
   "metadata": {},
   "source": [
    "## Most important features SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ddb6841",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC(kernel = 'linear') \n",
    "svmScores=LOO_Scores('Support vector machine',inputdata, target, svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b15f47",
   "metadata": {},
   "source": [
    "## Compare Feature importance between models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ac84c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine Feature Importance from the best performing models into dataframe\n",
    "Scores = {'RFC': RFCScores,'KNN':KNNcores,'LogReg':logScores,'SVM':svmScores}\n",
    "Scoreresults = pd.DataFrame(data=Scores, index=(range(11)))\n",
    "\n",
    "#Scale the values to calcualte mean\n",
    "Scores_sc= StandardScaler().fit_transform(Scoreresults.dropna())\n",
    "Scores_sc_df=pd.DataFrame(data=Scores_sc)\n",
    "Scores_sc_df['mean_Imp']=np.mean(Scores_sc_df,axis=1)\n",
    "Scores_sc_df.index=inputdata.columns\n",
    "Scores_sc_df=Scores_sc_df.sort_values('mean_Imp')\n",
    "Scores_sc_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91eda34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a barplot for the mean importances\n",
    "meanImp=Scores_sc_df['mean_Imp']\n",
    "meanImpt=pd.DataFrame(meanImp).transpose()\n",
    "meanImpt.columns= Scores_sc_df.index\n",
    "meanImpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e558f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(15,8)\n",
    "im = sns.barplot(data=meanImpt, ax=ax, orient='h')\n",
    "#plt.setp(im.get_xticklabels(), rotation=45)\n",
    "im.set_title('Scaled Scores after Feature Loss')\n",
    "im.set_ylabel('Feature left out')\n",
    "im.set_xlabel('Scaled Scores')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47835346",
   "metadata": {},
   "source": [
    "# Rerun models with 3 most important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7589c99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate skinny data\n",
    "dfs=pd.melt(data, id_vars=['CLASS'])\n",
    "dfs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e2f794",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(dfs, col=\"variable\", sharey=True,sharex=False, col_wrap=3, size=5, aspect=.5)\n",
    "g = g.map(sns.boxplot, \"value\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aea9f07",
   "metadata": {},
   "source": [
    "## Explore relation to target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07adfe93",
   "metadata": {},
   "source": [
    "# Generate new features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f74e45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['CellFeatureSUM']=data['UniCellSize'] + data['UniCellShape'] +data['MarginalAdhesion'] +data['SingleEpithelialCellSize']\n",
    "data['NucleusFeatureSum']=data['BareNuclei'] + data['BlandChromatin'] + data['NormalNucleoli'] + data['Mitoses']\n",
    "\n",
    "# Generate skinny data\n",
    "dfs2=pd.melt(data, id_vars=['CLASS'])\n",
    "dfs2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422c561c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comapre each feature by group\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(10,5)\n",
    "\n",
    "ax = sns.violinplot(x=\"variable\", y=\"value\", hue=\"CLASS\", data=dfs2, palette=\"muted\", split=True)\n",
    "plt.setp(ax.get_xticklabels(), rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ddd7c4d",
   "metadata": {},
   "source": [
    "# Classfication\n",
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a84389e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def runRFC_class(input_df, target, no_folds):\n",
    "    start_time=time.time()\n",
    "    rand_forest_class = ensemble.RandomForestClassifier()   \n",
    "    cvs = cross_val_score(rand_forest_class, input_df, target, cv=no_folds)    \n",
    "    print('Time taken: {} seconds.'.format('%.3f' % (time.time() - start_time)))\n",
    "    print('Average accuracy RFC: {}'.format('%.3f' % cvs.mean()))\n",
    "    print('Standard deviation of accuracy: {}'.format('%.3f' % np.std(cvs, ddof=1)))\n",
    "    return(cvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f5e528",
   "metadata": {},
   "outputs": [],
   "source": [
    "def runKNN_class(input_df, target,numNeigh, no_folds):\n",
    "    start_time=time.time()\n",
    "    knn_w = neighbors.KNeighborsClassifier(n_neighbors=numNeigh, weights='distance')\n",
    "    # cross validation\n",
    "    cvs = cross_val_score(knn_w, input_df, target, cv=no_folds)   \n",
    "    print('Time taken: {} seconds.'.format('%.3f' % (time.time() - start_time)))\n",
    "    print('Average accuracy KNN with weights: {}'.format('%.3f' % cvs.mean()))\n",
    "    print('Standard deviation of accuracy: {}'.format('%.3f' % np.std(cvs, ddof=1)))\n",
    "    return(cvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713b2fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic regession\n",
    "# Feature importance link:\n",
    "#https://stackoverflow.com/questions/34052115/how-to-find-the-importance-of-the-features-for-a-logistic-regression-model\n",
    "def runLogit(input_df,target,no_folds):\n",
    "    start_time=time.time()\n",
    "\n",
    "    logreg = linear_model.LogisticRegression(C=1e9)\n",
    "    # Very high C=1e9 in order to barely get any l2 penalties\n",
    "    logreg.fit(input_df, target)\n",
    "    print('Coefficients Log Regression:',logreg.coef_)\n",
    "      \n",
    "    cvs = cross_val_score(logreg, input_df, target, cv=no_folds)\n",
    "\n",
    "    print('Time taken: {} seconds.'.format('%.3f' % (time.time() - start_time)))\n",
    "    print('Average accuracy: {}'.format('%.3f' % cvs.mean()))\n",
    "    print('Standard deviation of accuracy: {}'.format('%.3f' % np.std(cvs, ddof=1)))\n",
    "    return(cvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8925d6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def runLogit_Ridge(input_df,target,lambd,no_folds):\n",
    "    start_time=time.time()\n",
    "\n",
    "    ridge = linear_model.Ridge (alpha = lambd)# C defaults to 1 => l2 penalties => Ridge\n",
    "    ridge.fit(input_df, target)\n",
    "    print('Coefficients Ridge Regression:',ridge.coef_)\n",
    "      \n",
    "    cvs = cross_val_score(ridge, input_df, target, cv=no_folds)\n",
    "\n",
    "    print('Time taken: {} seconds.'.format('%.3f' % (time.time() - start_time)))\n",
    "    print('Average accuracy: {}'.format('%.3f' % cvs.mean()))\n",
    "    print('Standard deviation of accuracy: {}'.format('%.3f' % np.std(cvs, ddof=1)))\n",
    "    return(cvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0435ca45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def runLogit_Lasso(input_df,target,lambd,no_folds):\n",
    "    start_time=time.time()\n",
    "\n",
    "    lasso = linear_model.Lasso(alpha = lambd)# C defaults to 1 => l2 penalties => Ridge\n",
    "    lasso.fit(input_df, target)\n",
    "    print('Coefficients Lasso Regression:',lasso.coef_)\n",
    "      \n",
    "    cvs = cross_val_score(lasso, input_df, target, cv=no_folds)\n",
    "\n",
    "    print('Time taken: {} seconds.'.format('%.3f' % (time.time() - start_time)))\n",
    "    print('Average accuracy: {}'.format('%.3f' % cvs.mean()))\n",
    "    print('Standard deviation of accuracy: {}'.format('%.3f' % np.std(cvs, ddof=1)))\n",
    "    return(cvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d57eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run a support vector as classifier\n",
    "# Instantiate our model and fit the data.\n",
    "\n",
    "def runSVM(input_df,target,no_folds):\n",
    "    start_time=time.time()\n",
    "    svm = SVC(kernel = 'linear')   \n",
    "    cvs=cross_val_score(svm,input_df, target, cv=no_folds)\n",
    "    print('Time taken: {} seconds.'.format('%.3f' % (time.time() - start_time)))\n",
    "    print('Average accuracy: {}'.format('%.3f' % cvs.mean()))\n",
    "    print('Standard deviation of accuracy: {}'.format('%.3f' % np.std(cvs, ddof=1)))\n",
    "    return(cvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7cb39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to run all classifier models at once and plot scores\n",
    "def predictCLASS(input_df, target,numNeigh,lowestalpha, no_folds):\n",
    "\n",
    "    print('Random Forest:')\n",
    "    RFC = runRFC_class(input_df, target, no_folds)\n",
    "    print()\n",
    "    print('K-Nearest Neighbors:')\n",
    "    KNN = runKNN_class(input_df, target,numNeigh, no_folds)\n",
    "    print()\n",
    "    print('Logistic Regression')\n",
    "    Logit=runLogit(input_df,target,no_folds)\n",
    "    print()\n",
    "    print('Suport Vector Maschine')\n",
    "    SVM=runSVM(input_df,target,no_folds)\n",
    "    \n",
    "    lambd=lowestalpha\n",
    "    \n",
    "    print()\n",
    "    print('Ridge Regression')\n",
    "    Ridge_lamda = runLogit_Ridge(input_df, target,lambd, 10)\n",
    "    Ridge_lamdax10 = runLogit_Ridge(input_df, target,lambd*10, 10)\n",
    "    Ridge_lamdax100 = runLogit_Ridge(input_df, target,lambd*100, 10)\n",
    "    Ridge_lamdax1000 = runLogit_Ridge(input_df, target,lambd*1000, 10)\n",
    "    print()\n",
    "    print('Lasso Regression')\n",
    "    Lasso_lamda = runLogit_Lasso(input_df, target,lambd, 10)\n",
    "    Lasso_lamdax10 = runLogit_Lasso(input_df, target,lambd*10, 10)\n",
    "    Lasso_lamdax100 = runLogit_Lasso(input_df, target,lambd*100, 10)\n",
    "    Lasso_lamdax1000 = runLogit_Lasso(input_df, target,lambd*1000, 10)\n",
    "    \n",
    "   \n",
    "    Scores = {'RFC': RFC,'KNN':KNN, 'Logit':Logit,'SVM':SVM, 'Ridge_L':Ridge_lamda,\n",
    "             'Ridge_10xL':Ridge_lamdax10, 'Ridge_100xL':Ridge_lamdax100,\n",
    "             'Ridge_1000xL':Ridge_lamdax1000,'Lasso_L':Lasso_lamda,\n",
    "             'Lasso_10xL':Ridge_lamdax10, 'Lasso_100xL':Lasso_lamdax100,\n",
    "             'Lasso_1000xL':Ridge_lamdax1000}\n",
    "    Scoreresults = pd.DataFrame(data=Scores, index=(range(no_folds)))\n",
    "\n",
    "    # Make a boxplot for comparison\n",
    "    fig, ax = plt.subplots()\n",
    "    fig.set_size_inches(5,5)\n",
    "    im = sns.boxplot(data=Scoreresults[Scoreresults.columns], ax=ax)\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45)\n",
    "    im.set_title('Scores of Classification Models')\n",
    "    im.set_ylabel('Scores')\n",
    "    im.set_xlabel('Models tried')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b169cc",
   "metadata": {},
   "source": [
    "## Prepare data for modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964613df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For modeling scale data\n",
    "print(data.shape)\n",
    "data_sc=StandardScaler().fit_transform(data.dropna())# calcualting z-scores\n",
    "#bringing the data back into shape\n",
    "data_sc = pd.DataFrame(data_sc, columns = data.columns)\n",
    "data_sc= data_sc.reset_index(drop=True)\n",
    "print(data_sc.shape)\n",
    "data_sc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb44ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define data and target for regression\n",
    "target=data_sc['CLASS'].astype('int64') # Random Forest needs integers as input\n",
    "inputdata=data_sc.drop('CLASS', axis=1).astype('int64')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a34c2ef",
   "metadata": {},
   "source": [
    "## Model data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b09d5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def predictCLASS(input_df, target,numNeigh,lowestalpha, no_folds):\n",
    "predictCLASS(inputdata, target, 5, 0.1, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365209cf",
   "metadata": {},
   "source": [
    "# Extract most important features\n",
    "\n",
    "The best performing models are RFC, KNN, Logit and SVM, all with accuracies above 0.9. Let's see which features carry the highest importance for all of those models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceed6a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LOO_Scores(Name,input_df, y,model):\n",
    "    i=0\n",
    "    print('Feature       Accuracy')\n",
    "    FeatImp=[]\n",
    "    for C in input_df.columns:\n",
    "        i=i+1\n",
    "        X = input_df.drop(C, axis=1)\n",
    "        scores = cross_val_score(model, X, target)\n",
    "        FeatImp.append(scores.mean())\n",
    "        print(C,scores.mean())\n",
    "    \n",
    "    # Convert FeatImp into plotable dataframe\n",
    "    FeatImpdf=pd.DataFrame(FeatImp)\n",
    "    FeatImpdft=FeatImpdf.transpose()\n",
    "    FeatImpdft.columns=input_df.columns\n",
    "    \n",
    "    # Sort columns by their mean values\n",
    "    Impdf=FeatImpdft.reindex(FeatImpdft.mean().sort_values().index, axis=1)\n",
    "\n",
    "    # Make a barplot for the importances\n",
    "    print(Name)\n",
    "    fig, ax = plt.subplots()\n",
    "    fig.set_size_inches(15,8)\n",
    "    im = sns.barplot(data=Impdf, ax=ax, orient='h')\n",
    "    #plt.setp(im.get_xticklabels(), rotation=45)\n",
    "    im.set_title('Score, when feature is left out')\n",
    "    im.set_ylabel('Feature left out')\n",
    "    im.set_xlabel('Scores')\n",
    "    ax.set_xlim(min(FeatImp)-0.05,1)\n",
    "    plt.show()\n",
    "        \n",
    "    return(FeatImp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de8a87e",
   "metadata": {},
   "source": [
    "## Most important features RFC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037098f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comapre each feature by group\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(10,5)\n",
    "\n",
    "ax = sns.violinplot(x=\"variable\", y=\"value\", hue=\"CLASS\", data=dfs, palette=\"muted\", split=True)\n",
    "plt.setp(ax.get_xticklabels(), rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42f1708",
   "metadata": {},
   "source": [
    "## Explore relation between features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64def649",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To compare the correlation between features, we need to add some jitter as the data is categorical\n",
    "def rand_jitter(arr):\n",
    "    stdev = .01*(max(arr)-min(arr))\n",
    "    return arr + np.random.randn(len(arr)) * stdev\n",
    "\n",
    "jitterdata= pd.DataFrame()\n",
    "for c in data.columns:\n",
    "    jitterdata[c]=rand_jitter(data[c])\n",
    "print(jitterdata.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82081ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(jitterdata.shape)\n",
    "print(jitterdata.dropna().shape)\n",
    "# Don't run this it takes forever\n",
    "#g = sns.PairGrid(jitterdata.dropna())\n",
    "#g.map_diag(plt.hist)\n",
    "#g.map_offdiag(plt.scatter)\n",
    "#g.add_legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43d0413",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define data and target for regression\n",
    "targetbf=data_sc['CLASS'].astype('int64') # Random Forest needs integers as input\n",
    "inputdatabf=data_sc[['BareNuclei', 'NormalNucleoli','Clump Thickness']].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a1e5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def predictCLASS(input_df, target,numNeigh,lowestalpha, no_folds):\n",
    "predictCLASS(inputdatabf, targetbf, 5, 0.1, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06503b36",
   "metadata": {},
   "source": [
    "# Determine sensitivity and specificity "
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
