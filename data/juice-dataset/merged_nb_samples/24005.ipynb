{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c11c859b",
   "metadata": {},
   "source": [
    "# MACHINE LEARNING FOR FINANCIAL SERVICES \n",
    "\n",
    "Welcome to IBM's Data Science Experience! This exciting tool will help your life a lot easier as a data scientist.  Below is a simple introductory example of how easy for you to load your data and run some simple regression models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b172ef",
   "metadata": {},
   "source": [
    "## Simple Linear Regression & Supervised Learning for Logistic Regression\n",
    "\n",
    "Regression mode is a quite popular statistical modeling technique as it is intuitive to understand its concept by showing relationship between attributes. There are two major types of regression models: linear and logistic regressions.  Linear regression is designed to show linear relationship between independent and dependent variables, while logistic regression is designed for categorical dependent variable. Logistic regression, despite its name, is a linear model for classification rather than regression.  In spite of its simple concept, the relationship should be carefully considered as it does not necessarily show causality, but rather correlation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e38d338",
   "metadata": {},
   "source": [
    "### Scikit Learn\n",
    "\n",
    "from [wikipedia](https://en.wikipedia.org/wiki/Scikit-learn)\n",
    "\n",
    ">Scikit-learn (formerly scikits.learn) is a free software machine learning library for the Python programming language. It features various classification, regression and clustering algorithms including support vector machines, random forests, gradient boosting, k-means and DBSCAN, and is designed to interoperate with the Python numerical and scientific libraries NumPy and SciPy.  It also includes a few rudimentary deep learning packages as well.  I plan to utilize Scikit Learn library for many of my illustrative examples as it is well-documented and well-used in Python community."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feaafe8c",
   "metadata": {},
   "source": [
    "## To load the data:\n",
    "\n",
    "1. Load your local file into your notebook. Click the **Find and Add Data** icon on the notebook action bar. Drop the file into the box or browse to select the file. The file is loaded to your object storage and appears in the Data Assets section of the project. For more information, see <a href=\"https://datascience.ibm.com/docs/content/analyze-data/load-and-access-data.html\" target=\"_blank\" rel=\"noopener noreferrer\">Load and access data</a>.\n",
    "1. click in the next code cell and select **Insert to code > pandas DataFrame** under the file name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e54d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import StringIO\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# @hidden_cell\n",
    "# This function accesses a file in your Object Storage. The definition contains your credentials.\n",
    "# You might want to remove those credentials before you share your notebook.\n",
    "def get_object_storage_file_with_credentials_fcf1c90868844bc1ab7d4fffe6063140(container, filename):\n",
    "    \"\"\"This functions returns a StringIO object containing\n",
    "    the file content from Bluemix Object Storage.\"\"\"\n",
    "\n",
    "    url1 = ''.join(['https://identity.open.softlayer.com', '/v3/auth/tokens'])\n",
    "    data = {'auth': {'identity': {'methods': ['password'],\n",
    "            'password': {'user': {'name': 'member_4a6fd2c26617760f817f90c4ebbaee820653e676','domain': {'id': 'xxxx Your ID xxxx'},\n",
    "            'password': 'xxxx Your Passwordxxx'}}}}}\n",
    "    headers1 = {'Content-Type': 'application/json'}\n",
    "    resp1 = requests.post(url=url1, data=json.dumps(data), headers=headers1)\n",
    "    resp1_body = resp1.json()\n",
    "    for e1 in resp1_body['token']['catalog']:\n",
    "        if(e1['type']=='object-store'):\n",
    "            for e2 in e1['endpoints']:\n",
    "                        if(e2['interface']=='public'and e2['region']=='dallas'):\n",
    "                            url2 = ''.join([e2['url'],'/', container, '/', filename])\n",
    "    s_subject_token = resp1.headers['x-subject-token']\n",
    "    headers2 = {'X-Auth-Token': s_subject_token, 'accept': 'application/json'}\n",
    "    resp2 = requests.get(url=url2, headers=headers2)\n",
    "    return StringIO(resp2.text)\n",
    "\n",
    "df = pd.read_csv(get_object_storage_file_with_credentials_fcf1c90868844bc1ab7d4fffe6063140('MLshowcase', 'CRPMT_SAMPLE.csv'))\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9cbec8",
   "metadata": {},
   "source": [
    "## Attributes in the sample file \n",
    "\n",
    "> this is a hypothetical sample file from a credit card company, in which a few attributes are mocked up for the various aspects of credit/payment business such as risk management, contact strategy and CRM\n",
    "\n",
    "1. ACCT_NO: Account Number\n",
    "1. PROD: Product Tier (1.REG: regular, 2.GOLD: gold and 3.PLAT: platinum cards)\n",
    "1. CURR_BAL: Current balance on the account\n",
    "1. TENURE: # of years since the account opened\n",
    "1. CUST_AGE: Customer's age in years\n",
    "1. PMT_DUE: Due amount on current billing cycle\n",
    "1. NO_DM_CNT: # of Direct Mail Contacts for the last 2 years\n",
    "1. WRITE_OFF_IND: Write-Off Indicator (0: Not written-off, 1: Written-Off)\n",
    "1. FICO_SCR: Fair-Issac Score or FICO (a credit score that is being calculated by US credit bureau such as Experian, Equifax or TransUnion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47fab71e",
   "metadata": {},
   "source": [
    "## SIMPLE LINEAR REGRESSION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0978055",
   "metadata": {},
   "source": [
    "## Are you sending junk mails to your profitable customers?\n",
    "\n",
    "In this section, I'd like to show a very simple linear regression relationship by taking a sample credit card data.  Across different industry sectors where direct customer and prospect marketing is necessary, this became a typical and annoying challenge for many companies and consumers as their marketing contact strategy was specifically concentrated on profitable customer segments.  In this sample credit card data, the higher credit-worthy customers were, the more pieces of direct mails were sent.  This led to \"adverse selection\" (meaning those responded the marketing contacts are usually borderline or marginally valued marketing segments) or to attrition or marketing opt-outs from the highly profitable customers.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc33f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a feature, FICO SCORE, and a response, # OF DIRECT MAIL CONTACTS, vectors\n",
    "\n",
    "X = df.FICO_SCR\n",
    "y = df.NO_DM_CNT\n",
    "\n",
    "\n",
    "# reshape X and y to the single array of the attributes as follows\n",
    "\n",
    "X = X.reshape(-1, 1)\n",
    "y = y.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5e7bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# running a linear regression model\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "linreg = LinearRegression()\n",
    "linreg.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6467df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the intercept and coefficients\n",
    "print(linreg.intercept_)\n",
    "print(linreg.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66aa5864",
   "metadata": {},
   "source": [
    "## Visualizing Linear Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49d13d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Matplotlib (scientific plotting library)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# allow plots to appear within the notebook\n",
    "%matplotlib inline\n",
    "\n",
    "# Plot true values versus the predictions\n",
    "plt.scatter(df.FICO_SCR, df.NO_DM_CNT, color=\"b\")\n",
    "plt.xlabel(\"FICO SCORE\")\n",
    "plt.ylabel(\"# of Direct Mail contacts\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d4892a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick visualization of data relationships using seaborn visualization API\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "# Using seabron to create a linear fit\n",
    "sns.lmplot('FICO_SCR','NO_DM_CNT', data = df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7fd158",
   "metadata": {},
   "source": [
    "## CREDIT DEFAULT PREDICTION \n",
    "\n",
    "### LOGSTIC REGRESSION MODEL SETUP, TRAINING & ACCURACY CHECK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f618accd",
   "metadata": {},
   "source": [
    "#### Below is an illustrative example of finding out how write-off response may be correlated with predictor (feature) variables by training a multi-variate logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a3cdb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select a few numerical variables (predictors)\n",
    "\n",
    "feature_cols = [          \n",
    "    'CURR_BAL',                                               \n",
    "    'TENURE',                       \n",
    "    'CUST_INC',                      \n",
    "    'CUST_AGE',                                \n",
    "    'PMT_DUE',                                               \n",
    "    'NO_DM_CNT',               \n",
    "    'FICO_SCR',\n",
    "    'PROD_NO'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dcbae68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a feature matrix 'X' \n",
    "\n",
    "X = df[feature_cols]\n",
    "X.shape\n",
    "\n",
    "#print (type(X))\n",
    "# X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95248f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a response vector series 'y' \n",
    "y = df.WRITE_OFF_IND\n",
    "y.shape\n",
    "#y.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ebfa7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you need to upgrade scikit learn\n",
    "#!pip install --upgrade scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8355ff75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting in-sample training and test datasets\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ffc63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default split is 75% for training and 25% for testing; but chose above test size (test_size)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d990f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import and instantiate a logistic regression model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "# train the model\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed11037",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make class predictions for X_test\n",
    "# as there are a large number of zero values, the predictions are also skewed into zeros as well\n",
    "\n",
    "y_pred_class = logreg.predict(X_test)\n",
    "y_pred_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6305ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate predicted probabilities for X_test (well calibrated)\n",
    "y_pred_prob = logreg.predict_proba(X_test)[:, 1]\n",
    "y_pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82a63da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics as metrics\n",
    "\n",
    "# calculate accuracy\n",
    "print 'Accuracy score is: {}'.format(metrics.accuracy_score(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffddb4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate AUC\n",
    "print 'AUC is: {}'.format(metrics.roc_auc_score(y_test, y_pred_prob))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb342bc",
   "metadata": {},
   "source": [
    "#### ROC curve allows to see how sensitivity and specificity are affected by various thresholds, and AUC is the percentage of the ROC plot that is underneath the curve\n",
    "\n",
    "- AUC is useful as a single number summary of classifier performance.\n",
    "- If you randomly chose one positive and one negative observation, AUC represents the likelihood that your classifier will assign a higher predicted probability to the positive observation.\n",
    "- AUC is useful even when there is high class imbalance (unlike classification accuracy)."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
