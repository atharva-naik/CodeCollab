{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7edc7581",
   "metadata": {},
   "source": [
    "<h1>Convolutional Neural Network with Small Images</h1> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7752ac23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a99743",
   "metadata": {},
   "source": [
    "Define the function <code>plot_channels</code> to plot out the kernel parameters of  each channel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61dfa623",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function for plotting the channels\n",
    "\n",
    "def plot_channels(W):\n",
    "    n_out = W.shape[0]\n",
    "    n_in = W.shape[1]\n",
    "    w_min = W.min().item()\n",
    "    w_max = W.max().item()\n",
    "    fig, axes = plt.subplots(n_out, n_in)\n",
    "    fig.subplots_adjust(hspace=0.1)\n",
    "    out_index = 0\n",
    "    in_index = 0\n",
    "    \n",
    "    #plot outputs as rows inputs as columns \n",
    "    for ax in axes.flat:\n",
    "        if in_index > n_in-1:\n",
    "            out_index = out_index + 1\n",
    "            in_index = 0\n",
    "        ax.imshow(W[out_index, in_index, :, :], vmin=w_min, vmax=w_max, cmap='seismic')\n",
    "        ax.set_yticklabels([])\n",
    "        ax.set_xticklabels([])\n",
    "        in_index = in_index + 1\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d201381b",
   "metadata": {},
   "source": [
    "Define the function <code>plot_parameters</code> to plot out the kernel parameters of each channel with Multiple outputs . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b9c36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function for plotting the parameters\n",
    "\n",
    "def plot_parameters(W, number_rows=1, name=\"\", i=0):\n",
    "    W = W.data[:, i, :, :]\n",
    "    n_filters = W.shape[0]\n",
    "    w_min = W.min().item()\n",
    "    w_max = W.max().item()\n",
    "    fig, axes = plt.subplots(number_rows, n_filters // number_rows)\n",
    "    fig.subplots_adjust(hspace=0.4)\n",
    "\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        if i < n_filters:\n",
    "            # Set the label for the sub-plot.\n",
    "            ax.set_xlabel(\"kernel:{0}\".format(i + 1))\n",
    "\n",
    "            # Plot the image.\n",
    "            ax.imshow(W[i, :], vmin=w_min, vmax=w_max, cmap='seismic')\n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "    plt.suptitle(name, fontsize=10)    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd0d2eac",
   "metadata": {},
   "source": [
    "Define the function <code>plot_activation</code> to plot out the activations of the Convolutional layers  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e177285e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function for plotting the activations\n",
    "\n",
    "def plot_activations(A, number_rows=1, name=\"\", i=0):\n",
    "    A = A[0, :, :, :].detach().numpy()\n",
    "    n_activations = A.shape[0]\n",
    "    A_min = A.min().item()\n",
    "    A_max = A.max().item()\n",
    "    fig, axes = plt.subplots(number_rows, n_activations // number_rows)\n",
    "    fig.subplots_adjust(hspace = 0.4)\n",
    "\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        if i < n_activations:\n",
    "            # Set the label for the sub-plot.\n",
    "            ax.set_xlabel(\"activation:{0}\".format(i + 1))\n",
    "\n",
    "            # Plot the image.\n",
    "            ax.imshow(A[i, :], vmin=A_min, vmax=A_max, cmap='seismic')\n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb7c4372",
   "metadata": {},
   "source": [
    "Define the function <code>show_data</code> to plot out data samples as images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f186ad1e",
   "metadata": {},
   "source": [
    "Define the loss function, the optimizer and the dataset loader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8b9811",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "learning_rate = 0.1\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=100)\n",
    "validation_loader = torch.utils.data.DataLoader(dataset=validation_dataset, batch_size=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34e1ee6",
   "metadata": {},
   "source": [
    "Train the model and determine validation accuracy technically test accuracy **(This may take a long time)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfdac279",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "n_epochs=3\n",
    "loss_list=[]\n",
    "accuracy_list=[]\n",
    "N_test=len(validation_dataset)\n",
    "\n",
    "def train_model(n_epochs):\n",
    "    for epoch in range(n_epochs):\n",
    "        for x, y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            z = model(x)\n",
    "            loss = criterion(z, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        correct=0\n",
    "        #perform a prediction on the validation  data  \n",
    "        for x_test, y_test in validation_loader:\n",
    "            z = model(x_test)\n",
    "            _, yhat = torch.max(z.data, 1)\n",
    "            correct += (yhat == y_test).sum().item()\n",
    "        accuracy = float(correct) / N_test\n",
    "        accuracy_list.append(accuracy)\n",
    "        loss_list.append(loss.data)\n",
    "train_model(n_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51a8968",
   "metadata": {},
   "source": [
    "<h2 id=\"Result\">Analyze Results</h2> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0210a30c",
   "metadata": {},
   "source": [
    "Plot the loss and accuracy on the validation data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c968bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the loss and accuracy\n",
    "\n",
    "fig, ax1 = plt.subplots()\n",
    "color = 'tab:red'\n",
    "ax1.plot(loss_list, color=color)\n",
    "ax1.set_xlabel('epoch', color=color)\n",
    "ax1.set_ylabel('total loss', color=color)\n",
    "ax1.tick_params(axis='y', color=color)\n",
    "    \n",
    "ax2 = ax1.twinx()  \n",
    "color = 'tab:blue'\n",
    "ax2.set_ylabel('accuracy', color=color)  \n",
    "ax2.plot( accuracy_list, color=color)\n",
    "ax2.tick_params(axis='y', color=color)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ee00e2",
   "metadata": {},
   "source": [
    "View the results of the parameters for the Convolutional layers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1e30ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the channels\n",
    "\n",
    "plot_channels(model.state_dict()['cnn1.weight'])\n",
    "plot_channels(model.state_dict()['cnn2.weight'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae803e5",
   "metadata": {},
   "source": [
    "Consider the following sample "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e293c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the second image\n",
    "\n",
    "show_data(train_dataset[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad16e3d",
   "metadata": {},
   "source": [
    "Determine the activations "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc0c7f3",
   "metadata": {},
   "source": [
    "The image below is the result of the activation map after the second output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3928d13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the outputs after the second CNN\n",
    "plot_activations(out[2], number_rows=32 // 4, name=\"Output after the 2nd CNN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2f5fc6",
   "metadata": {},
   "source": [
    "The image below is the result of the activation map after applying the second relu  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02683518",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the outputs after the second Relu\n",
    "plot_activations(out[3], number_rows=4, name=\"Output after the 2nd Relu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc18b7d8",
   "metadata": {},
   "source": [
    "We can  see the result for the third sample "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07d56ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the third image\n",
    "show_data(train_dataset[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75a7cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the CNN activations class to see the steps\n",
    "out = model.activations(train_dataset[2][0].view(1, 1, IMAGE_SIZE, IMAGE_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a000d37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the outputs after the first CNN\n",
    "plot_activations(out[0], number_rows=4, name=\"Output after the 1st CNN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef8ecb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the outputs after the first Relu\n",
    "plot_activations(out[1], number_rows=4, name=\"Output after the 1st Relu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e1684d",
   "metadata": {},
   "source": [
    "Plot the first five mis-classified samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c531aa21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_data(data_sample):\n",
    "    plt.imshow(data_sample[0].numpy().reshape(IMAGE_SIZE, IMAGE_SIZE), cmap='gray')\n",
    "    plt.title('y = '+ str(data_sample[1].item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39012a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 16\n",
    "\n",
    "composed = transforms.Compose([transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)), transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d68da2c",
   "metadata": {},
   "source": [
    "Load the training dataset by setting the parameters <code>train </code> to <code>True</code>. We use the transform defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8dabe59",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dsets.MNIST(root='./data', train=True, download=True, transform=composed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd115cd",
   "metadata": {},
   "source": [
    "Load the testing dataset by setting the parameters train  <code>False</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002dd3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the validating \n",
    "validation_dataset = dsets.MNIST(root='./data', train=False, download=True, transform=composed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c69f33b",
   "metadata": {},
   "source": [
    "We can see the data type is long."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd01d525",
   "metadata": {},
   "source": [
    "Print out the fourth label "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767a8eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The label for the fourth data element\n",
    "train_dataset[3][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030d7a5c",
   "metadata": {},
   "source": [
    "Plot the fourth sample "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76d9027",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The image for the fourth data element\n",
    "show_data(train_dataset[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b50848",
   "metadata": {},
   "source": [
    "The fourth sample is a \"1\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42797b1",
   "metadata": {},
   "source": [
    "<h2 id=\"CNN\">Build a Convolutional Neural Network Class</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa02313",
   "metadata": {},
   "source": [
    "Build a Convolutional Network class with two Convolutional layers and one fully connected layer. Pre-determine the size of the final output matrix. The parameters in the constructor are the number of output channels for the first and second layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f226c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the convolutional Neural Network Class\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    \n",
    "    # Contructor\n",
    "    def __init__(self, out_1=16, out_2=32):\n",
    "        super(CNN, self).__init__()\n",
    "        self.cnn1 = nn.Conv2d(in_channels=1, out_channels=out_1, kernel_size=5, padding=2)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=2)\n",
    "        self.cnn2 = nn.Conv2d(in_channels=out_1, out_channels=out_2, kernel_size=5, stride=1, padding=2)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=2)\n",
    "        self.fc1 = nn.Linear(out_2 * 4 * 4, 10)\n",
    "    \n",
    "    # Prediction\n",
    "    def forward(self, x):\n",
    "        out = self.cnn1(x)\n",
    "        out = self.relu1(out)\n",
    "        out = self.maxpool1(out)\n",
    "        out = self.cnn2(out)\n",
    "        out = self.relu2(out)\n",
    "        out = self.maxpool2(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc1(out)\n",
    "        return out\n",
    "    \n",
    "    # Outputs in each steps\n",
    "    def activations(self, x):\n",
    "        #outputs activation this is not necessary\n",
    "        z1 = self.cnn1(x)\n",
    "        a1 = self.relu1(z1)\n",
    "        out = self.maxpool1(a1)\n",
    "        \n",
    "        z2 = self.cnn2(out)\n",
    "        a2 = self.relu2(z2)\n",
    "        out = self.maxpool2(a2)\n",
    "        out = out.view(out.size(0),-1)\n",
    "        return z1, a1, z2, a2, out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481d5119",
   "metadata": {},
   "source": [
    "<h2 id=\"Train\">Define the Convolutional Neural Network Classifier, Criterion function, Optimizer and Train the Model</h2> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f4db5c",
   "metadata": {},
   "source": [
    "There are 16 output channels for the first layer, and 32 output channels for the second layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73468c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model object using CNN class\n",
    "model = CNN(out_1=16, out_2=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a00923",
   "metadata": {},
   "source": [
    "Plot the model parameters for the kernels before training the kernels. The kernels are initialized randomly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333f0019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the parameters\n",
    "plot_parameters(model.state_dict()['cnn1.weight'], number_rows=4, name=\"1st layer kernels before training \")\n",
    "plot_parameters(model.state_dict()['cnn2.weight'], number_rows=4, name='2nd layer kernels before training' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dae2eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the CNN activations class to see the steps\n",
    "out = model.activations(train_dataset[1][0].view(1, 1, IMAGE_SIZE, IMAGE_SIZE))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419124c1",
   "metadata": {},
   "source": [
    "Plot out the first set of activations "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb52ff85",
   "metadata": {},
   "source": [
    "The image below is the result after applying the relu activation function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9985cd5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the data type for each element in dataset\n",
    "train_dataset[0][1].type()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c37da3",
   "metadata": {},
   "source": [
    "Each element in the rectangular tensor corresponds to a number representing a pixel intensity as demonstrated by the following image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b650ceb",
   "metadata": {},
   "source": [
    "<img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0110EN/notebook_images%20/chapter%206/6.2.1imagenet.png\" width=\"550\" alt=\"MNIST data image\">"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
