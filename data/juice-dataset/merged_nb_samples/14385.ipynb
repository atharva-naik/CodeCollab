{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70e10873",
   "metadata": {},
   "source": [
    "# Homework 3: Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c08df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import folium\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import requests\n",
    "import re\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c88372",
   "metadata": {},
   "source": [
    "## Import data and obtain canton information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772df81f",
   "metadata": {},
   "source": [
    "We first find the canton ID (abbreviation) in the topo.json file provided and store it in canton_id array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca86859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the canton id in the json file\n",
    "with open('ch-cantons.topojson.json') as data_file:    \n",
    "    data_json = json.load(data_file)\n",
    "canton_id=[]\n",
    "for i in range(len(data_json[\"objects\"]['cantons']['geometries'])):\n",
    "    canton_id.append(data_json[\"objects\"]['cantons']['geometries'][i]['id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311ff465",
   "metadata": {},
   "source": [
    "We then import grant data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7d9d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute how much data we identified\n",
    "round(len(data_sorted)/len(data),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd986f06",
   "metadata": {},
   "source": [
    "This process allows us to know the canton location of 94% of the exploitable data, which is a lot higher that the 66% obtained without the above steps. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2f5915",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sorted.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f754fc22",
   "metadata": {},
   "source": [
    "## From institutions to cantons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee47878",
   "metadata": {},
   "source": [
    "In this section we study the Institution field more in depth to assign a canton abbreviation to each row.\n",
    "For this we will build a dictionary (insti2canton) that gives the correspondence between each institution and its canton. \n",
    "\n",
    "The process is very similar as for univeristies except that we do not extract the abbreviation (as there is no '-' symbol) and we do not check if words are in a list of words to exclude (as there are many, many different words that we should exclude). Instead, we compare if the word is a major swiss city, and if it is we search with geonames.\n",
    "\n",
    "However, due to the immense diversity of university (13 000 unique names), we run into geonames limitations and therefore didn't apply this method to the final tables. However this method could easily be implemented in the future if this issue is solved. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4b63ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of all institutions\n",
    "institutions = list(set(data_unsorted['Institution'].values))\n",
    "#institutions = institutions[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e50a3c",
   "metadata": {},
   "source": [
    "Here we download a list of swiss cities and only keep the ones having more than 20 000 people, as they might have a university."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5d1f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of major swiss cities and university abbreviations\n",
    "swiss_cities=pd.read_excel('swiss_cities.xlsx')\n",
    "swiss_cities = swiss_cities.drop(swiss_cities.columns[[0,2]], axis=1)\n",
    "cities = list(swiss_cities[swiss_cities['Population']>20000]['City'].values)\n",
    "cities[2] = 'Biel'\n",
    "cities.extend(['Bienne','Gallen','Yverdon','Neuchâtel','Zürich'])\n",
    "#cities.extend([HERE LIST OF UNIVERSITY CODES])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac8ee39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractInstiCity(instiName):\n",
    "    \"Function to extract swiss city from institution name\"\n",
    "    locs = [m.start() for m in re.finditer(' ', instiName)] # find blank spaces in the name\n",
    "    word = []\n",
    "    if len(locs)>0: # if there are several words in the institution name\n",
    "        if instiName[:locs[0]] in cities: # if word corresponds to a major swiss city or institution\n",
    "            word = [instiName[:locs[0]]]    \n",
    "        for i,loc in enumerate(locs): # extract all words in name\n",
    "            if i == len(locs)-1:\n",
    "                new_word = instiName[locs[i]+1:] \n",
    "            else: \n",
    "                new_word = instiName[locs[i]+1:locs[i+1]] \n",
    "            if new_word in cities: # if word is major swiss city add to our list\n",
    "                word.append(new_word)\n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a68538",
   "metadata": {},
   "outputs": [],
   "source": [
    "insti2canton = dict() # dictionary giving the relationship between the institution and its canton\n",
    "\n",
    "for insti in institutions[:20]:\n",
    "    \n",
    "    # Try extracting info from intitution whole name\n",
    "    to_search = insti\n",
    "    r = requests.get('http://api.geonames.org/searchJSON?name=%22'+ to_search + '%22&country=CH&maxRows=500&username=mericervi')\n",
    "    soup = BeautifulSoup(r.content) \n",
    "    canton = findCanton(soup)\n",
    "        \n",
    "    if not canton: # if we still haven't found the canton\n",
    "        # Try look at specific words in institution name\n",
    "        to_search = extractInstiCity(insti)\n",
    "        for word in to_search:\n",
    "            r = requests.get('http://api.geonames.org/searchJSON?name=%22'+word + '%22&country=CH&maxRows=500&username=mericervi')\n",
    "            soup = BeautifulSoup(r.content)\n",
    "            canton = findCanton(soup)\n",
    "            if not canton == []:\n",
    "                break\n",
    "    if canton =='00':\n",
    "        canton = []\n",
    "    insti2canton[insti] = canton\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d90e8cb",
   "metadata": {},
   "source": [
    "## Build interactive maps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4262368",
   "metadata": {},
   "source": [
    "In this section we build the final table containing canton abbreviation and total grant amount, and then plot it in an interactive map with folium."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0711168",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sorted=pd.read_pickle('data_sorted')\n",
    "#sum all the data per canton\n",
    "data_grouped=pd.DataFrame([])\n",
    "money=[]\n",
    "for i in canton_id:\n",
    "    money.append(np.sum(data_sorted['Approved Amount'][data_sorted.Canton==i]))\n",
    "data_grouped['Canton']=canton_id\n",
    "data_grouped['Money']=money\n",
    "data_grouped.set_index('Canton')\n",
    "data_grouped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da9cd16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#divide by 10^6 for visualisation (the data will be in million CHF) and keep only 2 decimals\n",
    "data_toplot=data_grouped\n",
    "data_toplot['Money']=np.round(data_toplot['Money']/10**6,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7bb8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the topojson map\n",
    "topo_path = r'ch-cantons.topojson.json'\n",
    "swiss_map = folium.Map(location=[46.8, 8.4], zoom_start=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7260739",
   "metadata": {},
   "outputs": [],
   "source": [
    "swiss_map.choropleth(geo_path=topo_path, \n",
    "                     data=data_toplot,\n",
    "                     columns=['Canton', 'Money'],\n",
    "                     threshold_scale=[0,100,1000,2000,3000,4000],\n",
    "                     key_on='feature.id',\n",
    "                     topojson='objects.cantons',\n",
    "                     fill_color='BuPu',\n",
    "                     legend_name = 'Grant money im million CHF',\n",
    "                     fill_opacity=0.7,\n",
    "                     line_opacity=0.2,\n",
    "                     reset=True\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c94cf8",
   "metadata": {},
   "source": [
    "To visualize the map open it from the html file provided in the repository.\n",
    "\n",
    "Notes: \n",
    "    <li> the legend values are given in millions\n",
    "    <li> the legend was selected manually to highlight differences between cantons (as some have way higher grant sums than others)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3341adc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the grant data\n",
    "data=pd.read_csv('P3_GrantExport.csv',sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8fd2095",
   "metadata": {},
   "source": [
    "We then clean the data. We create a data frame and then drop the following data:\n",
    "    <li> unnecessary columns (not relating to the university, institution or grant) \n",
    "    <li> rows where university field is empty or 'NA' (data documentation specifies that, in that case, the research has NOT been conducted in a swiss institute)\n",
    "    <li> rows where we have no grant amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a762b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop every column except university institution and approved amount\n",
    "data=data.drop(data.columns[[0,1,2,3,4,5,8,9,10,11,12,14]], axis=1)\n",
    "\n",
    "#drop the data for which we dont have university because the description of the data\n",
    "#mentions that if this field is empty the research is notconducted in a swiss institute\n",
    "double_NaN_idx = data[pd.isnull(data['University'])].index.values \n",
    "data = data.drop(data.index[[double_NaN_idx]],axis=0)\n",
    "data = data.reset_index('level_0')\n",
    "data = data.drop('index', axis=1)\n",
    "\n",
    "#drop the data for which we have no amount\n",
    "no_amount_idx = data[np.equal(data['Approved Amount'], 'data not included in P3')].index.values\n",
    "data = data.drop(data.index[[no_amount_idx]],axis=0)\n",
    "data = data.reset_index('level_0')\n",
    "data = data.drop('index', axis=1)\n",
    "\n",
    "# transform the approved amount in float\n",
    "data['Approved Amount']=data['Approved Amount'].astype(float)\n",
    "\n",
    "#we also have to remove the data that endswith or NA (the line university doesn't contain information)\n",
    "to_dropNA=data[data.University.str.endswith('NA')==True].index.values\n",
    "#create the dataframe with the grants for which we have the university info\n",
    "data=data.drop(data.index[[to_dropNA]],axis=0)\n",
    "# reset the index\n",
    "data.reset_index(inplace=True)\n",
    "#remove the old index column\n",
    "data=data.drop(data.columns[0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ca6e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f2c967",
   "metadata": {},
   "source": [
    "## Get the easily accessible cantons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76bfd0ae",
   "metadata": {},
   "source": [
    "In a first place we obtain a data frame of sorted data for which it is straightforward to obtain the canton.\n",
    "This will allow us to process less data in operations that are more time-consuming. The steps involved in this part are:\n",
    "    <li> for each row extract the abbreviations to the right of the '-' symbol in the university field\n",
    "    <li> manually replace two abbreviations to cantons that we know (LA --> VD and HEPFR --> FR) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c39c06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add a column for the cantons\n",
    "data[\"Canton\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55a7fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# /!\\ WARNING: DO NOT EXECUTE (time consuming step), if you really want to write if True:\n",
    "# Extract the letters after the '-' \n",
    "if False:\n",
    "    tiret=data.University.str.find('-').astype(int)\n",
    "    canton=[]\n",
    "    for i in range(len(data_uni)):\n",
    "        # keep everything that is after that\n",
    "        canton=data.University[[i]].str[tiret[i]+2:]\n",
    "        data.Canton[[i]]=canton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62cc6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save these data so we don't have to run the cleaning part again\n",
    "#data.to_pickle('data_incomplete_cantons')\n",
    "data=pd.read_pickle('data_incomplete_cantons')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2372e384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually replace a couple that were not identifiable with the identify university code\n",
    "data.Canton[data.Canton=='LA']='VD'\n",
    "data.Canton[data.Canton=='HEPFR']='FR'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244fd304",
   "metadata": {},
   "source": [
    "We then sort our data. Data for which a real canton has been identified (it is in canton_id) is moved to data_sorted. Data for which no real canton has been identitifed yet will be moved to data_unsorted for further processing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5356a570",
   "metadata": {},
   "source": [
    "This process allows us to know the canton location of 66% of the exploitable data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d6c980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the bad cantons from the unsorted table\n",
    "data_unsorted[\"Canton\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66cb3766",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sorted.to_pickle('data_sorted')\n",
    "data_unsorted.to_pickle('data_unsorted')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afadf7dc",
   "metadata": {},
   "source": [
    "## From university name to canton"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a108e54",
   "metadata": {},
   "source": [
    "In this section we study the University field more in depth to assign a canton abbreviation to each row.\n",
    "For this we will build a dictionary (uni2canton) that gives the correspondence between each university and its canton. \n",
    "\n",
    "In a first place we get the list of the unique different universities (array without repeating entries) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0010ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of all universities\n",
    "universities = list(set(data_unsorted['University'].values))\n",
    "#universities = universities[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b9f158",
   "metadata": {},
   "source": [
    "Then we build some functions that will be handy to extract useful information from the university field:\n",
    "    <li> extractUniName: will extract the whole name of the university\n",
    "    <li> extractUniID: will extract the abbreviation of the university (located to the right of the '-')\n",
    "    <li> extractUniCity: will try to find the city of the university by looking at the different words in the name\n",
    "    <li> findCanton: will do a request on geonames to find the canton of the found city or university"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5f15d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractUniName(university):\n",
    "    \"Extract name of university from table\"\n",
    "    loc = university.find('-')\n",
    "    uni = str(university[:loc -1])\n",
    "    return uni\n",
    "\n",
    "def extractUniID(university):\n",
    "    \"Extract university abbreviation\"\n",
    "    loc = university.find('-')\n",
    "    uni = str(university[loc + 2:])\n",
    "    return uni\n",
    "\n",
    "# List of terms that are generic and shouldn't be analyzed \n",
    "excluded = ['Université','University','Hochschule','Universität','école','Haute','Suisse','au','St.','du','Switzerland',\n",
    "            'Fachhochschule','Università','Institute','de','von','of','Swiss','für','di','et','for','und','sur','della',\n",
    "            'Schweiz.','Schweizer','Schweiz','Department','Dept.','School','and','Laboratory','Departement','Haute','pédagogique','canton']\n",
    "\n",
    "def extractUniCity(university):\n",
    "    \"Find city where the university is located\"\n",
    "    locT = university.find('-')\n",
    "    uniName = str(university[:locT -1]) # get university name\n",
    "    locs = [m.start() for m in re.finditer(' ', uniName)] # get location of white spaces within university name\n",
    "    word = []\n",
    "    if len(locs)>0: # if there are several words in the university name (several blank spaces)\n",
    "        word = [] # define the first word in the name\n",
    "        if not uniName[:locs[0]] in excluded:\n",
    "            word=[uniName[:locs[0]]]\n",
    "        for i,loc in enumerate(locs):\n",
    "            if i == len(locs)-1:\n",
    "                new_word = uniName[locs[i]+1:locT - 1] # the last word raises an exception, treat separately\n",
    "            else: \n",
    "                new_word = uniName[locs[i]+1:locs[i+1]] # extract next words \n",
    "            if not new_word in excluded: # if the word is not to be excluded append to our list\n",
    "                word.append(new_word) \n",
    "    return word\n",
    "    \n",
    "def findCanton(soup):\n",
    "    \"Function to extract the canton from Beautiful Soup Outputs\"\n",
    "    geonamesInfo = soup.find_all('p')[0].text\n",
    "    geonamesDict =json.loads(str(geonamesInfo))\n",
    "    canton = []\n",
    "    if not geonamesDict['geonames']: # if there are no search results\n",
    "        canton = []\n",
    "    elif 'adminCode1' in geonamesDict['geonames'][0]:\n",
    "        canton = geonamesDict['geonames'][0]['adminCode1'] # extract canton ID that is encoded in adminCode1 field\n",
    "    return canton   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509c8bdf",
   "metadata": {},
   "source": [
    "The algorithm consists on a hierarchical search where, if the search on geonames with a given attribute doesn't give any result, another deeper search will be performed. This will improve algorithm performance. The order of the different attribute searches is:\n",
    "    <li> search by university abbreviation\n",
    "    <li> search by university (whole) name\n",
    "    <li> search using the words within the university names. Here some generic words such as \"University\" or linkwords will be excluded. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ae5a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "uni2canton = dict() # dictionary giving the relationship between the university and its canton\n",
    "\n",
    "for uni in universities: # try for each university\n",
    "    \n",
    "    # Try extracting info from university abbreviation (e.g. EPFL)\n",
    "    to_search = extractUniID(uni)\n",
    "    r = requests.get('http://api.geonames.org/searchJSON?name=%22'+ to_search + '%22&country=CH&maxRows=500&username=mariacervera')\n",
    "    soup = BeautifulSoup(r.content,\"lxml\") \n",
    "    canton = findCanton(soup)\n",
    "    \n",
    "    if not canton:  # if canton hasn't been found for that uni\n",
    "        # Try to search using university (whole) name\n",
    "        to_search = extractUniName(uni)  \n",
    "        r = requests.get('http://api.geonames.org/searchJSON?name=%22'+ to_search + '%22&country=CH&maxRows=500&username=mariacervera')\n",
    "        soup = BeautifulSoup(r.content,\"lxml\") \n",
    "        canton = findCanton(soup)\n",
    "        \n",
    "        if not canton: # if we still haven't found the canton\n",
    "            # Try to look at specific words in university name\n",
    "            to_search = extractUniCity(uni)\n",
    "            for word in to_search:\n",
    "                r = requests.get('http://api.geonames.org/searchJSON?name=%22'+word + '%22&country=CH&maxRows=500&username=mariacervera')\n",
    "                soup = BeautifulSoup(r.content,\"lxml\") \n",
    "                canton = findCanton(soup)\n",
    "                if not canton == []: # if we found the canton with one word already, don't look at next words\n",
    "                    break\n",
    "    if canton =='00': # code given for the whole of switzerland in geonames\n",
    "        canton = []\n",
    "    uni2canton[uni] = canton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766fc327",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove the NPO from the dictionnary because they automatically go to bern and we want to treat them separaterly\n",
    "uni2canton.pop('NPO (Biblioth., Museen, Verwalt.) - NPO', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8634487",
   "metadata": {},
   "source": [
    "Once we have our dictionary uni2canton, we will check the name of the university of our unsorted data and write its found canton in the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c8c679",
   "metadata": {},
   "outputs": [],
   "source": [
    "#write the cantons of the new universities we just identified\n",
    "for i in range(len(data_unsorted)):\n",
    "    if str(data_unsorted.University[[i]].values[0]) in uni2canton:\n",
    "        data_unsorted.Canton[i]=uni2canton[str(data_unsorted.University[[i]].values[0])]     \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e467a08",
   "metadata": {},
   "source": [
    "Finally, we will have in our dataframe rows that have empty or non-valid cantons (such as [] or ''), so again, we will put these in another frame called data_unsorted2 for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11648aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# /!\\ WARNING: DO NOT EXECUTE (time consuming step), if you really want to write if True:\n",
    "#separate the good and bad data\n",
    "#reindex the unsorted_data\n",
    "if False:\n",
    "    data_unsorted2=pd.DataFrame()\n",
    "    for i in range(len(data_unsorted)):\n",
    "        if str(data_unsorted.Canton[[i]].values[0]) in canton_id:    \n",
    "            data_sorted=pd.concat((data_sorted,data_unsorted.iloc[[i]]))\n",
    "        else:\n",
    "            data_unsorted2=pd.concat((data_unsorted2,data_unsorted.iloc[[i]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bcd2686",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_unsorted2.to_pickle('data_unsorted2')\n",
    "data_sorted.to_pickle('data_sorted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2ed084",
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the data that already have a good canton and keep it aside\n",
    "data_sorted=pd.DataFrame()\n",
    "data_unsorted=pd.DataFrame()\n",
    "for i in range(len(data)):\n",
    "    if data.Canton[[i]].values[0] in canton_id:       \n",
    "        data_sorted=pd.concat((data_sorted,data.iloc[[i]]))\n",
    "    else:\n",
    "        data_unsorted=pd.concat((data_unsorted,data.iloc[[i]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201e59fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reindex everything\n",
    "data_unsorted = data_unsorted.reset_index('level_0')\n",
    "data_unsorted = data_unsorted.drop('index', axis=1)\n",
    "\n",
    "data_sorted = data_sorted.reset_index('level_0')\n",
    "data_sorted = data_sorted.drop('index', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc39e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute how much data we already have\n",
    "len(data_sorted)/len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0acf8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "swiss_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5d12cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "swiss_map.create_map(path='map.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764eaf4e",
   "metadata": {},
   "source": [
    "## Personal bonus: Add markers for each canton"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966b508d",
   "metadata": {},
   "source": [
    "In this extra part, we decided to add interactive markers for each canton to access its code and total grant amount, in order to access information more easily."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
