{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5e4667d",
   "metadata": {},
   "source": [
    "Real World Tutorial 1: Translating Poetry\n",
    "=========================================\n",
    "\n",
    "First example\n",
    "-------------\n",
    "\n",
    "We build workflows by calling functions. The simplest example of this\n",
    "is the \"diamond workflow\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d511686",
   "metadata": {},
   "outputs": [],
   "source": [
    "from noodles import run_single\n",
    "from noodles.tutorial import (add, sub, mul)\n",
    "\n",
    "u = add(5, 4)\n",
    "v = sub(u, 3)\n",
    "w = sub(u, 2)\n",
    "x = mul(v, w)\n",
    "\n",
    "answer = run_single(x)\n",
    "\n",
    "print(\"The answer is {0}.\".format(answer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04202cd4",
   "metadata": {},
   "source": [
    "That looks like any other Python code! But this example is a bit silly.\n",
    "How do we leverage Noodles to earn an honest living? Here's a slightly less\n",
    "silly example (but only just!). We will build a small translation engine\n",
    "that translates sentences by submitting each word to an online dictionary\n",
    "over a Rest API. To do this we make loops (\"For thou shalt make loops of \n",
    "blue\"). First we build the program as you would do in Python, then we\n",
    "sprinkle some Noodles magic and make it work parallel! Furthermore, we'll\n",
    "see how to:\n",
    "\n",
    "* make more loops\n",
    "* cache results for reuse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e71c35",
   "metadata": {},
   "source": [
    "## Making loops\n",
    "\n",
    "Thats all swell, but how do we make a parallel loop? Let's look at a `map` operation; in Python there are several ways to perform a function on all elements in an array. For this example, we will translate some words using the Glosbe service, which has a nice REST interface. We first build some functionality to use this interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156fce60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import json\n",
    "import re\n",
    "\n",
    "\n",
    "class Translate:\n",
    "    \"\"\"Translate words and sentences in the worst possible way. The Glosbe dictionary\n",
    "    has a nice REST interface that we query for a phrase. We then take the first result.\n",
    "    To translate a sentence, we cut it in pieces, translate it and paste it back into\n",
    "    a Frankenstein monster.\"\"\"\n",
    "    def __init__(self, src_lang='en', tgt_lang='fy'):\n",
    "        self.src = src_lang\n",
    "        self.tgt = tgt_lang\n",
    "        self.url = 'https://glosbe.com/gapi/translate?' \\\n",
    "                   'from={src}&dest={tgt}&' \\\n",
    "                   'phrase={{phrase}}&format=json'.format(\n",
    "                        src=src_lang, tgt=tgt_lang)\n",
    "    \n",
    "    def query_phrase(self, phrase):\n",
    "        with urllib.request.urlopen(self.url.format(phrase=phrase.lower())) as response:\n",
    "            translation = json.loads(response.read().decode())\n",
    "        return translation\n",
    "\n",
    "    def word(self, phrase):\n",
    "        translation = self.query_phrase(phrase)\n",
    "        #translation = {'tuc': [{'phrase': {'text': phrase.lower()[::-1]}}]}\n",
    "        if len(translation['tuc']) > 0 and 'phrase' in translation['tuc'][0]:\n",
    "            result = translation['tuc'][0]['phrase']['text']\n",
    "            if phrase[0].isupper():\n",
    "                return result.title()\n",
    "            else:\n",
    "                return result            \n",
    "        else:\n",
    "            return \"<\" + phrase + \">\"\n",
    "    \n",
    "    def sentence(self, phrase):\n",
    "        words = re.sub(\"[^\\w]\", \" \", phrase).split()\n",
    "        space = re.sub(\"[\\w]+\", \"{}\", phrase)\n",
    "        return space.format(*map(self.word, words))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b3c779",
   "metadata": {},
   "source": [
    "We start with a list of strings that desparately need translation. And add a little\n",
    "routine to print it in a gracious manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ffed7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "shakespeare = [\n",
    "    \"If music be the food of love, play on,\",\n",
    "    \"Give me excess of it; that surfeiting,\",\n",
    "    \"The appetite may sicken, and so die.\"]\n",
    "\n",
    "def print_poem(intro, poem):\n",
    "    print(intro)\n",
    "    for line in poem:\n",
    "        print(\"     \", line)\n",
    "    print()\n",
    "\n",
    "print_poem(\"Original:\", shakespeare)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0db4653",
   "metadata": {},
   "source": [
    "Beginning Python programmers like to append things; this is not how you are\n",
    "supposed to program in Python; if you do, please go and read Jeff Knupp's *Writing Idiomatic Python*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5d0e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "shakespeare_auf_deutsch = []\n",
    "for line in shakespeare:\n",
    "    shakespeare_auf_deutsch.append(\n",
    "        Translate('en', 'de').sentence(line))\n",
    "print_poem(\"Auf Deutsch:\", shakespeare_auf_deutsch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04b74c7",
   "metadata": {},
   "source": [
    "Rather use a comprehension like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e726e978",
   "metadata": {},
   "outputs": [],
   "source": [
    "shakespeare_ynt_frysk = \\\n",
    "    (Translate('en', 'fy').sentence(line) for line in shakespeare)\n",
    "print_poem(\"Yn it Frysk:\", shakespeare_ynt_frysk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a852c6b7",
   "metadata": {},
   "source": [
    "Or use `map`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c72f709",
   "metadata": {},
   "outputs": [],
   "source": [
    "shakespeare_pa_dansk = \\\n",
    "    map(Translate('en', 'da').sentence, shakespeare)\n",
    "print_poem(\"PÃ¥ Dansk:\", shakespeare_pa_dansk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3f4ed0",
   "metadata": {},
   "source": [
    "## Noodlify!\n",
    "If your connection is a bit slow, you may find that the translations take a while to process. Wouldn't it be nice to do it in parallel? How much code would we have to change to get there in Noodles? Let's take the slow part of the program and add a `@schedule` decorator, and run! Sadly, it is not that simple. We can add `@schedule` to the `word` method. This means that it will return a promise. \n",
    "\n",
    "* Rule: *Functions that take promises need to be scheduled functions, or refer to a scheduled function at some level.* \n",
    "\n",
    "We could write\n",
    "\n",
    "    return schedule(space.format)(*(self.word(w) for w in words))\n",
    "    \n",
    "in the last line of the `sentence` method, but the string format method doesn't support wrapping. We rely on getting the signature of a function by calling `inspect.signature`. In some cases of build-in function this raises an exception. We may find a work around for these cases in future versions of Noodles. For the moment we'll have to define a little wrapper function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e10c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from noodles import schedule\n",
    "\n",
    "\n",
    "@schedule\n",
    "def format_string(s, *args, **kwargs):\n",
    "    return s.format(*args, **kwargs)\n",
    "\n",
    "\n",
    "import urllib.request\n",
    "import json\n",
    "import re\n",
    "\n",
    "\n",
    "class Translate:\n",
    "    \"\"\"Translate words and sentences in the worst possible way. The Glosbe dictionary\n",
    "    has a nice REST interface that we query for a phrase. We then take the first result.\n",
    "    To translate a sentence, we cut it in pieces, translate it and paste it back into\n",
    "    a Frankenstein monster.\"\"\"\n",
    "    def __init__(self, src_lang='en', tgt_lang='fy'):\n",
    "        self.src = src_lang\n",
    "        self.tgt = tgt_lang\n",
    "        self.url = 'https://glosbe.com/gapi/translate?' \\\n",
    "                   'from={src}&dest={tgt}&' \\\n",
    "                   'phrase={{phrase}}&format=json'.format(\n",
    "                        src=src_lang, tgt=tgt_lang)\n",
    "    \n",
    "    def query_phrase(self, phrase):\n",
    "        with urllib.request.urlopen(self.url.format(phrase=phrase.lower())) as response:\n",
    "            translation = json.loads(response.read().decode())\n",
    "        return translation\n",
    "    \n",
    "    @schedule\n",
    "    def word(self, phrase):\n",
    "        #translation = {'tuc': [{'phrase': {'text': phrase.lower()[::-1]}}]}\n",
    "        translation = self.query_phrase(phrase)\n",
    "        \n",
    "        if len(translation['tuc']) > 0 and 'phrase' in translation['tuc'][0]:\n",
    "            result = translation['tuc'][0]['phrase']['text']\n",
    "            if phrase[0].isupper():\n",
    "                return result.title()\n",
    "            else:\n",
    "                return result            \n",
    "        else:\n",
    "            return \"<\" + phrase + \">\"\n",
    "        \n",
    "    def sentence(self, phrase):\n",
    "        words = re.sub(\"[^\\w]\", \" \", phrase).split()\n",
    "        space = re.sub(\"[\\w]+\", \"{}\", phrase)\n",
    "        return format_string(space, *map(self.word, words))\n",
    "    \n",
    "    def __str__(self):\n",
    "        return \"[{} -> {}]\".format(self.src, self.tgt)\n",
    "    \n",
    "    def __serialize__(self, pack):\n",
    "        return pack({'src_lang': self.src,\n",
    "                     'tgt_lang': self.tgt})\n",
    "\n",
    "    @classmethod\n",
    "    def __construct__(cls, msg):\n",
    "        return cls(**msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e491de",
   "metadata": {},
   "source": [
    "Let's take stock of the mutations to the original. We've added a `@schedule` decorator to `word`, and changed a function call in `sentence`. Also we added the `__str__` method; this is only needed to plot the workflow graph. Let's run the new script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7082b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from noodles import gather, run_parallel\n",
    "from noodles.tutorial import get_workflow_graph\n",
    "\n",
    "shakespeare_en_esperanto = \\\n",
    "    map(Translate('en', 'eo').sentence, shakespeare)\n",
    "\n",
    "wf = gather(*shakespeare_en_esperanto)\n",
    "workflow_graph = get_workflow_graph(wf._workflow)\n",
    "result = run_parallel(wf, n_threads=8)\n",
    "print_poem(\"Shakespeare en Esperanto:\", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f31acb4",
   "metadata": {},
   "source": [
    "The last peculiar thing that you may notice, is the `gather` function. It collects the promises that `map` generates and creates a single new promise. The definition of `gather` is very simple:\n",
    "    \n",
    "    @schedule\n",
    "    def gather(*lst):\n",
    "        return lst\n",
    "\n",
    "The workflow graph of the Esperanto translator script looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27ff8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow_graph.attr(size='10')\n",
    "workflow_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179e1e22",
   "metadata": {},
   "source": [
    "## Dealing with repetition\n",
    "In the following example we have a line with some repetition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f96f6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from noodles import (schedule, gather_all)\n",
    "import re\n",
    "\n",
    "@schedule\n",
    "def word_size(word):\n",
    "    return len(word)\n",
    "\n",
    "@schedule\n",
    "def format_string(s, *args, **kwargs):\n",
    "    return s.format(*args, **kwargs)\n",
    "\n",
    "def word_size_phrase(phrase):\n",
    "    words = re.sub(\"[^\\w]\", \" \", phrase).split()\n",
    "    space = re.sub(\"[\\w]+\", \"{}\", phrase)\n",
    "    word_lengths = map(word_size, words)\n",
    "    return format_string(space, *word_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a5a990",
   "metadata": {},
   "outputs": [],
   "source": [
    "from noodles.tutorial import display_workflows, run_and_print_log\n",
    "\n",
    "display_workflows(\n",
    "    prefix='poetry',\n",
    "    sizes=word_size_phrase(\"Oote oote oote, Boe\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eddcd413",
   "metadata": {},
   "source": [
    "Let's run the example workflows now, but focus on the actions taken, looking at the logs. The function ``run_and_print_log`` in the tutorial module runs our workflow with four parallel threads and caches results in a Sqlite3 database.\n",
    "\n",
    "To see how this program is being run, we monitor the job submission, retrieval and result storage. First, should you have run this tutorial before, remove the database file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adceecc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the database if it already exists\n",
    "!rm -f tutorial.db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d65331f",
   "metadata": {},
   "source": [
    "Running the workflow, we can now see that at the second occurence of the word 'oote', the function call is attached to the first job that asked for the same result. The job `word_size('oote')` is run only once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f1a391",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_and_print_log(word_size_phrase(\"Oote oote oote, Boe\"), highlight=range(4, 8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31807fd",
   "metadata": {},
   "source": [
    "Now, running a similar workflow again, notice that previous results are retrieved from the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65831541",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_and_print_log(word_size_phrase(\"Oe oe oote oote oote\"), highlight=range(5, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8dd9e02",
   "metadata": {},
   "source": [
    "Although the result of every single job is retrieved we still had to go through the trouble of looking up the results of `word_size('Oote')`, `word_size('oote')`, and `word_size('Boe')` to find out that we wanted the result from the `format_string`. If you want to cache the result of an entire workflow, pack the workflow in another scheduled function!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4153ec08",
   "metadata": {},
   "source": [
    "## Versioning\n",
    "We may add a version string to a function. This version is taken into account when looking up results in the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c7dc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@schedule(version='1.0')\n",
    "def word_size_phrase(phrase):\n",
    "    words = re.sub(\"[^\\w]\", \" \", phrase).split()\n",
    "    space = re.sub(\"[\\w]+\", \"{}\", phrase)\n",
    "    word_lengths = map(word_size, words)\n",
    "    return format_string(space, *word_lengths)\n",
    "\n",
    "run_and_print_log(\n",
    "    word_size_phrase(\"Kneu kneu kneu kneu ote kneu eur\"),\n",
    "    highlight=[1, 17])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d093f8ff",
   "metadata": {},
   "source": [
    "See how the first job is evaluated to return a new workflow. Note that if the version is omitted, it is automatically generated from the source of the function. For example, let's say we decided the function `word_size_phrase` should return a dictionary of all word sizes in stead of a string. Here we use the function called `lift` to transform a dictionary containing promises to a promise of a dictionary. `lift` can handle lists, dictionaries, sets, tuples and objects that are constructable from their `__dict__` member."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9117480d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from noodles import lift\n",
    "\n",
    "def word_size_phrase(phrase):\n",
    "    words = re.sub(\"[^\\w]\", \" \", phrase).split()\n",
    "    return lift({word: word_size(word) for word in words})\n",
    "\n",
    "display_workflows(prefix='poetry', lift=word_size_phrase(\"Kneu kneu kneu kneu ote kneu eur\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45a3cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_and_print_log(word_size_phrase(\"Kneu kneu kneu kneu ote kneu eur\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672c3a16",
   "metadata": {},
   "source": [
    "**Be careful with versions!** Noodles will believe you upon your word! If we lie about the version, it will go ahead and retrieve the result belonging to the old function:"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
