{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4ed89be",
   "metadata": {},
   "source": [
    "# Enron Dataset\n",
    "\n",
    "##  Data Cleaning\n",
    "\n",
    "####  Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ee23f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pickle\n",
    "import pandas as pd\n",
    "sys.path.append(\"../tools/\")\n",
    "\n",
    "from feature_format import featureFormat, targetFeatureSplit\n",
    "from tester import dump_classifier_and_data\n",
    "\n",
    "### Load the dictionary containing the dataset\n",
    "with open(\"final_project_dataset.pkl\", \"r\") as data_file:\n",
    "    data_dict = pickle.load(data_file)\n",
    "    df = pd.DataFrame(data_dict).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4e2118",
   "metadata": {},
   "source": [
    "####  Peek into Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52670d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda092c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a8375d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea975ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167f61f1",
   "metadata": {},
   "source": [
    "####  Number of POI ,  Non-POI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63df096c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "Counter(df.poi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a67816",
   "metadata": {},
   "source": [
    "#### Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbb9534",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "df = df.replace('NaN', np.nan)\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774b8e7c",
   "metadata": {},
   "source": [
    "*** There are too much missing values in restricted_stock_deferred, director_fees,deferral_payments, loan_advances. ***\n",
    "##  Select Features\n",
    "\n",
    "First, I removed features which have a lot of missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f222e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Task 1: Select what features you'll use.\n",
    "### features_list is a list of strings, each of which is a feature name.\n",
    "### The first feature must be \"poi\".\n",
    "\n",
    "features_list = ['poi','salary', 'bonus', 'total_payments', 'long_term_incentive', 'deferred_income',\n",
    "                      'total_stock_value', 'restricted_stock', 'exercised_stock_options', 'expenses', 'other',\n",
    "                'to_messages', 'from_poi_to_this_person', 'from_messages', 'from_this_person_to_poi']\n",
    "\n",
    "enron = df[features_list].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ebd8d3",
   "metadata": {},
   "source": [
    "##  Remove outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7defcef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Task 2: Remove outliers\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "plt.scatter(enron.salary, enron.bonus)\n",
    "plt.xlabel('Salary')\n",
    "plt.ylabel('Bonus')\n",
    "plt.title('Scatter plot ( Salary vs Bonus)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3015a174",
   "metadata": {},
   "source": [
    "As we can see a scatter plot there is on huge outlier.   \n",
    "Let's check what it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420c14be",
   "metadata": {},
   "outputs": [],
   "source": [
    "enron.salary.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d359ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "enron = enron.drop('TOTAL')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9a7eef",
   "metadata": {},
   "source": [
    "Drop 'TOTAL' and then draw scatter plot again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4da678c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(9,6))\n",
    "plt.scatter(enron.salary[enron.poi==1], enron.bonus[enron.poi==1],c='red',label='poi')\n",
    "plt.scatter(enron.salary[enron.poi==0], enron.bonus[enron.poi==0],c='skyblue',label='non-poi')\n",
    "plt.xlabel('Salary')\n",
    "plt.ylabel('Bonus')\n",
    "plt.title('Scatter plot ( Salary vs Bonus)')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737b7762",
   "metadata": {},
   "source": [
    "##  Create New Features\n",
    "\n",
    "I made new features fraction of message from poi and fraction of message to poi.  \n",
    "Let's check new featrues by drawing scatter plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c429d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "enron['fraction_from_poi'] = enron.from_poi_to_this_person / enron.to_messages\n",
    "enron['fraction_to_poi'] = enron.from_this_person_to_poi / enron.from_messages\n",
    "fig, ax = plt.subplots(figsize=(9,6))\n",
    "plt.scatter(enron.fraction_to_poi[enron.poi == 1], enron.fraction_from_poi[enron.poi == 1],c='red',alpha=0.8,label='poi')\n",
    "plt.scatter(enron.fraction_to_poi[enron.poi == 0], enron.fraction_from_poi[enron.poi == 0],c='skyblue', alpha=0.5, label='non-poi')\n",
    "plt.legend(loc='upper right')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90483c29",
   "metadata": {},
   "source": [
    "There is no distinct pattern, but their fraction are higher than ohters.   \n",
    "*** before extracting features, let's clean some features. ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b91dda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in data_dict:\n",
    "    \n",
    "    data_point = data_dict[name]\n",
    "\n",
    "    from_poi_to_this_person = data_point[\"from_poi_to_this_person\"]\n",
    "    to_messages = data_point[\"to_messages\"]\n",
    "    \n",
    "    from_this_person_to_poi = data_point[\"from_this_person_to_poi\"]\n",
    "    from_messages = data_point[\"from_messages\"]\n",
    "   \n",
    "    if from_poi_to_this_person == 'NaN' or to_messages == 'NaN' :\n",
    "        data_point[\"fraction_from_poi\"] = \"NaN\"\n",
    "    else :\n",
    "        fraction_from_poi = float(from_poi_to_this_person) / float(to_messages)\n",
    "        data_point[\"fraction_from_poi\"] = fraction_from_poi\n",
    "    \n",
    "    if from_this_person_to_poi == 'NaN' or from_messages == 'NaN' :\n",
    "        data_point['fraction_to_poi'] = \"NaN\"\n",
    "    else :\n",
    "        fraction_to_poi = float(from_this_person_to_poi) / float(from_messages)\n",
    "        data_point[\"fraction_to_poi\"] = fraction_to_poi\n",
    "data_dict.pop('TOTAL')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae0aebf",
   "metadata": {},
   "source": [
    "Now, let's extract features.  \n",
    "***  Add new features and remove features which were reduntant features. ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34861e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Task 3: Create new feature(s)\n",
    "### Store to my_dataset for easy export below.\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "my_dataset = data_dict\n",
    "\n",
    "features_list += ['fraction_from_poi','fraction_to_poi']\n",
    "remove_list = ['to_messages','from_messages','from_poi_to_this_person','from_this_person_to_poi']\n",
    "\n",
    "for x in remove_list :\n",
    "    features_list.remove(x)\n",
    "\n",
    "### Extract features and labels from dataset for local testing\n",
    "data = featureFormat(my_dataset, features_list, sort_keys = True)\n",
    "labels, features = targetFeatureSplit(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c72c210",
   "metadata": {},
   "source": [
    "*** Now, Let's split dataset to train and test ***"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
