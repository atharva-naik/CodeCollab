{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45df6e6f",
   "metadata": {},
   "source": [
    "# INTRODUCTION \n",
    "\n",
    "I have been living in the Boston area for the last few years since grad school. The dataset analyzed for the purposes of this project pertains to the Boston area. The Boston area dataset was exported from [openstreetmaps](http://www.openstreetmap.org/#map=17/40.71652/-73.94470&layers=H). The analysis included the following steps \n",
    "\n",
    "* **Question Phase:** This phase involves asking general questions about the dataset. The questions involve the problem we are trying to solve for. \n",
    "* **Data Auditing:** This phase involves auditing the data to identify anomalies and patterns. E.g. In the streetmap data we could run into street names which have some kind special characters in them, or we could run into zipcodes in the Boston area that have some kind of alphabetical characters in them. \n",
    "* **Data Cleansing:** This phase involves classifying the anomalies that are identified in the previous step and devising approaches to clean up the data. The cleansing could be either manual or done programmatically. The project assumes both a programmatic and a manual approach to cleansing data. The focus is mostly been around cleansing the data programmatically. However in certain cases there is also a need for a manual review \n",
    "\n",
    "Data Auditing and Data Cleansing follow a repetive approach till a fair amount of data anomalies have been identified and also cleansed approrpriately. \n",
    "\n",
    "* **Conclusion:** This phase involves drawing conclusion about the dataset, based on the auditing and cleansing steps \n",
    "* **Communication:** The phase involves communicating the results of the analysis to the audiences. In a real life scenario this would be the business users who make business decisions based on the dataset analysis. \n",
    "\n",
    "In addition, this project also involves importing the dataset into [mongoDB](https://www.mongodb.com/), followed by executing some of the mongoDB's aggregation commands to further analyze the dataset that has been imported. \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858e3a87",
   "metadata": {},
   "source": [
    "# Question Phase\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea1c5f5e",
   "metadata": {},
   "source": [
    "# Data Auditing\n",
    "## Identifying the TAGS along with the count of occurences of each of the TAGS\n",
    "\n",
    "This step involves doing an initial analysis of the dataset and doing an assessment of the XML nodes. The step also involves counting the number of instances of the specific node. While this step does provide a good start to the data auditing process, it does not answer a whole of questions that needs to be answered. This step definitely helps us confirm the validity of the XML format as the XML parser (ET.iterparse) is able to parse through the entire XML file. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90030989",
   "metadata": {},
   "source": [
    "The output of the step above is the creation of **\"Boston.osm.json\"** file, which is later been used to import into MongoDB. In addition as a part of the import the street names, phone numbers and zipcodes were also cleaned up "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33bcd46d",
   "metadata": {},
   "source": [
    "# Setting up for Mongo Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf91e307",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "import pprint\n",
    "client = MongoClient()\n",
    "db = client.boston\n",
    "print db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19840685",
   "metadata": {},
   "source": [
    "# Data Analysis/Data Exploration in MongoDB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f09ffd",
   "metadata": {},
   "source": [
    "# Assessing the Size of the Original OSM File and the JSON File "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21733d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print 'The original OSM file is {} MB'.format(os.path.getsize('Boston.osm')/1.0e6)\n",
    "print 'The JSON file is {} MB'.format(os.path.getsize('Boston.osm' + \".json\")/1.0e6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a5ff94",
   "metadata": {},
   "outputs": [],
   "source": [
    "boston = db['bostonc']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276e5a38",
   "metadata": {},
   "source": [
    "# Number of Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e70af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "boston.find().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a343d18d",
   "metadata": {},
   "source": [
    "# Number of Nodes and Ways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8c986d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print \"Number of nodes:\",boston.find({'tag': 'node'}).count()\n",
    "print \"Number of ways:\", boston.find({'tag': 'way'}).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe27dd0",
   "metadata": {},
   "source": [
    "# Top 10 Contributors along with the UserNames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f48b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = boston.aggregate( [\n",
    "                                        { \"$group\" : {\"_id\" : \"$created.user\", \"count\" : { \"$sum\" : 1} } },\n",
    "                                        { \"$sort\" : {\"count\" : -1} }, \n",
    "                                        { \"$limit\" : 10 } ] )\n",
    "\n",
    "pprint.pprint(list(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20af6605",
   "metadata": {},
   "source": [
    "# List of Top 50 Amenities in the Boston Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d604c7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = boston.aggregate( [            {'$match': {'amenity': {'$exists': 1}}},\n",
    "                                        { \"$group\" : {\"_id\" : \"$amenity\", \"count\" : { \"$sum\" : 1} } },\n",
    "                                        { \"$sort\" : {\"count\" : -1} }, \n",
    "                                        { \"$limit\" : 50 } ] )\n",
    "\n",
    "pprint.pprint(list(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30dddbad",
   "metadata": {},
   "source": [
    "# Extracting the List of Colleges from the DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb847c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "colleges = boston.aggregate([{\"$match\":{\"amenity\":{\"$exists\":1},\n",
    "                                 \"amenity\":\"college\",}},      \n",
    "                      {\"$group\":{\"_id\":{\"Name\":\"$name\"},\n",
    "                                 \"count\":{\"$sum\":1}}},\n",
    "                      {\"$project\":{\"_id\":0,\n",
    "                                  \"College\":\"$_id.Name\",\n",
    "                                  \"Name\":\"$count\"}},\n",
    "                      {\"$sort\":{\"Count\":-1}}, \n",
    "                      {\"$limit\":10}])\n",
    "pprint.pprint(list(colleges))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa239874",
   "metadata": {},
   "source": [
    "**This list is definitely missing some of the key universities in the Boston Area like Harvard, MIT, NorthEastern. On further review of the dataset I noticed that the missing schools and colleges are infact a part of the dataset, they just don't have an amenity of college attached to them** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1e9b41",
   "metadata": {},
   "source": [
    "# Extracting the list of Public Buildings in the Boston Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b6d4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "building = boston.aggregate([{\"$match\":{\"amenity\":{\"$exists\":1},\n",
    "                                 \"amenity\":\"public_building\",}},      \n",
    "                      {\"$group\":{\"_id\":{\"Name\":\"$name\"},\n",
    "                                 \"count\":{\"$sum\":1}}},\n",
    "                      {\"$project\":{\"_id\":0,\n",
    "                                  \"Building\":\"$_id.Name\",\n",
    "                                  \"Name\":\"$count\"}},\n",
    "                      {\"$sort\":{\"Count\":-1}}, \n",
    "                      {\"$limit\":10}])\n",
    "pprint.pprint(list(building))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc25157c",
   "metadata": {},
   "source": [
    "# Extracting the Top Cities in the Boston Area"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
