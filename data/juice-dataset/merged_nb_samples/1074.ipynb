{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87bf9721",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import pylab as pl\n",
    "from itertools import cycle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21da3eee",
   "metadata": {},
   "source": [
    "After the fit(), the pca model exposes the singular vectors in the components_ attribute:\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca58af71",
   "metadata": {},
   "source": [
    "# Digits\n",
    "OK - lets try something more exciting than the Iris dataset (this is taken from https://github.com/oreillymedia/t-SNE-tutorial) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3337dc23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn import manifold\n",
    "import matplotlib.patheffects as PathEffects\n",
    "digits = datasets.load_digits()\n",
    "digits.data.shape\n",
    "#print(digits['DESCR'])\n",
    "\n",
    "from sklearn.utils.extmath import _ravel\n",
    "# Random state.\n",
    "RS = 20150101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4352f34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows, ncols = 2, 5\n",
    "plt.figure(figsize=(6,3))\n",
    "plt.gray()\n",
    "for i in range(ncols * nrows):\n",
    "    ax = plt.subplot(nrows, ncols, i + 1)\n",
    "    ax.matshow(digits.images[i,...])\n",
    "    plt.xticks([]); plt.yticks([])\n",
    "    plt.title(digits.target[i])\n",
    "plt.savefig('images/digits-generated.png', dpi=150)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d692f16",
   "metadata": {},
   "source": [
    "Now let's run the t-SNE algorithm on the dataset. It just takes one line with scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61c631b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We first reorder the data points according to the handwritten numbers.\n",
    "X = np.vstack([digits.data[digits.target==i]\n",
    "               for i in range(10)])\n",
    "y = np.hstack([digits.target[digits.target==i]\n",
    "               for i in range(10)])\n",
    "digits_proj = manifold.TSNE(random_state=RS).fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573367c6",
   "metadata": {},
   "source": [
    "Here is a utility function used to display the transformed dataset. The color of each point refers to the actual digit (of course, this information was not used by the dimensionality reduction algorithm)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b8bd63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatter(x, colors):\n",
    "    # We choose a color palette with seaborn.\n",
    "    palette = np.array(sns.color_palette(\"hls\", 10))\n",
    "\n",
    "    # We create a scatter plot.\n",
    "    f = plt.figure(figsize=(8, 8))\n",
    "    ax = plt.subplot(aspect='equal')\n",
    "    sc = ax.scatter(x[:,0], x[:,1], lw=0, s=40,\n",
    "                    c=palette[colors.astype(np.int)])\n",
    "    plt.xlim(-25, 25)\n",
    "    plt.ylim(-25, 25)\n",
    "    ax.axis('off')\n",
    "    ax.axis('tight')\n",
    "\n",
    "    # We add the labels for each digit.\n",
    "    txts = []\n",
    "    for i in range(10):\n",
    "        # Position of each label.\n",
    "        xtext, ytext = np.median(x[colors == i, :], axis=0)\n",
    "        txt = ax.text(xtext, ytext, str(i), fontsize=24)\n",
    "        txt.set_path_effects([\n",
    "            PathEffects.Stroke(linewidth=5, foreground=\"w\"),\n",
    "            PathEffects.Normal()])\n",
    "        txts.append(txt)\n",
    "\n",
    "    return f, ax, sc, txts\n",
    "\n",
    "scatter(digits_proj, y)\n",
    "plt.savefig('images/digits_tsne-generated.png', dpi=120)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2899575a",
   "metadata": {},
   "source": [
    "Observe that the images corresponding to the different digits are clearly separated into different clusters of points."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c53d3c",
   "metadata": {},
   "source": [
    "# Topic Goal\n",
    "\n",
    "We want to apply what you learned yesterday on **machine learning approaches to learning low-dimensional projections** to high-dimensional data from a human motion tracking example\n",
    "\n",
    "## Human Motion capture data\n",
    "Let us now look at some data from human motion capture, to see if we can usefully view this high-dimensional data in a lower dimensional space. \n",
    "\n",
    "Although you have a large number of measurement points on a human body, that does not mean that each one is independent of the others.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0959b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in some motion data\n",
    "from sklearn import manifold\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "from sklearn.utils.extmath import _ravel\n",
    "# Random state.\n",
    "RS = 20150101\n",
    "\n",
    "X = pd.read_csv('handtracker/olddata/2016-6-6-9.20/data/trackerOutput5_pincer.txt')\n",
    "Xbend = pd.read_csv('handtracker/olddata/2016-6-6-9.20/data/trackerOutput12_finger_bending.txt')\n",
    "X.columns = ['t']+['x','y','z']*32+['c']\n",
    "Xbend.columns = ['t']+['x','y','z']*32+['c']\n",
    "\n",
    "X['t']= pd.to_datetime(X['t'], unit='us')\n",
    "Xbend['t']= pd.to_datetime(Xbend['t'], unit='us')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cced59d",
   "metadata": {},
   "source": [
    "We can plot this in parallel coordinates, but it isn't clear what the intrinsic dimensionality of the data is. How independent are these time-series?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb825f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X.plot(x='t', y=range(3,97,3),legend=False,title='z')\n",
    "X.plot(x='t', y=range(2,97,3),legend=False,title='y')\n",
    "X.plot(x='t', y=range(1,97,3),legend=False,title='x')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872d44c3",
   "metadata": {},
   "source": [
    "but what if we try to bring this down to two dimensions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f48676",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xbend.columns = ['t']+['x','y','z']*32+['c']\n",
    "Xbend.plot(x='t', y=range(3,97,3),legend=False,title='z')\n",
    "Xbend.plot(x='t', y=range(2,97,3),legend=False,title='y')\n",
    "Xbend.plot(x='t', y=range(1,97,3),legend=False,title='x')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1713d836",
   "metadata": {},
   "source": [
    "so far we have been looking at each hand pose as a static hand configuration, so it is not picking up change of state. What if we apply some derivative operators to the time-series?"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
