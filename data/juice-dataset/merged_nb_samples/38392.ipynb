{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6df278c3",
   "metadata": {},
   "source": [
    "**Method 2 of one-hot-encoding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0e6785",
   "metadata": {},
   "outputs": [],
   "source": [
    "Pclass_lb = preprocessing.LabelBinarizer()\n",
    "Pclass_one_hot_encoded = Pclass_lb.fit_transform(data.Pclass.values)\n",
    "\n",
    "dfOneHot_Encoded = pd.DataFrame(Pclass_one_hot_encoded, \n",
    "columns = [\"Pclass_\"+str(int(i+1)) for i in range(Pclass_one_hot_encoded.shape[1])],\n",
    "index=data.index\n",
    ") # we now construct a dataframe out of this one-hot-encoded data\n",
    "\n",
    "data = pd.concat([data, dfOneHot_Encoded], axis=1)\n",
    "# we now add our one-hot-encoded Embarked features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1423c018",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0dfcac",
   "metadata": {},
   "source": [
    "Now we have finished preprocessing our data we can extract our feature and target varaibles to be used to train, validate and test our learning algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6e2614",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['Survived']\n",
    "X = data.drop(['Survived'], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450cb2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.drop(labels=['Sex', 'Pclass', 'Embarked', 'Embarked_numeric'], axis=1, inplace=True) # we drop the features that we have one-hot-encoded but not removed yet (we left these in to check the encoding had worked correctly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00672adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c2d1d9",
   "metadata": {},
   "source": [
    "## [Train, Validation, Test] splitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1c0620",
   "metadata": {},
   "source": [
    "Now lets split our pre-processed data into a training set, cross validation set and test set with a 60/20/20 split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9258de9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_temp, X_test, y_temp, y_test = model_selection.train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "X_train, X_cv, y_train, y_cv = model_selection.train_test_split(X_temp, y_temp, train_size=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693ef92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Data split is as follows:\")\n",
    "print(\"-------------------------\")\n",
    "print(\"train: {} \\ncross-validation: {} \\ntest: {}\".format(X_train.shape[0], X_cv.shape[0], X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ee109e",
   "metadata": {},
   "source": [
    "## First lets just predict everyone dies, no learning algorithm, to see how that goes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa8096d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X):\n",
    "    return np.zeros(X_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc91bd27",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249cb97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "100*sum(prediction == y_test)/y_test.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a49db9a",
   "metadata": {},
   "source": [
    "This achieves an accuracy of ~57%, which doesn't seem that bad. But if we now look at the truth table of our target variable vs our prediction we can see the truth, that we are just predicting false all the time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab04b07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "TruePositives = sum((prediction == y_test) & (y_test == 1))\n",
    "TrueNegatives = sum((prediction == y_test) & (y_test == 0))\n",
    "FalsePositives = sum((prediction != y_test) & (prediction == 1))\n",
    "FalseNegatives = sum((prediction != y_test) & (prediction == 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b959f2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = tt.Texttable()\n",
    "table.add_rows([\n",
    "                [\"\", \"\", \"Real Value\", \"\"],\n",
    "                [\"\", \"\", \"Positive\", \"Negative\"],\n",
    "                [\"Prediction\", \"Positive\", TruePositives, FalsePositives],\n",
    "                [\"\", \"Negative\", FalseNegatives, TrueNegatives],\n",
    "                ])\n",
    "print(table.draw() + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70843522",
   "metadata": {},
   "outputs": [],
   "source": [
    "PredictedPositives = TruePositives + FalsePositives\n",
    "Precision = TruePositives/PredictedPositives\n",
    "\n",
    "ActualPositives = TruePositives + FalseNegatives\n",
    "Recall = TruePositives/ActualPositives\n",
    "\n",
    "print(\"Precision: {}\".format(Precision))\n",
    "\n",
    "print(\"Recall: {}\".format(Recall))\n",
    "\n",
    "F1score = 2*Precision*Recall/(Precision+Recall)\n",
    "\n",
    "print(\"F1score: {}\".format(Recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b88b5e",
   "metadata": {},
   "source": [
    "It is much more obvious from this that our predicting everyone dies is a bad method to predict survival."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86633ba",
   "metadata": {},
   "source": [
    "## First lets attempt a logistic regression\n",
    "#### i.e. Not using any additional higher order features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63df6f2",
   "metadata": {},
   "source": [
    "Now we predict on the Kaggle data and submit to get a score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67353f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_kaggle_data = svm_model.predict(data_kaggle_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2791ae4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('prediction_submission_SVM_Linear_Kernel.csv', 'w') as file:\n",
    "    print('PassengerId,Survived', file=file)\n",
    "    for i, id_ in enumerate(data_kaggle_test.index):\n",
    "        print('{},{}'.format(id_, prediction_kaggle_data[i]), file=file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc492dd",
   "metadata": {},
   "source": [
    "Got ~76% accuracy on Kaggle."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2535475",
   "metadata": {},
   "source": [
    "### Learning curve for Linear Kernal SVM with best C (0.03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ff895f",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_array = np.round(np.linspace(20, X_train.shape[0], 20)).astype(int)\n",
    "train_acc_array = np.zeros(len(m_array))\n",
    "cv_acc_array = np.zeros(len(m_array))\n",
    "\n",
    "for i, m in enumerate(m_array):\n",
    "    print(i, end=', ')\n",
    "    svm_model_iter = svm.SVC(C=bestC, kernel=kernel)\n",
    "    # we now fit to the training data\n",
    "    svm_model_iter.fit(X_train.head(m), y_train.head(m)) # training on the first m training data examples\n",
    "    train_accuracy = svm_model_iter.score(X_train, y_train)\n",
    "    train_acc_array[i] = train_accuracy\n",
    "    cv_accuracy = svm_model_iter.score(X_cv, y_cv)\n",
    "    cv_acc_array[i] = cv_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4bd3691",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(m_array, 1-train_acc_array, label='train')\n",
    "ax.plot(m_array, 1-cv_acc_array, label='cross-validation')\n",
    "ax.legend()\n",
    "ax.set_xlabel('m (size of training data)')\n",
    "ax.set_ylabel('error (1-accuracy)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ffd8f5c",
   "metadata": {},
   "source": [
    "### We will now try an SVM with a Gaussian Kernal\n",
    "\n",
    "\n",
    "### We will use the Gaussian radial-basis function (RBF kernel)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75df8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "C = 1 # start with penalty parameter equal to 1 as we don't know what value this should take yet, larger C -> lower bias, higher variance, smaller C -> higher bias, lower varaince. Since we don't have that much data a lower bias algorithm is probably best to avoid overfitting\n",
    "\n",
    "kernel = 'rbf' # we'll use the radial basis function (Gaussian) kernal to see how ths performs\n",
    "\n",
    "gamma = 'auto' # a second hyperparameter to tune for the Guassian kernal - the width of the Gaussian function used\n",
    "\n",
    "svm_model = svm.SVC(C=C, kernel=kernel, gamma=gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ead07a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d084ea86",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model.score(X_cv, y_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb52d30",
   "metadata": {},
   "source": [
    "Not very good performance. Since we now have 2 hyperparameters to tune we will make use of scikit learns grid_search function which allows you to provide a range of values of parameters and search over the grid for the best hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed6a3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "TruePositives = sum((prediction_cv == y_cv) & (y_cv == 1))\n",
    "TrueNegatives = sum((prediction_cv == y_cv) & (y_cv == 0))\n",
    "FalsePositives = sum((prediction_cv != y_cv) & (prediction_cv == 1))\n",
    "FalseNegatives = sum((prediction_cv != y_cv) & (prediction_cv == 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75f7743",
   "metadata": {},
   "source": [
    "Looking at our truth table this looks much better than we got just predicting everyone dies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7a18ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "PredictedPositives = TruePositives + FalsePositives\n",
    "Precision = TruePositives/PredictedPositives\n",
    "\n",
    "ActualPositives = TruePositives + FalseNegatives\n",
    "Recall = TruePositives/ActualPositives\n",
    "\n",
    "print(\"Precision: {:.3f}\".format(Precision))\n",
    "\n",
    "print(\"Recall: {:.3f}\".format(Recall))\n",
    "\n",
    "F1score = 2*Precision*Recall/(Precision+Recall)\n",
    "\n",
    "print(\"F1score: {:.3f}\".format(F1score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee608941",
   "metadata": {},
   "source": [
    "And we now get a decent precision and recall, although recall is worse, giving us a decent F1score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f015ae83",
   "metadata": {},
   "source": [
    "### Learning Curve for Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d8d742",
   "metadata": {},
   "source": [
    "Lets look at the learning curve for this algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664d3431",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_array = np.round(np.linspace(20, X_train.shape[0], 100)).astype(int)\n",
    "train_acc_array = []\n",
    "cv_acc_array = []\n",
    "\n",
    "for m in m_array:\n",
    "    lr_model_iter = linear_model.LogisticRegression(fit_intercept=True)\n",
    "    # we now fit to the training data\n",
    "    lr_model_iter.fit(X_train.head(m), y_train.head(m)) # training on the first m training data examples\n",
    "    train_accuracy = lr_model_iter.score(X_train, y_train)\n",
    "    train_acc_array.append(train_accuracy)\n",
    "    cv_accuracy = lr_model_iter.score(X_cv, y_cv)\n",
    "    cv_acc_array.append(cv_accuracy)\n",
    "\n",
    "train_acc_array = np.array(train_acc_array)\n",
    "cv_acc_array = np.array(cv_acc_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308810da",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = lr_model.score(X_test, y_test)\n",
    "\n",
    "print(\"accuracy on testing data: {:0.2f}\".format(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b535ef",
   "metadata": {},
   "source": [
    "Now we have a model accuracy of ~80% on our testing data, which the classifier has never seen before we will apply it to the actual testing data to submit to Kaggle."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa87d1cb",
   "metadata": {},
   "source": [
    "## Loading Test Data to Predict On for Kaggle Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaba168c",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9af35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/train.csv', index_col='PassengerId')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9888a70",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff9ed5c",
   "metadata": {},
   "source": [
    "### removing unhelpful columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a70df2e",
   "metadata": {},
   "source": [
    "First we need to preprocess the data remove unique data like the name and ticket number that may not be useful in predicting the target variable: i.e. did the passenger survive.\n",
    "\n",
    "Here we choose to remove the columns : \n",
    "- name\n",
    "- ticket number\n",
    "- Cabin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f5218a",
   "metadata": {},
   "outputs": [],
   "source": [
    "del data.index.name # lets also remove this row with just the name on it to make things easier later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2432177",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(labels=['Name', 'Ticket', 'Cabin'], axis=1) # dropping name, ticket and Cabin columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7614a05",
   "metadata": {},
   "source": [
    "### Dealing with NaN values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc2e276",
   "metadata": {},
   "source": [
    "Now we need to treat NaN values somehow as they can have break our learning algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c03018b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_dropped_removing_Nans = len(data) - len(data.dropna()) # calculate number of entries we would drop if we dropped all entries containing NaN\n",
    "percent_dropped_removing_Nans = 100*(len(data) - len(data.dropna()))/len(data)\n",
    "\n",
    "print(num_dropped_removing_Nans) # dropping all rows with NaNs in them drops 708 examples\n",
    "print(\"Percent dropped by removing NaNs: {:.2f}%\".format(percent_dropped_removing_Nans))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c489b3",
   "metadata": {},
   "source": [
    "Removing entries with NaNs is not a good option as it leads to loss of almost 20% of the data, we should find another way to deal with these NaN entries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58aa72ce",
   "metadata": {},
   "source": [
    "Lets take a look at some of our NaN entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b14183",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_temp = data[data.isnull().any(axis=1)] # get any row that has a NaN in it\n",
    "data_temp[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee64300",
   "metadata": {},
   "source": [
    "Our options are to replace NaNs with:\n",
    "- A constant value that has meaning within the domain, such as 0, distinct from all other values.\n",
    "- A value from another randomly selected record.\n",
    "- A mean, median or mode value for the column.\n",
    "- A value estimated by another predictive model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335ec968",
   "metadata": {},
   "source": [
    "I have tested the first 3 methods and found using the mean value to produce the best performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc73cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data.Embarked.notnull()] # remove data where embarked is null as we can't calculate a numerical value for this with the below methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164ded40",
   "metadata": {},
   "source": [
    "#### Here we are using scikit learns imputer to guess missing values from other data, in practise the method we are using is to calculate the mean of that column and replace NaN values with the column mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c15600",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = preprocessing.Imputer(strategy=\"mean\", axis=0)\n",
    "data_nans_replaced = data.copy()\n",
    "data_nans_replaced['Age'] = imputer.fit_transform(data_nans_replaced['Age'].reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5611a0e0",
   "metadata": {},
   "source": [
    "And lets look what the NaNs were replaced with "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e801ff74",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_temp = data_nans_replaced[data.isnull().any(axis=1)] # get rows of the replaced data where the rows used to contain NaNs\n",
    "data_temp[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2623beb4",
   "metadata": {},
   "source": [
    "Repacing these in this way may cause some issues, but we will go forward with this method for now and see how it affects the performance of our learning algorithm later by comparing performance of the learning algorithm with some of the other methods to replace NaN values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c635dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_nans_replaced # replace data with data where we have replaced NaNs with mean values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053d52ae",
   "metadata": {},
   "source": [
    "Lets check we really got rid of all the NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a2ff69",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_best = np.argmax(validation_score_array)\n",
    "bestC = C_array[index_best]\n",
    "print('C that performed best on validation data was C={}'.format(bestC))\n",
    "print(\"train score: {:0.3f}, validation score: {:0.3f}\".format(train_score_array[index_best], validation_score_array[index_best]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f3ceb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model = svm.SVC(C=bestC, kernel=kernel)\n",
    "svm_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53de5f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02c5159",
   "metadata": {},
   "source": [
    "We get ~80 percent accuracy on the test data we held back from our training and validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a964b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_kaggle_test = pd.read_csv('data/test.csv', index_col='PassengerId')\n",
    "del data_kaggle_test.index.name # lets also remove this row with just the name on it to make things easier later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c53144",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_kaggle_test[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3087f54d",
   "metadata": {},
   "source": [
    "### Preprocessing the data as we did for the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764fad41",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_kaggle_test = data_kaggle_test.drop(labels=['Name', 'Ticket', 'Cabin'], axis=1) # dropping name, ticket and Cabin columns\n",
    "\n",
    "data_kaggle_test['Age'] = imputer.fit_transform(data_kaggle_test['Age'].reshape(-1, 1))\n",
    "\n",
    "# ----- one-hot encoding sex ----- \n",
    "\n",
    "data_kaggle_test['Sex_numeric'] = le_sex.transform(data_kaggle_test.Sex) # transform the data from labels to numeric\n",
    "\n",
    "\n",
    "# ----- one-hot encoding Embarked ----- \n",
    "\n",
    "data_kaggle_test['Embarked_numeric'] = le_Embarked.transform(data_kaggle_test.Embarked) # transform the data from labels to numeric\n",
    "\n",
    "encoded_column_vector = data_kaggle_test.Embarked_numeric.values.reshape(-1,1) # gets numeric embarked data and rehsapes it to column vector\n",
    "\n",
    "Embarked_one_hot_encoded = enc_Embarked.transform(encoded_column_vector).toarray() # transforms the data to one-hot-encoded data\n",
    "\n",
    "dfOneHot_Encoded = pd.DataFrame(Embarked_one_hot_encoded, \n",
    "columns = [\"Embarked_\"+le_Embarked.inverse_transform(int(i)) for i in range(Embarked_one_hot_encoded.shape[1])],\n",
    "index=data_kaggle_test.index\n",
    ") # we now construct a dataframe out of this one-hot-encoded data\n",
    "\n",
    "data_kaggle_test = pd.concat([data_kaggle_test, dfOneHot_Encoded], axis=1)\n",
    "# we now add our one-hot-encoded Embarked features\n",
    "\n",
    "# ----- one-hot encoding Pclass ----- \n",
    "\n",
    "Pclass_lb = preprocessing.LabelBinarizer()\n",
    "Pclass_one_hot_encoded = Pclass_lb.fit_transform(data_kaggle_test.Pclass.values)\n",
    "\n",
    "dfOneHot_Encoded = pd.DataFrame(Pclass_one_hot_encoded, \n",
    "columns = [\"Pclass_\"+str(int(i+1)) for i in range(Pclass_one_hot_encoded.shape[1])],\n",
    "index=data_kaggle_test.index\n",
    ") # we now construct a dataframe out of this one-hot-encoded data\n",
    "\n",
    "data_kaggle_test = pd.concat([data_kaggle_test, dfOneHot_Encoded], axis=1)\n",
    "# we now add our one-hot-encoded Embarked features\n",
    "\n",
    "data_kaggle_test.drop(labels=['Sex', 'Pclass', 'Embarked', 'Embarked_numeric'], axis=1, inplace=True) # we drop the features that we have one-hot-encoded but not removed yet (we left these in to check the encoding had worked correctly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce251ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "inds = pd.isnull(data_kaggle_test).any(1).nonzero()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5bd924",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_kaggle_test[inds[0]:inds[0]+1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28b5a96",
   "metadata": {},
   "source": [
    "We didn't have a training example where the Fare was NaN so we now fit an imputer to the training data in order to impute a mean training value to use here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e427586f",
   "metadata": {},
   "source": [
    "Pclass is already numeric and takes values 1 -> 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2762796",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Pclass.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1913fea0",
   "metadata": {},
   "source": [
    "Now that Pclass and Embarked take numeric integer values we can now apply the one-hot-encoding to generate binary features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6cbdfc",
   "metadata": {},
   "source": [
    "**Method 1 of one-hot-encoding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5a3705",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_Embarked = preprocessing.OneHotEncoder()\n",
    "encoded_column_vector = data.Embarked_numeric.values.reshape(-1,1) # gets numeric embarked data and rehsapes it to column vector\n",
    "\n",
    "Embarked_one_hot_encoded = enc_Embarked.fit_transform(encoded_column_vector).toarray() # we now apply a fit and transform step to the data simultaneous which fits the one-hot-encoder and transforms the data to one-hot-encoded data\n",
    "\n",
    "dfOneHot_Encoded = pd.DataFrame(Embarked_one_hot_encoded, \n",
    "columns = [\"Embarked_\"+le_Embarked.inverse_transform(int(i)) for i in range(Embarked_one_hot_encoded.shape[1])],\n",
    "index=data.index\n",
    ") # we now construct a dataframe out of this one-hot-encoded data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2e4833",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([data, dfOneHot_Encoded], axis=1)\n",
    "# we now add our one-hot-encoded Embarked features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce9b1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer_fare = preprocessing.Imputer(strategy=\"mean\", axis=0)\n",
    "imputer_fare.fit(data['Age'].reshape(-1, 1))\n",
    "data_kaggle_test['Fare'] = imputer_fare.transform(data_kaggle_test['Fare'].reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad417185",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_kaggle_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28899a3",
   "metadata": {},
   "source": [
    "### We now predict on our test data and write the predictions to a CSV file to submit to Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9b029e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_dropped_removing_Nans = len(data) - len(data.dropna())\n",
    "percent_dropped_removing_Nans = 100*(len(data) - len(data.dropna()))/len(data)\n",
    "\n",
    "print(num_dropped_removing_Nans) # dropping all rows with NaNs in them drops 708 examples\n",
    "print(\"Percent dropped by removing NaNs: {:.2f}%\".format(percent_dropped_removing_Nans))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54674ce5",
   "metadata": {},
   "source": [
    "We did!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6935b38",
   "metadata": {},
   "source": [
    "### Encoding categorical features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44cf3a15",
   "metadata": {},
   "source": [
    "We now need to encode the categorical features into many binary features. This is nessesary because of the way the algorithm interprets numbers. If we have a categorical feature that takes values 0, 1, 2, 3, 4 it assumes the higher numbers are 'better' (e.g. 4>3) even though they are arbitrary encodings, because ultimately it is calculating values/weights/parameters to be multiplied by these feature variables to give a term which enters into the linear regression. One common way to deal with this is one-hot-encoding, where a feature N takes values 0, 1, 2 for example we would generate 3 features which takes binary values 0 or 1. An example is shown below\n",
    "\n",
    "We have the original feature data:\n",
    "\n",
    "| Entry        | N          |\n",
    "| ------------ |:----------:|\n",
    "| 0            | 1          | \n",
    "| 1            | 2          |\n",
    "| 2            | 0          |\n",
    "| 3            | 1          |\n",
    "| 4            | 2          |\n",
    "| 5            | 0          |\n",
    "\n",
    "Which when encoded becomes:\n",
    "\n",
    "| Entry        | N==0       | N==1       | N==2       |\n",
    "| ------------ |:----------:|:----------:|:----------:|\n",
    "| 0            | 0          | 1          | 0          | \n",
    "| 1            | 0          | 0          | 1          | \n",
    "| 2            | 1          | 0          | 0          | \n",
    "| 3            | 0          | 1          | 0          | \n",
    "| 4            | 0          | 0          | 1          | \n",
    "| 5            | 1          | 0          | 0          | \n",
    "\n",
    "\n",
    "Here we need some insight into the data. The categorical features are:\n",
    "- pclass : the Ticket class\n",
    "- sex : the gender/sex of the passenger \n",
    "- embarked : the port where the passenger embarked from\n",
    "    - C = Cherbourg\n",
    "    - Q = Queenstown\n",
    "    - S = Southampton"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce781030",
   "metadata": {},
   "source": [
    "We encode sex with 0 or 1 and save the mapping we have used to a dictionary so we now how to transform new data we get in future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4816a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Sex[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a31d1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "le_sex = preprocessing.LabelEncoder()\n",
    "le_sex.fit(data.Sex.unique()) # fits a value to each unique integer value of the feature variable sex\n",
    "data['Sex_numeric'] = le_sex.transform(data.Sex) # transform the data from labels to numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b066ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Sex_numeric[0:5] # values are now encoded numerically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5120a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "le_sex.inverse_transform(data.Sex_numeric[0:5]) # and the label encoder lets us reverse this if need be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496fcf29",
   "metadata": {},
   "outputs": [],
   "source": [
    "le_Embarked = preprocessing.LabelEncoder()\n",
    "le_Embarked.fit(data.Embarked.unique()) # fits a value to each unique integer value of the feature variable sex\n",
    "data['Embarked_numeric'] = le_Embarked.transform(data.Embarked) # transform the data from labels to numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243f2119",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_kaggle_data = lr_model.predict(data_kaggle_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe57998a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_kaggle_test.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7142fa29",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('prediction_submission_LR.csv', 'w') as file:\n",
    "    print('PassengerId,Survived', file=file)\n",
    "    for i, id_ in enumerate(data_kaggle_test.index):\n",
    "        print('{},{}'.format(id_, prediction_kaggle_data[i]), file=file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851ee62f",
   "metadata": {},
   "source": [
    "The result is quite variable, but I get scores of 75.1%-77.5% from 4 submissions with different random train/validation/test splits."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af15edf1",
   "metadata": {},
   "source": [
    "## Lets now attempt to train a Support Vector Machine to predict surivival"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d16979",
   "metadata": {},
   "source": [
    "### Feature scaling\n",
    "\n",
    "We will now perform feature scaling on the continous variables, namely Age, SibSp, Parch, and Fare, such that they are all around the same scale. This wasn't so important for logistic regression but IS important for SVMs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ddebfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_age = preprocessing.StandardScaler().fit(data['Age'].reshape(-1, 1))\n",
    "data['Age'] = scaler_age.transform(data['Age'].reshape(-1, 1))\n",
    "\n",
    "scaler_SibSp = preprocessing.StandardScaler().fit(data['SibSp'].reshape(-1, 1))\n",
    "data['SibSp'] = scaler_SibSp.transform(data['SibSp'].reshape(-1, 1))\n",
    "\n",
    "scaler_Parch = preprocessing.StandardScaler().fit(data['Parch'].reshape(-1, 1))\n",
    "data['Parch'] = scaler_Parch.transform(data['Parch'].reshape(-1, 1))\n",
    "\n",
    "scaler_Fare = preprocessing.StandardScaler().fit(data['Fare'].reshape(-1, 1))\n",
    "data['Fare'] = scaler_Fare.transform(data['Fare'].reshape(-1, 1))\n",
    "\n",
    "X_temp, X_test, y_temp, y_test = model_selection.train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "X_train, X_cv, y_train, y_cv = model_selection.train_test_split(X_temp, y_temp, train_size=0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941d42ed",
   "metadata": {},
   "source": [
    "We now perform our feature scaling with the fitted scalers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d7dbe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_kaggle_test['Age'] = scaler_age.transform(data_kaggle_test['Age'].reshape(-1, 1))\n",
    "\n",
    "data_kaggle_test['SibSp'] = scaler_SibSp.transform(data_kaggle_test['SibSp'].reshape(-1, 1))\n",
    "\n",
    "data_kaggle_test['Parch'] = scaler_Parch.transform(data_kaggle_test['Parch'].reshape(-1, 1))\n",
    "\n",
    "data_kaggle_test['Fare'] = scaler_Fare.transform(data_kaggle_test['Fare'].reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2699535",
   "metadata": {},
   "outputs": [],
   "source": [
    "C = 1 # start with penalty parameter equal to 1 as we don't know what value this should take yet, larger C -> lower bias, higher variance, smaller C -> higher bias, lower varaince. Since we don't have that much data a lower bias algorithm is probably best to avoid overfitting\n",
    "\n",
    "kernel = 'linear' # we'll start with a simple linear kernal to see how ths performs\n",
    "\n",
    "svm_model = svm.SVC(C=C, kernel=kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba58ef83",
   "metadata": {},
   "outputs": [],
   "source": [
    "C_array = np.array([0.003, 0.01, 0.02, 0.03, 0.05, 0.1, 0.3, 1, 3])\n",
    "train_score_array = np.zeros_like(C_array)\n",
    "validation_score_array = np.zeros_like(C_array)\n",
    "for i, C in enumerate(C_array):\n",
    "    print(i, C)\n",
    "    svm_model = svm.SVC(C=C, kernel=kernel)\n",
    "    svm_model.fit(X_train, y_train)\n",
    "    train_score_array[i] = svm_model.score(X_train, y_train)\n",
    "    validation_score_array[i] = svm_model.score(X_cv, y_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f71a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(C_array, train_score_array, label='train accuracy')\n",
    "ax.plot(C_array, validation_score_array, label='validation accuracy')\n",
    "ax.semilogx()\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d35462",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We now use scikit learn to fit a regularised logistic regression \n",
    "# model with each of the feature variables being linear\n",
    "# setting fit_intercept=True fits the Theta_0 term - an intercept term\n",
    "\n",
    "lr_model = linear_model.LogisticRegression(fit_intercept=True)\n",
    "\n",
    "# we now fit to the training data\n",
    "lr_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede9d778",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2adfd5ba",
   "metadata": {},
   "source": [
    "We get ~80% accuracy on our training data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445af1b4",
   "metadata": {},
   "source": [
    "We now evaluate our performance on the cross validation data it hasn't seen. We using our cross-validation data instead of our testing data to evaluate the classifier as we are using the cross-validation performance to pick our final algorithm and we don't want to pick an algorithm that happens to work well on the testing data but doesn't generalise well to new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281ecb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model.score(X_cv, y_cv) # this very simple logisitc regression with "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e17822",
   "metadata": {},
   "source": [
    "We get ~80% accuracy, which is very good, lets look at our truth table, precision, recall and f1score values as well to get a better idea what's going on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce02cb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_cv = lr_model.predict(X_cv)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
