{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01c2e4f9",
   "metadata": {},
   "source": [
    "# optimizer-test\n",
    "\n",
    "## Model search on MNIST\n",
    "\n",
    "[MNIST](http://yann.lecun.com/exdb/mnist/) is a dataset of 60,000 handwritten digits for training and 10,000 for testing. It is used as the \"Hello World\" of computer vision and it is a standard dataset for machine learning. Thus, we have chosen it as the first testing ground for our study.\n",
    "\n",
    "## Testing the optimization tools\n",
    "\n",
    "In this notebook, we going to test implementations of the four optimization methods studied:\n",
    "\n",
    "* **Random search:** `hyperopt`.\n",
    "* **Tree of Parzen Estimators (TPE):** `hyperopt`.\n",
    "* **Gaussian Process (GP) SMBO:** `BayesianOptimization`.\n",
    "* **Sequential Model-based Algorithm Configuration (SMAC):** `pysmac`.\n",
    "\n",
    "\n",
    "## Libraries & code\n",
    "\n",
    "Use use pretty much all of the stardard machine learning tools out there. Following are some of the most important: \n",
    "\n",
    "* `pandas`, `scikit-learn`, `XGBoost`, `H2O`, `lasagne`\n",
    "* `Theano`, `scikit-neuralnetwork`, `Auto-sklearn`\n",
    "* `hyperopt`, `numpy`, `scipy`, `seaborn`, `matplotlib`\n",
    "* `BayesianOptimization`, `pysmac`\n",
    "\n",
    "Let us start by importing all libraries and code. We use a base script to write all important functions, including the proposed pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb8063c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# starting up a console attached to this kernel\n",
    "%matplotlib inline\n",
    "%qtconsole\n",
    "import os\n",
    "\n",
    "# importing base code\n",
    "os.chdir('C:\\\\Users\\\\Guilherme\\\\Documents\\\\TCC\\\\tsne-optim\\\\code')\n",
    "from base import *\n",
    "\n",
    "# changing to competition dir\n",
    "os.chdir('C:\\\\Users\\\\Guilherme\\\\Documents\\\\TCC\\\\tsne-optim')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7f6764",
   "metadata": {},
   "source": [
    "## Target Function\n",
    "\n",
    "For this simple demonstration, let's use the function defined at one of the `BayesianOptimization` [examples](https://github.com/fmfn/BayesianOptimization/blob/master/examples/visualization.ipynb):\n",
    "\n",
    "$$f(x) = e^{-(x - 2)^2} + e^{-\\frac{(x - 6)^2}{10}} + \\frac{1}{x^2 + 1} $$ \n",
    "\n",
    "Let us write it in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25eb980",
   "metadata": {},
   "outputs": [],
   "source": [
    "def target(x):\n",
    "    return np.exp(-(x - 2)**2) + np.exp(-(x - 6)**2/10) + 1/ (x**2 + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045e0e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(-2, 10, 1000)\n",
    "y = target(x)\n",
    "plt.figure(figsize=[16,6])\n",
    "plt.plot(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff9ff36",
   "metadata": {},
   "source": [
    "# Optimization algorithms\n",
    "\n",
    "Let us define the optimization objectives and frameworks for each of the optimization methods.\n",
    "\n",
    "## `hyperopt`: Random Search and TPE\n",
    "\n",
    "Let us start with `hyperopt` implementing **Random Search** and **Tree of Parzen Estimators**. We have to make a small modification to the target function for it to work. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80cc3750",
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_hyperopt(space):\n",
    "    return {'loss': -target(space['x']),\n",
    "            'x': space['x'],\n",
    "            'status': STATUS_OK\n",
    "            }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00f2668",
   "metadata": {},
   "source": [
    "Now we have to define the search space, which is just the interval between -2 and 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b982c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "space = {'x': hp.uniform('x',-2,10)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3ba193",
   "metadata": {},
   "source": [
    "Finally, the optimization function. Let us do **Random Search** first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680b79fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# object that is going to carry trial information\n",
    "trials = Trials()\n",
    "\n",
    "# parameters of optim function\n",
    "evals = 100\n",
    "algo = rand.suggest \n",
    "\n",
    "# minimization function\n",
    "fmin(target_hyperopt, space, algo=algo, trials=trials, max_evals=evals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ada8a68",
   "metadata": {},
   "source": [
    "Let us plot the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31270ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting trials\n",
    "x_trials = [e['result']['x'] for e in trials.trials]\n",
    "loss_trials = [-e['result']['loss'] for e in trials.trials]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56fac9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the samples \n",
    "plt.figure(figsize=[16,6])\n",
    "plt.plot(x, y)\n",
    "plt.plot(x_trials, loss_trials, 'ro')\n",
    "plt.title('Objective Samples [Random Search]', fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579f94e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[16,6])\n",
    "plt.plot(loss_trials)\n",
    "plt.title('Loss over rounds [Random Search]', fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720b3edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[16,6])\n",
    "plt.plot(x_trials, 'bo')\n",
    "plt.title('Candidate solutions [Random Search]',fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8bca862",
   "metadata": {},
   "source": [
    "Let us try **TPE** now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa85dec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# object that is going to carry trial information\n",
    "trials = Trials()\n",
    "\n",
    "# parameters of optim function\n",
    "evals = 100\n",
    "algo = tpe.suggest \n",
    "\n",
    "# minimization function\n",
    "fmin(target_hyperopt, space, algo=algo, trials=trials, max_evals=evals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd5247e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the samples \n",
    "plt.figure(figsize=[16,6])\n",
    "plt.plot(x, y)\n",
    "plt.plot(x_trials, loss_trials, 'ro')\n",
    "plt.title('Objective Samples [TPE]', fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f58bc22",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[16,6])\n",
    "plt.plot(loss_trials)\n",
    "plt.title('Loss over rounds [TPE]', fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc845698",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[16,6])\n",
    "plt.plot(x_trials, 'bo')\n",
    "plt.title('Candidate solutions [TPE]',fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b232a0a3",
   "metadata": {},
   "source": [
    "**TPE** does explore less the unpromising areas of the function than **Random Search**, and it looks like it changes its behavior in steps of 20 samples. being more focused as time passes. Let us move to **SMAC**!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3fbed1",
   "metadata": {},
   "source": [
    "## `pysmac`: SMAC\n",
    "\n",
    "`pysmac` is a Python wrapper for the Sequential Model-based Algorithm Configuration [library](http://www.cs.ubc.ca/labs/beta/Projects/SMAC/). It works roughly the same way as the previous algortihms. We need to define search bounds and a initial point for each parameter (in our case it's only `x`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4ad342",
   "metadata": {},
   "outputs": [],
   "source": [
    "# module\n",
    "import pysmac\n",
    "\n",
    "# initial point and search space\n",
    "init_x = random.uniform(-2,10)\n",
    "space = {'x': ('real', [-2, 10], init_x)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d74ddb",
   "metadata": {},
   "source": [
    "Next we define the optimization function and run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eccc8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optim object\n",
    "opt = pysmac.SMAC_optimizer(working_directory='output/smac')\n",
    "\n",
    "# target for SMAC\n",
    "def target_smac(x):\n",
    "    return(-target(x))\n",
    "\n",
    "# minimizing\n",
    "value, space = opt.minimize(target_smac, 100, space)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e8ee53",
   "metadata": {},
   "source": [
    "Let us visualize! It is a bit more complicated to get the trials from SMAC, as it is saved in a output file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0e2ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading SMAC trials file\n",
    "smac_trials = pd.read_csv('output/smac/out/scenario/state-run0/runs_and_results-it36.csv')\n",
    "\n",
    "# reading parameter trials\n",
    "from pysmac.utils.smac_output_readers import read_paramstrings_file\n",
    "param_trials = read_paramstrings_file('output/smac/out/scenario/state-run0/paramstrings-it36.txt')\n",
    "x_trials = [float(e['x']) for e in param_trials]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dfaef8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the samples \n",
    "plt.figure(figsize=[16,6])\n",
    "plt.plot(x, y)\n",
    "plt.plot(x_trials, -smac_trials['Response Value (y)'], 'ro')\n",
    "plt.title('Objective Samples [SMAC]', fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed61903a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[16,6])\n",
    "plt.plot(-smac_trials['Response Value (y)'])\n",
    "plt.title('Loss over rounds [SMAC]', fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5deac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[16,6])\n",
    "plt.plot(x_trials, 'bo')\n",
    "plt.title('Candidate solutions [SMAC]',fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfbafec4",
   "metadata": {},
   "source": [
    "**SMAC** does more exploration around local (and global) maxima. It was very effective. Now, to the last method, **Gaussian Processes**!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e824709a",
   "metadata": {},
   "source": [
    "## `BayesianOptimization`: Gaussian Processes\n",
    "\n",
    "With `BayesianOptimization` we can use Gaussian Processes to optimize functions. The first thing we need to do is define search bounds for the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c40c12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing\n",
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "# defining bounds\n",
    "bounds = {'x': (-2, 10)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301aefac",
   "metadata": {},
   "source": [
    "Then, we create the optimization task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9d173e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bo = BayesianOptimization(target, bounds, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffbdca93",
   "metadata": {},
   "source": [
    "And finally define the optimization parameters and execute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f21691",
   "metadata": {},
   "outputs": [],
   "source": [
    "bo.maximize(init_points=2, n_iter=30, acq='ucb', kappa=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4ac7ed",
   "metadata": {},
   "source": [
    "Let's visualize!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c7db96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the samples \n",
    "plt.figure(figsize=[16,6])\n",
    "plt.plot(x, y)\n",
    "plt.plot(bo.X, bo.Y, 'ro')\n",
    "plt.title('Objective Samples [Gaussian Process]', fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8540cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[16,6])\n",
    "plt.plot(bo.Y)\n",
    "plt.title('Loss over rounds [Gaussian Process]', fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5023e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[16,6])\n",
    "plt.plot(bo.X, 'bo')\n",
    "plt.title('Candidate solutions [Gaussian Process]',fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdec6be5",
   "metadata": {},
   "source": [
    "Remarkable! **GP's** do estimate very well the target function. Let us see the function it came up with."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
