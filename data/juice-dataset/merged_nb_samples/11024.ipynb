{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "635d8c0d",
   "metadata": {},
   "source": [
    "## Object-oriented KMeans Clustering implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84cf28d8",
   "metadata": {},
   "source": [
    "In this repo is an implementation of the KMeans clustering algorithm using an object oriented approach, vaguely in the style of **SKlearn**.\n",
    "\n",
    "The KMeans algorithm is an unsupervised learning technique for clustering similar data points. \n",
    "\n",
    "The algorithm is as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba6bae8",
   "metadata": {},
   "source": [
    "\n",
    "  1. Initialize K centroids by choosing K random samples from the data\n",
    "  2. For each data point:\n",
    "    - Calculate distance to each centroid\n",
    "    - Assign the point to the centroid to which it has the lowest distance\n",
    "  3. Update each centroid to the mean location of all the data points assigned to it\n",
    "  \n",
    "This algorithm is then repeated a given number of times, or until the algorithm converges.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c13fff9",
   "metadata": {},
   "source": [
    "## Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c084ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from kmeans import kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7ca975",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load sample data (the iris data set)\n",
    "X = datasets.load_iris().data\n",
    "y = datasets.load_iris().target\n",
    "\n",
    "# Split into training and testing data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ee564c",
   "metadata": {},
   "source": [
    "With the data loaded, we can initialize and train the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94041151",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = kmeans.Kmeans(k=10,\n",
    "                      num_iter=100,\n",
    "                      dist_func=kmeans.euclidean_dist,\n",
    "                      random_state=10,\n",
    "                      score=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad69a18",
   "metadata": {},
   "source": [
    "Note that the above are all defaults, so the algorithm can be more succinctly initialized as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3218838",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = kmeans.Kmeans(k=3, random_state=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2b4eaa",
   "metadata": {},
   "source": [
    "We then fit the model using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c358a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbebb777",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing the model displays the final error (sum of squared errors)\n",
    "# and the number of iterations until the model converged\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695e0415",
   "metadata": {},
   "source": [
    "We can make predictions on new data using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7fa502",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(X_test)\n",
    "preds[1:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86426fd",
   "metadata": {},
   "source": [
    "### Visualization of Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943e9037",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b3b262",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#Make the cluster labels match - due to the unsupervised nature, labels are not\n",
    "# identical, even if the clusters are correct\n",
    "y_train = np.where(y_train == 2, 1,\n",
    "                 np.where(y_train == 0, 0, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6de317",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, (ax1, ax2) = plt.subplots(1, 2, sharey=True, figsize=(14, 6))\n",
    "ax1.scatter(x=X_train[:,0], y=X_train[:,1], c=model.results, cmap=\"viridis\")\n",
    "ax1.set_title('KMeans Cluster Result')\n",
    "ax2.scatter(x=X_train[:,0], y=X_train[:,1], c=y_train, cmap=\"viridis\")\n",
    "ax2.set_title('Actual Clusters');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039c6130",
   "metadata": {},
   "source": [
    "Finally, we can visualize the convergence of the algorithm by using the `score` parameter. This will calculate the sum of the squared error at each iteration:"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
