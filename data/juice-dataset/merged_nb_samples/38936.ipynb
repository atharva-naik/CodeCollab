{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00e1ba38",
   "metadata": {},
   "source": [
    "# Behavioral_Cloning_Pipeline_based_on_Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e6d4c3",
   "metadata": {},
   "source": [
    "This pipeline contains the following steps:\n",
    "\n",
    "* Reading & Loading the Collected Data: my dataset is based on (1- Udacity collected dataset 2- Recovery data helps the model to get back to the center of the lane when it gets into the road ledges).\n",
    "\n",
    "* Data Preprocessing: consists of three main steps (1- Cropping the top and bottom redundant segments of each image as they alwas contain unuseful data. 2- Resizing each image to suite the model expected input shape (66,200,3)   3- Converting the image color space into YUV space as Nvidia paper recommends this.)\n",
    "\n",
    "* Data Augmentation: consists of two main steps (1- Data Flipping. 2- Random Shadding).\n",
    "\n",
    "* Data Visulaizing: Exploring random samples of the preprocessed data and assuring the dataset balancing.\n",
    "\n",
    "* Data Batching: Python generators provide us with a very powerful utility that we can load a specified batch of data only when we're in need for it, (i.e so no need to load all the data set at the same time as this is most likely will not fit into our memory so we just load a specified batch on a fly!)\n",
    "\n",
    "* Model Training: I've implemented the architecture mentioned in this paper.\n",
    "\n",
    "* Model Validation: 20% of the collected data to be considered as validation set.\n",
    "\n",
    "* Visualizing both of training & validation loss to make sure that the model doesn't suffer from overfitting or underfitting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b9d4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing the necessary libs\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import cv2\n",
    "import sklearn\n",
    "import random, pylab\n",
    "import matplotlib\n",
    "import matplotlib.image as mpimg\n",
    "#import keras\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import img_to_array, load_img\n",
    "\n",
    "from skimage.exposure import equalize_adapthist\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure, imshow, axis\n",
    "%matplotlib inline\n",
    "\n",
    "import os, sys\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd5f8fc",
   "metadata": {},
   "source": [
    "# Data Preprocessing & Augmentation APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3a0fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Resizing API\n",
    "def img_resize(img):\n",
    "    \n",
    "    resized_img = cv2.resize(img, (img_width,img_height))\n",
    "    return resized_img\n",
    "\n",
    "## Cropping API\n",
    "def img_crop(img):\n",
    "    cropped_img = img[50:140,:,:] ## This should trim the top 50 rows and the bottom 20 rows of each image.\n",
    "    return cropped_img\n",
    "\n",
    "## Changing Colorspace\n",
    "def YUV_convert(img):\n",
    "    YUV_img = cv2.cvtColor(img, cv2.COLOR_RGB2YUV) ## \n",
    "    return YUV_img\n",
    "\n",
    "def random_shadow(img):\n",
    "    \"\"\"\n",
    "    Applying dark shadow to random segments of the image.\n",
    "        Parameters:\n",
    "            image: The input image.\n",
    "    \"\"\"\n",
    "    if(np.random.uniform(0,1) > 0.4): ## This should randomly shade only 50% of data\n",
    "        \n",
    "        img_height, img_width = img.shape[0], img.shape[1]\n",
    "        [x1, x2] = np.random.choice(img_width, 2, replace=False)\n",
    "        k = img_height / (x2 - x1)\n",
    "        b = - k * x1\n",
    "        for i in range(img_height):\n",
    "            c = int((i - b) / k)\n",
    "            img[i, :c, :] = (img[i, :c, :] * .5).astype(np.int32)\n",
    "    return img\n",
    "\n",
    "def horizontal_flip(img, steer):\n",
    "    \"\"\"\n",
    "    Flipping the images horizontally to aaugment the curved images.\n",
    "        Parameters:\n",
    "            image: The input image.\n",
    "    \"\"\"\n",
    "    \n",
    "    vertical_img = cv2.flip( img, 1 ) ## This should produce mirrored images\n",
    "    steer = -steer\n",
    "    return vertical_img, steer\n",
    "\n",
    "def random_brightness(image):\n",
    "    \"\"\"\n",
    "    Altering the brightness of the input image.\n",
    "        Parameters:\n",
    "            image: The input image.\n",
    "    \"\"\"\n",
    "    # HSV (Hue, Saturation, Value) is also called HSB ('B' for Brightness).\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "    ratio = 1.0 + (np.random.rand() - 0.5)\n",
    "    hsv[:,:,2] =  hsv[:,:,2] * ratio\n",
    "    return cv2.cvtColor(hsv, cv2.COLOR_HSV2RGB)\n",
    "\n",
    "def random_transform(image, steering_angle):\n",
    "    \"\"\"\n",
    "    Applying random translation to the image.\n",
    "        Parameters:\n",
    "            image: The input image.\n",
    "    \"\"\"\n",
    "    range_x = 100\n",
    "    range_y = 10\n",
    "    if(np.random.uniform(0,1) > 0.5):\n",
    "        trans_x = range_x * (np.random.rand() - 0.5)\n",
    "        trans_y = range_y * (np.random.rand() - 0.5)\n",
    "        steering_angle += trans_x * 0.002\n",
    "        trans_m = np.float32([[1, 0, trans_x], [0, 1, trans_y]])\n",
    "        height, width = image.shape[:2]\n",
    "        image = cv2.warpAffine(image, trans_m, (width, height))    \n",
    "    #if(np.random.uniform(0,1) > 0.2):\n",
    "    #    image = random_brightness(image)    \n",
    "    return image, steering_angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde906cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sets the plts font\n",
    "\n",
    "font = {'family' : 'normal',\n",
    "        'weight' : 'bold',\n",
    "        'size'   : 22}\n",
    "\n",
    "matplotlib.rc('font', **font)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59fd9005",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This processing is applied to each frame before passing it to the model either for taining or testing\n",
    "\n",
    "Firstly, I've used grayscale image with CLAHE Histogram for contrast enhancement firstly but it showed poor performance \n",
    "on the data, then ended up using YUV color space which showed up a very stable & correct steers along the track. \n",
    "\"\"\"\n",
    "def image_preprocess(img):\n",
    "    \n",
    "    cropped_img = img_crop(img)\n",
    "    resized_img = img_resize(cropped_img)\n",
    "    YUV_img = YUV_convert(resized_img)\n",
    "    #gray = cv2.cvtColor(resized_img, cv2.COLOR_RGB2GRAY)\n",
    "    #gray = np.asarray(gray)\n",
    "    #eulized_img = equalize_adapthist(gray)\n",
    "    #eulized_img = np.reshape(np.ravel(eulized_img), (66, 200, 1))\n",
    "    return YUV_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f58404",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Displaying random samples of any data set with their corresponding lables\n",
    "\n",
    "Parameters: Images dataset , Labels as file names.\n",
    "\"\"\"\n",
    "def display_DataSample(dataSet, file_names):\n",
    "    fig = plt.figure(figsize=(50, 50))  \n",
    "    for i in range(10): \n",
    "        index = random.randint(0, (len(dataSet)-1))\n",
    "        image = dataSet[index].squeeze()\n",
    "        \n",
    "        sub = fig.add_subplot(5, 2, i+1)\n",
    "        sub.imshow(image, interpolation='nearest')\n",
    "        plt.title(file_names[index])\n",
    "       \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a2dc82",
   "metadata": {},
   "source": [
    "# Data Extractor API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32729aa2",
   "metadata": {},
   "source": [
    "* This API is responsible for extracting the center,left and right images with their names and their corresponsing steering angles for any given random driving log using randomData_Display() wrapper.\n",
    "\n",
    "* I've implemented this API to help me extracting any data in order to preprocess them or visualize any related statistics of them (i.e. This API is almost similar to the generator used in the training below but I've used it as an independent utility to extract data randomly).\n",
    "\n",
    "* Also it contains the data augmentation steps which are (1- Flipping all the images with non-zero steering angles and augment the data by the flipped images (i.e. Because flipping images with zero steering angles doesn't seem to help.) 2- Randomly Shadding 50% of the collected images and augment the data by the shaded images.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1353ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data Extractor API\n",
    "\"\"\"\n",
    "This function acts as a generator but only for extarcting data for exploration and visualization not for training.\n",
    "Parameters: Random Data Patch (Images & Steers &Labels)\n",
    "\"\"\"\n",
    "def data_extractor(random_batch):\n",
    "    \n",
    "    car_images=[]\n",
    "    steering_angles=[]\n",
    "    file_names = []  \n",
    "    \n",
    "    for batch_sample in random_batch:\n",
    "                    \n",
    "                    \n",
    "                   \n",
    "        ### Center Camera Data\n",
    "        batch_sample_center = batch_sample[0]\n",
    "        redund_path_center, filename_center = os.path.split(batch_sample_center)\n",
    "        \n",
    "        current_path_center = 'Udacitydata/data/IMG/' + filename_center\n",
    "        image_center = mpimg.imread(current_path_center)\n",
    "        \n",
    "        steering_center = float(batch_sample[3])\n",
    "        correction = 0.2\n",
    "        \n",
    "        if image_center is not None:\n",
    "            \"\"\"\n",
    "            Augmenting our data by the left & right camera images don't produce useful data when the\n",
    "            steering angle is zero.\n",
    "            \"\"\"\n",
    "            if(steering_center == 0):\n",
    "                if(np.random.uniform(0,1) > 0.95): #Dataset Balancing\n",
    "                    car_images.append(image_center)\n",
    "                    steering_angles.append(steering_center)\n",
    "                    file_names.append(filename_center)\n",
    "                    \n",
    "                    shaded_img_center = random_shadow(image_center)\n",
    "                    car_images.append(shaded_img_center)\n",
    "                    steering_angles.append(steering_center)\n",
    "                    file_names.append(filename_center+' \"shaded\"')\n",
    "            \n",
    "            \n",
    "        \n",
    "            \n",
    "                \n",
    "            if(steering_center != 0):\n",
    "                car_images.append(image_center)\n",
    "                steering_angles.append(steering_center)\n",
    "                file_names.append(filename_center)\n",
    "                \n",
    "                flipped_image_center, flipped_steering_center = horizontal_flip(image_center, steering_center)\n",
    "            \n",
    "                \n",
    "                car_images.append(flipped_image_center)\n",
    "                steering_angles.append(flipped_steering_center)\n",
    "                file_names.append(filename_center+' \"flipped\"')\n",
    "                \n",
    "                shaded_img_center = random_shadow(image_center)\n",
    "                car_images.append(shaded_img_center)\n",
    "                steering_angles.append(steering_center)\n",
    "                file_names.append(filename_center+' \"shaded\"')\n",
    "                \n",
    "                #bright_img_center, steering_center_center = random_transform(image_center, steering_center)\n",
    "                #car_images.append(bright_img_center)\n",
    "                #steering_angles.append(steering_center_center)\n",
    "        \n",
    "        \n",
    "        if(steering_center != 0):\n",
    "        \n",
    "            ### Left Camera Data\n",
    "            batch_sample_left = batch_sample[1]\n",
    "            redund_path_left, filename_left = os.path.split(batch_sample_left)\n",
    "            current_path_left = 'Udacitydata/data/IMG/' + filename_left\n",
    "            image_left = mpimg.imread(current_path_left)\n",
    "            \n",
    "            \n",
    "            # create adjusted steering measurements for the side camera images\n",
    "            # this is a parameter to tune\n",
    "            steering_left = steering_center + correction\n",
    "            \n",
    "            if image_left is not None:\n",
    "                car_images.append(image_left)\n",
    "                steering_angles.append(steering_left)\n",
    "                file_names.append(filename_left)\n",
    "                \n",
    "                shaded_img_left = random_shadow(image_left)\n",
    "                car_images.append(shaded_img_left)\n",
    "                steering_angles.append(steering_left)\n",
    "                file_names.append(filename_left+' \"shaded\"')\n",
    "                \n",
    "                flipped_image_left, flipped_steering_left = horizontal_flip(image_left, steering_left)\n",
    "                    \n",
    "                car_images.append(flipped_image_left)\n",
    "                steering_angles.append(flipped_steering_left)\n",
    "                file_names.append(filename_left+' \"flipped\"')\n",
    "                \n",
    "                #bright_img_left, steering_left_left = random_transform(image_left, steering_left)\n",
    "                #car_images.append(bright_img_left)\n",
    "                #steering_angles.append(steering_left_left)\n",
    "                \n",
    "            ### Right Camera Data         \n",
    "            batch_sample_right = batch_sample[2]\n",
    "            redund_path_right, filename_right = os.path.split(batch_sample_right)\n",
    "            current_path_right = 'Udacitydata/data/IMG/' + filename_right\n",
    "            image_right = mpimg.imread(current_path_right)\n",
    "            \n",
    "            \n",
    "            # create adjusted steering measurements for the side camera images\n",
    "            # this is a parameter to tune\n",
    "            steering_right = steering_center - correction\n",
    "        \n",
    "            if image_right is not None:\n",
    "                car_images.append(image_right)\n",
    "                steering_angles.append(steering_right)\n",
    "                file_names.append(filename_right)\n",
    "                \n",
    "                shaded_img_right = random_shadow(image_right)\n",
    "                car_images.append(shaded_img_right)\n",
    "                steering_angles.append(steering_right)\n",
    "                file_names.append(filename_right+' \"shaded\"')\n",
    "                \n",
    "                flipped_image_right, flipped_steering_right = horizontal_flip(image_right, steering_right)\n",
    "                 \n",
    "                    \n",
    "                car_images.append(flipped_image_right)\n",
    "                steering_angles.append(flipped_steering_right)\n",
    "                file_names.append(filename_right+' \"flipped\"')\n",
    "                        \n",
    "                    \n",
    "                            \n",
    "                        \n",
    "        \n",
    "        \n",
    "    return car_images, steering_angles, file_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab44f3f",
   "metadata": {},
   "source": [
    "# Displaying Random Data From a Given Batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d0d0e9",
   "metadata": {},
   "source": [
    "This API acts as a wrapper abstracting the user from data_extractor() API directly, as it randomly selects random samples from the given data batch and then calls data_extractor() API to handle the useful data extraction then calls display_DataSample() to display the images with their corresponding labels.\n",
    "\n",
    "\n",
    "<img src=\"behClon.png\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb6f319",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This API acts as warapper which calls data_extractor() to load the data and then display them using display_DataSample()\n",
    "Parameters: Data Patch (Images & Steers &Labels).\n",
    "\"\"\"\n",
    "def randomData_Display(sampleData):\n",
    "    \n",
    "    random_batch=[]\n",
    "    \n",
    "    for smapleCntr in range(100): ## 100 is adjustable range for the random samples to be selected\n",
    "        index = random.randint(0, len(sampleData))\n",
    "        random_batch.append(sampleData[index])\n",
    "    \n",
    "    img_list, steers_list, file_names = data_extractor(random_batch) ## Data Extraction\n",
    "    \n",
    "    img_list_prep = list(map(image_preprocess, img_list)) ## In order to visualize the preprocessing results\n",
    "    display_DataSample(img_list_prep, file_names)\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9cb2d96",
   "metadata": {},
   "source": [
    "# Dataset Balance Explorer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39520c7c",
   "metadata": {},
   "source": [
    "This API explores the representation of each steering value in the dataset (Note that: we've taken steps to balance the dataset in the data_extractor() API)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9858cee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This API diplays the histogram of the passed data set in order to explore the data set balancing.\n",
    "You'll observe that the both training and validation data sets are fairly balanced here as I've taken steps to balance them\n",
    "through down sampling the zero steers images representations in both datasets.\n",
    "\"\"\"\n",
    "def dataset_distribution(datasample):\n",
    "    \n",
    "    img_list, steers_list, file_name = data_extractor(datasample)\n",
    "\n",
    "    fig=plt.figure()\n",
    "    dataset = fig.add_subplot(1,1,1)\n",
    "    \n",
    "    #Axes Data\n",
    "    dataset.hist( steers_list ,bins = 30, rwidth = 0.6) \n",
    "    \n",
    "    #Labels and Tit\n",
    "    plt.title('Steering Angles Distribution')\n",
    "    plt.xlabel('Steering Angel Value')\n",
    "    plt.ylabel('Representation in the Data set')\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb8347d",
   "metadata": {},
   "source": [
    "# Reading & Loading the Collected Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d8bbe4",
   "metadata": {},
   "source": [
    "# Data Visulaizing & Exploring Dataset Balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459c2672",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "lines = []\n",
    "\n",
    "with open('Udacitydata/data/driving_log.csv') as csvfile: \n",
    "    training_readings = csv.reader(csvfile)\n",
    "\n",
    "\n",
    "    for line in training_readings:\n",
    "        lines.append(line)\n",
    "\n",
    "train_samples, validation_samples = train_test_split(lines, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ee134e",
   "metadata": {},
   "outputs": [],
   "source": [
    "randomData_Display(train_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a968375",
   "metadata": {},
   "outputs": [],
   "source": [
    "randomData_Display(validation_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa26c8d",
   "metadata": {},
   "source": [
    "# Dataset Before Balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6fc7d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The original data set histogram\n",
    "\"\"\"\n",
    "dataset_distribution(train_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c3973b",
   "metadata": {},
   "source": [
    "# Dataset After Balancing"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
