{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f4dbeaa",
   "metadata": {},
   "source": [
    "# Introduction to Machine Learning Code Supplement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90053a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_selection import VarianceThreshold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83c0d15",
   "metadata": {},
   "source": [
    "## Exercises: What type of ML could you use to approach these problems?\n",
    "\n",
    "Note: for some of these, there's no one right answer! It's all about how you frame the specific problem. Discuss with the person next to you."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1234f493",
   "metadata": {},
   "source": [
    "1) Suppose you wanted to make a robot that can avoid colliding with other objects. What kind of learning? (supervised, unsupervised, etc.) Would you use classification or regression?  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75aa02e9",
   "metadata": {},
   "source": [
    "2) Suppose that given an audio file, you want to figure out if the person is saying 'cat' or 'dog'. What kind of learning? (supervised, unsupervised, etc.) Would you use classification or regression?  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0603e8",
   "metadata": {},
   "source": [
    "3) Suppose you wanted to make an AI that can find some trends in numerical galaxy data. You're not sure what trends you want, but you really just want to let your AI run wild! What kind of learning? (supervised, unsupervised, etc.) Would you use classification or regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d76ae21",
   "metadata": {},
   "source": [
    "## Feature Selection\n",
    "\n",
    "Feature selection is very important because if we put unhelpful, noisy data in, then we're going to get strange results. By using feature selection, the model trains faster, and can improve its accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719429ac",
   "metadata": {},
   "source": [
    "### Qualitative Feature Selection Example: Cancer Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8cc14c",
   "metadata": {},
   "source": [
    "Suppose that given a specific person, we're trying to predict whether or not they have cancer. Below are a list of potential features.\n",
    "\n",
    "Tumor Size  \n",
    "Gender  \n",
    "Location of Tumor\n",
    "Address of the Hospital where a Patient is Treated  \n",
    "Hospital Name (where Patient was Diagnosed)\n",
    "\n",
    "Which features would you keep? Which features would you drop?  \n",
    "Discuss with the person next to you."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301d0ace",
   "metadata": {},
   "source": [
    "## Evaluating Our Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869b7f5e",
   "metadata": {},
   "source": [
    "### What does our data look like?\n",
    "\n",
    "Continuing with our cancer example, let's look at a standard breast cancer dataset and practice evaluating a classification model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996b25fb",
   "metadata": {},
   "source": [
    "#### Practice\n",
    "\n",
    "Your task is to define the 'recall' variable in terms of num_true_pos and num_false_neg. Remember that recall = (true positive)/(true positive + false negative)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b720ef83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Define variable 'recall' in terms of num_true_pos and num_false_neg.\n",
    "recall = 0\n",
    "print(\"Recall:\")\n",
    "print(recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edabdcbe",
   "metadata": {},
   "source": [
    "### F1\n",
    "\n",
    "The formula for calculating F1 is 2 x (precision x recall)/(precision + recall).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33749f76",
   "metadata": {},
   "source": [
    "#### Practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fec8baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Define f1 in terms of the precision and recall variables.\n",
    "f1 = 0\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423c4558",
   "metadata": {},
   "source": [
    "## Questions\n",
    "\n",
    "1. Given that we're doing a cancer detection task, which error is worse: a false positive (reporting that a tumor is malignant when it actually isn't) or a false negative (reporting that a tumor is benign when it's not)?  \n",
    "\n",
    "\n",
    "2. Precision is best for when it's really bad to have false positives, and recall is the best for when it's bad to have false negatives. Given your answer from above and our precision or recall score, how do you think the model is doing? (5 = amazingly, 1 = very poor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805e039c",
   "metadata": {},
   "source": [
    "### Optional--Quantitative Feature Selection\n",
    "\n",
    "Quantitative feature selection is less important than the qualitative version, yet it is still interesting! It is used for optimizing and getting your code to run faster by dropping pieces of data that don't tell you much about the outcome you're trying to predict."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fdf67a5",
   "metadata": {},
   "source": [
    "### Variance Threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3334fa03",
   "metadata": {},
   "source": [
    "The idea behind a Variance Threshold is that if a feature doesn't change very much in our dataset, then it must not be useful for predicting something. In other words, if it has a low variance, then it's unimportant.  \n",
    "\n",
    "An example is if we're trying to predict an elephant's age, and every elephant in our dataset has a trunk. Therefore, knowing that a given elephant has a trunk doesn't tell us anything about its age, and that feature can be dropped."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be2b314",
   "metadata": {},
   "source": [
    "In order to make one of the columns useless, let's just always keep the second column a 5.\n",
    "This way, that column really doesn't tell us anything about the data, since it never changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc908446",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [[0,5,0], [1,5,2], [3,5,7], [2,5,6], [11,5,135], [12,5,16], [1355,5,1356868]]\n",
    "\n",
    "# Print X\n",
    "\n",
    "for i in range(0, len(X)):\n",
    "    for j in range(0, len(X[i])):\n",
    "        print(X[i][j], end = \" \")\n",
    "    print('')\n",
    "    \n",
    "# Note that the second column always stays the same!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ab2806",
   "metadata": {},
   "source": [
    "Variance is the measure of how much a number changes. If we set our threshold to 0.2, then any column with variance <= 0.2 will be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3bb4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer = datasets.load_breast_cancer() # Load the cancer dataset from scikit-learn\n",
    "\n",
    "print(\"Feature Names\")\n",
    "print(cancer.feature_names) # These are all the different features in the dataset. Would you consider dropping \n",
    "# one of these features?\n",
    "print('')\n",
    "\n",
    "print(\"Names of Classes\")\n",
    "print(cancer.target_names)\n",
    "# We find that either a tumor is 'malignant' or it is 'benign'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35633a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, let's plot our data and see if we see any correlation between two features!\n",
    "\n",
    "X = cancer.data\n",
    "y = cancer.target\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.Set1,\n",
    "            edgecolor='k')\n",
    "plt.xlabel('Mean radius')\n",
    "plt.ylabel('Mean texture')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3899a23",
   "metadata": {},
   "source": [
    "Do you see any clear data trends? Plotting helps machine learning researchers get a feel for what the data looks like. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6b6245",
   "metadata": {},
   "source": [
    "### Evaluating the Model\n",
    "\n",
    "Now, let's make a decision tree model which, given an arbitrary tumor, identifies whether it is malignant or benign.\n",
    "\n",
    "We want to figure out how well it is doing. Don't worry too much if some of the code goes over your head; the main focus is on evaluating our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f927e936",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = DecisionTreeClassifier()\n",
    "X = cancer.data # X, what we're using to predict, is the features\n",
    "y = cancer.target # y, what we're predicting, is the classes\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20) # We split the data into 'train' and 'test'\n",
    "classifier.fit(X_train, y_train) # Put these into the classifier\n",
    "prediction = classifier.predict(X_test)\n",
    "# Note that these predictions aren't necessarily correct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8adf6033",
   "metadata": {},
   "source": [
    "### Accuracy\n",
    "\n",
    "The accuracy, as we normally think of it, is defined as the number of correct predictions / total predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7728283",
   "metadata": {},
   "source": [
    "#### Calculating the Correct and Total Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6355a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From scratch way\n",
    "\n",
    "correct = [] # This list stores every prediction that was correct\n",
    "for i in range(0, len(y_test)): # Iterate through all of our predictions\n",
    "        if (y_test[i] == prediction[i]): # If our prediction matches the actual value,\n",
    "            correct.append(y_test[i]) # then put it in the 'correct' list\n",
    "\n",
    "num_correct = len(correct)\n",
    "num_pred = len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc08ffe5",
   "metadata": {},
   "source": [
    "#### Practice\n",
    "\n",
    "Using the accuracy formula, define accuracy in terms of num_correct and num_pred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b86edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "accuracy = 0\n",
    "# Our accuracy is defined by the number of \n",
    "print(\"Accuracy:\")\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3150155d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A faster way is to do it with a built-in function, accuracy_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Accuracy:\")\n",
    "accuracy_score(y_test, prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba173cfc",
   "metadata": {},
   "source": [
    "### Precision\n",
    "\n",
    "The formula for precision is (true positive)/(true positive + false positive)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe41805",
   "metadata": {},
   "source": [
    "#### Calculating the Number of True Positives\n",
    "\n",
    "\n",
    "A true positive is a tumor prediction that says 'malignant' and matches with the correct value (in y_test).\n",
    "Note: 1 = 'malignant' and 0 = 'benign'\n",
    "To calculate the number of true positives, let's iterate through and find predictions that are both 'malignant' and correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affa09b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_positive = []\n",
    "for i in range(0, len(y_test)): # Iterate through all of our predictions\n",
    "        if (prediction[i] == 1 and y_test[i] == prediction[i]): # If we predict malignant and our prediction is correct\n",
    "            true_positive.append(y_test[i]) # then this prediction is a true positive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b5f509",
   "metadata": {},
   "source": [
    "#### Calculating the Number of False Positives\n",
    "\n",
    "A false positive is a tumor prediction that says 'malignant' and does NOT match with the correct value (in y_test). To calculate the number of false positives, let's go through all of our predictions and see which ones are 'malignant' and don't match their correct values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca03c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "false_positive = []\n",
    "for i in range(0, len(y_test)): # Iterate through all of our predictions\n",
    "        if (prediction[i] == 1 and y_test[i] != prediction[i]): # If we predict malignant and our prediction is incorrect\n",
    "            false_positive.append(y_test[i]) # then this prediction is a false positive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24a09a2",
   "metadata": {},
   "source": [
    "Now we define num_true_pos as the length of the true positives list, and num_false_pos similarly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e3936c",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_true_pos = len(true_positive)\n",
    "num_false_pos = len(false_positive)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7317126c",
   "metadata": {},
   "source": [
    "#### Practice\n",
    "\n",
    "Your task is to now use num_true_pos and num_false_pos to calculate the precision, with our formula: precision = (true positive)/(true positive + false positive)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f714e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Define variable 'precision' in terms of num_true_pos and num_false_pos, using our formula.\n",
    "precision = 0\n",
    "\n",
    "print(\"Precision: \")\n",
    "print(precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d19f485",
   "metadata": {},
   "source": [
    "### Recall\n",
    "\n",
    "The formula for recall is (true positive)/(true positive + false negative).  \n",
    "We can use the true_positive array from earlier, so now all we have to calculate is a false_negative."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db43ba48",
   "metadata": {},
   "source": [
    "#### Calculating False Negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd19496",
   "metadata": {},
   "outputs": [],
   "source": [
    "false_negative = []\n",
    "for i in range(0, len(y_test)):\n",
    "    if (prediction[i] == 0 and y_test[i] != prediction[i]):\n",
    "        false_negative.append(y_test[i])\n",
    "\n",
    "num_false_neg = len(false_negative)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
