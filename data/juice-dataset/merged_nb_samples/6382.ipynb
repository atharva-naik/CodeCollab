{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b428fb1",
   "metadata": {},
   "source": [
    "# Classification with 2017 and 2018 team stats\n",
    "\n",
    "In this notebook, we will perform classification with the team statistics data from the 2016-2017 and 2017-2018 season. More specifically, we will apply first apply a PCA with 7 components on 2016-2017 team data. We will then train the transformed on some of the 2016-2017 data using different machine learning classification techniques. We will try to find the classification algorithm that when trained on the 2016-2017 data, has the greatest accuracy and smallest training time. The following table summarizes what we will find in this notebook.\n",
    "\n",
    "| Method | Approximate Training time | '16-'17 percent accuracy | '17-'18 percent accuracy |\n",
    "| :-----------------------------------------: | ------------------- | ----------------------------- | ------------------------- |\n",
    "| Logistic Regression | $0.007$ sec | $79.0\\%$ | $76.3\\%$ |\n",
    "| Decision Tree | $0.014$ sec | $67.2\\%$ | $65.6\\%$ |\n",
    "| Support Vector Machine | $1$ hr $25$ min | $77.7\\%$ | $75.0\\%$ |\n",
    "| Random Forest | $0.046$ sec | $73.4\\%$ | $70.5\\%$ |\n",
    "| Gradient Tree Boosting | $0.934$ sec | $75.2\\%$ | $72.3\\%$ |\n",
    "| k-Nearest Neighbors (k-NN)| $0.004$ sec | $70.5\\%$ | $68.8\\%$ |\n",
    "| Voting (k-NN, Log. Reg., and Ran. For.) | $0.049$ sec | $76.3\\%$ | $75.0\\%$ | \n",
    "\n",
    "\n",
    "\n",
    "We begin by importing some necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc06c116",
   "metadata": {},
   "outputs": [],
   "source": [
    "% matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns',None)\n",
    "from pandas.util.testing import assert_frame_equal\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams.update({'axes.titlesize' : 20,\n",
    "                     'axes.labelsize' : 18,\n",
    "                     'legend.fontsize': 16})\n",
    "\n",
    "# Set default seaborn plotting style\n",
    "sns.set_style('white')\n",
    "\n",
    "from datetime import datetime\n",
    "import time\n",
    "from nose.tools import assert_equal\n",
    "\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7763a4",
   "metadata": {},
   "source": [
    "## Collecting 2016-17 and 2017-18 team stats data\n",
    "\n",
    "We begin by importing all of the team stats data from the 2016-17 and 2017-18 seasons. We recall that we stored the team stats data for the past 10 seasons (2009-10 and on) in the file 'all_team_stats_2009_to_2018.csv'. Unfortunately, this file does not directly contain the year in which the season occurred. We will need to use the information from the file 'all_games_04_on.csv', which contains this information. We use SQL on these two files to filter to the games occuring in the past two seasons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a177d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_18 = lr_model.predict(trans_team_stats_18)\n",
    "\n",
    "lr_score_18 = 100.0 * accuracy_score(team_stats_18.loc[:,'won'], predicted_18)\n",
    "\n",
    "print(\"Logistic regression score for '17-'18 data: {0:4.1f}%\\n\".format(lr_score_18))\n",
    "\n",
    "print(classification_report(team_stats_18.loc[:,'won'], predicted_18))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39241b8b",
   "metadata": {},
   "source": [
    "### Decision tree classification\n",
    "\n",
    "We will now run the same process using decision trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201df319",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "dtc = DecisionTreeClassifier(random_state=23)\n",
    "\n",
    "dtc = dtc.fit(x_train_17, y_train_17)\n",
    "\n",
    "predicted = dtc.predict(x_test_17)\n",
    "\n",
    "print('Training decision tree classifier took ' + str(time.time() - start_time) + ' seconds.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df13a6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc_score = 100.0 * accuracy_score(y_test_17,predicted)\n",
    "\n",
    "print(\"Decision tree score for '16-'17 data: {0:4.1f}%\\n\".format(dtc_score))\n",
    "\n",
    "print(classification_report(y_test_17,predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027afb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_18 = dtc.predict(trans_team_stats_18)\n",
    "\n",
    "dtc_score_18 = 100.0 * accuracy_score(team_stats_18.loc[:,'won'], predicted_18)\n",
    "\n",
    "print(\"Decision tree score for '17-'18 data: {0:4.1f}%\\n\".format(dtc_score_18))\n",
    "\n",
    "print(classification_report(team_stats_18.loc[:,'won'], predicted_18))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47d06d0",
   "metadata": {},
   "source": [
    "We find that using a base model for a Decision Tree Classifier predicts the '16-17 testing data with $67\\%$ accuracy and the '17-'18 games with $65\\%$. It also takes a split second to train the decision tree classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44937fea",
   "metadata": {},
   "source": [
    "### Support vector machine classification\n",
    "\n",
    "We now employ a Support Vector Machine with linear kernel for classification. I suspect that it will take longer, but be more accurate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a64b302",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "svc_model = SVC(kernel='linear', C=1E6, random_state=23)\n",
    "svc_model = svc_model.fit(x_train_17, y_train_17)\n",
    "predicted = svc_model.predict(x_test_17)\n",
    "\n",
    "print('Training SVC took ' + str(time.time() - start_time) + ' seconds.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34266919",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_score = 100.0 * accuracy_score(y_test_17,predicted)\n",
    "\n",
    "print(\"SVC score for '16-'17 data: {0:4.1f}%\\n\".format(svc_score))\n",
    "\n",
    "print(classification_report(y_test_17,predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eeeadcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_18 = svc_model.predict(trans_team_stats_18)\n",
    "\n",
    "svc_score_18 = 100.0 * accuracy_score(team_stats_18.loc[:,'won'], predicted_18)\n",
    "\n",
    "print(\"SVC score for '17-'18 data: {0:4.1f}%\\n\".format(svc_score_18))\n",
    "\n",
    "print(classification_report(team_stats_18.loc[:,'won'], predicted_18))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e591f1",
   "metadata": {},
   "source": [
    "We find that the Support Vector Classification works with similar accuracy as Logistic Regression. The main difference is that it took around 1 hour 50 minutes to train the Support Vector Classifier while it took less than 1 second to train the Logistic Regressor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc43049b",
   "metadata": {},
   "source": [
    "### Classification with Random forests\n",
    "\n",
    "While classifying with Decision Trees had very fast training speed, it was much less accurate than classifying with Logistic Regression and Support Vector Classifiers. It may be that employing many Decision Trees in the form of Random Forest may be more accurate.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18512671",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "#input estimators\n",
    "clf1 = KNeighborsClassifier(n_neighbors=5)\n",
    "clf2 = LogisticRegression(random_state=23)\n",
    "clf3 = RandomForestClassifier(random_state=23, max_depth=10)\n",
    "\n",
    "#create list of tuples, matching names to input estimator\n",
    "est_list = [('knn', clf1), ('lr', clf2), ('rfc', clf3)]\n",
    "\n",
    "#soft voting- classifying based on summed classification probs\n",
    "vclf = VotingClassifier(estimators=est_list, voting='soft') \n",
    "\n",
    "#fit to '16-'17 team stats\n",
    "vclf = vclf.fit(x_train_17, y_train_17)\n",
    "\n",
    "print('Training Voting Classifier took ' + str(time.time() - start_time) + ' seconds.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252ebb20",
   "metadata": {},
   "outputs": [],
   "source": [
    "vclf_score = 100.0 * vclf.score(x_test_17, y_test_17)\n",
    "\n",
    "print(\"Voting Classifier score for '16-'17 data using K-NN, Logistic Regression, and Random Forest: {0:4.1f}%\\n\".format(vclf_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092d92ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "vclf_score_18 = 100.0 * vclf.score(trans_team_stats_18, team_stats_18.loc[:,'won'])\n",
    "\n",
    "print(\"Voting Classifier score for '17-'18 data using K-NN, Logistic Regression, and Random Forest: {0:4.1f}%\\n\".format(vclf_score_18))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f67d6b",
   "metadata": {},
   "source": [
    "The voting classifier performs similarly to the Support Vector Classifier. The training time is still sub-second."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0bfe310",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, we applied a Principal Component Analysis with the team stats from the 2016-17 NBA season. We used the elbow method to decide to keep the 7 most important components, which explained $77.2\\%$ of the variance. We then transformed the 2017-18 team stats data using this fitted PCA. \n",
    "\n",
    "We then applied several different machine learning classification methods on this data. We trained the methods on the same $70\\%$ of the '16-'17 data. The methods worked with varying training speed and accuracy, summarized as fellows.\n",
    "\n",
    "Each item describes a method, its training time, its accuracy in classifying '16-'17 data, and its accuracy in classifying '17-'18 data.\n",
    "\n",
    "- __Logistic Regression__, Training time: $0.007$ sec, '16-'17 classification: $79.0\\%$, '17-'18 classification: $76.3\\%$\n",
    "- __Decision Tree__, TT: $0.014$ sec, '16-'17: $67.2\\%$, '17-'18: $65.6\\%$ \n",
    "- __Support Vector Machine__, TT: $1$ hr $25$ min, '16-'17: $77.7\\%$, '17-'18: $75.0\\%$ \n",
    "- __Random Forest__, TT: $0.046$ sec, '16-'17: $73.4\\%$, '17-'18: $70.5\\%$\n",
    "- __Gradient Tree Boosting__, TT: $0.934$ sec, '16-'17: $75.2\\%$, '17-'18: $72.3\\%$\n",
    "- __k-Nearest Neighbors (k-NN)__, TT: $0.004$ sec, '16-'17: $70.5\\%$, '17-'18: $68.8\\%$\n",
    "- __Voting (k-NN, Log. Reg., $\\&$ Ran. For.)__, TT: $0.049$ sec, '16-'17: $76.3\\%$, '17-'18: $75.0\\%$\n",
    "\n",
    "The best method surprisingly was the first one we used: simple Logistic Regression. It had the best accuracy for both seasons and had the second fastest training time clocking in at nearly a hundredth of a second.\n",
    "\n",
    "More work can be done on why Logistic Regression performed the best, what happens when we include more components, and which stats are most influential towards winning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77791337",
   "metadata": {},
   "source": [
    "## Applying Logistic Regression to all '16-'17 and '17-'18 team stats\n",
    "\n",
    "We will conclude by applying Logistic Regression to all of the team stats from the '16-'17 and '17-'18 seasons. Recall we applying a PCA, keeping 7 components, to the '16-'17 team stats. We then applied Logistic Regression to the transformed stats, keeping in mind that the 7 kept components only explained $77.2\\%$ of the variance. As Logistic Regression was very quick, we will apply it to all 27 original team stats.\n",
    "\n",
    "Recall that all of the team stats for the '16-'17 season, '17-'18 season were stored in the DataFrames `num_team_stats_17`, `num_team_stats_18`, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76100eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scale stats\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "ss = StandardScaler()\n",
    "\n",
    "scaled_team_stats_17 = ss.fit_transform(num_team_stats_17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0adaf786",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train/test split keeping 30% for testing\n",
    "x_train_all_17, x_test_all_17, y_train_all_17, y_test_all_17 = train_test_split(scaled_team_stats_17, \\\n",
    "                                                                team_stats_17.loc[:,'won'],\\\n",
    "                                                                test_size=0.3, \\\n",
    "                                                                stratify=team_stats_17.loc[:,'won'],\\\n",
    "                                                                random_state=23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af37ddcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "#fit logistic regression to '16-'17 data\n",
    "#high value for C to reduce regularization\n",
    "\n",
    "model = LogisticRegression(C=1E6, random_state=23)\n",
    "lr_model = model.fit(x_train_all_17, y_train_all_17)\n",
    "predicted = lr_model.predict(x_test_all_17)\n",
    "\n",
    "\n",
    "print('Training took ' + str(time.time() - start_time) + ' seconds.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99426510",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_score_all = 100.0 * accuracy_score(y_test_all_17,predicted)\n",
    "\n",
    "print(\"Logistic regression score for '16-'17 data: {0:4.1f}%\\n\".format(lr_score_all))\n",
    "\n",
    "print(classification_report(y_test_all_17,predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f944a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_team_stats_18 = ss.transform(num_team_stats_18)\n",
    "\n",
    "predicted_all_18 = lr_model.predict(scaled_team_stats_18)\n",
    "\n",
    "lr_score_all_18 = 100.0 * accuracy_score(team_stats_18.loc[:,'won'], predicted_all_18)\n",
    "\n",
    "print(\"Logistic regression score for '17-'18 data: {0:4.1f}%\\n\".format(lr_score_all_18))\n",
    "\n",
    "print(classification_report(team_stats_18.loc[:,'won'], predicted_all_18))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9afb24d",
   "metadata": {},
   "source": [
    "We find that Logistic Regression increases $6.6\\%$, $10.2\\%$ in accuracy as one jumps from 7 components to all of the stats. Also the training time is still negligible. (Training the support vector machine would have taken many more hours if we used all of the stats.) More work could be done on tuning parameters and studying how accurate by team Logistic Regression is for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333c1539",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save DataFrames in tables\n",
    "\n",
    "all_team_stats.to_sql(name='team_stats_tb', con=con, if_exists='replace', \\\n",
    "                     index=False, chunksize=1000)\n",
    "\n",
    "all_game_info_17.to_sql(name='game_info_17_tb', con=con, if_exists='replace', \\\n",
    "                       index=False, chunksize=1000)\n",
    "\n",
    "all_game_info_18.to_sql(name='game_info_18_tb', con=con, if_exists='replace', \\\n",
    "                       index=False, chunksize=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbcb8bb1",
   "metadata": {},
   "source": [
    "We now check that the first few rows of each table looks correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87999dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#all team stats table\n",
    "sql_team_stats_access = \"\\\n",
    "SELECT * \\\n",
    "FROM team_stats_tb \\\n",
    "LIMIT 3 \\\n",
    "\"\n",
    "\n",
    "cur.execute(sql_team_stats_access)\n",
    "\n",
    "for row in cur:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60427046",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_game_17_access = \"\\\n",
    "SELECT * \\\n",
    "FROM game_info_17_tb \\\n",
    "LIMIT 3\\\n",
    "\"\n",
    "\n",
    "cur.execute(sql_game_17_access)\n",
    "\n",
    "for row in cur:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e3c595",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_game_18_access = \"\\\n",
    "SELECT *\\\n",
    "FROM game_info_18_tb \\\n",
    "LIMIT 3\\\n",
    "\"\n",
    "\n",
    "cur.execute(sql_game_18_access)\n",
    "\n",
    "for row in cur:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1632e455",
   "metadata": {},
   "source": [
    "We are now to filter the team stats data to the 2016-17 and 2017-18 seasons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de758ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter team stats for 2016-17 season\n",
    "\n",
    "sql_game_stats_17_join = \"\\\n",
    "SELECT DISTINCT game_tb.season_end_year, game_tb.season_type,\\\n",
    "game_tb.game_date, game_tb.matchup_id AS game_matchup_id, \\\n",
    "team_tb.*\\\n",
    "FROM game_info_17_tb AS game_tb \\\n",
    "JOIN team_stats_tb AS team_tb \\\n",
    "ON game_tb.matchup_id = team_tb.matchup_id \\\n",
    "\"\n",
    "\n",
    "team_stats_17 = pd.read_sql(sql_game_stats_17_join, con)\n",
    "\n",
    "print('Number of team stat rows: ' + str(team_stats_17.shape[0]) + ' (2 for each distinct game)')\n",
    "\n",
    "team_stats_17.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6cb1318",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter to team stats data for 2017-2018 season\n",
    "\n",
    "sql_game_stats_18_join = \"\\\n",
    "SELECT DISTINCT game_tb.season_end_year, game_tb.season_type,\\\n",
    "game_tb.game_date, game_tb.matchup_id AS game_matchup_id, \\\n",
    "team_tb.*\\\n",
    "FROM game_info_18_tb AS game_tb \\\n",
    "JOIN team_stats_tb AS team_tb \\\n",
    "ON game_tb.matchup_id = team_tb.matchup_id \\\n",
    "\"\n",
    "\n",
    "team_stats_18 = pd.read_sql(sql_game_stats_18_join, con)\n",
    "\n",
    "print('Number of team stat rows: ' + str(team_stats_18.shape[0]) + ' (2 for each distinct game)')\n",
    "\n",
    "team_stats_18.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd50cc9",
   "metadata": {},
   "source": [
    "We conclude this section by finding the summary statistics of these team stats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec88b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#summary stats of 2016-17 team stats\n",
    "team_stats_17.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2959b7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#summary stats of 2017-18 team stats\n",
    "team_stats_18.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dda13b8",
   "metadata": {},
   "source": [
    "## PCA with components on team stats\n",
    "\n",
    "We now have two DataFrames: the team stats data for all games during the 2016-2017 season and the same for the 2017-2018 season. The 2016-17 DataFrame has the team stats for 1309 games while the 2017-18 DataFrame has them for 1312 games.\n",
    "\n",
    "We will run Principal Component Analysis on these two DataFrames, keeping some number of principal components. We will take into account all of the team stats, from `first_qtr_points` to `flagrant_fouls`. We will fit our PCA to the 2016-2017 team stats data. We will then transform the data on the past two seasons to this fitted PCA model. The exact number of components we consider will depend on how much variance we wish to explain relative to the complexity of our data.\n",
    "\n",
    "We begin by extracting the numerical stats from the two team stats DataFrames. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14cc60f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#all column names (including season end year)\n",
    "all_stat_names = team_stats_17.columns.tolist()\n",
    "\n",
    "#find indices for first qtr points and flagrant fouls\n",
    "first_qtr_points_idx = all_stat_names.index('first_qtr_points')\n",
    "flagrant_fouls_idx = all_stat_names.index('flagrant_fouls')\n",
    "\n",
    "#stat names for numerical stats\n",
    "num_stat_names = all_stat_names[first_qtr_points_idx: flagrant_fouls_idx+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9fb6b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract 2016-17 numerical team stats data\n",
    "num_team_stats_17 = team_stats_17[num_stat_names]\n",
    "\n",
    "#2017-18 numerical team stats data\n",
    "num_team_stats_18 = team_stats_18[num_stat_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5903b20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check first few rows of restricted 2016-17 team stats\n",
    "num_team_stats_17.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548d8cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "#conduct PCA to understand how much variance explained with components\n",
    "pca_exploring = PCA()\n",
    "\n",
    "#fit PCA to '16-'17 team stats\n",
    "pca_exploring.fit(num_team_stats_17)\n",
    "\n",
    "#explained variance of components\n",
    "exp_vars = pca_exploring.explained_variance_ratio_\n",
    "\n",
    "print('Variance: Projected dimension')\n",
    "print('-----------------------------')\n",
    "\n",
    "for idx, row in enumerate(pca_exploring.components_):\n",
    "    output = '{0:4.1f}%:     '.format(100.0*exp_vars[idx])\n",
    "    output += \" + \".join(\"{0:5.2f} * {1:s}\".format(val, name) \\\n",
    "                        for val, name in zip(row, num_stat_names))\n",
    "    print(output + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559ba8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print cumulative explained variances by number of principal components\n",
    "cum_exp_vars = []\n",
    "\n",
    "#total number of principal components\n",
    "num_cmpts = pca_exploring.explained_variance_ratio_.shape[0]\n",
    "\n",
    "for idx in range(num_cmpts):\n",
    "    if idx == 0: #first include variance of first component\n",
    "        cum_exp_vars.append(100 * pca_exploring.explained_variance_ratio_[0])\n",
    "    else:\n",
    "        cum_exp_vars.append(cum_exp_vars[idx-1] + 100 * pca_exploring.explained_variance_ratio_[idx])\n",
    "\n",
    "for idx in range(num_cmpts):\n",
    "    if idx == 0:\n",
    "        print('1 component: {0:4.1f}% variance explained'.format(cum_exp_vars[0]))\n",
    "        \n",
    "    else:\n",
    "        print('{0} components: {1:4.1f}% variance explained'.format(idx+1, cum_exp_vars[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef6524e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#show explained variance vs. number of components \n",
    "        \n",
    "plt.plot(np.arange(1,28), cum_exp_vars, 'bo')\n",
    "plt.title('Explained variance by number of components')\n",
    "plt.ylabel('Explained variance (%)')\n",
    "plt.xlabel('Number of components')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e5e5eb",
   "metadata": {},
   "source": [
    "Taking a look at this graph, we decide to choose 7 components. Up to 7 components, there is an increase in nearly $5\\%$ of explained variance for each added component. From thereon out, there is an increase of at most $3.2\\%$ per added component. Thus, we refit our PCA keeping only 7 components. We then transform the '16-'17 and '17-'18 team stats data with this PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5858d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#keep 7 components of PCA\n",
    "pca_7_cmpts = PCA(n_components=7)\n",
    "\n",
    "#fit to '16-'17 team stats \n",
    "pca_7_cmpts.fit(num_team_stats_17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d655ee5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform '16-'17 data with PCA\n",
    "trans_team_stats_17 = pca_7_cmpts.transform(num_team_stats_17)\n",
    "\n",
    "print(trans_team_stats_17[:5,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88eeb3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform '17-'18 data with fitted PCA\n",
    "trans_team_stats_18 = pca_7_cmpts.transform(num_team_stats_18)\n",
    "\n",
    "print(trans_team_stats_18[:5,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48844fb2",
   "metadata": {},
   "source": [
    "## Classification with transformed '16-'17 and '17-'18 team stats data\n",
    "\n",
    "We will now apply several classification methods to our transformed data, keeping track of training time and accuracy. \n",
    "\n",
    "We train our data on $70\\%$ of the '16-'17 team stats data. We then use the model to classify the testing '16-'17 data and _all_ of the '17-'18 data. We start by splitting the data and use the same split when employing all the methods. We will stratify according to wins and losses, so there are the same proportions of winning and losing teams in the training and testing data. We will also fix a random state for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d26675",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#split '16-'17 transformed team stats with 30% for testing \n",
    "x_train_17, x_test_17, y_train_17, y_test_17 = train_test_split(trans_team_stats_17, \\\n",
    "                                                                team_stats_17.loc[:,'won'],\\\n",
    "                                                                test_size=0.3, \\\n",
    "                                                                stratify=team_stats_17.loc[:,'won'],\\\n",
    "                                                                random_state=23)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7ab29a",
   "metadata": {},
   "source": [
    "### Logistic regression \n",
    "\n",
    "We begin by classifying with logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55dacb3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "#fit logistic regression to '16-'17 data\n",
    "#high value for C to reduce regularization\n",
    "\n",
    "model = LogisticRegression(C=1E6, random_state=23)\n",
    "lr_model = model.fit(x_train_17, y_train_17)\n",
    "predicted = lr_model.predict(x_test_17)\n",
    "\n",
    "\n",
    "print('Training took ' + str(time.time() - start_time) + ' seconds.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3645b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884e3b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "lr_score = 100.0 * accuracy_score(y_test_17,predicted)\n",
    "\n",
    "print(\"Logistic regression score for '16-'17 data: {0:4.1f}%\\n\".format(lr_score))\n",
    "\n",
    "print(classification_report(y_test_17,predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef1965b",
   "metadata": {},
   "source": [
    "$79\\%$ accuracy is a nice baseline for prediction, especially considering how quick it took to train our Logistic Regression model. __Remember that the all spam method (classifying all games as wins) would be accurate at $50\\%$.__ \n",
    "\n",
    "We now check how accurate this model is for classifying wins for all games during the '17-'18 season. We will find that it is $76\\%$ accurate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c113e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=10, max_features='auto', \\\n",
    "                            min_samples_split=2, random_state=23)\n",
    "\n",
    "#Fit to '16-'17 data\n",
    "rfc = rfc.fit(x_train_17, y_train_17)\n",
    "\n",
    "print('Training Random Forest Classifier took ' + str(time.time() - start_time) + ' seconds.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e5b719",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_score = 100.0 * rfc.score(x_test_17, y_test_17)\n",
    "\n",
    "print(\"Random Forest Classifier score for '16-'17 data: {0:4.1f}%\\n\".format(rfc_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7e3cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_score_18 = 100.0 * rfc.score(trans_team_stats_18, team_stats_18.loc[:,'won'])\n",
    "\n",
    "print(\"Random Forest Classifier score for '17-'18 data: {0:4.1f}%\\n\".format(rfc_score_18))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d46d485",
   "metadata": {},
   "source": [
    "We find that the Random Forest Classifier is slightly less accurate than classifying with Logistic Regression and the Support Vector Classifier. It is still very fast with split second speed to train."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a64bc9",
   "metadata": {},
   "source": [
    "### Gradient Tree Boosting\n",
    "\n",
    "We continue to use decision trees, but in a slightly different way with boosting. We will test classification with Gradient Tree Boosting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afeaca9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "gbtc = GradientBoostingClassifier(n_estimators=500, max_depth=3, random_state=23)\n",
    "\n",
    "#fit to '16-'17 team stats\n",
    "gbtc = gbtc.fit(x_train_17, y_train_17)\n",
    "\n",
    "print('Training Gradient Boosting Classifier took ' + str(time.time() - start_time) + ' seconds.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db1e8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbtc_score = 100.0 * gbtc.score(x_test_17, y_test_17)\n",
    "\n",
    "print(\"Gradient Boosting Classifier score for '16-'17 data: {0:4.1f}%\\n\".format(gbtc_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43d2ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbtc_score_18 = 100.0 * gbtc.score(trans_team_stats_18, team_stats_18.loc[:,'won'])\n",
    "\n",
    "print(\"Gradient Boosting Classifier score for '17-'18 data: {0:4.1f}%\\n\".format(gbtc_score_18))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc17aba",
   "metadata": {},
   "source": [
    "Using Gradient Boosting had slightly improved performance in terms of accuracy over using a Random Forest. While it took just over a second to train, Gradient Boosting took over 100 times longer than Logistic Regression to train."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604546a1",
   "metadata": {},
   "source": [
    "### k-Nearest Neighbors classifier\n",
    "\n",
    "We will now use a bit more intuitive classifier: the k-Nearest Neighbors Classifier. Recall that it labels new data by considering the labels of nearby training points. Unfortunately, it fails under the _curse of dimensionality_: our data has too many features (7) relative to the number of data points (around 2000). For this reason, we will classify according to the first 4 principal components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd5970d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import neighbors\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "#number of neighbors\n",
    "nbrs=10\n",
    "\n",
    "knc = neighbors.KNeighborsClassifier(n_neighbors=nbrs)\n",
    "\n",
    "#train model with best 4 principal components of '16-'17 data\n",
    "knc = knc.fit(x_train_17[:,:4], y_train_17)\n",
    "\n",
    "print('Training K-nearest Neighbors Classifier took ' + str(time.time() - start_time) + ' seconds.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59771da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "knc_score = 100.0 * knc.score(x_test_17[:,:4], y_test_17)\n",
    "\n",
    "print(\"K-nearest Neighbors Classifier score for '16-'17 data: {0:4.1f}%\\n\".format(knc_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31190662",
   "metadata": {},
   "outputs": [],
   "source": [
    "knc_score_18 = 100.0 * knc.score(trans_team_stats_18[:,:4], team_stats_18.loc[:,'won'])\n",
    "\n",
    "print(\"K-nearest Neighbors Classifier score for '17-'18 data: {0:4.1f}%\\n\".format(knc_score_18))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c987e6",
   "metadata": {},
   "source": [
    "While the training speed is just low as any other method, the accuracy is a few percentage points lower than others."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe390a11",
   "metadata": {},
   "source": [
    "### Voting Classification\n",
    "\n",
    "We have tested several machine learning methods of classification in this notebook. We will conclude by seeing what happens when we combine a few of the methods by the way of Voting Classification. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c0b5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DataFrame of all team stats since 2009-2010 season\n",
    "all_team_stats = pd.read_csv('all_team_stats_2009_to_2018.csv').loc[:,'team':]\n",
    "\n",
    "all_team_stats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9806062a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DataFrame of info on all games since 2004-2005 season \n",
    "all_game_info = pd.read_csv('all_games_04_on.csv').loc[:,'team':]\n",
    "\n",
    "#restrict to games during 2016-2017 season\n",
    "season_17_bool = all_game_info['season_end_year'] == 2017\n",
    "all_game_info_17 = all_game_info[season_17_bool]\n",
    "\n",
    "#restrict to games during 2017-2018 season\n",
    "season_18_bool = all_game_info['season_end_year'] == 2018\n",
    "all_game_info_18 = all_game_info[season_18_bool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d17d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of 2016-17 team stat rows: ' + str(all_game_info_17.shape[0]))\n",
    "\n",
    "all_game_info_17.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0df6804",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of 2017-18 team stat rows: ' + str(all_game_info_18.shape[0]))\n",
    "\n",
    "all_game_info_18.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0fc9c4",
   "metadata": {},
   "source": [
    "We now employ SQLite to match up the Matchup ID's for each year with the corresponding team stats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09cd3497",
   "metadata": {},
   "outputs": [],
   "source": [
    "home_dir = !echo $HOME\n",
    "\n",
    "#Define data directory\n",
    "database_dir = home_dir[0] + '/database'\n",
    "\n",
    "print(f'Database will persist at {database_dir}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e431aab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s %%bash  \"$database_dir\"\n",
    "\n",
    "#passed Python variable, later accessed with $1\n",
    "\n",
    "#check if directory exists\n",
    "if [ -d \"$1\" ] ; then\n",
    "\n",
    "    echo \"Directory already exists.\"\n",
    "\n",
    "else\n",
    "    #otherwise grapb file from Internet and store locally in data directory\n",
    "    \n",
    "    mkdir $1\n",
    "    echo \"creating database directory\"\n",
    "\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a4021e",
   "metadata": {},
   "outputs": [],
   "source": [
    "con = sqlite3.connect(\"stats_629.db\")\n",
    "\n",
    "cur = con.cursor()"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
