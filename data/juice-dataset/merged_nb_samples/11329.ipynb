{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "150f5ea5",
   "metadata": {},
   "source": [
    "# <center> Stochastic Optimization and Automatic Differentiation for Machine Learning<br/><br/>SDCA<br/><br/>Zakarya Ali</center>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68730e8e",
   "metadata": {},
   "source": [
    "In this notebook, I implement the **SDCA (Stochastic Dual Coordinate Ascent)** algorithm (from the article [Stochastic Dual Coordinate Ascent Methods for Regularized Loss Minimization by Shai Shalev-Shwartz  and Tong Zhang](http://www.jmlr.org/papers/volume14/shalev-shwartz13a/shalev-shwartz13a.pdf) to estimate Support Vector Machines. First, I apply the algorithm on randomly generated data, then I use a credit fraud dataset to compare **SDCA** compare it with **PEGASOS (Primal Estimated subGrAdient SOlver for SVM)**, a sub-gradient descent approach."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665e1af3",
   "metadata": {},
   "source": [
    "# Prerequisites\n",
    "\n",
    "We call and create the tools we will need throughout the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee6f995",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing, svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "np.random.seed(2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b7583c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hinge_losses(y, X, w, n_samples):\n",
    "    \"\"\"Compute the sum of individual hinge losses\"\"\"\n",
    "    return np.sum(np.fmax(np.zeros(n_samples), np.ones(n_samples) - (y * (X.dot(w)))))\n",
    "\n",
    "def get_accuracy(X, y, w):\n",
    "    \"\"\"Return the accuracy of linear SVM for a given parameter w\"\"\"\n",
    "    preds = np.dot(X, w)\n",
    "    preds[preds >= 0] = 1\n",
    "    preds[preds < 0] = -1\n",
    "    return accuracy_score(y, preds)\n",
    "\n",
    "def convergence_plot(plot_data, labels, ylim=[None, None]):\n",
    "    \"\"\"plot the convergence of various primal curves\"\"\"\n",
    "    fig=plt.figure(figsize=(12,8))\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    if (ylim != [None, None]):\n",
    "        ax.set_ylim(ylim)\n",
    "    for i in range(len(labels)) :\n",
    "        plt.plot(plot_data[i], label = labels[i])\n",
    "    plt.title(\"Convergence plot\")\n",
    "    plt.ylabel(\"Primal Objective\")\n",
    "    plt.xlabel(\"Steps\")\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4402b7",
   "metadata": {},
   "source": [
    "# 1. Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2674896",
   "metadata": {},
   "source": [
    "## 1.1. SDCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615658d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def primal_param(X, alpha, lambda_, n_samples):\n",
    "    \"\"\"Return the primal parameter w associated to a dual parameter alpha\"\"\"\n",
    "    return (1 / (lambda_ * n_samples)) * (np.dot(np.transpose(X), alpha))\n",
    "\n",
    "def get_delta_alpha_q(X, y, alpha, q, lambda_, n_samples, w):\n",
    "    \"\"\"Compute SDCA update\"\"\"\n",
    "    A = (1 / (lambda_ * n_samples)) * (np.dot(np.transpose(X[q]), X[q]))\n",
    "    B = np.dot(np.transpose(X[q]) , w)\n",
    "    delta_alpha_tilde_q = (y[q] - B) / A\n",
    "    return y[q] * max(0 , min(1 , y[q]*(delta_alpha_tilde_q + alpha[q]))) - alpha[q] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1539156",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here is the code for the different SDCA implementation (random, cyclic and permutation)\n",
    "\n",
    "def sdca_svm_random(X, y, n_samples, T_0, lambda_, nb_epochs=50):\n",
    "\n",
    "    # initialization \n",
    "    alpha = np.zeros(n_samples)\n",
    "    w_history = []\n",
    "    primal_history = []\n",
    "    w = primal_param(X, alpha, lambda_, n_samples)\n",
    "\n",
    "    for t in range(n_samples * nb_epochs):\n",
    "        q = np.random.randint(0, n_samples)\n",
    "        # SDCA update step\n",
    "        delta_alpha_q = get_delta_alpha_q(X, y, alpha, q, lambda_, n_samples, w)\n",
    "        e = np.zeros(n_samples)\n",
    "        e[q] = 1\n",
    "        sdca_update = e * delta_alpha_q\n",
    "        alpha = alpha + sdca_update\n",
    "        w = primal_param(X, alpha, lambda_, n_samples)\n",
    "\n",
    "        w_history.append(w)\n",
    "        primal_history.append(hinge_losses(y, X, w, n_samples) / n_samples + (lambda_ / 2) * np.linalg.norm(w)**2)\n",
    "\n",
    "    return asarray(w_history[T_0:]).mean(axis = 0), w_history, primal_history\n",
    "    \n",
    "def sdca_svm_permutation(X, y, n_samples, T_0, lambda_, nb_epochs=50):\n",
    "\n",
    "    # initialization \n",
    "    alpha = np.zeros(n_samples)\n",
    "    w_history = []\n",
    "    primal_history = []\n",
    "    w = primal_param(X, alpha, lambda_, n_samples)\n",
    "    \n",
    "    count = 0\n",
    "    for t in range(nb_epochs):\n",
    "        perm = np.random.permutation(n_samples)\n",
    "        for q in perm :\n",
    "            # SDCA update step\n",
    "            delta_alpha_q = get_delta_alpha_q(X, y, alpha, q, lambda_, n_samples, w)\n",
    "            e = np.zeros(n_samples)\n",
    "            e[q] = 1\n",
    "            sdca_update = e * delta_alpha_q\n",
    "            alpha = alpha + sdca_update\n",
    "            w = primal_param(X, alpha, lambda_, n_samples)\n",
    "\n",
    "            w_history.append(w)\n",
    "            primal_history.append(hinge_losses(y, X, w, n_samples) / n_samples + (lambda_ / 2) * np.linalg.norm(w)**2)\n",
    "            count +=1\n",
    "\n",
    "    return asarray(w_history[T_0:]).mean(axis = 0), w_history, primal_history\n",
    "\n",
    "def sdca_svm_cyclic(X, y, n_samples, T_0, lambda_, nb_epochs=50):\n",
    "\n",
    "    # initialization \n",
    "    alpha = np.zeros(n_samples)\n",
    "    w_history = []\n",
    "    primal_history = []\n",
    "    w = primal_param(X, alpha, lambda_, n_samples)\n",
    "    \n",
    "    count = 0\n",
    "    perm = np.random.permutation(n_samples)\n",
    "    for t in range(nb_epochs):\n",
    "        for q in perm :\n",
    "            # SDCA update step\n",
    "            delta_alpha_q = get_delta_alpha_q(X, y, alpha, q, lambda_, n_samples, w)\n",
    "            e = np.zeros(n_samples)\n",
    "            e[q] = 1\n",
    "            sdca_update = e * delta_alpha_q\n",
    "            alpha = alpha + sdca_update\n",
    "            w = primal_param(X, alpha, lambda_, n_samples)\n",
    "\n",
    "            w_history.append(w)\n",
    "            primal_history.append(hinge_losses(y, X, w, n_samples) / n_samples + (lambda_ / 2) * np.linalg.norm(w)**2)\n",
    "            count +=1\n",
    "                \n",
    "    return asarray(w_history[T_0:]).mean(axis = 0), w_history, primal_history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9971e5d4",
   "metadata": {},
   "source": [
    "## 1.2. Pegasos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4770dfdc",
   "metadata": {},
   "source": [
    "Main difference with SDCA : \n",
    "- We compute sub-gradients and not gradients at each steps \n",
    "- The step size is always $\\frac{1}{\\lambda t}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5552c6",
   "metadata": {},
   "source": [
    "We undersample the majority class in order to get a better training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1172592d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rus = RandomUnderSampler(random_state=42, ratio={-1: 1000})\n",
    "X_res, y_res = rus.fit_sample(X_train, y_train)\n",
    "n_samples = X_res.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646dc6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(y_res)\n",
    "plt.title('Distribution of resampled credit card transaction (-1 = no fraud | 1 = fraud)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d09448",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807f5726",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_res.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c830b24c",
   "metadata": {},
   "source": [
    "## 3.1. SDCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c67196",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SDCA Random\n",
    "gen_opt_w_sdca_avg_r, gen_w_hist_sdca_avg_r, gen_primal_hist_sdca_avg_r = sdca_svm_random(X_res, y_res, \n",
    "                                                                                          n_samples, T_0=50 * n_samples // 2, \n",
    "                                                                                          lambda_=50) \n",
    "#SDCA Permutation\n",
    "gen_opt_w_sdca_avg_p, gen_w_hist_sdca_avg_p, gen_primal_hist_sdca_avg_p = sdca_svm_permutation(X_res, y_res, \n",
    "                                                                                               n_samples, T_0=50 * n_samples // 2, \n",
    "                                                                                               lambda_=50)\n",
    "#SDCA Cyclic\n",
    "gen_opt_w_sdca_avg_c, gen_w_hist_sdca_avg_c, gen_primal_hist_sdca_avg_c = sdca_svm_cyclic(X_res, y_res, \n",
    "                                                                                          n_samples, T_0=50 * n_samples // 2, \n",
    "                                                                                          lambda_=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebcc09ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "convergence_plot([gen_primal_hist_sdca_avg_r, gen_primal_hist_sdca_avg_p, gen_primal_hist_sdca_avg_c],\n",
    "                 [\"Random\", \"Permutation\", \"Cyclic\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd53c26",
   "metadata": {},
   "source": [
    "## 3.2. PEGASOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423d7d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PEGASOS\n",
    "gen_opt_w_peg_avg, gen_w_hist_peg_avg, gen_primal_hist_peg_avg = pegasos_svm(X_res, y_res, \n",
    "                                                                             n_samples, T_0=50 * n_samples // 2, \n",
    "                                                                             lambda_=50, proj=False)\n",
    "#PEGASOS (Projected)\n",
    "gen_opt_w_peg_avg_proj, gen_w_hist_peg_avg_proj, gen_primal_hist_peg_avg_proj = pegasos_svm(X_res, y_res, \n",
    "                                                                                            n_samples, T_0=50 * n_samples // 2, \n",
    "                                                                                            lambda_=50, proj=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68aecfab",
   "metadata": {},
   "outputs": [],
   "source": [
    "convergence_plot([gen_primal_hist_peg_avg, gen_primal_hist_peg_avg_proj], \n",
    "                 [\"Pegasos\", \"Proj\"], \n",
    "                 ylim=[0.898, 0.9])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7e958d",
   "metadata": {},
   "source": [
    "## 3.3. Accelerated mini-batch SDCA (ASDCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63be8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Non projected PEGASOS\n",
    "opt_w_peg, w_hist_peg, primal_hist_peg = pegasos_svm(X_train, y_train,\n",
    "                                                        n_samples_train, T_0=50 * n_samples // 2,\n",
    "                                                        lambda_=1 / n_samples, proj=False)\n",
    "#Projected PEGASOS\n",
    "opt_w_peg_p, w_hist_peg_p, primal_hist_peg_p = pegasos_svm(X_train, y_train,\n",
    "                                                            n_samples_train, T_0=50 * n_samples // 2,\n",
    "                                                            lambda_=1 / n_samples, proj=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36c8ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "convergence_plot([primal_hist_peg, primal_hist_peg_p], \n",
    "                 [\"Non projected PEGASOS\", \"Projected PEGASOS\"], \n",
    "                 ylim=[0,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb49f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction accuracy on test set\n",
    "print(\"Non projected PEGASOS\", get_accuracy(X_test, y_test, w_hist_peg[-1]))\n",
    "print(\"Projected PEGASOS\", get_accuracy(X_test, y_test, w_hist_peg_p[-1]))\n",
    "print(\"Average PEGASOSO\", get_accuracy(X_test, y_test, opt_w_peg))\n",
    "print(\"Average projected PEGASOS\", get_accuracy(X_test, y_test, opt_w_peg_p))\n",
    "print(\"True\", get_accuracy(X_test, y_test, beta))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33426385",
   "metadata": {},
   "source": [
    "## 2.3. Accelerated mini-batch SDCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c38a26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ASDCA\n",
    "opt_w_sdca_batch, w_hist_sdca_batch, primal_hist_sdca_batch = asdca_svm(X_train, y_train, \n",
    "                                                                        n_samples_train, T_0=50 * n_samples // 2, \n",
    "                                                                        lambda_=1 / n_samples, batch_size = 8, theta = 0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59421bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "convergence_plot(primal_hist_sdca_batch, \n",
    "                 [\"ASDCA\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a874630d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing prediction accuracy on test set\n",
    "print(\"ASDCA\", get_accuracy(X_test, y_test, w_hist_sdca_batch[-1]))\n",
    "print(\"Average ASDCA\", get_accuracy(X_test, y_test, opt_w_sdca_batch))\n",
    "print(\"True\", get_accuracy(X_test, y_test, beta))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53be5ac2",
   "metadata": {},
   "source": [
    "## 2.4. Mini-batch PEGASOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0586a050",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mini-batch PEGASOS\n",
    "opt_w_peg_batch, w_hist_peg_batch, primal_hist_peg_batch = mini_batch_pegasos_svm(X_train, y_train, \n",
    "                                                                                  n_samples_train, T_0=50 * n_samples // 2,\n",
    "                                                                                lambda_=1 / n_samples, batch_size=8, proj=False)\n",
    "# Mini-batch PEGASOS (Projected)\n",
    "opt_w_peg_batch_p, w_hist_peg_batch_p, primal_hist_peg_batch_p = mini_batch_pegasos_svm(X_train, y_train, \n",
    "                                                                                        n_samples_train, T_0=50 * n_samples // 2, \n",
    "                                                                                        lambda_=1 / n_samples, batch_size=8, proj=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003049cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "convergence_plot([primal_hist_peg_batch, primal_hist_peg_batch_p], \n",
    "                 [\"Mini-Batch Non projected PEGASOS\", \"Mini-Batch projected PEGASOS\"],\n",
    "                 ylim=[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c3f1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing prediction accuracy on test set\n",
    "print(\"Mini Batch PEGASOS\", get_accuracy(X_test, y_test, w_hist_peg_batch[-1]))\n",
    "print(\"Mini Batch PEGASOS (Projected)\", get_accuracy(X_test, y_test, w_hist_peg_batch_p[-1]))\n",
    "print(\"Average Mini Batch PEGASOS\", get_accuracy(X_test, y_test, opt_w_peg_batch))\n",
    "print(\"Average Mini Batch PEGASOS (Projected)\", get_accuracy(X_test, y_test, opt_w_peg_batch_p))\n",
    "print(\"True\", get_accuracy(X_test, y_test, beta))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee6cb8f",
   "metadata": {},
   "source": [
    "## 2.5. Results comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97266575",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split for this dataset :\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_std, y, test_size=0.33, stratify=y, random_state=2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c8c89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "y_train.hist()\n",
    "plt.title('Distribution of resampled credit card transaction (-1 = no fraud | 1 = fraud)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54a30f2",
   "metadata": {},
   "source": [
    "The problem is highly unbalanced (0.175% of credit fraud in the dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd36a411",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convergence comparison :\n",
    "convergence_plot([primal_hist_sdca_r, primal_hist_peg, primal_hist_sdca_batch, primal_hist_peg_batch],\n",
    "                 [\"SDCA\", \"PEGASOS\", \"ASDCA\", \"Mini-Batch PEGASOS\"], \n",
    "                 ylim = [0, 2.5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757ecb81",
   "metadata": {},
   "source": [
    "# 3. Application: Credit Fraud detection (highly unbalanced dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40fe56d5",
   "metadata": {},
   "source": [
    "This is a dataset from a Kaggle competition : https://www.kaggle.com/mlg-ulb/creditcardfraud/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56bc2123",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rework_labels(label):\n",
    "    result = label\n",
    "    if label == 0:\n",
    "        result = -1\n",
    "    return result\n",
    "\n",
    "data = pd.read_csv(\"data/creditcard.csv\")\n",
    "data = data.dropna()\n",
    "print(data.shape)\n",
    "X = data.drop(columns=[\"Class\"])\n",
    "y = data[\"Class\"].apply(rework_labels)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bcc9043",
   "metadata": {},
   "source": [
    "Our dataset contain 30 features and 284807 observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9853faed",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0951b6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd44211b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardisation of features is required before SVM :\n",
    "X_std = preprocessing.StandardScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba04bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def partial_sub_gradient(w, X, y, q, lambda_):\n",
    "    \"\"\"Partial Subgradient for the hinge-loss\"\"\"\n",
    "    if ( y[q]*np.dot(w, X[q]) < 1 ):\n",
    "        return lambda_ * w - y[q] * X[q]\n",
    "    else:\n",
    "        return lambda_ * w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c1b7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pegasos_svm(X, y, n_samples, T_0, lambda_, nb_epochs=50, proj=False):\n",
    "    \"\"\"Compute the PEGASOS SVM for both projection and non projection options\"\"\"\n",
    "    # initialization \n",
    "    w = np.zeros(X.shape[1])\n",
    "    w_history = []\n",
    "    primal_history = []\n",
    "    \n",
    "    for t in range(1, n_samples * nb_epochs):\n",
    "        # compute Pegasos step size\n",
    "        step_size = 1 / (lambda_ * t)\n",
    "        # pick random sample\n",
    "        q = np.random.randint(0, n_samples)\n",
    "        # compute and apply Pegasos update rule\n",
    "        w = w - step_size * partial_sub_gradient(w, X, y, q, lambda_)\n",
    "        # projection step (optional)\n",
    "        if (proj == True):\n",
    "            w = min(1, 1 / (np.sqrt(lambda_) * np.linalg.norm(w))) * w\n",
    "        \n",
    "        w_history.append(w)        \n",
    "        primal_history.append(hinge_losses(y, X, w, n_samples) / n_samples + (lambda_ / 2) * np.linalg.norm(w)**2)\n",
    "        \n",
    "    return asarray(w_history[T_0:]).mean(axis = 0), w_history, primal_history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd43bfb6",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606273f3",
   "metadata": {},
   "source": [
    " ## 1.3. Accelerated mini-batch SDCA (ASDCA)\n",
    "For accelerated mini-batch SDCA, the smooth version of the hinge loss is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d970f88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def partial_gradient_smooth(w, X, y, q):\n",
    "    \"\"\"Gradient of the smooth hinge loss\"\"\"\n",
    "    results = np.zeros(X.shape[1])\n",
    "    partial_gradient = y[q] * np.dot(X[q], w)\n",
    "    \n",
    "    if (0 <= partial_gradient <= 1 ):\n",
    "        results = (partial_gradient - 1) * y[q] * X[q]\n",
    "    elif (y[q] * np.dot(w, X[q]) < 0 ):\n",
    "        results = - y[q] * X[q]\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613fa5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def asdca_svm(X, y, n_samples, T_0, lambda_, batch_size, theta=0.3, nb_epochs=50):\n",
    "\n",
    "    # initialization\n",
    "    alpha = np.zeros(shape = (X.shape[1], n_samples))\n",
    "    bar_alpha = np.mean(alpha, axis=1)\n",
    "    w = np.zeros(X.shape[1])\n",
    "    w_history = []\n",
    "    primal_history = []\n",
    "\n",
    "    for t in range(n_samples * nb_epochs):\n",
    "        u = (1 - theta) * w + (theta / lambda_) * bar_alpha\n",
    "        # mini-batch sampling\n",
    "        batch = np.random.choice(np.arange(0, n_samples), batch_size, replace=False)\n",
    "        alpha_dif = []\n",
    "        # update step\n",
    "        for q in batch:\n",
    "            old_alpha_q = alpha[:,q].copy()\n",
    "            alpha[:,q] = (1 - theta) * alpha[:,q] - theta * partial_gradient_smooth(u, X, y, q)\n",
    "            alpha_dif.append(alpha[:,q] - old_alpha_q)\n",
    "        bar_alpha = bar_alpha + (1 / n_samples) * sum(alpha_dif, axis=0)\n",
    "        w = (1 - theta) * w + (theta / lambda_) * bar_alpha\n",
    "        \n",
    "        w_history.append(w)\n",
    "        primal_history.append(hinge_losses(y, X, w, n_samples) / n_samples + (lambda_ / 2) * np.linalg.norm(w)**2)\n",
    "\n",
    "    return asarray(w_history[T_0:]).mean(axis = 0), w_history, primal_history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c216e89",
   "metadata": {},
   "source": [
    "## 1.4. Mini-batch Pegasos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84d8ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mini_batch_pegasos_svm(X, y, n_samples, T_0, lambda_, batch_size, nb_epochs=50, proj=False):\n",
    "\n",
    "    # initialization\n",
    "    w = np.zeros(X.shape[1])\n",
    "    w_history = []\n",
    "    primal_history = []\n",
    "    \n",
    "    # main loop\n",
    "    for t in range(1, n_samples * nb_epochs):\n",
    "        step_size = 1 / (lambda_ * t)\n",
    "        # mini-batch sampling\n",
    "        batch = np.random.choice(np.arange(0, n_samples), batch_size, replace=False)\n",
    "        sum_vect = []\n",
    "        for q in batch:\n",
    "            if (y[q] * np.dot(X[q], w) < 1):\n",
    "                sum_vect.append(y[q] * X[q])\n",
    "            else:\n",
    "                sum_vect.append(np.zeros(X.shape[1]))\n",
    "                \n",
    "        w = w - step_size * (lambda_ * w - (1 / batch_size) * sum(sum_vect, axis=0))\n",
    "        # Projection step\n",
    "        if (proj == True):\n",
    "            w = min(1, 1 / (np.sqrt(lambda_) * np.linalg.norm(w))) * w\n",
    "            \n",
    "        w_history.append(w)\n",
    "        primal_history.append(hinge_losses(y, X, w, n_samples) / n_samples + (lambda_ / 2) * np.linalg.norm(w)**2)\n",
    "    \n",
    "    return asarray(w_history[T_0:]).mean(axis = 0), w_history, primal_history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b4ad53",
   "metadata": {},
   "source": [
    "# 2. Application: Simulated data\n",
    "We now apply those algorithms on simulated data: 1000 observations with 100 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12eb18ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples, n_features = 1000, 100\n",
    "# Feature matrix\n",
    "X = np.random.randn(n_samples, n_features)\n",
    "# ground truth parameter\n",
    "beta = np.random.randn(n_features)\n",
    "# Binary label vector\n",
    "y = np.dot(X, beta) + np.random.randn(n_samples)\n",
    "y[y >= 0] = 1\n",
    "y[y < 0] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beec0dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We normalize the features before applying SVM\n",
    "X_std = preprocessing.StandardScaler().fit_transform(X)\n",
    "\n",
    "# Then we split our dataset for training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_std, y, test_size=0.33, random_state=42)\n",
    "n_samples_train = X_train.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59e1ba1",
   "metadata": {},
   "source": [
    "## 2.1. SDCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b65dc4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ASDCA\n",
    "gen_opt_w_sdca_batch_avg, gen_w_hist_sdca_batch_avg, gen_primal_hist_sdca_batch_avg = asdca_svm(X_res, y_res, \n",
    "                                                                                              n_samples, T_0=50 * n_samples // 2, \n",
    "                                                                                              lambda_=50, batch_size = 8, theta = 0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b24c9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "convergence_plot([gen_primal_hist_sdca_batch_avg], \n",
    "                 [\"ASDCA\"], \n",
    "                 ylim=[0.905, 0.915])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c9faba",
   "metadata": {},
   "source": [
    "## 3.4. Mini-batch PEGASOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44481c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mini-batch PEGASOS\n",
    "gen_opt_w_peg_batch_avg, gen_w_hist_peg_batch_avg, gen_primal_hist_peg_batch_avg = mini_batch_pegasos_svm(X_res, y_res, \n",
    "                                                                                                          n_samples, T_0=50 * n_samples // 2, \n",
    "                                                                                                          lambda_=50, batch_size=8, proj=False)\n",
    "#Mini-batch PEGASOS (Projected)\n",
    "gen_opt_w_peg_batch_avg_proj, gen_w_hist_peg_batch_avg_proj, gen_primal_hist_peg_batch_avg_proj = mini_batch_pegasos_svm(X_res, y_res, n_samples, \n",
    "                                                                                                                         T_0=50 * n_samples // 2, \n",
    "                                                                                                                         lambda_=50, batch_size=8, proj=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b57572a",
   "metadata": {},
   "outputs": [],
   "source": [
    "convergence_plot([gen_primal_hist_peg_batch_avg, gen_primal_hist_peg_batch_avg_proj], \n",
    "                [\"Batch\", \"Proj\"], \n",
    "                ylim=[0.898, 0.9])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8528886e",
   "metadata": {},
   "source": [
    "## 3.5. Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2e3478",
   "metadata": {},
   "outputs": [],
   "source": [
    "convergence_plot([gen_primal_hist_sdca_avg_r, gen_primal_hist_peg_avg, gen_primal_hist_sdca_batch_avg, gen_primal_hist_peg_batch_avg],\n",
    "                 [\"SDCA\", \"PEGASOS\", \"ASDCA\", \"Mini-Batch PEGASOS\"], \n",
    "                 ylim = [0.8, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e9b8a3",
   "metadata": {},
   "source": [
    "## 3.6 Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e4473d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SDCA Random\n",
    "opt_w_sdca_r, w_hist_sdca_r, primal_hist_sdca_r = sdca_svm_random(X_train, y_train,\n",
    "                                                                            n_samples_train, T_0=50 * n_samples // 2,\n",
    "                                                                            lambda_=1 / n_samples)\n",
    "#SDCA Permutation\n",
    "opt_w_sdca_p, w_hist_sdca_p, primal_hist_sdca_p = sdca_svm_permutation(X_train, y_train,\n",
    "                                                                            n_samples_train, T_0=50 * n_samples // 2,\n",
    "                                                                            lambda_=1 / n_samples)\n",
    "#SDCA Cyclic\n",
    "opt_w_sdca_c, w_hist_sdca_c, primal_hist_sdca_c = sdca_svm_cyclic(X_train, y_train,\n",
    "                                                                            n_samples_train, T_0=50 * n_samples // 2,\n",
    "                                                                            lambda_=1 / n_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e09ac6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "convergence_plot([primal_hist_sdca_r, primal_hist_sdca_p, primal_hist_sdca_c], \n",
    "                 [\"Random\", \"Permutation\", \"Cyclic\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de09605d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction accuracy on test set\n",
    "print(\"SDCA Random:\", get_accuracy(X_test, y_test, w_hist_sdca_r[-1]))\n",
    "print(\"SDCA Permutation:\", get_accuracy(X_test, y_test, w_hist_sdca_p[-1]))\n",
    "print(\"SDCA Cyclic:\", get_accuracy(X_test, y_test, w_hist_sdca_c[-1]))\n",
    "print(\"SDCA Average Random:\", get_accuracy(X_test, y_test, opt_w_sdca_r))\n",
    "print(\"SDCA Average Permutation:\", get_accuracy(X_test, y_test, opt_w_sdca_p))\n",
    "print(\"SDCA Average Cyclic:\", get_accuracy(X_test, y_test, opt_w_sdca_c))\n",
    "print(\"True:\", get_accuracy(X_test, y_test, beta))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef6c56d",
   "metadata": {},
   "source": [
    "## 2.2. PEGASOS"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
