{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20dbb03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab nbagg\n",
    "from tvb.simulator.lab import *\n",
    "LOG= get_logger('demo')\n",
    "from tvb.simulator.plot.tools import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6360ae",
   "metadata": {},
   "source": [
    "# Exploring information flow between memory and oculomotor systems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df94f49",
   "metadata": {},
   "source": [
    "We want to look into possible pathways and their functional significance. We will start off by running a V1 stimulations to check our parameters. Once you are happy with your activation times and parameters. We will stimulation one of the hippocampal nodes and check their activation times if they ever activate. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1b72d8",
   "metadata": {},
   "source": [
    "## Defining the stimulus "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b2cda2",
   "metadata": {},
   "source": [
    "We'll start by choosing a specific node to stimulate, in this case V1, and defining the weighting of the stimulus coming into that node. Below we'll define the temporal profile with the default Gaussian equation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69b57ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "v1_node = 68\n",
    "#spatial pattern\n",
    "weighting = numpy.zeros((154))\n",
    "weighting [[v1_node]] = 0.03\n",
    "\n",
    "#temporal profile\n",
    "eqn_t = equations.PulseTrain()\n",
    "eqn_t.parameters['onset'] = 10000\n",
    "eqn_t.parameters['T'] = 1000.0\n",
    "eqn_t.parameters['tau'] = 50.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a74063",
   "metadata": {},
   "source": [
    "We will be using a connectivity matrix that is not the default matrix and so we will need to load in this matrix. Make sure after loading it in you should name the files appropriately, zip them and then place the package in the connectivity file in tvb's data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f309d5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_conn= connectivity.Connectivity.from_file(\"newconn.zip\")\n",
    "new_conn.configure()\n",
    "new_conn.weights= (np.loadtxt('/home/htian/Data/avg9/weights.txt'))\n",
    "new_conn.tract_lengths= np.loadtxt('/home/htian/Data/avg9/tract_lengths.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a393becb",
   "metadata": {},
   "source": [
    "Now, combine the spatial pattern with the temporal profile into one object. We must first configure the stimulus which happens automatically in the simulator. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e14d506",
   "metadata": {},
   "source": [
    "## Bar Graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170e2fe8",
   "metadata": {},
   "source": [
    "We'll be graphing a bunch of bar graphs for visualization purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e071307b",
   "metadata": {},
   "source": [
    "#### activation times of all nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7146075e",
   "metadata": {},
   "source": [
    "To display the activation times we will want to start displaying the time of the stimulation as 0. To do this we will need to loop through the activation times and subtract 10000 from each value. If the value is already less than 10000 we will replace it with nan since it does not activate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e264b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "activation_times=np.zeros(len(activation_time))\n",
    "\n",
    "for i in range(len(activation_time)):\n",
    "    if activation_time[i] == 0 or activation_time[i] < 10000:\n",
    "        activation_times[i]= nan\n",
    "    else:\n",
    "        activation_times[i]= activation_time[i] - 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c1e00d",
   "metadata": {},
   "source": [
    "Since our data doesn't include the stimulated node, we will need to remove that label from our labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b672138",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_nodes = [i for i in range(154) if i != v1_node]\n",
    "labels_nostim=region_labels_lr[lst_nodes]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a85cf3",
   "metadata": {},
   "source": [
    "Now, just load the labels and activation times into a dataframe. Then, sort the activation times in ascending order. Finally, plot the ordered activation times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fa9752",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_activation= pd.DataFrame(activation_times, region_labels_lr) \n",
    "\n",
    "df_activation_sort = df_activation.sort(columns =0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afbb5e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = df_activation_sort.plot(kind='barh', title=\"distances\", figsize=(17,17), legend=False)\n",
    "y_pos = np.arange(len(df_activation_sort))\n",
    "width= 0.35\n",
    "rects = ax.barh(y_pos, df_activation_sort, width)\n",
    "\n",
    "ax.set_ylabel('node acronyms')\n",
    "ax.set_xlabel('time activation(ms)')\n",
    "ax.invert_yaxis()\n",
    "ax.set_title('Node Activation Times')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71462b1",
   "metadata": {},
   "source": [
    "#### activation times of specific nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33199f3",
   "metadata": {},
   "source": [
    "Now repeat the same process for your specified nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb171f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "stimulus = patterns.StimuliRegion( temporal = eqn_t, \n",
    "                                  connectivity = new_conn, \n",
    "                                  weight = weighting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c88f3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "stimulus.configure_space()\n",
    "stimulus.configure_time(numpy.arange(0.,12000, 2**-4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3b42c3",
   "metadata": {},
   "source": [
    "## Simulate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4901069",
   "metadata": {},
   "source": [
    "We must define the parameters for our simulation. Here we are using parameters that we've come up with based off of the Spiegler model and previous trials. Adjust these values to what best fits your data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28717599",
   "metadata": {},
   "source": [
    "## Visualize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a29bf1",
   "metadata": {},
   "source": [
    "Since the stimulated node's amplitude is much greater than the amplitudes of the other nodes. To be able to see the data in an appropriate scope we will exclude the stimulated node from certain calculations. Here we are inlcuding all the data except the data of the stimulated node into an array. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad182a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_nodes = [i for i in range(154) if i != v1_node]\n",
    "nostimnode=tavg_data[:, 0, lst_nodes, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1474a146",
   "metadata": {},
   "source": [
    "In the graph, the black lines will represent all nodes except the stimulated node, red is for the stimulated node, and green is for certain nodes that we want to investigate.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50134fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "datas_raw= (nostimnode)\n",
    "v1_raw= (tavg_data[:, 0, v1_node, 0])\n",
    "follow_raw=( tavg_data[:, 0, 36, 0],tavg_data[:, 0, 45, 0],tavg_data[:, 0, 46, 0],tavg_data[:, 0, 47, 0],\n",
    "             tavg_data[:, 0, 69, 0],tavg_data[:, 0, 70, 0],tavg_data[:, 0, 72, 0])\n",
    "#follow nodes are in the order FEF, MSTd, MSTl, MT, V1, V2, V3, V4 \n",
    "\n",
    "datas= np.squeeze(datas_raw)\n",
    "v1= np.squeeze(v1_raw).T\n",
    "follow = np.squeeze(follow_raw).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc7ebc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#time vs temporal average graph\n",
    "figure()\n",
    "plot(tavg_time, datas,'k', alpha = 0.5)\n",
    "plot(tavg_time, v1, 'r', alpha = 1)\n",
    "plot(tavg_time, follow, 'g', alpha =0.5)\n",
    "ylabel(\"Temporal average\")\n",
    "xlabel (\"Time(ms)\")\n",
    "plt.grid('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eba9d80",
   "metadata": {},
   "source": [
    "## Finding thresholds\n",
    "\n",
    "We will need to define thresholds of each invidual node. Here we are using the data 200 ms before stimlation. After finding the maximum amplitude of each node in that time period, we will make an array in the same shape as the shape of the data we are comparing it to. Next, look for when the data is greater than the maximum then when it is less than the maximum. Finally, we add them together in a single array to see when it passes threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54802f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_notrans = tavg_time[range(9800,12000)]\n",
    "data_notrans_mean= tavg_data.squeeze().T[:,range(9800, 10000)]\n",
    "data_notrans= tavg_data.squeeze().T[:,range(9800, 12000)]\n",
    "\n",
    "data_notrans_posthr= []\n",
    "data_notrans_negthr= []\n",
    "data_notrans_thr= []\n",
    "\n",
    "for node in range(len(data_notrans_mean)):\n",
    "    data_notrans_posthr.append(np.array(data_notrans[node]>(data_notrans_mean[node].max())))\n",
    "    data_notrans_negthr.append(np.array(data_notrans[node]<(data_notrans_mean[node].min())))\n",
    "    \n",
    "    data_notrans_thr.append(np.array(data_notrans_posthr[node] + data_notrans_negthr[node]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c459bdf",
   "metadata": {},
   "source": [
    "## Finding activation times"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b16354",
   "metadata": {},
   "source": [
    "Here we will be finding the activation times using the positive and negative thresholds. We have already compared the data with the thresholds to see what times it will surpass them. We will first find them for all nodes followed by calculating them for the specified nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d010431",
   "metadata": {},
   "outputs": [],
   "source": [
    "activation_time=np.array(np.zeros(len(data_notrans_thr)))\n",
    "for node in range(len(data_notrans_thr)):\n",
    "    for time in range(9800,12000):\n",
    "        if np.array(data_notrans_thr[node][time -9800]) == True:\n",
    "            activation_time[node]=time\n",
    "            break\n",
    "        else:\n",
    "            activation_time[node]= nan\n",
    "#activation_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e630f06",
   "metadata": {},
   "source": [
    "Compare the times to see if they match the results from the empircal data, if not change the parameters and try again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6661fdb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (10, 10))\n",
    "sns.heatmap(df_tavg_labs.ix[9800:12000].T, ax=ax, vmin=-0.001, vmax=0.001, xticklabels='')\n",
    "ax.imshow(df_tavg.ix[9800:12000].T.values,vmin=-0.001, vmax=0.001, aspect='auto',cmap='coolwarm',\n",
    "          interpolation='none')\n",
    "ax.set_yticklabels\n",
    "ax.grid('off')\n",
    "for label in ax.get_yticklabels(): label.set_rotation(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608f5fe4",
   "metadata": {},
   "source": [
    "## Covariance matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324b72f0",
   "metadata": {},
   "source": [
    "We will need to calculate the covariance values 200ms before the stimulationand plot them on a matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d5fd23",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_notrans_prestim= np.squeeze(nostimnode.T)[:,range(9800, 10000)]\n",
    "dat_notrans_cov = np.cov(dat_notrans_prestim)\n",
    "\n",
    "fig, ax= plt.subplots(figsize= (9,9))\n",
    "fig.canvas.draw()\n",
    "ax.set_xticks(range(len(labels_nostim)))\n",
    "ax.set_yticks(range(len(labels_nostim)))\n",
    "ax.set_xticklabels(labels_nostim,rotation=90,fontsize=8)\n",
    "ax.set_yticklabels(labels_nostim, fontsize=8)\n",
    "plt.imshow(dat_notrans_cov, cmap= 'jet')\n",
    "plt.grid('off')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c18a73",
   "metadata": {},
   "source": [
    "#### Eigenvector matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0423c6",
   "metadata": {},
   "source": [
    "Calculate the Eigen vector matrix from covariance matrix and plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3f3d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.linalg import eig\n",
    "\n",
    "dat_notrans_cov_evals, dat_notrans_cov_evecs = np.linalg.eig(dat_notrans_cov)\n",
    "\n",
    "fig, ax =plt.subplots(figsize= (9,9))\n",
    "fig.canvas.draw()\n",
    "ax.set_xticks(range(len(labels_nostim)))\n",
    "ax.set_yticks(range(len(labels_nostim)))\n",
    "ax.set_xticklabels(labels_nostim,rotation=90,fontsize=8)\n",
    "ax.set_yticklabels(labels_nostim, fontsize= 8)\n",
    "\n",
    "dat_notrans_cov_evecs_154 = np.zeros([154,154])\n",
    "dat_notrans_cov_evecs_154[:153,:153] = dat_notrans_cov_evecs\n",
    "plt.imshow(dat_notrans_cov_evecs_154, cmap= 'jet')\n",
    "plt.grid('off')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53fe2525",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3503da10",
   "metadata": {},
   "source": [
    "Later, our data will require a null entry so we will create a version of our eigenvector matrix that has 155 nodes as the last one will be for the null entry. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e84661",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_notrans_cov_evecs_155 = np.zeros([155,155])\n",
    "dat_notrans_cov_evecs_155[:153,:153] = dat_notrans_cov_evecs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0fc4e2",
   "metadata": {},
   "source": [
    "## Time Slice on Brain Surface"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c5cc19",
   "metadata": {},
   "source": [
    "To follow the dissipation visually, we will be plotting the data on a brain surface."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb9eba2",
   "metadata": {},
   "source": [
    "# Make the plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab6c0d2",
   "metadata": {},
   "source": [
    "We will be saving the figures then displaying them since these are a little big and have difficulties loading them on the spot. Expect at least a few minutes for the figures to load. Change the ts times to display the time frames you want to look at. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c155d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd '/tmp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50bb757",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=1, nrows=10)\n",
    "cmap = cm.Reds\n",
    "cmap.set_under(color='w')\n",
    "\n",
    "kws = {'edgecolors': 'k', 'vmin': 0, 'cmap': cmap, \n",
    "       'vmax': 1, 'alpha': None, 'linewidth': 0.01}\n",
    "\n",
    "ts=[10000.5, 10035.5, 10070.5, 10105.5, 10140.5, 10175.5, 10210.5, 10245.5, 10280.5, 10315.5]\n",
    "\n",
    "for t_it,t in enumerate(ts):\n",
    "\n",
    "    data = np.append(df_notstim.ix[t].abs().values, nan)\n",
    "    \n",
    "    plot_surface_mpl_mv(vtx=vtx,tri=tri,rm=rm,data=data, figsize=(10,10),\n",
    "                    hemi=hemi ,shade_kwargs=kws) \n",
    "    \n",
    "    f = '/tmp/braintmp_v1_t%1.1fms.png' %t\n",
    "    plt.savefig(f,bbox_inches='tight')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab533acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=10, figsize= (12,40))\n",
    "\n",
    "for t_it,t in enumerate(ts):\n",
    "    f =  '/tmp/braintmp_v1_t%1.1fms.png' %t\n",
    "    ax[t_it].imshow(plt.imread(f))\n",
    "    ax[t_it].axis('off')\n",
    "    ax[t_it].set_title('t=%1.1fms' %t,fontsize=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af31c45c",
   "metadata": {},
   "source": [
    "Next, we will be displaying figures at given eigen vector slices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94559466",
   "metadata": {},
   "outputs": [],
   "source": [
    "#display the data with one color\n",
    "\n",
    "kws = {'edgecolors': 'k', 'vmin': 0, 'cmap': 'Reds', #'vmin': 0.4\n",
    "       'vmax': 1, 'alpha': None, 'linewidth': 0.01}\n",
    "\n",
    "fig, ax = plt.subplots(ncols=4,nrows=2,figsize=(12,6))\n",
    "\n",
    "for e_it in range(4):\n",
    "    dat = np.abs(dat_notrans_cov_evecs_155[:,e_it])\n",
    "\n",
    "    plot_surface_mpl(vtx=vtx,tri=tri,data=dat,rm=rm,ax=ax[0][e_it],\n",
    "                     shade_kwargs=kws,view='rh_lat', title='evec %s' %e_it)\n",
    "\n",
    "    plot_surface_mpl(vtx=vtx,tri=tri,data=dat,rm=rm,ax=ax[1][e_it],\n",
    "                     shade_kwargs=kws,view='superior')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8db302a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b27cbf",
   "metadata": {},
   "source": [
    "# HC stimulation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e475703",
   "metadata": {},
   "source": [
    "Now repeat the process with the node you want to stimulate. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90044db1",
   "metadata": {},
   "source": [
    "These parameters are the same as the ones above. If you change the parameters in the V1 stimulation, remember to change them here as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1b9dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = new_conn\n",
    "mod= models.Generic2dOscillator(d = (1/1000.) * 76.74,\n",
    "                                tau =1., f= 1.,e= 0., g= -0.1, \n",
    "                            alpha =1., gamma= 1., c= 0., b= -12.3083, beta =0., a =0.)\n",
    "integrators = integrators.HeunStochastic(dt = 0.1, noise=noise.Additive(nsig=5e-15)) \n",
    "coupling = coupling.Linear(a=0.01)\n",
    "monitors= monitors.TemporalAverage(period = 1.0)\n",
    "conn.speed= 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583d308e",
   "metadata": {},
   "source": [
    "### Defining the weighting of the stimuli"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c80f3b",
   "metadata": {},
   "source": [
    "Specify the name and node number of the node you want to stimulate ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c33a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "stim_node= 29\n",
    "stim_name= 'CA1'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3410b83f",
   "metadata": {},
   "source": [
    "Don't forget to change these values if you change them above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463b86d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "datas_raw= (nostimnode)\n",
    "d_raw= (tavg_data[:, 0, stim_node, 0])\n",
    "follow_raw=( tavg_data[:, 0, 36, 0],tavg_data[:, 0, 69, 0],tavg_data[:, 0, 72, 0],tavg_data[:, 0, 22, 0],\n",
    "             tavg_data[:, 0, 13, 0],tavg_data[:, 0, 14, 0],tavg_data[:, 0, 40, 0],tavg_data[:, 0, 66, 0],\n",
    "             tavg_data[:, 0, 8, 0], tavg_data[:, 0, 19, 0])\n",
    "\n",
    "datas= np.squeeze(datas_raw)\n",
    "d= np.squeeze(d_raw).T\n",
    "follow = np.squeeze(follow_raw).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b6a9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#time vs temporal average graph\n",
    "figure()\n",
    "plot(tavg_time, d, 'r', alpha = 1)\n",
    "plot(tavg_time, follow, 'g', alpha =1)\n",
    "ylabel(\"Temporal average\")\n",
    "xlabel (\"Time(ms)\")\n",
    "plt.grid('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c302b8",
   "metadata": {},
   "source": [
    "### Finding a threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74703253",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_notrans = tavg_time[range(9800,12000)]\n",
    "data_notrans_mean= tavg_data.squeeze().T[:,range(9800, 10000)]\n",
    "data_notrans= tavg_data.squeeze().T[:,range(9800, 12000)]\n",
    "\n",
    "data_notrans_posthr= []\n",
    "data_notrans_negthr= []\n",
    "data_notrans_thr= []\n",
    "\n",
    "for node in range(len(data_notrans_mean)):\n",
    "    data_notrans_posthr.append(np.array(data_notrans[node]>(data_notrans_mean[node].max())))\n",
    "    data_notrans_negthr.append(np.array(data_notrans[node]<(data_notrans_mean[node].min())))\n",
    "    data_notrans_thr.append(np.array(data_notrans_posthr[node] + data_notrans_negthr[node]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91f0d18",
   "metadata": {},
   "source": [
    "### Finding activation times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab48d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = [stim_node,36,69,72,22,13,14,40,66,8,19, 18,3,56,49,1,2]\n",
    "activation_time_spec=np.array(np.zeros(len(s)))\n",
    "i= 0\n",
    "for node in s: \n",
    "    for time in range(9800,12000):\n",
    "        if np.array(data_notrans_thr[node][time -9800]) == True:\n",
    "            activation_time_spec[i]=time\n",
    "            break\n",
    "        else:\n",
    "            activation_time_spec[i]= nan\n",
    "    i += 1\n",
    "activation_time_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b565de9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "activation_times_spec=np.zeros(len(activation_time_spec))\n",
    "for i in range(len(activation_time_spec)):\n",
    "    if activation_time_spec[i] == 0 or activation_time_spec[i] < 10000:\n",
    "        activation_times_spec[i]= nan\n",
    "    else:\n",
    "        activation_times_spec[i]= activation_time_spec[i] - 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483b8c2b",
   "metadata": {},
   "source": [
    "Save the activation times externally for future use. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d120d8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd /tmp/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3b02e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name= stim_name + '_data.txt'\n",
    "np.savetxt(file_name, activation_times_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35866174",
   "metadata": {},
   "source": [
    "### Loading in region labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ccecdeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "weighting = numpy.zeros((154))\n",
    "weighting [[stim_node]] = 0.03\n",
    "\n",
    "#temporal profile\n",
    "eqn_t = equations.PulseTrain()\n",
    "eqn_t.parameters['onset'] = 10000\n",
    "eqn_t.parameters['T'] = 1000.0\n",
    "eqn_t.parameters['tau'] = 50.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da953c73",
   "metadata": {},
   "source": [
    "### Creating the stimulus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8faff66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "activation_times_spec=np.zeros(len(activation_time_spec))\n",
    "\n",
    "for i in range(len(activation_time_spec)):\n",
    "    if activation_time_spec[i] == 0 or activation_time_spec[i] < 10000:\n",
    "        activation_times_spec[i]= 0\n",
    "    else:\n",
    "        activation_times_spec[i]= activation_time_spec[i] - 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661c06ec",
   "metadata": {},
   "source": [
    "Here, you will need to manually include your label names in the same order as before or feel free to write a loop to include the labels that you want. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8b8176",
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_spec= np.array(['FEF_L', 'MST(45)', 'MST(46)', 'MT_L', 'V1_L', 'V2_L', 'V3_L', 'V4_L'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ad24a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_activation_spec= pd.DataFrame(activation_times_spec, lab_spec) \n",
    "\n",
    "df_activation_spec_sort = df_activation_spec.sort(columns= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33af4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = df_activation_spec_sort.plot(kind='barh', title=\"distances\", figsize=(6,3), legend=False)\n",
    "y_pos = np.arange(len(df_activation_spec_sort))\n",
    "width= 0.05\n",
    "rects = ax.barh(y_pos, df_activation_spec_sort, width)\n",
    "\n",
    "ax.set_ylabel('node acronyms')\n",
    "ax.set_xlabel('time activation(ms)')\n",
    "ax.invert_yaxis()\n",
    "ax.set_title('Node Activation Times')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f922bdb5",
   "metadata": {},
   "source": [
    "#### distances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac60a893",
   "metadata": {},
   "source": [
    "We'll be making a bar graph to display the distances in order of closest to farthest nodes from our stimulated node (V1 for this case)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769d4be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=1, nrows=10)\n",
    "cmap = cm.Reds\n",
    "cmap.set_under(color='w')\n",
    "\n",
    "kws = {'edgecolors': 'k', 'vmin': 0, 'cmap': cmap, \n",
    "       'vmax': 1, 'alpha': None, 'linewidth': 0.01}\n",
    "\n",
    "\n",
    "#ts=[10000.5, 10050.5, 10100.5, 10150.5, 10200.5, 10250.5, 10300.5, 100.5, 10400.5, 10450.5]\n",
    "ts=[10000.5, 10175.5, 10350.5, 10525.5, 10700.5, 10875.5, 11050.5, 11225.5, 11400.5, 11575.5]\n",
    "\n",
    "for t_it,t in enumerate(ts):\n",
    "    data = np.append(df_notstim.ix[t].abs().values, nan)\n",
    " \n",
    "    plot_surface_mpl_mv(vtx=vtx ,tri= tri,rm=rm,data=data, figsize=(10,10),\n",
    "                    hemi=hemi ,shade_kwargs=kws) \n",
    "    \n",
    "    f = '/tmp/braintmp_' + stim_name +'_t%1.1fms.png' %t\n",
    "    plt.savefig(f,bbox_inches='tight')\n",
    "    plt.close()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5517a7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=10, figsize= (12,60))\n",
    "for t_it,t in enumerate(ts):\n",
    "    f =  '/tmp/braintmp_' + stim_name + '_t%1.1fms.png' %t\n",
    "    ax[t_it].imshow(plt.imread(f))\n",
    "    ax[t_it].axis('off')\n",
    "    ax[t_it].set_title('t=%1.1fms' %t,fontsize=9)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a46014",
   "metadata": {},
   "source": [
    "### Plotting eigenvector on brain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3089f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#display the data\n",
    "kws = {'edgecolors': 'k', 'vmin': -1, 'cmap': 'coolwarm', 'vmax': 1, 'alpha': None, 'linewidth': 0.01}\n",
    "fig, ax = plt.subplots(ncols=4,nrows=2,figsize=(12,6))\n",
    "for e_it in range(4): \n",
    "    dat = dat_notrans_cov_evecs_155[:,e_it]\n",
    "    \n",
    "    plot_surface_mpl(vtx=vtx,tri=tri,data=dat,rm=rm,ax=ax[0][e_it],\n",
    "                 shade_kwargs=kws,view='rh_lat', title='evec %s' %e_it)\n",
    "    \n",
    "    plot_surface_mpl(vtx=vtx,tri=tri,data=dat,rm=rm,ax=ax[1][e_it],\n",
    "                 shade_kwargs=kws,view='superior')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76786dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#display the data with one color\n",
    "\n",
    "kws = {'edgecolors': 'k', 'vmin': 0, 'cmap': 'Reds', #'vmin': 0.4\n",
    "       'vmax': 1, 'alpha': None, 'linewidth': 0.01}\n",
    "\n",
    "fig, ax = plt.subplots(ncols=4,nrows=2,figsize=(12,6))\n",
    "\n",
    "for e_it in range(4):\n",
    "    dat = np.abs(dat_notrans_cov_evecs_155[:,e_it])\n",
    "\n",
    "    plot_surface_mpl(vtx=vtx,tri=tri,data=dat,rm=rm,ax=ax[0][e_it],\n",
    "                     shade_kwargs=kws,view='rh_lat', title='evec %s' %e_it)\n",
    "\n",
    "    plot_surface_mpl(vtx=vtx,tri=tri,data=dat,rm=rm,ax=ax[1][e_it],\n",
    "                     shade_kwargs=kws,view='superior')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6088ed34",
   "metadata": {},
   "source": [
    "### all activation times"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae46f69",
   "metadata": {},
   "source": [
    "After running all the stimulations you wanted, load in all your files that you saved previously. Here, we will be saving all the activation times in a dataframe to compare activation times of all stimulations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c249f865",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "act_times= []\n",
    "act_times.append(np.array(np.loadtxt('S_data.txt')))\n",
    "act_times.append(np.array(np.loadtxt('CA3_data.txt')))\n",
    "act_times.append(np.array(np.loadtxt('CA1_data.txt')))\n",
    "act_times.append(np.array(np.loadtxt('ER_data.txt')))\n",
    "act_times= np.array(act_times)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499560e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_labs= ['S','CA3', 'CA1', 'ER']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607a89d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_activation_spec_all = pd.DataFrame(act_times.T,lab_spec, columns= col_labs) \n",
    "df_activation_spec_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20da87a",
   "metadata": {},
   "source": [
    "Here we visualizing the data with a bar graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb99786d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_rows',200)\n",
    "df_tavg = pd.DataFrame(np.squeeze(tavg_data),index=tavg_time)\n",
    "labs= pd.read_csv('/home/htian/Data/kelly_matrix/labelnames.txt',sep='\\t')['acronym'].values\n",
    "lh_labs = [l + '_L' for l in labs]\n",
    "rh_labs = [l + '_R' for l in labs]\n",
    "region_labels_lr = np.concatenate([lh_labs, rh_labs])\n",
    "df_tavg_labs = df_tavg.copy()\n",
    "df_tavg_labs.columns= region_labels_lr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5501cd19",
   "metadata": {},
   "source": [
    "### Bar graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c604c6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_spec= np.array(['stim' ,'FEF', 'V2', 'V4', '7a', '35', '36', 'Ig', 'TF', '24/ACC', '46', \n",
    "                    '45', '12', 'Pro', 'PAC', '10', '11'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783a8289",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_activation_spec= pd.DataFrame(activation_times_spec, lab_spec) \n",
    "lst_nodes = [i for i in range(154) if i != stim_node]\n",
    "labels_nostim=region_labels_lr[lst_nodes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baea923e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_activation_spec_sort = df_activation_spec.sort(columns= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9dfe9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_activation_spec_sort = df_activation_spec.sort(columns =0)\n",
    "ax = df_activation_spec_sort.plot(kind='barh', title=\"distances\", figsize=(9,6), legend=False)\n",
    "y_pos = np.arange(len(df_activation_spec_sort))\n",
    "width= 0.05\n",
    "rects = ax.barh(y_pos, df_activation_spec_sort, width)\n",
    "\n",
    "ax.set_ylabel('node acronyms')\n",
    "ax.set_xlabel('time activation(ms)')\n",
    "ax.invert_yaxis()\n",
    "ax.set_title('Node Activation Times')\n",
    "ax.set_xlim(0,1600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a26bf96",
   "metadata": {},
   "source": [
    "### distances from stim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc6e442",
   "metadata": {},
   "outputs": [],
   "source": [
    "i =v1_node\n",
    "distances= np.array(np.zeros(len(new_conn.tract_lengths)))\n",
    "\n",
    "for j in range(len(new_conn.tract_lengths)):\n",
    "    distances[j]= new_conn.tract_lengths[i, j]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ad6b9c",
   "metadata": {},
   "source": [
    "Here we will need to slice the distances array at 77 because we only care about the distances of the nodes in the left hemisphere. Load them into a dataframe then sort. Then, plot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e1f039",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod= models.Generic2dOscillator(d = (1/1000.) * 76.74,\n",
    "                                tau =1., f= 1.,e= 0., g= -0.1, \n",
    "                            alpha =1., gamma= 1., c= 0., b= -12.3083, beta =0., a =0.)\n",
    "integrators = integrators.HeunStochastic(dt = 0.1, noise=noise.Additive(nsig=5e-15)) \n",
    "coupling = coupling.Linear(a=0.01)\n",
    "monitors= monitors.TemporalAverage(period = 1.0)\n",
    "new_conn.speed= 8."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d71d5f7",
   "metadata": {},
   "source": [
    "Create and run the simulation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013e03cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = simulator.Simulator(\n",
    "        model = mod,\n",
    "        connectivity = new_conn,\n",
    "        coupling = coupling,\n",
    "        integrator = integrators,\n",
    "        monitors = monitors,\n",
    "        stimulus = stimulus, \n",
    "        simulation_length = 12000,\n",
    "        ).configure()\n",
    "\n",
    "(tavg_time, tavg_data), = sim.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c74408",
   "metadata": {},
   "source": [
    "### Time slice on brain using surface plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1a3c67",
   "metadata": {},
   "source": [
    "### Make fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2999f884",
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx_file= '/home/htian/Data/newzip.zip'\n",
    "rm= np.loadtxt('/home/htian/Data/region_mapping.txt')\n",
    "hemi= np.loadtxt('/home/htian/Data/fv91_srfData_20170215/hemispheres.txt')\n",
    "ctx = cortex.Cortex.from_file(source_file = ctx_file)\n",
    "vtx,tri = ctx.vertices,ctx.triangles\n",
    "\n",
    "notstim= np.squeeze(tavg_data).copy()\n",
    "notstim[:, stim_node]= 0\n",
    "           \n",
    "m = np.array([(np.abs(notstim[i])).max() for i in range(len(notstim))])\n",
    "for i in range(len(notstim)):\n",
    "    for j in range(len(notstim[1])):\n",
    "        notstim[i,j] /= m[i]\n",
    "\n",
    "df_notstim = pd.DataFrame(notstim,index=tavg_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710f78be",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = df_max_amp_sort.plot(kind='barh', title=\"amplitudes\", figsize=(10,10), legend=False)\n",
    "y_pos = np.arange(len(df_max_amp_sort))\n",
    "width= 0.35\n",
    "rects = ax.barh(y_pos, df_max_amp_sort, width)\n",
    "\n",
    "ax.set_ylabel('node acronyms')\n",
    "ax.set_xlabel('amplitude')\n",
    "ax.invert_yaxis()\n",
    "ax.set_title('Amplitudes')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03daf215",
   "metadata": {},
   "source": [
    "## Heat Map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1143bc",
   "metadata": {},
   "source": [
    "As another way to visualize the dissipation of the stimulus is to use a heatmap. It is important to adjust vmin and vmax accordingly.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acea0768",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = [36,45,46,47,68,69,70,72]\n",
    "activation_time_spec=np.array(np.zeros(len(s)))\n",
    "i= 0\n",
    "\n",
    "for node in s: \n",
    "    for time in range(9800,12000):\n",
    "        if np.array(data_notrans_thr[node][time -9800]) == True:\n",
    "            activation_time_spec[i]=time\n",
    "            break\n",
    "        else:\n",
    "            activation_time_spec[i]= nan\n",
    "    i += 1\n",
    "activation_time_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd423eea",
   "metadata": {},
   "source": [
    "## Loading in region labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1b04f4",
   "metadata": {},
   "source": [
    "Load in region labels and place them in a dataframe for easy manipulation later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2409fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_rows',200)\n",
    "df_tavg = pd.DataFrame(np.squeeze(tavg_data),index=tavg_time)\n",
    "\n",
    "labs= pd.read_csv('/home/htian/Data/kelly_matrix/labelnames.txt',sep='\\t')['acronym'].values\n",
    "\n",
    "lh_labs = [l + '_L' for l in labs]\n",
    "rh_labs = [l + '_R' for l in labs]\n",
    "region_labels_lr = np.concatenate([lh_labs, rh_labs])\n",
    "\n",
    "df_tavg_labs = df_tavg.copy()\n",
    "df_tavg_labs.columns= region_labels_lr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a915b90",
   "metadata": {},
   "source": [
    "We're going to normalize all values at their respective time. We will set the stimulated node to 0 because we only care about the amplitudes of all other nodes and we don't want it to be taken as the maximum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b011400b",
   "metadata": {},
   "outputs": [],
   "source": [
    "notstim= np.squeeze(tavg_data).copy()\n",
    "notstim[:, 68]= 0\n",
    "m = np.array([(np.abs(notstim[i])).max() for i in range(len(notstim))])\n",
    "for i in range(len(notstim)):\n",
    "    for j in range(len(notstim[1])):\n",
    "        print i,\n",
    "        notstim[i,j] /= m[i]\n",
    "        \n",
    "df_notstim = pd.DataFrame(notstim,index=tavg_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9093122",
   "metadata": {},
   "outputs": [],
   "source": [
    "stimulus = patterns.StimuliRegion( temporal = eqn_t, \n",
    "                                  connectivity = conn, \n",
    "                                  weight = weighting)\n",
    "\n",
    "stimulus.configure_space()\n",
    "stimulus.configure_time(numpy.arange(0.,12000, 2**-4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c69e967",
   "metadata": {},
   "source": [
    "### Putting together the simulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b80d8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tvb.datatypes.cortex import Cortex\n",
    "from tvb.datatypes.region_mapping import RegionMapping\n",
    "from tvb.datatypes.projections import ProjectionMatrix\n",
    "import pandas as pd\n",
    "from matplotlib.tri import Triangulation\n",
    "from numpy import pi, cos, sin\n",
    "from matplotlib import cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68b508a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_surface_mpl(vtx,tri,data=None,rm=None,reorient=None,view='superior',\n",
    "                     shaded=False,ax=None,figsize=(6,4), title=None,\n",
    "                     lthr=None,uthr=None, nz_thr = 1E-20,\n",
    "                     shade_kwargs = {'edgecolors': 'k', 'linewidth': 0.1,\n",
    "                                     'alpha': None, 'cmap': 'coolwarm',\n",
    "                                     'vmin': None, 'vmax': None}):\n",
    "\n",
    "    # in the namespace inadvertently. \n",
    "    vtx,tri = vtx.copy(),tri.copy()\n",
    "    if data is not None: data = data.copy()\n",
    "\n",
    "    # 1. Set the viewing angle \n",
    "  \n",
    "    if reorient == 'tvb':\n",
    "        # The tvb default brain has coordinates in the order \n",
    "        # yxz for some reason. So first change that:   \n",
    "        vtx = np.array([vtx[:,1],vtx[:,0],vtx[:,2]]).T.copy()\n",
    "        # Also need to reflect in the x axis\n",
    "        vtx[:,0]*=-1\n",
    "\n",
    "    # (reorient == 'fs' is same as reorient=None; so not strictly needed\n",
    "    #  but is included for clarity)\n",
    "\n",
    "    # ...get rotations for standard view options\n",
    "    \n",
    "    if   view == 'lh_lat'    : rots =  [(0,-90),(1,90)  ]\n",
    "    elif view == 'lh_med'    : rots =  [(0,-90),(1,-90) ] \n",
    "    elif view == 'rh_lat'    : rots =  [(0,-90),(1,-90) ]\n",
    "    elif view == 'rh_med'    : rots =  [(0,-90),(1,90)  ]\n",
    "    elif view == 'superior'  : rots =   None\n",
    "    elif view == 'inferior'  : rots =   (1,180)\n",
    "    elif view == 'anterior'  : rots =   (0,-90)\n",
    "    elif view == 'posterior' : rots =  [(0, -90),(1,180)]\n",
    "    elif (type(view) == tuple) or (type(view) == list): rots = view \n",
    "\n",
    "    # (rh_lat is the default 'view' argument because no rotations are \n",
    "    #  for that one; so if no view is specified when the function is called, \n",
    "    #  the 'rh_lat' option is chose here and the surface is shown 'as is'                          \n",
    "                            \n",
    "    # ...apply rotations                          \n",
    "    if rots is None: rotmat = np.eye(3)\n",
    "    else:            rotmat = get_combined_rotation_matrix(rots)\n",
    "    vtx = np.dot(vtx,rotmat)\n",
    "\n",
    "    # 2. Sort out the data\n",
    "                                    \n",
    "    # ...if no data is given, plot a vector of 1s. \n",
    "    #    if using region data, create corresponding surface vector \n",
    "    if data is None: \n",
    "        data = np.ones(vtx.shape[0]) \n",
    "    elif data.shape[0] != vtx.shape[0]: \n",
    "        data = np.array([data[r] for r in rm])\n",
    "    \n",
    "    # ...apply thresholds\n",
    "    if uthr: data *= (data < uthr)\n",
    "    if lthr: data *= (data > lthr)\n",
    "    data *= (np.abs(data) > nz_thr)\n",
    "\n",
    "    # 3. Create the surface triangulation object \n",
    "    x,y,z = vtx.T\n",
    "    tx,ty,tz = vtx[tri].mean(axis=1).T\n",
    "    tr = Triangulation(x,y,tri[np.argsort(tz)])\n",
    "                \n",
    "    # 4. Make the figure \n",
    "    if ax is None: fig, ax = plt.subplots(figsize=figsize)  \n",
    "  \n",
    "    #if shade = 'gouraud': shade_opts['shade'] = \n",
    "    tc = ax.tripcolor(tr, np.squeeze(data), **shade_kwargs)\n",
    "                        \n",
    "    ax.set_aspect('equal')\n",
    "    ax.axis('off')\n",
    "    \n",
    "    if title is not None: ax.set_title(title)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408935f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_surface_mpl_mv(vtx=None,tri=None,data=None,rm=None,hemi=None,   # Option 1\n",
    "                        vtx_lh=None,tri_lh=None,data_lh=None,rm_lh=None, # Option 2\n",
    "                        vtx_rh=None,tri_rh=None,data_rh=None,rm_rh=None,\n",
    "                        title=None,**kwargs):\n",
    " \n",
    "    if vtx is not None:                                    # Option 1\n",
    "        tri_hemi = hemi[tri].any(axis=1)\n",
    "        tri_lh,tri_rh = tri[tri_hemi==0],tri[tri_hemi==1]\n",
    "    elif vtx_lh is not None:                               # Option 2\n",
    "        vtx = np.vstack([vtx_lh,vtx_rh])\n",
    "        tri = np.vstack([tri_lh,tri_rh+tri_lh.max()+1])\n",
    "\n",
    "    if data_lh is not None:                                # Option 2\n",
    "        data = np.hstack([data_lh,data_rh])\n",
    "    \n",
    "    if rm_lh is not None:                                  # Option 2 \n",
    "        rm = np.hstack([rm_lh,rm_rh + rm_lh.max() + 1])\n",
    "    \n",
    " \n",
    "    # 2. Now do the plots for each view\n",
    "\n",
    "    # (Note: for the single hemispheres we only need lh/rh arrays for the \n",
    "    #  faces (tri); the full vertices, region mapping, and data arrays\n",
    "    #  can be given as arguments, they just won't be shown if they aren't \n",
    "    #  connected by the faces in tri )\n",
    "  \n",
    "    # LH lateral\n",
    "    plot_surface_mpl(vtx,tri_lh,data=data,rm=rm,view='lh_lat',\n",
    "                   ax=subplot(2,3,1),**kwargs)\n",
    "    \n",
    "    # LH medial\n",
    "    plot_surface_mpl(vtx,tri_lh, data=data,rm=rm,view='lh_med',\n",
    "                   ax=subplot(2,3,4),**kwargs)\n",
    "    \n",
    "    # RH lateral\n",
    "    plot_surface_mpl(vtx,tri_rh, data=data,rm=rm,view='rh_lat',\n",
    "                   ax=subplot(2,3,3),**kwargs)\n",
    "    \n",
    "    # RH medial\n",
    "    plot_surface_mpl(vtx,tri_rh, data=data,rm=rm,view='rh_med',\n",
    "                   ax=subplot(2,3,6),**kwargs)\n",
    "    \n",
    "    # Both superior\n",
    "    plot_surface_mpl(vtx,tri, data=data,rm=rm,view='superior',\n",
    "                   ax=subplot(1,3,2),title=title,**kwargs)\n",
    "    \n",
    "    plt.subplots_adjust(left=0.0, right=1.0, bottom=0.0,\n",
    "                      top=1.0, wspace=0, hspace=0) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ea23fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_combined_rotation_matrix(rotations):\n",
    "    rotmat = np.eye(3)\n",
    "    \n",
    "    if type(rotations) is tuple: rotations = [rotations] \n",
    "    for r in rotations:\n",
    "        newrot = get_rotation_matrix(r[0],r[1])\n",
    "        rotmat = np.dot(rotmat,newrot)\n",
    "    return rotmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74bebe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rotation_matrix(rotation_axis, deg):\n",
    "    # (note make deg minus to change from anticlockwise to clockwise rotation)\n",
    "    th = -deg * (pi/180) # convert degrees to radians\n",
    "    \n",
    "    if rotation_axis == 0:\n",
    "        return np.array( [[    1,         0,         0    ],\n",
    "                          [    0,      cos(th),   -sin(th)],\n",
    "                          [    0,      sin(th),    cos(th)]])\n",
    "    elif rotation_axis ==1:\n",
    "        return np.array( [[   cos(th),    0,        sin(th)],\n",
    "                          [    0,         1,          0    ],\n",
    "                          [  -sin(th),    0,        cos(th)]])\n",
    "    elif rotation_axis ==2:\n",
    "        return np.array([[   cos(th),  -sin(th),     0    ],\n",
    "                         [    sin(th),   cos(th),     0   ],\n",
    "                         [     0,         0,          1   ]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a736e9f",
   "metadata": {},
   "source": [
    "We willl now need to load in the region mapping files to help us create the plotting surface. Here, we have appended the path where our files are located. Our region mapping file works when manually loaded in so that is what we will do for our file but feel free to attach the zip file name instead. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220ea618",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_distances= pd.DataFrame([labs, distances[:77]]).T\n",
    "\n",
    "df_distances_labs= df_distances.sort(columns= 1, ascending= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33407dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = df_distances_labs.plot(kind='barh', title=\"distances\", figsize=(10,10), legend=False)\n",
    "\n",
    "y_pos = np.arange(len(distances[:77]))\n",
    "width= 0.35\n",
    "rects = ax.barh(y_pos,df_distances_labs[1], width)\n",
    "ax.set_ylabel('node acronyms')\n",
    "ax.set_xlabel('Distances')\n",
    "ax.set_title('Distance from node \"V1\"')\n",
    "ax.invert_yaxis()\n",
    "\n",
    "ax.set_yticks(range(len(labs)))\n",
    "ytickNames = ax.set_yticklabels(df_distances_labs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb9cb9c",
   "metadata": {},
   "source": [
    "## Finding amplitudes of each node"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac1d419",
   "metadata": {},
   "source": [
    "To find the amplitudes we will need to loop through the data (excluding the stimulated node) and make an array of each node's max"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
