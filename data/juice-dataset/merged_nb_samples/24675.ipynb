{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08d8ab9b",
   "metadata": {},
   "source": [
    "# PySpark training for data engineers\n",
    "## 05. Data Enriching"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08974d39",
   "metadata": {},
   "source": [
    "### Goal\n",
    "\n",
    "Adding more value to the data by \n",
    "* Adding new columns\n",
    "* Using lambda functions\n",
    "* Using user defined functions\n",
    "\n",
    "### Highlights\n",
    "* `df.withColumn('new_col', Function())` a new column is added to the DataFrame\n",
    "* `len_fun = udf(lambda z: len(z), IntegerType())` is a User Defined Function that returns the length of the input as integer\n",
    "* `df = df.withColumn('length_col', len_fun('text_col'))` will add a column `length_col` with the length of the item in `text_col`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b56e226",
   "metadata": {},
   "source": [
    "### Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71fbc5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import SQLContext\n",
    "config = SparkConf().setMaster('local')\n",
    "spark = SparkContext.getOrCreate(conf=config)\n",
    "sqlContext = SQLContext(spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d983c773",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sqlContext.read.parquet('notebook-04-parquet/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb83ba59",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21809711",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn('double_age', df.age*2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8b14b8",
   "metadata": {},
   "source": [
    "Define a user defined function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99226b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "\n",
    "@udf('integer')\n",
    "def calc_name_length(name):\n",
    "    return len(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3afb4662",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn('name_length', calc_name_length(df.first_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256f0735",
   "metadata": {},
   "source": [
    "Define a lambda function with one input parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21abf323",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import IntegerType\n",
    "len_udf_int = udf(lambda z: len(z), IntegerType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181d7bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn('last_name_length', len_udf_int('last_name'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc61bede",
   "metadata": {},
   "source": [
    "Define a lambda function with two input parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fae7efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "len_udf_two_int = udf(lambda z,y: len(z)+len(y), IntegerType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e84c45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn('full_name_length', len_udf_two_int('first_name', 'last_name'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f7dd84",
   "metadata": {},
   "source": [
    "Remove a column from the dataframe:"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
