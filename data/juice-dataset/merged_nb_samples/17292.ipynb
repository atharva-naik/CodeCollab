{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df327dc0",
   "metadata": {},
   "source": [
    "Â© 2018 Suzy Beeler. This work is licensed under a [Creative Commons Attribution License CC-BY 4.0](https://creativecommons.org/licenses/by/4.0/). All code contained herein is licensed under an [MIT license](https://opensource.org/licenses/MIT) \n",
    "\n",
    "This exercise was generated from a Jupyter notebook. You can download the notebook [here](inferring_p_heads.ipynb).\n",
    "___\n",
    "\n",
    "# Objective \n",
    "\n",
    "This tutorial will serve as a brief introduction to Bayesian inference, a way in which was can estimate the probability of different parameters values from our data. As an example, we will work with a simulated coin, which has probability $0 \\leq p \\leq 1$ of revealing heads. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba214ae",
   "metadata": {},
   "source": [
    "# Bayes' Theorem\n",
    "\n",
    "Bayes' Theorem is given by\n",
    "\n",
    "$$ P(A|B) = \\frac{P(B|A)P(A)}{P(B)}, \\tag{1}$$\n",
    "\n",
    "where $A$ and $B$ are certain events that respectively have probability $P(A)$ and $P(B)$ of occurring. Additionally, $P(A|B)$ (read as \"probability of $A$ given $B$\") is defined as the probability that $A$ occurs *given* that event $B$ has already occurred. This is also known as a *conditional probability* since event $A$ is conditional on event $B$. In the context of scientific endeavors, we are interested in the probability that a model, $M$ (i.e. a given parameter value or set of parameter values), is correct *given* our data, $D$. Couched in the formulation of Bayes' Theorem, we have\n",
    "\n",
    "$$ P(M|D) = \\frac{P(D|M)P(M)}{P(D)}. \\tag{2}$$\n",
    "\n",
    "Each of these four components of Bayes' Theorem has their own name and interpretation:\n",
    "- $P(M|D)$ is the posterior probability. As scientists, this is what we are ultimately trying to assess. That is, we have a certain model as a hypothesis and we would like to quantify the probability that our model is correct given the data we have collected.\n",
    "\n",
    "- $P(D|M)$ is the likelihood. Given a clearly articulated model, we should be able to compute the probability (i.e. likelihood) that our data could occur. \n",
    "\n",
    "- $P(M)$ is the prior probability. This is our best guess of the model's parameter value(s) *prior* to taking any data. \n",
    "\n",
    "- $P(D)$ is the evidence. This is the probability of the data occurring, independent of any hypothesis. This is a hard (if not impossible) thing to compute. But this term can just be considered a normalization constant, since it doesn't contain the model, $M$, which is the value we ultimately wish to assess. \n",
    "\n",
    "After disregarding the evidence term, we are left with\n",
    "\n",
    "$$P(M|D) \\propto P(D|M)P(M). \\tag{3}$$\n",
    "\n",
    "Let's now put Bayes' Theorem to use with the case of an unbiased coin."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e52d82c",
   "metadata": {},
   "source": [
    "# Formulating Bayes' Theorem with coin flips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab1d699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary modules\n",
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# For pretty plots\n",
    "import seaborn as sns\n",
    "rc={'lines.linewidth': 2, 'axes.labelsize': 14, 'axes.titlesize': 14, \\\n",
    "    'xtick.labelsize' : 14, 'ytick.labelsize' : 14}\n",
    "sns.set(rc=rc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47950a9e",
   "metadata": {},
   "source": [
    "## Specifying the prior probabilities\n",
    "\n",
    "We now want to specify our prior probability $P(p_{head})$, that is, our best guess at the probability of getting heads *before* the \"experiment\" was done. If we were dealing with a real coin, our prior probability should be centered around $0.5$ since we expect real coins to be fair. However, if we are dealing with a simulated coin or any other process for which we don't know the underlying mechanism, a uniform prior (where all probability of heads are equally likely) would be more appropriate. Below we specify these two possible priors and plot their probability density functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9d83da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the possible range of values for p_head (i.e. from 0 to 1)\n",
    "p_heads = np.linspace(0,1,100)\n",
    "\n",
    "# use scipy's built in uniform\n",
    "uniform_pdf = stats.uniform.pdf(p_heads)\n",
    "\n",
    "# use scipy's built in normal pdf to get gaussian pdf\n",
    "gaussian_pdf = stats.norm.pdf(p_heads, loc=0.5, scale=0.1)\n",
    "\n",
    "# plot uniform prior\n",
    "plt.plot(p_heads, uniform_pdf)\n",
    "\n",
    "# plot gaussian prior\n",
    "plt.plot(p_heads, gaussian_pdf) \n",
    "\n",
    "plt.xlabel('$p_{head}$')\n",
    "plt.ylabel('probability')\n",
    "plt.legend(['uniform prior','Gaussian prior']);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c75ebcc",
   "metadata": {},
   "source": [
    "## Creating the \"data\"\n",
    "\n",
    "Now that we have specified our priors, we can conduct the \"experiment,\" where we will flip a coin `n_flips` times and see how many heads we get. To simulate coin flips, we will once again be using `numpy`'s `random.uniform()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6020938a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of coin flips to be done\n",
    "n_flips = 10\n",
    "\n",
    "# probability of getting a head\n",
    "p_head = 0.5\n",
    "\n",
    "# conduct the flips\n",
    "flips = np.random.uniform(size=n_flips)\n",
    "\n",
    "# count the number of heads\n",
    "n_heads = sum(flips < p_head)\n",
    "\n",
    "# diplay number of heads\n",
    "print(n_heads)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98a82e0",
   "metadata": {},
   "source": [
    "## Calculating the likelihood\n",
    "\n",
    "With our data (the number of heads we got), we can now compute the likelihood of $P(n_\\text{heads} \\ | \\ 10 \\ \\text{flips}, \\  p_{head})$. This is given by the binomial distribution,\n",
    "\n",
    "$$ P(k \\ | \\ n,p) =  \\left( \\begin{array} { l } { n } \\\\ { k } \\end{array} \\right) p ^ { k } ( 1 - p ) ^ { n - k }, \\tag{4}$$\n",
    "\n",
    "where $k$ is the number of heads, $n$ is the number of flips, and $p$ is the probability of heads. We can calculate the likelihood by calling `scipy`'s bulit-in binomial probability mass function for all possible values of `p_heads` (from $0$ to $1$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49913825",
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihood = stats.binom.pmf(n_heads, n_flips, p_heads)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813db127",
   "metadata": {},
   "source": [
    "## Calculating the posterior probability\n",
    "\n",
    "Now that we've specified the likelihood, we can get the posterior probability from just multiplying our priors by our likelihood. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a150c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the posterior probabilities from likelihood and priors\n",
    "posterior_uniformed = likelihood * uniform_pdf\n",
    "posterior_informed = likelihood * gaussian_pdf\n",
    "\n",
    "# plot the posterior probabilities\n",
    "plt.plot(p_heads, posterior_uniformed)\n",
    "plt.plot(p_heads, posterior_informed)\n",
    "plt.xlabel('$p_{head}$')\n",
    "plt.ylabel('$\\propto$ P($p_{head}$ | D)')\n",
    "plt.legend(['with uniform prior','with Gaussian prior'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfada816",
   "metadata": {},
   "source": [
    "From these posterior probabilities, we can note some interesting differences depending on which prior we used. We see the posterior probability when we used a Gaussian prior remains largely unperturbed from $p_{head}=0.5$. This makes sense. If I actually gave you a real quarter and you got $4$ out of $10$ heads, a reasonable interpretation would be that you just got \"unlucky\" with your 4 heads and not that the coin is actually biased. However, when we used a uniform prior, the posterior probability takes on $0.4$ as the most probable value of $p_{head}$ since we have no other information to convince us otherwise. This illustrates the value of mathematically encoding what we already know as a prior as a way to inform how we interpret our data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d185f7a9",
   "metadata": {},
   "source": [
    "## Behavior as the number of coin flips increases\n",
    "\n",
    "Using the code below, we can run it for varying values of `n_flips` and `p_head`, and watch as the posterior probability tightens up around the \"true\" value of $p_{head}$ as we increase the number of coin flips. This illustrates that provided enough data, we can overwhelm the effect of our specified prior. "
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
