{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65ff1753",
   "metadata": {},
   "source": [
    "# Importing our wordlists"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cfa7000",
   "metadata": {},
   "source": [
    "Here we import all of our wordlists and add them to an array which me can merge at the end. \n",
    "\n",
    "This wordlists should not be filtered at this point. However they should all contain the same columns to make merging easier for later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61cebff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordlists = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acbd1f2b",
   "metadata": {},
   "source": [
    "## Dictcc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb62009b",
   "metadata": {},
   "source": [
    "#### Download the dictionary from http://www.dict.cc/?s=about%3Awordlist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd5e968",
   "metadata": {},
   "source": [
    "#### Print out the first 20 lines of the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d369324",
   "metadata": {},
   "outputs": [],
   "source": [
    "!head -n 20 de-en.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d5763f0",
   "metadata": {},
   "source": [
    "#### Use pandas library to import csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613bcaca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "dictcc_df = pd.read_csv(\"de-en.txt\", \n",
    "                        sep='\\t',\n",
    "                        skiprows=8,\n",
    "                        header=None, \n",
    "                        names=[\"GermanWord\",\"Word\",\"WordType\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72c8d37",
   "metadata": {},
   "source": [
    "#### Preview a few entries of the wordlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b2fbe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictcc_df[90:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864809a8",
   "metadata": {},
   "source": [
    "#### We only need \"Word\" and \"WordType\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ceb821",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictcc_df = dictcc_df[[\"Word\", \"WordType\"]][:].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6563ad77",
   "metadata": {},
   "source": [
    "#### Convert WordType Column to a pandas.Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebf69d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_types = dictcc_df[\"WordType\"].astype('category')\n",
    "dictcc_df[\"WordType\"] = word_types\n",
    "# show data types of each column in the dataframe\n",
    "dictcc_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd2ee55f",
   "metadata": {},
   "source": [
    "#### List the current distribution of word types in dictcc dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e881b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk TaggedCorpusParses requires uppercase WordType\n",
    "dictcc_df[\"WordType\"] = dictcc_df[\"WordType\"].str.upper()\n",
    "dictcc_df[\"WordType\"].value_counts().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87467d2b",
   "metadata": {},
   "source": [
    "#### Add dictcc corpus to our wordlists array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2b9f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordlist_filtered = wordlist_filtered.drop_duplicates(\"Word\")\n",
    "wordlist_filtered.describe()\n",
    "wordlist_filtered[\"WordType\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955d43e9",
   "metadata": {},
   "source": [
    "### Load our wordlists into nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96613fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The TaggedCorpusReader likes to use the forward slash character '/'\n",
    "# as seperator between the word and part-of-speech tag (WordType).\n",
    "wordlist_filtered.to_csv(\"dictcc_moby.csv\",index=False,sep=\"/\",header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be90aea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import TaggedCorpusReader\n",
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "nltk_wordlist = TaggedCorpusReader(\"./\", \"dictcc_moby.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c736b8",
   "metadata": {},
   "source": [
    "# NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef33a71c",
   "metadata": {},
   "source": [
    "- Use NLTK to help us merge our wordlists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4a53a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our custom wordlist\n",
    "import nltk\n",
    "custom_cfd = nltk.ConditionalFreqDist((tag, word) for (word, tag) in nltk_wordlist.tagged_words() if len(word) < 9 and word.isalpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1ba272",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Brown Corpus\n",
    "import nltk\n",
    "brown_cfd = nltk.ConditionalFreqDist((tag, word) for (word, tag) in nltk.corpus.brown.tagged_words() if word.isalpha() and len(word) < 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cceccace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge Nouns from all wordlists\n",
    "nouns = set(brown_cfd[\"NN\"]) | set(brown_cfd[\"NP\"]) | set(custom_cfd[\"NOUN\"])\n",
    "# Lowercase all words to remove duplicates\n",
    "nouns = set([noun.lower() for noun in nouns])\n",
    "print(\"Total nouns count: \" + str(len(nouns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2933f763",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge Verbs from all wordlists\n",
    "verbs = set(brown_cfd[\"VB\"]) | set(brown_cfd[\"VBD\"]) | set(custom_cfd[\"VERB\"])\n",
    "# Lowercase all words to remove duplicates\n",
    "verbs = set([verb.lower() for verb in verbs])\n",
    "print(\"Total verbs count: \" + str(len(verbs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73dc8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge Adjectives from all wordlists\n",
    "adjectives = set(brown_cfd[\"JJ\"]) | set(custom_cfd[\"ADJ\"])\n",
    "# Lowercase all words to remove duplicates\n",
    "adjectives = set([adjective.lower() for adjective in adjectives])\n",
    "print(\"Total adjectives count: \" + str(len(adjectives)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c826c367",
   "metadata": {},
   "source": [
    "# Make Some Placewords Magic Happen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92576b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordlists.append(dictcc_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c1e30c",
   "metadata": {},
   "source": [
    "## Moby"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74da4a37",
   "metadata": {},
   "source": [
    "#### Download the corpus from http://icon.shef.ac.uk/Moby/mpos.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365c2ac1",
   "metadata": {},
   "source": [
    "#### Perform some basic cleanup on the wordlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b77b077",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the readme file in `nltk/corpora/moby/mpos` gives some information on how to parse the file\n",
    "\n",
    "result = []\n",
    "# replace all DOS line endings '\\r' with newlines then change encoding to UTF8\n",
    "moby_words = !cat nltk/corpora/moby/mpos/mobyposi.i | iconv --from-code=ISO88591 --to-code=UTF8 | tr -s '\\r' '\\n' | tr -s 'Ã—' '/'\n",
    "result.extend(moby_words)\n",
    "moby_df = pd.DataFrame(data = result, columns = ['Word'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93813a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "moby_df.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8851b38",
   "metadata": {},
   "source": [
    "- sort out the nouns, verbs and adjectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a22857",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matches nouns\n",
    "nouns = moby_df[moby_df[\"Word\"].str.contains('/[Np]$')].copy()\n",
    "nouns[\"WordType\"] = \"NOUN\"\n",
    "# Matches verbs\n",
    "verbs = moby_df[moby_df[\"Word\"].str.contains('/[Vti]$')].copy()\n",
    "verbs[\"WordType\"] = \"VERB\"\n",
    "# Magtches adjectives\n",
    "adjectives = moby_df[moby_df[\"Word\"].str.contains('/A$')].copy()\n",
    "adjectives[\"WordType\"] = \"ADJ\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba8596f",
   "metadata": {},
   "source": [
    "- remove the trailing stuff and concatenate the nouns, verbs and adjectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8d5484",
   "metadata": {},
   "outputs": [],
   "source": [
    "nouns[\"Word\"] = nouns[\"Word\"].str.replace(r'/N$','')\n",
    "verbs[\"Word\"] = verbs[\"Word\"].str.replace(r'/[Vti]$','')\n",
    "adjectives[\"Word\"] = adjectives[\"Word\"].str.replace(r'/A$','')\n",
    "# Merge nouns, verbs and adjectives into one dataframe\n",
    "moby_df = pd.concat([nouns,verbs,adjectives])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c2f3435",
   "metadata": {},
   "source": [
    "#### Add moby corpus to wordlists array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2f87c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordlists.append(moby_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d783f6",
   "metadata": {},
   "source": [
    "## Combine all wordlists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3beb56aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordlist = pd.concat(wordlists)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b702c79e",
   "metadata": {},
   "source": [
    "# Filter for results that we want"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25155fb9",
   "metadata": {},
   "source": [
    "- We want to remove words that aren't associated with a type (null WordType)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbaacd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordlist_filtered = wordlist[wordlist[\"WordType\"].notnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7a70d1",
   "metadata": {},
   "source": [
    "- We want to remove words that contain non word characters (whitespace, hypens, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c25b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we choose [a-z] here and not [A-Za-z] because we do _not_\n",
    "# want to match words starting with uppercase characters.\n",
    "# ^to matches verbs in the infinitive from `dictcc`\n",
    "word_chars = r'^[a-z]+$|^to\\s'\n",
    "is_word_chars = wordlist_filtered[\"Word\"].str.contains(word_chars, na=False)\n",
    "wordlist_filtered = wordlist_filtered[is_word_chars]\n",
    "wordlist_filtered.describe()\n",
    "wordlist_filtered[\"WordType\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec33973",
   "metadata": {},
   "source": [
    "-  We want results that are less than 'x' letters long (x+3 for verbs since they are in their infinitive form in the dictcc wordlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6cd7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lt_x_letters = (wordlist_filtered[\"Word\"].str.len() < 9) |\\\n",
    "               ((wordlist_filtered[\"Word\"].str.contains('^to\\s\\w+\\s')) &\\\n",
    "                (wordlist_filtered[\"Word\"].str.len() < 11)\\\n",
    "               )\n",
    "wordlist_filtered = wordlist_filtered[lt_x_letters]\n",
    "wordlist_filtered.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217dcebe",
   "metadata": {},
   "source": [
    "- We want to remove all duplicates"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
