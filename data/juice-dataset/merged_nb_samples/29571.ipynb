{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65104bca",
   "metadata": {},
   "source": [
    "<h1><center>It’s Time to Make Some Crazy Money!</center></h1>\n",
    "<h1><center>Predicting a NYC Taxi Trip Duration</center></h1>\n",
    "*****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56958062",
   "metadata": {},
   "source": [
    "## Table of contents\n",
    "1. [Introduction](#introduction)\n",
    "    1. [Loading libraries](#libraries)\n",
    "    2. [Acquiring data](#acquire)\n",
    "    3. [Data content](#content)\n",
    "    4. [Missing values](#missing)\n",
    "    5. [Dummy variables](#dummies)\n",
    "    6. [Changing data types](#datatypes)\n",
    "    7. [Adding columns](#columns)\n",
    "2. [Exploratory Data Analysis](#EDA)\n",
    "    1. [Feature visualization](#features)\n",
    "    2. [Relationships](#related)\n",
    "    3. [GPS Precision](#gps)\n",
    "    4. [Repeated Trips](#repeated)\n",
    "    4. [Pickup vs Dropoff activity](#activity)\n",
    "    5. [Rush Hour](#rush)\n",
    "3. [Save Data](#save)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1d613e",
   "metadata": {},
   "source": [
    "## 1. Introduction <a name=\"introduction\"></a>\n",
    "***\n",
    "\n",
    "With an estimated 2017 [population of 8,622,698](https://en.wikipedia.org/wiki/New_York_City) distributed over a land area of about 302.6 square miles (784 $km^2$), New York City is the most densely populated major city in the United States. As well as of 2016, the cities transportation infrastructure encompass more than [13,000 yellow taxicabs](https://ny.curbed.com/2017/1/17/14296892/yellow-taxi-nyc-uber-lyft-via-numbers) and more than **60,000 black cars**(for-hire vehicles), of which more than **46,000** are connected with Uber so traffic is unavoidable.\n",
    "\n",
    "If a dispatcher knew approximately when all the fleet of taxis would be ending their current ride, it would be easier to identify which driver to assign to each pickup request and maximize their revenue. It is important to be able to predict how long a driver will have the taxi occupied to improve the efficiency of dispatching systems.\n",
    "\n",
    "Big companies like Uber, Lyft, Taxify, Didi Chuxing, and other peer-to-peer ride sharing companies can use such a model to predict the duration of a taxi trip in major cities. They can make better estimates of how much to charge per ride as well as better predictions on the duration of the ride. From the customer's point of view, the price paid per ride could decrease with the improvement and optimization of a driver's traveling time improving customer satisfaction.\n",
    "\n",
    "The data with the total ride duration of taxi trips in New York City has been acquired from [Kaggle](https://www.kaggle.com/c/nyc-taxi-trip-duration/data). The dataset includes pickup time, geo-coordinates, number of passengers, and several other variables. It contains data collected for the year 2016 from two different vendors. The evaluation metric for this project is [Root Mean Squared Logarithmic Error](https://www.kaggle.com/wiki/RootMeanSquaredLogarithmicError). The RMSLE is calculated as:\n",
    "\n",
    "$$ \\epsilon = \\sqrt{\\frac{1}{n} \\sum_{i=1}^n (log(p_i+1) - log(a_i+1))^2 } $$\n",
    "\n",
    "Where:\n",
    "\n",
    "- *ϵ* is the RMSLE value (score)\n",
    "- *n* is the total number of observations in the (public/private) data set\n",
    "- $p_i$ is your prediction of trip duration\n",
    "- $a_i$ is the actual trip duration for *i* \n",
    "- *log(x)* is the natural logarithm of *x*\n",
    "\n",
    "Since the goal is to predict the duration of a taxi trip with labeled data, a supervised regression algorithm is a good fit for the project. This notebook covers Data Wrangling, Exploratory Data Analysis, Feature Engineering, Data Cleaning, and Modeling.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95154dd",
   "metadata": {},
   "source": [
    "### Loading libraries <a name=\"libraries\"></a>\n",
    "***\n",
    "These are some of the libraries used for data wrangling and EDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8bd88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "repeated_trips = merged[(merged['pickup_latitude'] != merged['dropoff_latitude']) \n",
    "       & (merged['pickup_longitude'] != merged['dropoff_longitude'])]\n",
    "repeated_trips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7333257",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = []\n",
    "for index, row in repeated_trips[['pickup_longitude','pickup_latitude', 'dropoff_latitude', 'dropoff_longitude']].iterrows():\n",
    "    s.append([[row['pickup_latitude'], row['pickup_longitude']] , [row['dropoff_latitude'], row['dropoff_longitude']]])\n",
    "    \n",
    "folium_map = folium.Map(location=[40.738, -73.98],\n",
    "                        zoom_start=12,\n",
    "                        tiles=\"CartoDB dark_matter\")\n",
    "for i in range(len(s)):\n",
    "    folium.PolyLine(s[i],color='yellow',weight=1.0,opacity=0.7).add_to(folium_map)\n",
    "\n",
    "folium_map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb46c3b",
   "metadata": {},
   "source": [
    "Only 6 trips are repeated routes that have a travel distance more than zero. Each of these 6 trips is repeated twice and the data shows that both trips per route have the same *trip_duration*, which is suspicious."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b27e2a6",
   "metadata": {},
   "source": [
    "### Pickup vs Dropoff Activity<a name='activity'></a>\n",
    "***\n",
    "Previously, the data showed that most of the activity is in Manhattan and some on both airports. Now let's plot the activity to get an idea of the flow of trips."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78656389",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_style = {'grid': False}  \n",
    "matplotlib.rc('axes', **new_style)  \n",
    "# from matplotlib import rcParams  \n",
    "rcParams['figure.figsize'] = (17.5, 17) #Size of figure  \n",
    "rcParams['figure.dpi'] = 250\n",
    "\n",
    "plt.style.use(['dark_background'])\n",
    "train.plot(kind='scatter', x='pickup_longitude', y='pickup_latitude',color='yellow',xlim=(-74.06,-73.77),ylim=(40.61, 40.91),s=.02,alpha=.6)\n",
    "plt.title('Pickup Activity')\n",
    "plt.xlabel('longitude')\n",
    "plt.ylabel('latitude')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cdb6184",
   "metadata": {},
   "source": [
    "As seen from the pickup graph, most of the activity is in Manhattan, as well as some activity on JFK and La Guardia airport as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98640027",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.plot(kind='scatter', x='dropoff_longitude', y='dropoff_latitude',color='yellow',xlim=(-74.06,-73.77),ylim=(40.61, 40.91),s=.02,alpha=.6)\n",
    "plt.title('Dropoff Activity')\n",
    "plt.xlabel('longitude')\n",
    "plt.ylabel('latitude')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704cc13b",
   "metadata": {},
   "source": [
    "The dropoff location graphs shows that most of the dropoff activity is also in Manhattan and the both airports. However, there is an increase of activity on the surrounding boroughs such as Queens, Brooklyn and the Bronx. Both maps give a clear idea that Manhattan has the most activity which it was expected since most of the trips last between 3 to 50 minutes. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67e98f7",
   "metadata": {},
   "source": [
    "### Rush Hour<a name='rush'></a>\n",
    "***\n",
    "Traffic can easily double the *trip_duration* in NYC for similar routes. Let's look when are the hours during the week that you would expect to pay more for a trip. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24ed921",
   "metadata": {},
   "outputs": [],
   "source": [
    "pylab.rcParams.update(params)\n",
    "plt.style.use(['seaborn-white'])\n",
    "\n",
    "train['pickup_datetime_day_of_week'] = train['pickup_datetime'].dt.weekday_name\n",
    "days = train['pickup_datetime_day_of_week'].unique()\n",
    "\n",
    "for day in days:\n",
    "    r = train[train['pickup_datetime_day_of_week'] == day]['pickup_datetime'].dt.hour.value_counts().sort_index()\n",
    "    r.plot(legend=True,label=day)\n",
    "\n",
    "plt.title('Number of pickups per hour')\n",
    "plt.xlabel('Hours')\n",
    "plt.ylabel('Count')\n",
    "plt.margins(0.04)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f88f01ed",
   "metadata": {},
   "source": [
    "- There is a really high demand after midnight on Friday, Saturday and Sunday. \n",
    "- For the 7 days of the week the demand is really low around 5 AM.\n",
    "- Rush hour is between 7 and 10 AM from Monday to Friday.\n",
    "- Taxi demand stabilizes after 10 AM until 4 PM for all of the days in the week but still being pretty high.\n",
    "- After 4 PM there is another rush hour for every day except Sunday.\n",
    "- At night, demand starts to slow down except on Fridays and Saturdays.\n",
    "\n",
    "Something interesting to point out is that for some people Mondays are considered the days with the most traffic but as the graph shows, it is lower compared to the other 4 week days. \n",
    "\n",
    "As pointed out, it is expected that trip durations will increase between 7 to 10 AM and 5 to 10 PM since are the busiest times in NYC and should be substantially shorter trip durations around 5 am. So for trips with the same distance we can try and compare if this holds true. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9430ba86",
   "metadata": {},
   "source": [
    "## 3. Save Data <a name=\"save\"></a>\n",
    "***\n",
    "Some of the data types were changed. As well, columns were added to the data. So let's save the data into a new csv file for further reference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046facd9",
   "metadata": {},
   "source": [
    "The store and fwd flag shows that many taxis sent the taxi trip information immediately(0) and only few of them had an issue with connecting to the server and had to store it (1). Also, vendor 2 had more trips in the 6 month period in 2016.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19dc5a94",
   "metadata": {},
   "source": [
    "### Relationships <a name='related'></a>\n",
    "***\n",
    "Now let's look at some of the relationship between the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960c907c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(train.corr(),annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57aea154",
   "metadata": {},
   "source": [
    "The response variable *trip_duration* has no linear relationship with any of the features. However, we see positive linear relationship among the latitude and longitude of the trips. As well, there is a positive correlation between vendor_id and passenger_count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b0dd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinates = train[(train['pickup_latitude'] >= 40) & (train['pickup_latitude'] <= 42) &\n",
    "             (train['pickup_longitude'] >= -75) & (train['pickup_longitude'] <= -73) &\n",
    "             (train['dropoff_latitude'] >= 40) & (train['dropoff_latitude'] <= 42) &\n",
    "             (train['dropoff_longitude'] >= -75) & (train['dropoff_longitude'] <= -73)]\n",
    "sns.pairplot(coordinates, vars=['pickup_latitude','pickup_longitude','dropoff_latitude','dropoff_longitude'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d09c8a",
   "metadata": {},
   "source": [
    "### GPS Precision<a name='gps'></a>\n",
    "***\n",
    "If you have visited a big city like Manhattan, you are probably aware that gps precision is not the best at times. Precision in this case is measured by the number of decimals in each coordinate. Taking this into cosideration let's plot the latitude and longitude and check the gps precision of each trip. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab95a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,18))\n",
    "cols = ['pickup_latitude', 'pickup_longitude', 'dropoff_latitude', 'dropoff_longitude']\n",
    "for index, each in enumerate(cols):\n",
    "    s = train[each].astype(str)\n",
    "    dec = s.apply(lambda x: abs(Decimal(x).as_tuple().exponent))\n",
    "    plt.subplot(len(cols)/2,2,index+1)\n",
    "    graph = sns.countplot(dec)\n",
    "    graph.set_yscale('log')\n",
    "    plt.title(each)\n",
    "    plt.xlabel('number of decimals')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889378f9",
   "metadata": {},
   "source": [
    "The GPS precision of the taxis vary from 1 up to 15 decimals. According to the [Degree Precision vs. Length Table](https://en.wikipedia.org/wiki/Decimal_degrees) from Wikipedia, a coordinate with 15 decimals would be equal to 0.1 nanometer(the size of an atom!), which sounds unrealistic for a taxi. In this case, it sounds reasonable to use from the fifth decimal place and up, which is worth up to 1.1 m. According to Wikipedia, it distinguishes trees from each other which sounds like a good precision for a big city. \n",
    "\n",
    "Also, it is important to point out that one would expect to see similar graphs for the 4 different features. Since this is not the case, it means that one trip might have diffent precision at pickup but not dropoff. Let's check which trips have the same amount of precision on the 4 different features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53325fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(train)\n",
    "\n",
    "cols = ['pickup_latitude', 'pickup_longitude', 'dropoff_latitude', 'dropoff_longitude']\n",
    "for index, each in enumerate(cols):\n",
    "    s = df[each].astype(str)\n",
    "    df[each + '_decimal'] = s.apply(lambda x: abs(Decimal(x).as_tuple().exponent))\n",
    "    \n",
    "coor = df[(df['pickup_latitude_decimal'] <= 4) | (df['pickup_longitude_decimal'] <= 4) | \n",
    "          (df['dropoff_latitude_decimal'] <= 4) | (df['dropoff_longitude_decimal'] <= 4)]\n",
    "coor['trip_duration'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02ffb7c",
   "metadata": {},
   "source": [
    "There are 642 trips that have at least one latitude or longitude that have less than 5 decimal precision. Let's see which ones angular distances are the most common. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08ef152",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['pickup_latitude', 'pickup_longitude', 'dropoff_latitude', 'dropoff_longitude']\n",
    "plt.figure(figsize=(18,18))\n",
    "for index, each in enumerate(cols):\n",
    "    plt.subplot(len(cols)/2,2,index+1)\n",
    "    coor[coor[each + '_decimal'] <= 4][each].value_counts().plot(kind='bar')\n",
    "    plt.title('Top ' + each + ' with low precision')\n",
    "    plt.xlabel('Coordinates')\n",
    "    plt.ylabel('Count')\n",
    "    plt.xticks(rotation=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154d7ffd",
   "metadata": {},
   "source": [
    "The graphs show that there is a common angular distance for pickup and dropoff were the precision is lower. It might come across as being a specific location with coordinates $[40.75, -74.0]$. Let's check if this is true."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1b9b03",
   "metadata": {},
   "source": [
    "### Acquiring data <a name=\"acquire\"></a>\n",
    "***\n",
    "The data was acquired from a Kaggle's Competition called [New York City Taxi Trip Duration](https://www.kaggle.com/c/nyc-taxi-trip-duration)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da15748",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54cbbc9",
   "metadata": {},
   "source": [
    "### Data content <a name=\"content\"></a>\n",
    "***\n",
    "Let's look at the content of the data such as shape, columns, and summary statistics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d41411",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c271e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4912bfcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a500d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce5b6c4",
   "metadata": {},
   "source": [
    "The data consists of a large number of rows with the file memory being 122.4+ MB. To make the file lighter lets convert category column 'store_and_fwd_flag' to category data type and see how much memory can be saved. As well, we will convert pickup and dropoff datetime columns to  datetime objects and re-format into a more useful shape. Also, converting all integers to floats will make data easier to work with. The max value of trip duration seems unrealistic for a taxi trip duration causing our standard deviation to be very high. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1212b499",
   "metadata": {},
   "source": [
    "### Missing values <a name='missing'></a>\n",
    "***\n",
    "Let's calculate the fraction of missing values per column. This will give us an idea if there is a need to drop columns or rows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04de8ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.isnull().sum()/len(train)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31dc5cb",
   "metadata": {},
   "source": [
    "There are no missing values so we can proceed using all of the data for the time being."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b1c048",
   "metadata": {},
   "source": [
    "### Dummy Variables <a name='dummies'></a>\n",
    "***\n",
    "Let's make store_and_fwd_flag into a dummy variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5435d3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.get_dummies(train,columns=['store_and_fwd_flag'],drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88bdcce3",
   "metadata": {},
   "source": [
    "### Changing data types <a name=\"datatypes\"></a>\n",
    "***\n",
    "As mentioned previously, let's convert data objects to date times and integers to floats. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443a752d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to datetime object\n",
    "train['pickup_datetime'] = pd.to_datetime(train['pickup_datetime'], format='%Y-%m-%d %H:%M:%S') \n",
    "train['dropoff_datetime'] = pd.to_datetime(train['dropoff_datetime'], format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# # Convert to Float datatype\n",
    "int_feat = train.dtypes[(train.dtypes != 'object') & (train.dtypes != 'float64') & (train.dtypes != 'datetime64[ns]')].index\n",
    "train[int_feat] = train[int_feat].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e905c296",
   "metadata": {},
   "source": [
    "### Adding columns <a name='columns'></a>\n",
    "***\n",
    "To be able to use the date of every trip, it is necessary to split the *pickup_datetime* and *dropoff_datetime* column into year, month, day and seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525f4c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Float columns to split datetime objects\n",
    "train['pickup_month'] = train['pickup_datetime'].dt.month.astype(float)\n",
    "train['pickup_day'] = train['pickup_datetime'].dt.day.astype(float)\n",
    "train['pickup_hour'] = train['pickup_datetime'].dt.hour.astype(float)\n",
    "train['pickup_minute'] = train['pickup_datetime'].dt.minute.astype(float)\n",
    "train['pickup_second'] = train['pickup_datetime'].dt.second.astype(float)\n",
    "\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6503b8fb",
   "metadata": {},
   "source": [
    "## 2. Exploratory Data Analysis <a name='EDA'></a>\n",
    "***\n",
    "Let's do EDA to explore to get a visual understanding of the data. First, let's explore trip_duration which is the target column. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d6ee18",
   "metadata": {},
   "source": [
    "### Feature Visualization <a name='features'></a>\n",
    "***\n",
    "Let's check each feature of the training data and analyze it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f81c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.log(train['trip_duration']).values,bins=300)\n",
    "plt.title('trip_duration distribution')\n",
    "plt.xlabel('log(trip_duration)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62573193",
   "metadata": {},
   "source": [
    "The histogram shows that most of taxi trips have a duration of $e^{5}$  to $e^{8}$ which is between 3 to 50 minutes. As well, the graph shows some unsual data with value of $e^{11}$ which is almost 1000 minutes and $e^{2}$ wich is just a few seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79fd415d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.sort_values(['trip_duration'],ascending=[False]).set_index('trip_duration').head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca0c071",
   "metadata": {},
   "source": [
    "The table above shows that some trips lasted more than a few days and someone spending more than one month in a cab which is impossible. \n",
    "\n",
    "Now let's take a look at the latitude and longitude of 99.9% of the trips to exclude some outliers outside of this range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d83cd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['pickup_latitude', 'pickup_longitude', 'dropoff_latitude', 'dropoff_longitude']\n",
    "percentile = [0.05,99.95] ## USING 99.9% of the data\n",
    "for index, name in enumerate(cols):\n",
    "    plt.subplot(len(cols)/2,2,index+1)\n",
    "    train[(train[name] >= np.percentile(train[name],percentile[0])) & (train[name] <= np.percentile(train[name],percentile[1]))][name].plot(kind='hist',bins=400)\n",
    "    plt.xlabel(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695a11f9",
   "metadata": {},
   "source": [
    "The latitude and longitude features give important information:\n",
    "\n",
    "- Most of the pickup_latitude and dropoff_latitude lie between 40.70 and 40.80\n",
    "\n",
    "- Most of the pickup_longitude and dropoff_longitude lie between -74.05 and -73.95\n",
    "\n",
    "- There is some pickup_latitude and dropoff_latitude happening around 40.65\n",
    "\n",
    "- There is some pickup_longitude and dropoff_longitude happening around -73.80\n",
    "\n",
    "- There is also some pickup_longitude and dropoff_longitude happening around -73.88\n",
    "\n",
    "Coordinates by themselves are hard to understand what is happening. To have a better sense of what is happening let's plot these points on a map. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5a7350",
   "metadata": {},
   "outputs": [],
   "source": [
    "coor = [[40.7, -74.05], [40.7,-73.95]],[[40.7,-73.95],[40.8,-73.95]], [[40.8,-74.05],[40.8,-73.95]], [[40.7,-74.05],[40.8,-74.05]]\n",
    "coor2 = [[40.65,-73.80],[40.65,-73.80]]\n",
    "coor3 = [[40.77,-73.88],[40.77,-73.88]]\n",
    "\n",
    "folium_map = folium.Map(location=[40.738, -73.98],\n",
    "                        zoom_start=10,\n",
    "                        tiles='Stamen Terrain')\n",
    "\n",
    "folium.PolyLine(coor,color='red',weight=4.5,opacity=0.7).add_to(folium_map)\n",
    "folium.PolyLine(coor2,color='red',weight=15,opacity=0.7).add_to(folium_map)\n",
    "folium.PolyLine(coor3,color='red',weight=15,opacity=0.7).add_to(folium_map)\n",
    "folium_map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b5a81b",
   "metadata": {},
   "source": [
    "The map shows that most of the activity is happening in Manhattan. As well, there is some activity in the airports J.F. Kennedy and La Guardia. After exploring duration and location of trips, let's focus on the distribution of trips by time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a61c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickup = df[(df['pickup_latitude'] == 40.75) & (df['pickup_longitude'] == -74.0)]['trip_duration'].count()\n",
    "dropoff = df[(df['dropoff_latitude'] == 40.75) & (df['dropoff_longitude'] == -74.0)]['trip_duration'].count()\n",
    "\n",
    "print('Total number of columns with pickup_latitude = 40.75 and pickup_longitude = -74.0: {}'.format(pickup))\n",
    "print('Total number of columns with dropoff_latitude = 40.75 and dropoff_longitude = -74.0: {}'.format(dropoff))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b76efd0",
   "metadata": {},
   "source": [
    "This means it is not a specific location. However, the latitudes and longitudes tend to be a repeated angular distance in several trips. To have a better idea of these trips let's plot it in a map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051e0df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = []\n",
    "for index, row in coor[['pickup_longitude','pickup_latitude', 'dropoff_latitude', 'dropoff_longitude']].iterrows():\n",
    "    s.append([[row['pickup_latitude'], row['pickup_longitude']] , [row['dropoff_latitude'], row['dropoff_longitude']]])\n",
    "    \n",
    "folium_map = folium.Map(location=[40.738, -73.98],\n",
    "                        zoom_start=13,\n",
    "                        tiles=\"CartoDB dark_matter\")\n",
    "for i in range(len(s)):\n",
    "    folium.PolyLine(s[i],color='yellow',weight=1.0,opacity=0.7).add_to(folium_map)\n",
    "\n",
    "folium_map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ed8d40",
   "metadata": {},
   "source": [
    "These values might be an issue due to the fact that most of them have a pickup or dropoff in Manhattan and not having an accurate precision can take you to a different block. This might easily add more seconds to the trip, even minutes. These can be candidate trips to drop due to lower precision. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1e8762",
   "metadata": {},
   "source": [
    "### Repeated trips<a name='repeated'></a>\n",
    "***\n",
    "Now that we have an idea of the right precision for the coordinates, let's look if there are similar trips with high precision (at least 5 decimals)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b498c11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['pickup_latitude', 'pickup_longitude', 'dropoff_latitude', 'dropoff_longitude']\n",
    "\n",
    "above_five_decimals = df[(df['pickup_latitude_decimal'] >= 5) & (df['pickup_longitude_decimal'] >= 5) & \n",
    "          (df['dropoff_latitude_decimal'] >= 5) & (df['dropoff_longitude_decimal'] >= 5)]\n",
    "five_decimals = above_five_decimals[['pickup_latitude', 'pickup_longitude', 'dropoff_latitude', 'dropoff_longitude','trip_duration']].round(5)\n",
    "a = five_decimals.groupby(cols).size().reset_index().rename(columns={0:'count'}).sort_values(by='count',ascending=False)\n",
    "s = five_decimals.groupby(cols).trip_duration.agg(['min','max','mean']).reset_index()\n",
    "\n",
    "merged = pd.merge(a,s,on=cols)\n",
    "merged = merged[merged['count']>=2]\n",
    "merged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176ed9ba",
   "metadata": {},
   "source": [
    "Looking at similar trips with 5 precision decimals, the data shows that at least the top 5 most popular trips have the same pickup and dropoff location and still their *trip_duration* varies, which it appears to be error in the data. Let's find out if all of the repeated trips are basically a distance traveled of 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ce32f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.set_index('pickup_datetime').resample('D').count()['vendor_id'].plot()\n",
    "plt.title('Pickup Datetime Plot by Day')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Count')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a84f3e7",
   "metadata": {},
   "source": [
    "The line plot shows that the amount of daily pickups during January 2016 and June 2016 were fairly homogeneous. However, there is a drop near the end of January. The drop can be explained by doing some research. From January 22 to 24, 2016, there was a blizzard that hit the East Coast. According to [weather.gov](https://www.weather.gov/okx/Blizzard_Jan2016), Central Park, NY received 27.5\" of snow, which is the largest snowstorm since records began in 1869."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2c503c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.set_index('dropoff_datetime').resample('D').count()['vendor_id'].plot()\n",
    "plt.title('Dropoff Datetime Plot by Day')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Count')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b9a4b7",
   "metadata": {},
   "source": [
    "The dropoff graph looks fairly similar to the pickup graph. At the beginning of July there is a drop but is due to the fact that is the cutoff date for the data. \n",
    "\n",
    "Now let's explore the other features that are left."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98661ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(1,2,1)\n",
    "w = train['pickup_datetime'].dt.weekday.value_counts().sort_index()\n",
    "ax = w.plot(marker='.',linestyle='none',markersize=25,visible=True)\n",
    "ax.set_xticklabels(['','Mon','Tue','Wed','Thur','Fri','Sat','Sun'])\n",
    "plt.title('Number of pickups per day')\n",
    "plt.xlabel('Days of the week')\n",
    "plt.ylabel('Count')\n",
    "plt.margins(0.04)\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "p = train['passenger_count'].value_counts().sort_index().plot(kind='bar')\n",
    "plt.title('Passenger Count')\n",
    "plt.xlabel('Number of passengers per ride')\n",
    "plt.ylabel('Count')\n",
    "plt.ticklabel_format(axis='y',style='sci',scilimits=(0,0))\n",
    "labels = train['passenger_count'].value_counts().sort_index().values\n",
    "rects = p.patches\n",
    "for rect, label in zip(rects, labels):\n",
    "    height = rect.get_height()\n",
    "    p.text(rect.get_x() + rect.get_width()/2, height + 25, label, ha='center', va='bottom')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3e507d",
   "metadata": {},
   "source": [
    "The busiest day during the week for taxi drivers in NYC is Friday and the slowest day is Monday. Also, the passenger count graph shows that most of the taxi trips carry only one passenger. It is important to point out that the data has 60 trips with 0 passengers which it seems it is an error in the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81606cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = train['pickup_datetime'].dt.hour.value_counts().sort_index()\n",
    "ax2 = h.plot(marker='.',linestyle='none',markersize=15,visible=True)\n",
    "plt.title('Number of pickups per hour')\n",
    "plt.xlabel('Hours')\n",
    "plt.ylabel('Count')\n",
    "plt.margins(0.04)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a0148f",
   "metadata": {},
   "source": [
    "The number of pickups per hour is higher at night with a peak between 6 and 7 PM which most people get out of work. At around 5 in the morning, the taxi demand is low. There is a rise of demand thoughout the day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3bcadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(1,2,1)\n",
    "sns.countplot(x='store_and_fwd_flag_Y',data=train)\n",
    "plt.title('Store and Fwd Flag')\n",
    "plt.xlabel('Store and Fwd Flag')\n",
    "plt.ylabel('Count')\n",
    "plt.ticklabel_format(axis='y',style='sci',scilimits=(0,0))\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "sns.countplot(x='vendor_id',data=train)\n",
    "plt.title('Vendor ID')\n",
    "plt.xlabel('ID number')\n",
    "plt.ylabel('Count')\n",
    "plt.ticklabel_format(axis='y',style='sci',scilimits=(0,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd31979",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "import seaborn as sns\n",
    "import folium\n",
    "\n",
    "import operator\n",
    "from decimal import Decimal\n",
    "import timeit\n",
    "\n",
    "from geopy.distance import vincenty\n",
    "\n",
    "%matplotlib inline\n",
    "%pylab inline\n",
    "\n",
    "params = {'legend.fontsize': 'x-large',\n",
    "          'figure.figsize': (17.5, 10),\n",
    "         'axes.labelsize': 'x-large',\n",
    "         'axes.titlesize':'x-large',\n",
    "         'xtick.labelsize':'x-large',\n",
    "         'ytick.labelsize':'x-large'}\n",
    "\n",
    "pylab.rcParams.update(params)\n",
    "plt.style.use(['seaborn-white'])"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
