{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfca0556",
   "metadata": {},
   "source": [
    "## API tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501e7ef3",
   "metadata": {},
   "source": [
    "### Expression Building\n",
    "\n",
    "(This tutorial is tested on DyNet 2.0.4+ and Python 2.7.)\n",
    "\n",
    "If you find any issues while running, please try to restart the kernel and run it again. :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e43a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "from __future__ import absolute_import\n",
    "\n",
    "# Note: please import dynet_config before import dynet\n",
    "import dynet_config\n",
    "# set random seed to have the same result each time\n",
    "dynet_config.set(random_seed=0)\n",
    "import dynet as dy\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "## ==== Create a new computation graph\n",
    "# (There is a single global computation graph that is used at any point.\n",
    "# dy.renew_cg() clears the current one and starts a new one)\n",
    "dy.renew_cg();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81fc8da6",
   "metadata": {},
   "source": [
    "#### Create Expressions\n",
    "Expressions are used as an interface to the various functions that can be used to build DyNet computation graphs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62cb59b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a scalar expression.\n",
    "value = 5.0\n",
    "x = dy.scalarInput(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc64f653",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a vector expression.\n",
    "dimension = 3\n",
    "v = dy.vecInput(dimension)\n",
    "v.set([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7760b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a matrix expression from a list\n",
    "mat1 = dy.inputTensor([[1,2], [3,4]]) # Row major\n",
    "\n",
    "# or, using a numpy array\n",
    "mat2 = dy.inputTensor(np.array([[1,2], [3,4]]))\n",
    "\n",
    "mat3 = dy.inputTensor(np.zeros((2,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1f8381",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a vector/matrix expression of special values\n",
    "# Different from other toolkits such as TensorFlow or PyTorch.\n",
    "# DyNet has a special \"batch\" dimension, see here for more\n",
    "# details: http://dynet.readthedocs.io/en/latest/minibatch.html\n",
    "\n",
    "# zeros\n",
    "dim = 5\n",
    "batch_size = 3\n",
    "e = dy.zeros(dim, batch_size=batch_size)\n",
    "print('zeors of dim {} and batch_size {}:\\n{}'.format(dim, batch_size, e.npvalue()))\n",
    "\n",
    "# ones\n",
    "e = dy.ones(dim, batch_size=batch_size)\n",
    "print('ones of dim {} and batch_size {}:\\n{}'.format(dim, batch_size, e.npvalue()))\n",
    "\n",
    "# constant\n",
    "val = 2\n",
    "e = dy.constant(dim, val, batch_size=batch_size)\n",
    "print('constant {} of dim {} and batch_size {}:\\n{}'.format(val, dim, batch_size, e.npvalue()))\n",
    "\n",
    "# random_normal\n",
    "mean = 0\n",
    "stddev = 1.0\n",
    "e = dy.random_normal(dim, mean=mean, stddev=stddev, batch_size=batch_size)\n",
    "print('A {} dim random_normal of mean {} and stddev {} and batch_size {}:\\n{}'.format(dim, mean, stddev, batch_size, e.npvalue()))\n",
    "\n",
    "# random_bernoulli\n",
    "p = 0.3 # The p in Bernoulli distribution\n",
    "scale = 2.0 # Scaling factor to apply to the sampled tensor (default: (1.0))\n",
    "e = dy.random_bernoulli(dim, p=p, scale=scale, batch_size=batch_size)\n",
    "print('A {} dim random bernoulli distribution of p={} and scale={}, batch_size={}:\\n{}'.format(dim, p, scale, batch_size, e.npvalue()))\n",
    "\n",
    "# random_uniform\n",
    "left = -1\n",
    "right = 1\n",
    "e = dy.random_uniform(dim, left=left, right=right, batch_size=batch_size)\n",
    "print('A {} dim random uniform distribution of left={} and right={}, batch_size={}:\\n{}'.format(dim, left, right, batch_size, e.npvalue()))\n",
    "\n",
    "# random_gumbel\n",
    "# Create a vector distributed according to a Gumbel distribution with the specified parameters. \n",
    "# (Currently only the defaults of mu=0.0 and beta=1.0 supported.\n",
    "mu = 0.0\n",
    "beta = 1.0\n",
    "e = dy.random_gumbel(dim, mu=mu, beta=beta, batch_size=batch_size)\n",
    "print('A {} dim random gumbel distribution of mu={} and beta={}, batch_size={}:\\n{}'.format(dim, mu, beta, batch_size, e.npvalue()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ff1c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ==== Calculate the value of an expression.\n",
    "# This will run the forward step of the neural network.\n",
    "print(mat1.value())   \n",
    "print(mat1.npvalue())    # as numpy array\n",
    "print(v.vec_value())     # as vector, if vector\n",
    "print(x.scalar_value())  # as scalar, if scalar\n",
    "print(x.value())         # choose the correct one"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65344dee",
   "metadata": {},
   "source": [
    "#### Create Parameters\n",
    "Parameters are things need to be trained. In contrast to a system like Torch where computational modules may have their own parameters, in DyNet parameters are just parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f2c607",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters are things we tune during training.\n",
    "# Usually a matrix or a vector.\n",
    "\n",
    "# First we create a parameter collection and add the parameters to it.\n",
    "m = dy.ParameterCollection() \n",
    "W = m.add_parameters((8,8)) # an 8x8 matrix, return an expr\n",
    "b = m.add_parameters(8) # an 8x1 vector, return as expr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c1bd55",
   "metadata": {},
   "source": [
    "It should be noticed that in DyNet 2.0.4+, the dy.parameters() is depecated so explicitly adding parameters to the computation graph is no longer necessary. Any used parameter will be added automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292f6f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are several ways to initial parameters\n",
    "# Specifiying parameter initialization\n",
    "scale, mean, stddev = 1, 0, 1\n",
    "\n",
    "# Creates 3x5 matrix filled with 0 (or any other float)\n",
    "p1 = m.add_parameters((3,5), init=0)\n",
    "# Creates 3x5 matrix initialized with U([-scale, scale])\n",
    "p2 = m.add_parameters((3,5), init='uniform', scale=scale)\n",
    "# Creates 3x5 matrix initialized with N(mean, stddev)\n",
    "p3 = m.add_parameters((3,5), init='normal', mean=mean, std=stddev)\n",
    "# Creates 5x5 identity matrix\n",
    "p4 = m.add_parameters((5,5), init='identity')\n",
    "# Creates 3x5 matrix with glorot init\n",
    "p5 = m.add_parameters((3,5), init='glorot')\n",
    "p6 = m.add_parameters((3,5)) # By default, the init = 'glorot'\n",
    "# Creates 3x5 matrix with he init\n",
    "p7 = m.add_parameters((3,5), init='he')\n",
    "# Creates 3x5 matrix from a numpy array (size is inferred)\n",
    "p8 = m.add_parameters((3,5), np.ones((3,5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42f3ebc",
   "metadata": {},
   "source": [
    "#### Create LookupParameters\n",
    "LookupParameters represents a table of parameters. They are used to embed a set of discrete objects (e.g. word embeddings). They can be sparsely updated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d31ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ===== Lookup parameters\n",
    "# Similar to parameters, but are representing a \"lookup table\" that maps numbers to vectors.\n",
    "# These are often used for things like word embeddings.\n",
    "# For example, this will have VOCAB_SIZE rows, each of DIM dimensions.\n",
    "VOCAB_SIZE = 100\n",
    "DIM = 10\n",
    "lp = m.add_lookup_parameters((VOCAB_SIZE, DIM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c33211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create expressions from lookup parameters.\n",
    "e5  = dy.lookup(lp, 5)   # create an Expression from row 5.\n",
    "e5  = lp[5]              # same\n",
    "e5c = dy.lookup(lp, 5, update=False)  # as before, but don't update when optimizing.\n",
    "\n",
    "e45  = dy.lookup_batch(lp, [4, 5])   # create a batched Expression from rows 4 and 5.\n",
    "e45  = lp.batch([4, 5])\n",
    "print('e45 dim:', e45.dim())\n",
    "\n",
    "e0_9 = dy.lookup_batch(lp, range(10))  # create a batched Expression from rows 0 to 9\n",
    "e0_9 = lp.batch(range(10))\n",
    "print('e0_9 dim:', e0_9.dim())\n",
    "\n",
    "e5.set(10)  # now the e5 expression contains row 10\n",
    "print('e5 dim after applying set method', e5.dim())\n",
    "print(e5.value())\n",
    "\n",
    "# We can check if it is actually containing row 10\n",
    "e10 = lp[10]\n",
    "print(e5.value() == e10.value())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bcda0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similar to Parameters, we have several ways to\n",
    "# initialize LookupParameters.\n",
    "scale, mean, stddev = 1, 0, 1\n",
    "\n",
    "# Creates 3x5 matrix filled with 0 (or any other float)\n",
    "lp1 = m.add_lookup_parameters((3,5), init=0)\n",
    "# Creates 3x5 matrix initialized with U([-scale, scale])\n",
    "lp2 = m.add_lookup_parameters((3,5), init='uniform', scale=scale)\n",
    "# Creates 3x5 matrix initialized with N(mean, stddev)\n",
    "lp3 = m.add_lookup_parameters((3,5), init='normal', mean=mean, std=stddev)\n",
    "# Creates 5x5 identity matrix\n",
    "lp4 = m.add_lookup_parameters((5,5), init='identity')\n",
    "# Creates 3x5 matrix with glorot init\n",
    "lp5 = m.add_lookup_parameters((3,5), init='glorot')\n",
    "lp6 = m.add_parameters((3,5)) # By default, the init = 'glorot'\n",
    "# Creates 3x5 matrix with he init\n",
    "lp7 = m.add_lookup_parameters((3,5), init='he')\n",
    "# Creates 3x5 matrix from a numpy array (size is inferred)\n",
    "lp8 = m.add_lookup_parameters((3,5), np.ones((3,5)))\n",
    "# Creates 3x5 matrix from a numpy array (size is inferred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a456e7",
   "metadata": {},
   "source": [
    "#### More Expression Manipulation\n",
    "DyNet provides hundreds of operations on Expressions. The user can manipulate Expressions, or build complex Expression easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16507c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fist we create some vector Expressions.\n",
    "e1 = dy.vecInput(4)\n",
    "e1.set([1, 2, 3, 4])\n",
    "\n",
    "e2 = dy.vecInput(4)\n",
    "e2.set([5, 6, 7, 8])\n",
    "\n",
    "# Concatenate list of expressions to a single batched expression.\n",
    "# All input expressions must have the same shape.\n",
    "e_batch = dy.concatenate_to_batch([e1, e2])\n",
    "\n",
    "mat1 = dy.inputTensor(np.array([[1, 2], [3, 4], [5, 6], [7, 8]]))  # A 4x2 matrix\n",
    "mat2 = dy.inputTensor(np.array([[1, 0], [0, 1]]))  # A 2x2 matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37a6496",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Math Operations\n",
    "\n",
    "# Add\n",
    "e = e1 + e2  # Element-wise addition\n",
    "\n",
    "# Minus\n",
    "e = e2 - e1 # Element-wise minus\n",
    "# Negative\n",
    "e = -e1  # Should be [-1.0, -2.0, -3.0, -4.0]\n",
    "\n",
    "# Multiply\n",
    "e = e1 * dy.transpose(e1)  #It's Matrix multiplication (like e1.dot(e2) in numpy)\n",
    "\n",
    "mat = mat1 * mat2\n",
    "\n",
    "# Dot product\n",
    "e = dy.dot_product(e1, e2)  # dot product = sum(component-wise multiply)\n",
    "\n",
    "# Component-wise multiply\n",
    "e = dy.cmult(e1, e2)\n",
    "\n",
    "# Component-wise division\n",
    "e = dy.cdiv(e1, e2)\n",
    "\n",
    "# Column-wise addition\n",
    "# colwise_add(x, y)\n",
    "#  x:  An MxN matrix\n",
    "#  y:  A length M vector\n",
    "mat = dy.colwise_add(mat1, e1)  # column-wise addition\n",
    "\n",
    "# Useful math operations\n",
    "# abs()\n",
    "e = dy.abs(e1)\n",
    "\n",
    "# cube()\n",
    "# Elementwise cubic\n",
    "e = dy.cube(e1)\n",
    "\n",
    "# exp()\n",
    "e = dy.exp(e1)\n",
    "\n",
    "# pow()\n",
    "# For each element in e1, calculate e1^{y}\n",
    "e = dy.pow(e1, dy.inputTensor([2]))\n",
    "e_ = dy.square(e1)\n",
    "assert e.value() == e_.value()\n",
    "\n",
    "# bmin()\n",
    "# Calculate an output where the ith element is min(x_i, y_i)\n",
    "e = dy.bmin(e1, e2)\n",
    "assert e.value() == e1.value()\n",
    "\n",
    "# bmax()\n",
    "# Calculate an output where the ith element is max(x_i, y_i)\n",
    "e = dy.bmax(e1, e2)\n",
    "assert e.value() == e2.value()\n",
    "\n",
    "# sin()\n",
    "e = dy.sin(e1)\n",
    "\n",
    "# cos()\n",
    "e = dy.cos(e1)\n",
    "\n",
    "# tan()\n",
    "e = dy.tan(e1)\n",
    "\n",
    "# asin()\n",
    "e = dy.asin(e1)\n",
    "\n",
    "# acos()\n",
    "e = dy.acos(e1)\n",
    "\n",
    "# atan()\n",
    "e = dy.atan(e1)\n",
    "\n",
    "# sinh()\n",
    "e = dy.sinh(e1)\n",
    "\n",
    "# cosh()\n",
    "e = dy.cosh(e1)\n",
    "\n",
    "# tanh()\n",
    "e = dy.tanh(e1)\n",
    "\n",
    "# asinh()\n",
    "e = dy.asinh(e1)\n",
    "\n",
    "# acosh()\n",
    "e = dy.acosh(e1)\n",
    "\n",
    "# atanh\n",
    "e = dy.atanh(e1)\n",
    "\n",
    "# square()\n",
    "e = dy.square(e1)\n",
    "\n",
    "# sqrt()\n",
    "e = dy.sqrt(e1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63f56b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrix manipulation\n",
    "\n",
    "# Reshape\n",
    "new_dimension = (2, 2)\n",
    "e = dy.reshape(e1, new_dimension)  # Col major\n",
    "print('reshape a vector:\\n', e.value())\n",
    "\n",
    "# Transpose\n",
    "e = dy.transpose(e1)\n",
    "print('e1 dimension:', e1.dim())\n",
    "print('e1 transpose dimension', e.dim())\n",
    "\n",
    "# inverse\n",
    "# Not implemented on GPU yet.\n",
    "e = dy.inverse(dy.inputTensor([[1, 3], [3, 1]]))\n",
    "print('Inverse a matrix:\\n', e.npvalue())\n",
    "\n",
    "# logdet\n",
    "# Not implemented on GPU yet\n",
    "e = dy.logdet(dy.inputTensor([[1, 0], [0, 2]]))\n",
    "print('logdet diag(1,2) is log(2):\\n', e.npvalue())\n",
    "\n",
    "# trace_of_product\n",
    "# Not implemented on GPU yet\n",
    "diag_12 = dy.inputTensor([[1, 0], [0, 2]])\n",
    "e = dy.trace_of_product(diag_12, diag_12)\n",
    "# or on matrix\n",
    "e = dy.trace_of_product(mat1, mat1)\n",
    "\n",
    "# circ_conv\n",
    "sig_1 = dy.inputTensor([1,2,1,0])\n",
    "sig_2 = dy.inputTensor([0,1,1,1])\n",
    "e = dy.circ_conv(sig_1, sig_2)\n",
    "\n",
    "# circ_corr\n",
    "e = dy.circ_corr(sig_1, sig_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54f39e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other Per-element unary functions.\n",
    "\n",
    "# erf()\n",
    "# Elementwise calculation of the Gaussian error function\n",
    "e = dy.erf(e1)\n",
    "\n",
    "# log()\n",
    "e = dy.log(e1)\n",
    "\n",
    "# log_sigmoid()\n",
    "e = dy.log_sigmoid(e1)\n",
    "\n",
    "# lgamma()\n",
    "# Definition of gamma function ca be found here\n",
    "# https://en.wikipedia.org/wiki/Gamma_function\n",
    "e = dy.lgamma(e1)\n",
    "e_ = dy.log(dy.inputTensor([1, 1, 2, 6]))\n",
    "assert e.value() == e_.value()\n",
    "\n",
    "# sigmoid()\n",
    "e = dy.logistic(e1)   # Sigmoid(x)\n",
    "\n",
    "# rectify()\n",
    "# Rectifier (or ReLU, Rectified Linear Unit)\n",
    "e = dy.rectify(e1)    # Relu (= max(x,0))\n",
    "\n",
    "# elu()\n",
    "# Exponential Linear Unit (ELU)\n",
    "# Definition can be found here:\n",
    "# https://en.wikipedia.org/wiki/Rectifier_(neural_networks)#ELUs\n",
    "e = dy.elu(e1)\n",
    "\n",
    "# selu()\n",
    "# Scaled Exponential Linear Unit (SELU)\n",
    "# Definition can be found here:\n",
    "# https://arxiv.org/abs/1706.02515\n",
    "e = dy.selu(e1)\n",
    "\n",
    "# silu()\n",
    "# Sigmoid Linear Unit / sigmoid-weighted linear unit\n",
    "# SILU / SiL / Swish\n",
    "# Definition can be found here:\n",
    "# https://openreview.net/pdf?id=Bk0MRI5lg\n",
    "e = dy.silu(e1)\n",
    "\n",
    "# sparsemax()\n",
    "# **Note:** This function is not yet implemented on GPU.\n",
    "# Similar to softmax, but induces sparse solutions where \n",
    "# most of the vector elements are zero.\n",
    "e = dy.sparsemax(e1)\n",
    "\n",
    "# softsign()\n",
    "e = dy.softsign(e1)    # x/(1+|x|)\n",
    "\n",
    "# softmax()\n",
    "e = dy.softmax(e1)\n",
    "print('softmax result:', e.value())\n",
    "\n",
    "# log_softmax\n",
    "# logsoftmax = logits - log(reduce_sum(exp(logits), dim))\n",
    "# restrict is a set of indices. if not empty, only entries \n",
    "# in restrict are part of softmax computation, others get -inf.\n",
    "e_log_softmax = dy.log_softmax(e1)\n",
    "e_log_softmax = dy.log_softmax(e1, restrict=[0,1,2])\n",
    "print('log_softmax result', e_log_softmax.value())\n",
    "\n",
    "# constrained_softmax()\n",
    "# **Note:** This function is not yet implemented on GPU.\n",
    "# similar to softmax, but defines upper bounds for the resulting probabilities. \n",
    "e = dy.constrained_softmax(e1, dy.inputTensor([0.01, 0.05, 0.10, 0.55]))\n",
    "print('constrained_softmax result', e.value())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f714058d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Picking values from vector expressions\n",
    "\n",
    "k, v = 1, 3\n",
    "# Pick one element from a vector or matrix\n",
    "# similar to python's e1[k] for list.\n",
    "# k can be negative, which has exactly the same behavior\n",
    "# as it is in python\n",
    "e = dy.pick(e1, k)\n",
    "print('The {} element of vector is {}'.format(k+1, e.value())) # index starts from 0\n",
    "# which is also equivalent to:\n",
    "e = e1[k]\n",
    "# k can be negative. -1 means the last element\n",
    "e = e1[-1]\n",
    "print(e.value())\n",
    "\n",
    "mat = dy.pick(mat1, k)\n",
    "print('The {} element of matrix mat1 is {}'.format(k+1, mat.value()))\n",
    "# which is equivalent to:\n",
    "mat = mat1[k]\n",
    "\n",
    "# Pick several elements from a vector or matrix\n",
    "# similar to python's e1[k:v] for lists. \n",
    "# e1 is an Expression, k, v are integers.\n",
    "# Important: v should not exceed the e1's dimension.\n",
    "e = dy.pickrange(e1, k, v)\n",
    "print('Pick range[k, v) from a vector', e.value())\n",
    "# which is also equivalent to:\n",
    "e = e1[k:v]\n",
    "e = e1[:v]  # similar to python, you can neglect k\n",
    "e = e1[:]   # or even both k and v\n",
    "# ERROR: Don't try this\n",
    "# e = e1[0:10], the v value should not exceed the dimension.\n",
    "\n",
    "mat = dy.pickrange(mat1, k, v)\n",
    "print('Pick range[k, v) from a matrix:\\n', mat.value())\n",
    "\n",
    "# pickneglogsoftmax\n",
    "# which is equivalent to: dy.pick(-dy.log(dy.softmax(e1)), k)\n",
    "e = dy.pickneglogsoftmax(e1, k)\n",
    "e_ = dy.pick(-dy.log(dy.softmax(e1)), k)\n",
    "print('{0:.6f} and {0:6f}'.format(e.value(), e_.value()))\n",
    "\n",
    "# pickneglogsoftmax_batch\n",
    "# similar to pickneglogsoftmax, this is negative softmax log likelihood on a batch\n",
    "# The difference is, a list of intergers is required for True classes.\n",
    "e = dy.pickneglogsoftmax_batch(e1, [k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431bda2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting vectors from matrix Expressions\n",
    "\n",
    "# select_rows\n",
    "# works similar to pickrange\n",
    "e = dy.select_rows(mat1, [0,1])\n",
    "e_ = mat1[:2]\n",
    "assert np.all(e.value() == e_.value())\n",
    "\n",
    "# select_cols\n",
    "e = dy.select_cols(mat1, [0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35684594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expressions concatenation & other useful manipuulations\n",
    "\n",
    "# This performs an elementwise sum over all the expressions included.\n",
    "# All expressions should have the same dimension.\n",
    "e = dy.esum([e1, e2])\n",
    "# which is equivalent to:\n",
    "e_ = e1 + e2\n",
    "assert e.value() == e_.value()\n",
    "\n",
    "# This performs an elementwise average over all the expressions included.\n",
    "# All expressions should have the same dimension.\n",
    "e = dy.average([e1, e2])\n",
    "# which is equivalent to:\n",
    "e_ = (e1 + e2)/2\n",
    "assert e.value() == e_.value()\n",
    "\n",
    "# Concate vectors/matrix column-wise\n",
    "# All expressions should have the same dimension.\n",
    "# e1, e2,.. are column vectors. return a matrix. (sim to np.hstack([e1,e2,...])\n",
    "e = dy.concatenate_cols([e1, e2])\n",
    "print('vector and vector concatenate_cols:\\n', e.value())\n",
    "\n",
    "mat = dy.concatenate_cols([mat1, e2])\n",
    "print('mattix and vector concatenate_cols:\\n', mat.value())\n",
    "\n",
    "# Concate vectors/matrix\n",
    "# All expressions should have the same dimension.\n",
    "# e1, e2,.. are column vectors. return a matrix. (sim to np.hstack([e1,e2,...])\n",
    "e = dy.concatenate([e1, e2])\n",
    "print('vector concatenate:', e.value())\n",
    "\n",
    "mat = dy.concatenate([mat2, mat2])\n",
    "print('matrix concatenate:\\n',mat.value())\n",
    "\n",
    "# affine transform\n",
    "e0 = dy.vecInput(2)\n",
    "e0.set([-1, 0])\n",
    "e = dy.affine_transform([e1,mat1,e0])\n",
    "print('affine_transform:', e.value())\n",
    "\n",
    "# sum_elems\n",
    "# Sum all elements\n",
    "e = dy.sum_elems(mat1)\n",
    "print('sum_elems:', e.value())\n",
    "\n",
    "# sum_dim\n",
    "# sum_dim(Expression x, list d, bool b=False, unsigned n=0)\n",
    "# d (list): Dimensions along which to reduce\n",
    "# b (bool): Whether to include batch dimension\n",
    "# Sum along an arbitrary dimension\n",
    "# Here, mat1 has dimension ((4, 2), 1),\n",
    "e = dy.sum_dim(mat1, [0])\n",
    "print('sum over the 0th dimension', e.value())\n",
    "\n",
    "e = dy.sum_dim(mat1, [1])\n",
    "print('sum over the 1st dimension', e.value())\n",
    "\n",
    "# sum_batches\n",
    "# Sum an expression that consists of multiple minibatches into \n",
    "# one of equal dimension but with only a single minibatch. \n",
    "# This is useful for summing loss functions at the end of minibatch training.\n",
    "e = dy.sum_batches(e1)\n",
    "\n",
    "# cumsum\n",
    "# usage: cumsum(Expression x, unsigned d=0)\n",
    "# Computes the cumulative sum along an arbitrary dimension.\n",
    "# d (int): Dimension along which to compute the cumulative sums (default: 0)\n",
    "e = dy.cumsum(mat1, 1)\n",
    "print('cumsum:\\n', e.value())\n",
    "\n",
    "# mean_elems\n",
    "# Computes the mean of all the elements of each minibatch.\n",
    "e = dy.mean_elems(mat1)\n",
    "print('mean_elems', e.value()) # will return 4.5 in this case.\n",
    "\n",
    "# mean_dim\n",
    "# usage:  mean_dim(Expression x, list d, bool b, unsigned n=0)\n",
    "#         x (dynet.Expression): Input expression\n",
    "#         d (list): Dimensions along which to reduce\n",
    "#         b (bool): Whether to include batch dimension\n",
    "#         n (int): If > 0, overwrite the n in the equation by this value, useful for masking\n",
    "# Computes the mean along an arbitrary dimension.\n",
    "e = dy.mean_dim(mat1, [0], True)\n",
    "print('mean_dim:', e.value())\n",
    "e_ = dy.mean_dim(mat1, [1], True)\n",
    "print('mean_dim:', e_.value())\n",
    "\n",
    "# mean_batches\n",
    "# Mean along the batch dimension\n",
    "e = dy.mean_batches(mat1)\n",
    "\n",
    "# std_elems\n",
    "# Computes the standard deviation of all the elements of each minibatch\n",
    "e = dy.std_elems(mat1)\n",
    "print('std_elems:', e.value())\n",
    "\n",
    "# std_dim\n",
    "# usage:  std_dim(Expression x, list d, bool b, unsigned n=0)\n",
    "#         x (dynet.Expression): Input expression\n",
    "#         d (int): Dimensions along which to reduce\n",
    "#         b (bool): Whether to include batch dimension\n",
    "#         n (int): If > 0, overwrite the n in the equation by this value, useful for masking\n",
    "# Computes the standard deviation along arbitrary dimensions.\n",
    "e = dy.std_dim(mat1, [0], True)\n",
    "print('std_dim', e.value())\n",
    "\n",
    "# std_batches\n",
    "# Standard deviation along the batch dimension\n",
    "e = dy.std_batches(mat1)\n",
    "\n",
    "# moment_elems\n",
    "# Statistical moment of elements of the tensor\n",
    "# usage:  moment_elems(Expression x, unsigned r)\n",
    "#         x (dynet.Expression): Input expression\n",
    "#         r (int): Moment order\n",
    "e = dy.moment_elems(mat1, 1)\n",
    "print('moment_elems:', e.value())\n",
    "\n",
    "# moment_dim\n",
    "# Statistical moment along an arbitrary dimension\n",
    "# usage:  moment_dim(Expression x, list d, unsigned r, bool b, unsigned n=0)\n",
    "#             x (dynet.Expression): Input expression\n",
    "#             d (list): Dimensions along which to reduce\n",
    "#             r (int): Moment order\n",
    "#             b (bool): Whether to include batch dimension\n",
    "#             n (int): If > 0, overwrite the n in the equation by this value, useful for masking\n",
    "e = dy.moment_dim(mat1, [0], 2, False)\n",
    "print('moment_dim:', e.value())\n",
    "\n",
    "# moment_batches\n",
    "# Statistical moment along the batch dimension\n",
    "e = dy.moment_batches(mat1, 2)\n",
    "\n",
    "# fold_rows\n",
    "# usage: fold_rows(Expression x, unsigned nrows=2)\n",
    "e = dy.fold_rows(mat1)\n",
    "print('fold_rows:\\n', e.value())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48bf75f7",
   "metadata": {},
   "source": [
    "### DyNet in Neural Networks\n",
    "This part contains Neural Networks related issues."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
