{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48b7846c",
   "metadata": {},
   "source": [
    "## Import Packages needed for data import and Wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618955a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "import matplotlib.mlab as mlab\n",
    "from mysql.connector import errorcode\n",
    "import matplotlib.pyplot as plt\n",
    "from __future__ import print_function\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "from IPython.html.widgets import *\n",
    "import plotly as py\n",
    "import plotly.graph_objs as go\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import r2_score\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import pickle\n",
    "import requests\n",
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f7ecdc",
   "metadata": {},
   "source": [
    "# Set up config parameters for importing data\n",
    "\n",
    "Referencing these parameters will be easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9f0e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Our data is stored in an AWS MySQL Database\n",
    "##Let's store the connection information so we can reference it later\n",
    "\n",
    "CONFIG = {\n",
    "    'user': 'db_gtown_2018',\n",
    "    'password': 'Gtown2018',\n",
    "    'port': '3306',\n",
    "    'host': 'nflnumbers.czuayagz62va.us-east-1.rds.amazonaws.com',\n",
    "    'database': 'db_nfl',\n",
    "    'raise_on_warnings': True,\n",
    "}\n",
    "\n",
    "##Now let's create a query to extract the inputs we need from the database\n",
    "##This Notebook is focused on forecasting Quarterback Pro Bowl selections, so this query is quarterback specific.\n",
    "\n",
    "QUERY = \"\"\"\n",
    "\n",
    "SELECT \n",
    "PASSER.PNAME AS PASSER\n",
    ", CONCAT(PASSER.PNAME, ', ', GAME.SEAS) AS PASSER_SEAS\n",
    ", CASE WHEN PASSER_PRO_BOWL.PLAYER_ID IS NOT NULL\n",
    "THEN 1\n",
    "ELSE 0\n",
    "END AS PASSER_PRO_BOWL\n",
    "\n",
    ", CASE WHEN PASSER.DPOS > 0\n",
    "THEN PASSER.DPOS\n",
    "ELSE 256\n",
    "END AS PASSER_DRAFT_SPOT\n",
    ", CASE WHEN PASSER.DPOS > 0\n",
    "THEN 1\n",
    "ELSE 0\n",
    "END AS PASSER_DRAFTED \n",
    "\n",
    ",TARGET.PNAME AS TARGET\n",
    ",CASE WHEN PASS_FULL.LOC IN ('DL', 'DM', 'DR')\n",
    "THEN 1\n",
    "ELSE 0\n",
    "END AS DEEP_PASS\n",
    ",CASE WHEN PASS_FULL.LOC IN ('L', 'M', 'R', 'NL')\n",
    "THEN 1\n",
    "ELSE 0\n",
    "END AS MED_PASS\n",
    ",CASE WHEN PASS_FULL.LOC IN ('SL', 'SM', 'SR')\n",
    "THEN 1\n",
    "ELSE 0\n",
    "END AS SHORT_PASS\n",
    ", PASS_FULL.YDS\n",
    ", 1 AS PASS_ATTEMPT\n",
    ", PASS_FULL.COMP\n",
    ", PASS_FULL.TD\n",
    ", PASS_FULL.INTRCPT\n",
    ", PASSER_RATING.PASS_RAT\n",
    ", PASSER.HEIGHT AS PASSER_HGHT\n",
    ", GAME.SEAS - RIGHT(PASSER.DOB,4) AS PASSER_AGE\n",
    ", PASSER.START AS PASSER_CAREER_STRT\n",
    "/*, GAME.SEAS - */\n",
    ", TARGET.HEIGHT AS TGT_HGHT\n",
    ", TARGET.WEIGHT AS TGT_WGHT\n",
    ", CASE WHEN TARGET_PRO_BOWL.PLAYER_ID IS NOT NULL\n",
    "THEN 1\n",
    "ELSE 0\n",
    "END AS TARGET_PRO_BOWL\n",
    "\n",
    ", GAME.SEAS - RIGHT(TARGET.DOB,4) AS TGT_AGE\n",
    ", CASE WHEN TARGET.DPOS IS NULL\n",
    "THEN 256\n",
    "WHEN TARGET.DPOS = 0\n",
    "THEN 256\n",
    "ELSE TARGET.DPOS\n",
    "END AS TGT_DRAFT_SPOT\n",
    ", CASE WHEN TARGET.DPOS > 0\n",
    "THEN 1\n",
    "ELSE 0\n",
    "END AS TGT_DRAFTED \n",
    ", TARGET.START AS TGT_CAREER_STRT /*'USE TO FIGURE OUT YEARS IN LEAGUE'*/\n",
    ", CASE WHEN TARGET.FORTY = 0\n",
    "THEN ROUND(AVERAGE_FORTY.AVG_FORTY,3)\n",
    "ELSE TARGET.FORTY\n",
    "END AS TGT_FORTY\n",
    ", CASE WHEN TARGET.VERTICAL = 0\n",
    "THEN ROUND(AVERAGE_VERTICAL.AVG_VERT,3)\n",
    "ELSE TARGET.VERTICAL\n",
    "END AS TGT_VERT\n",
    ", CASE WHEN TARGET.POS1 = 'RB'\n",
    "THEN 1\n",
    "ELSE 0\n",
    "END AS RB_TGT\n",
    ", CASE WHEN TARGET.POS1 = 'WR'\n",
    "THEN 1\n",
    "ELSE 0\n",
    "END AS WR_TGT\n",
    ", CASE WHEN TARGET.POS1 = 'TE'\n",
    "THEN 1\n",
    "ELSE 0\n",
    "END AS TE_TGT\n",
    ", CASE WHEN TARGET.POS1 <> 'RB'\n",
    "AND TARGET.POS1 <> 'TE'\n",
    "AND TARGET.POS1 <> 'WR'\n",
    "THEN 1\n",
    "ELSE 0\n",
    "END AS TRICK_PLAY\n",
    "\n",
    "/*,QTR\n",
    ",MIN *//*'CAN BE USED FOR TWO MIN DRILL'*/\n",
    ", YTG\n",
    ", Case when PASS_FULL.YDS >= YTG\n",
    "THEN 1\n",
    "ELSE 0\n",
    "END AS FIRST_DOWN_CONVERSION\n",
    "\n",
    ", CASE WHEN ZONE = 5\n",
    "THEN 1\n",
    "ELSE 0\n",
    "END AS RED_ZONE_ATTMPT /*'DEFINITION AVAILABLE'*/\n",
    ", CASE WHEN ZONE = 5\n",
    "THEN PASSER_RATING.PASS_RAT\n",
    "ELSE NULL\n",
    "END AS RED_ZONE_QB_RAT /*'DEFINITION AVAILABLE'*/\n",
    ", CASE WHEN DWN = 4\n",
    "AND PASS_FULL.YDS >= YTG\n",
    "THEN 1\n",
    "when DWN = 4\n",
    "AND PASS_FULL.YDS < YTG\n",
    "THEN 0\n",
    "ELSE NULL\n",
    "END\n",
    "AS FOURTH_DOWN_SUCCESS\n",
    ", CASE WHEN DWN = 3\n",
    "AND PASS_FULL.YDS >= YTG\n",
    "THEN 1\n",
    "when DWN = 3\n",
    "AND PASS_FULL.YDS < YTG\n",
    "THEN 0\n",
    "ELSE NULL\n",
    "END\n",
    "AS THIRD_DOWN_SUCCESS\n",
    ", CASE WHEN QTR = 4\n",
    "THEN PASSER_RATING.PASS_RAT\n",
    "ELSE null\n",
    "END AS FOURTH_QTR_PASS_RAT\n",
    ", CASE WHEN SG = 'Y'\n",
    "THEN 1 \n",
    "ELSE 0\n",
    "END as SHOTGUN\n",
    ", CASE WHEN NH = 'Y'\n",
    "THEN 1\n",
    "ELSE 0\n",
    "END AS  NO_HUDDLE\n",
    ", CASE WHEN PENALTY.ACT IS NOT NULL\n",
    "THEN 1\n",
    "ELSE 0\n",
    "END AS DEF_PENALTY_DCLND\n",
    ",CASE WHEN PENALTY.ACT IS NOT NULL\n",
    "THEN PASSER_RATING.PASS_RAT\n",
    "ELSE NULL\n",
    "END AS FREE_PLAY_PASS_RAT\n",
    ", PENALTY.DESC as PENALTY_DESC\n",
    ",GAME.SEAS\n",
    "/* ,GAME.WK\n",
    ",GAME.DAY\n",
    ",GAME.V 'FIGURE OUT HOW TO DO HOME OR AWAY'\n",
    ",GAME.H*/\n",
    "/*HOW DO WE CALCULATE WHETHER THE PASSER IS AT HOME OR AWAY?*/\n",
    ",GAME.TEMP\n",
    ",GAME.HUMD\n",
    ",GAME.WSPD\n",
    ",case when COND IN ('Rain', 'Showers', 'Snow', 'Thunderstorms', 'Cold'\n",
    ",'Flurries'\n",
    ",'Light Rain'\n",
    ",'Light Showers'\n",
    ",'Light Snow'\n",
    ",'Windy'\n",
    ")\n",
    "THEN 1\n",
    "ELSE 0\n",
    "END AS BAD_WEATH\n",
    ", case when COND IN ('Chance Rain'\n",
    ",'Clear'\n",
    ",'Closed Roof'\n",
    ",'Cloudy'\n",
    ",'Covered Roof'\n",
    ",'Dome'\n",
    ",'Fair'\n",
    ",'Foggy'\n",
    ",'Hazy'\n",
    ",'Mostly Cloudy'\n",
    ",'Mostly Sunny'\n",
    ",'Overcast'\n",
    ",'Partly Cloudy'\n",
    ",'Partly Sunny'\n",
    ",'Sunny' )\n",
    "THEN 1\n",
    "WHEN COND IS NULL\n",
    "THEN 1\n",
    "ELSE 0\n",
    "END AS GOOD_WEATH\n",
    ",GAME.COND\n",
    ", CASE WHEN GAME.COND = 'DOME'\n",
    "THEN 1\n",
    "ELSE 0\n",
    "END AS DOME_GAME\n",
    ", CASE WHEN GAME.SURF <> 'GRASS'\n",
    "THEN 1\n",
    "ELSE 0\n",
    "END AS TURF_FIELD\n",
    ", CASE WHEN POSTSEASON_RUN.FINAL_WK >17\n",
    "THEN 1\n",
    "ELSE 0\n",
    "END AS POSTSEASON\n",
    ",  CASE WHEN POSTSEASON_RUN.FINAL_WK >18\n",
    "THEN 1\n",
    "ELSE 0\n",
    "END AS DIVISIONAL_APPEARANCE\n",
    ", CASE \n",
    "WHEN PASSER_PRO_BOWL_PRIOR.PLAYER_ID IS NULL\n",
    "THEN 0\n",
    "ELSE 1\n",
    "END AS PASSER_PRO_BOWL_LAST_YEAR\n",
    ",NULL AS RUSH_YDS\n",
    ",NULL AS RUSH_SUCCESS\n",
    ", NULL AS RUSH_TD\n",
    ", NULL AS FUMBLE\n",
    " FROM PBP\n",
    " INNER JOIN PASS_FULL\n",
    " ON PBP.PID = PASS_FULL.PID\n",
    "left outer join GAME\n",
    "ON PBP.GID = GAME.GID\n",
    "LEFT OUTER JOIN PENALTY\n",
    "ON PBP.PID = PENALTY.PID\n",
    "AND PENALTY.CAT = '4'\n",
    "AND PENALTY.ACT = 'D'\n",
    "INNER JOIN PLAYER PASSER\n",
    "ON PASS_FULL.PSR = PASSER.PLAYER\n",
    "LEFT OUTER JOIN PLAYER TARGET\n",
    "ON PASS_FULL.TRG = TARGET.PLAYER\n",
    "LEFT OUTER JOIN PASSER_RATING\n",
    "ON PASS_FULL.YDS = PASSER_RATING.YDS\n",
    "AND PASS_FULL.COMP = PASSER_RATING.COMPL\n",
    "AND PASS_FULL.TD = PASSER_RATING.TD\n",
    "AND PASS_FULL.INTRCPT = PASSER_RATING.INTRCPT\n",
    "LEFT OUTER JOIN (SELECT \n",
    "POS1\n",
    ", AVG(FORTY) AS AVG_FORTY\n",
    ",COUNT(*)\n",
    "FROM PLAYER\n",
    "WHERE FORTY > 0\n",
    "GROUP BY \n",
    "POS1) AVERAGE_FORTY\n",
    "ON TARGET.POS1 = AVERAGE_FORTY.POS1\n",
    "LEFT OUTER JOIN\n",
    "(SELECT \n",
    "POS1\n",
    ", AVG(VERTICAL) AS AVG_VERT\n",
    ",COUNT(*)\n",
    "FROM PLAYER\n",
    "WHERE VERTICAL > 0\n",
    "GROUP BY \n",
    "POS1) AVERAGE_VERTICAL\n",
    "ON TARGET.POS1 = AVERAGE_VERTICAL.POS1\n",
    "LEFT OUTER JOIN PRO_BOWL PASSER_PRO_BOWL\n",
    "ON GAME.SEAS = PASSER_PRO_BOWL.ProBowl_Year\n",
    "AND PASSER.PLAYER = PASSER_PRO_BOWL.PLAYER_ID\n",
    "LEFT OUTER JOIN PRO_BOWL PASSER_PRO_BOWL_PRIOR\n",
    "ON (GAME.SEAS -1) = PASSER_PRO_BOWL_PRIOR.ProBowl_Year\n",
    "AND PASSER.PLAYER = PASSER_PRO_BOWL_PRIOR.PLAYER_ID\n",
    "LEFT OUTER JOIN PRO_BOWL TARGET_PRO_BOWL\n",
    "ON GAME.SEAS = TARGET_PRO_BOWL.ProBowl_Year\n",
    "AND TARGET.PLAYER = TARGET_PRO_BOWL.PLAYER_ID\n",
    "LEFT OUTER JOIN\n",
    "(SELECT SEAS, TEAM, MAX(FINAL_WK) AS FINAL_WK\n",
    "FROM (\n",
    "(SELECT SEAS, V AS TEAM, MAX(WK) AS FINAL_WK FROM GAME VISIT\n",
    "GROUP BY SEAS, V) \n",
    "UNION\n",
    "(SELECT SEAS, H AS TEAM, MAX(WK) AS FINAL_WK FROM GAME HOME\n",
    "GROUP BY SEAS, H)\n",
    ") WIN_RECORD\n",
    "GROUP BY SEAS, TEAM) POSTSEASON_RUN\n",
    "ON PBP.OFF = POSTSEASON_RUN.TEAM\n",
    "AND GAME.SEAS = POSTSEASON_RUN.SEAS\n",
    "\n",
    "\n",
    "WHERE PASS_FULL.SPK = 0\n",
    "AND WK <= 17\n",
    "\n",
    "UNION ALL\n",
    "SELECT \n",
    "RUSHER.PNAME AS PNAME\n",
    "\n",
    ", CONCAT(RUSHER.PNAME, ', ', GAME.SEAS) AS PASSER_SEAS\n",
    ", CASE WHEN RUSHER_PRO_BOWL.PLAYER_ID IS NOT NULL\n",
    "THEN 1\n",
    "ELSE 0\n",
    "END AS PASSER_PRO_BOWL\n",
    "\n",
    ", CASE WHEN RUSHER.DPOS > 0\n",
    "THEN RUSHER.DPOS\n",
    "ELSE 256\n",
    "END AS PASSER_DRAFT_SPOT\n",
    ", CASE WHEN RUSHER.DPOS > 0\n",
    "THEN 1\n",
    "ELSE 0\n",
    "END AS PASSER_DRAFTED \n",
    "\n",
    ",NULL AS TARGET\n",
    ",NULL AS DEEP_PASS\n",
    ",NULL AS MED_PASS\n",
    ",NULL AS SHORT_PASS\n",
    ", NULL AS YDS\n",
    ", NULL AS PASS_ATTEMPT\n",
    ", NULL AS COMP\n",
    ", NULL AS TD\n",
    ", NULL AS INTRCPT\n",
    ", NULL AS PASS_RAT\n",
    ", RUSHER.HEIGHT AS PASSER_HGHT\n",
    ", GAME.SEAS - RIGHT(RUSHER.DOB,4) AS PASSER_AGE\n",
    ", RUSHER.START AS PASSER_CAREER_STRT\n",
    "/*, GAME.SEAS - */\n",
    ", NULL AS TGT_HGHT\n",
    ", NULL AS TGT_WGHT\n",
    ", NULL AS TARGET_PRO_BOWL\n",
    "\n",
    ", NULL AS TGT_AGE\n",
    ", NULL AS TGT_DRAFT_SPOT\n",
    ", NULL AS TGT_DRAFTED \n",
    ", NULL AS TGT_CAREER_STRT /*'USE TO FIGURE OUT YEARS IN LEAGUE'*/\n",
    ", NULL AS TGT_FORTY\n",
    ", NULL AS TGT_VERT\n",
    ", NULL AS RB_TGT\n",
    ", NULL AS WR_TGT\n",
    ", NULL AS TE_TGT\n",
    ", NULL AS TRICK_PLAY\n",
    "\n",
    "/*,QTR\n",
    ",MIN *//*'CAN BE USED FOR TWO MIN DRILL'*/\n",
    ", YTG\n",
    ", Case when RUSH.YDS >= YTG\n",
    "THEN 1\n",
    "ELSE 0\n",
    "END AS FIRST_DOWN_CONVERSION\n",
    "\n",
    ", NULL AS RED_ZONE_ATTMPT /*'DEFINITION AVAILABLE'*/\n",
    ", NULL AS RED_ZONE_QB_RAT /*'DEFINITION AVAILABLE'*/\n",
    ", CASE WHEN DWN = 4\n",
    "AND RUSH.YDS >= YTG\n",
    "THEN 1\n",
    "when DWN = 4\n",
    "AND RUSH.YDS < YTG\n",
    "THEN 0\n",
    "ELSE NULL\n",
    "END\n",
    "AS FOURTH_DOWN_SUCCESS\n",
    ", CASE WHEN DWN = 3\n",
    "AND RUSH.YDS >= YTG\n",
    "THEN 1\n",
    "when DWN = 3\n",
    "AND RUSH.YDS < YTG\n",
    "THEN 0\n",
    "ELSE NULL\n",
    "END\n",
    "AS THIRD_DOWN_SUCCESS\n",
    ", NULL AS FOURTH_QTR_PASS_RAT\n",
    ", CASE WHEN SG = 'Y'\n",
    "THEN 1 \n",
    "ELSE 0\n",
    "END as SHOTGUN\n",
    ", CASE WHEN NH = 'Y'\n",
    "THEN 1\n",
    "ELSE 0\n",
    "END AS  NO_HUDDLE\n",
    ", CASE WHEN PENALTY.ACT IS NOT NULL\n",
    "THEN 1\n",
    "ELSE 0\n",
    "END AS DEF_PENALTY_DCLND\n",
    ", NULL AS FREE_PLAY_PASS_RAT\n",
    ", PENALTY.DESC as PENALTY_DESC\n",
    ",GAME.SEAS\n",
    "/* ,GAME.WK\n",
    ",GAME.DAY\n",
    ",GAME.V 'FIGURE OUT HOW TO DO HOME OR AWAY'\n",
    ",GAME.H*/\n",
    "/*HOW DO WE CALCULATE WHETHER THE PASSER IS AT HOME OR AWAY?*/\n",
    ",GAME.TEMP\n",
    ",GAME.HUMD\n",
    ",GAME.WSPD\n",
    ",case when COND IN ('Rain', 'Showers', 'Snow', 'Thunderstorms', 'Cold'\n",
    ",'Flurries'\n",
    ",'Light Rain'\n",
    ",'Light Showers'\n",
    ",'Light Snow'\n",
    ",'Windy'\n",
    ")\n",
    "THEN 1\n",
    "ELSE 0\n",
    "END AS BAD_WEATH\n",
    ", case when COND IN ('Chance Rain'\n",
    ",'Clear'\n",
    ",'Closed Roof'\n",
    ",'Cloudy'\n",
    ",'Covered Roof'\n",
    ",'Dome'\n",
    ",'Fair'\n",
    ",'Foggy'\n",
    ",'Hazy'\n",
    ",'Mostly Cloudy'\n",
    ",'Mostly Sunny'\n",
    ",'Overcast'\n",
    ",'Partly Cloudy'\n",
    ",'Partly Sunny'\n",
    ",'Sunny' )\n",
    "THEN 1\n",
    "WHEN COND IS NULL\n",
    "THEN 1\n",
    "ELSE 0\n",
    "END AS GOOD_WEATH\n",
    ",GAME.COND\n",
    ", CASE WHEN GAME.COND = 'DOME'\n",
    "THEN 1\n",
    "ELSE 0\n",
    "END AS DOME_GAME\n",
    ", CASE WHEN GAME.SURF <> 'GRASS'\n",
    "THEN 1\n",
    "ELSE 0\n",
    "END AS TURF_FIELD\n",
    ", CASE WHEN GAME.WK >17\n",
    "THEN 1\n",
    "ELSE 0\n",
    "END AS POSTSEASON\n",
    ",  CASE WHEN GAME.WK >18\n",
    "THEN 1\n",
    "ELSE 0\n",
    "END AS DIVISIONAL_APPEARANCE\n",
    ", NULL AS PASSER_PRO_BOWL_LAST_YEAR\n",
    ",RUSH.YDS AS RUSH_YDS\n",
    ",RUSH.SUCC AS RUSH_SUCCESS\n",
    ", case when PBP.PTS >= 6\n",
    "THEN 1\n",
    "ELSE 0\n",
    "END AS RUSH_TD\n",
    ", CASE \n",
    "WHEN PBP.FUM = ''\n",
    "THEN 0\n",
    "WHEN PBP.FUM IS NOT NULL\n",
    "THEN 1\n",
    "ELSE 0\n",
    "END AS FUMBLE\n",
    " FROM PBP\n",
    " INNER JOIN RUSH\n",
    " ON PBP.PID = RUSH.PID\n",
    "LEFT OUTER JOIN PLAYER RUSHER\n",
    "ON RUSH.BC = RUSHER.PLAYER\n",
    "left outer join GAME\n",
    "ON PBP.GID = GAME.GID\n",
    "LEFT OUTER JOIN PRO_BOWL RUSHER_PRO_BOWL\n",
    "ON GAME.SEAS = RUSHER_PRO_BOWL.ProBowl_Year\n",
    "AND RUSHER_PRO_BOWL.PLAYER_ID = RUSH.BC\n",
    "LEFT OUTER JOIN PENALTY\n",
    "ON PBP.PID = PENALTY.PID\n",
    "WHERE RUSH.KNE = 0\n",
    "AND RUSHER.POS1 = 'QB'\n",
    "AND WK <= 17\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "##Now we are identifying the features that are included in our query\n",
    "\n",
    "FEATURES = ['PASSER', \n",
    "'PASSER_SEAS',\n",
    "'PASSER_PRO_BOWL', \n",
    "'PASSER_DRAFT_SPOT', \n",
    "'PASSER_DRAFTED', \n",
    "'TARGET', \n",
    "'DEEP_PASS', \n",
    "'MED_PASS', \n",
    "'SHORT_PASS', \n",
    "'YDS', \n",
    "'PASS_ATTEMPT',\n",
    "'COMP', \n",
    "'TD', \n",
    "'INTRCPT', \n",
    "'PASS_RAT', \n",
    "'PASSER_HGHT', \n",
    "'PASSER_AGE', \n",
    "'PASSER_CAREER_STRT', \n",
    "'TGT_HGHT', \n",
    "'TGT_WGHT', \n",
    "'TARGET_PRO_BOWL', \n",
    "'TGT_AGE', \n",
    "'TGT_DRAFT_SPOT', \n",
    "'TGT_DRAFTED', \n",
    "'TGT_CAREER_STRT', \n",
    "'TGT_FORTY', \n",
    "'TGT_VERT', \n",
    "'RB_TGT', \n",
    "'WR_TGT', \n",
    "'TE_TGT', \n",
    "'TRICK_PLAY', \n",
    "'YTG', \n",
    "'FIRST_DOWN_CONVERSION', \n",
    "'RED_ZONE_ATTMPT', \n",
    "'RED_ZONE_QB_RAT', \n",
    "'FOURTH_DOWN_SUCCESS', \n",
    "'THIRD_DOWN_SUCCESS', \n",
    "'FOURTH_QTR_PASS_RAT', \n",
    "'SHOTGUN', \n",
    "'NO_HUDDLE', \n",
    "'DEF_PENALTY_DCLND', \n",
    "'FREE_PLAY_PASS_RAT', \n",
    "'PENALTY_DESC', \n",
    "'SEAS', \n",
    "'TEMP', \n",
    "'HUMD', \n",
    "'WSPD', \n",
    "'BAD_WEATH', \n",
    "'GOOD_WEATH', \n",
    "'COND', \n",
    "'DOME_GAME', \n",
    "'TURF_FIELD',\n",
    "'POSTSEASON',\n",
    "'DIVISIONAL_APPEARANCE',\n",
    "'PASSER_PRO_BOWL_LAST_YEAR',\n",
    "'RUSH_YDS',\n",
    "'RUSH_SUCCESS',\n",
    "'RUSH_TD',\n",
    "'FUMBLE'\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02979cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Create a function that uses the query and connection info to pull data from MySQL and saves it as a pandas dataframe\n",
    "\n",
    "def fetch_data():   \n",
    "    try:\n",
    "        cnx = mysql.connector.connect(**CONFIG)\n",
    "        cursor = cnx.cursor()\n",
    "        #Let's read all the rows in the table\n",
    "        cursor.execute(QUERY)\n",
    "        #specify the attributes that you want to display\n",
    "        df = DataFrame(cursor.fetchall())    \n",
    "        df.columns = FEATURES\n",
    "        cnx.commit()\n",
    "    except mysql.connector.Error as err:\n",
    "        if err.errno == errorcode.ER_ACCESS_DENIED_ERROR:\n",
    "            print(\"Something is wrong with your user name or password\")\n",
    "        elif err.errno == errorcode.ER_BAD_DB_ERROR:\n",
    "            print(\"Database does not exist\")\n",
    "        else:\n",
    "            print(err)\n",
    "    else:\n",
    "        \n",
    "        return df\n",
    "        cursor.close()\n",
    "        cnx.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330a32b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Call fetch data function and display results\n",
    "\n",
    "data = fetch_data()     \n",
    "data.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dbded7a",
   "metadata": {},
   "source": [
    "## Per-pass totals between Pro-Bowl passers and non-pro-bowlers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f4416a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,4))\n",
    "data[\"PASSER_PRO_BOWL\"].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad153078",
   "metadata": {},
   "source": [
    "## Aggregating per-play data into season-long data\n",
    "\n",
    "There are a huge number of passes thrown by quarterbacks. Because Pro-Bowl elections are made on a per-season basis, it makes it difficult to assess whether individual plays are \"Pro-Bowl Quality\". After all, even the best quarterbacks will throw interceptions and have incomplete passes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ecc11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Too many pass attemps, lets group them group into a per season/passer\n",
    "#df.groupby(['PASSER', 'SEAS']).size()\n",
    "\n",
    "df_passer_by_season = data.groupby(['PASSER', 'SEAS']).agg({\n",
    "    'PASSER': np.min, \n",
    "    'PASSER_SEAS': np.min, \n",
    "    'PASSER_PRO_BOWL': np.max, \n",
    "    'PASS_RAT': np.mean, \n",
    "    'PASS_ATTEMPT': np.sum,\n",
    "    'COMP': np.sum,\n",
    "    'PASSER_DRAFT_SPOT': np.max, \n",
    "    'PASSER_DRAFTED': np.max, \n",
    "    'DEEP_PASS': np.mean,  \n",
    "    'MED_PASS': np.mean, \n",
    "    'SHORT_PASS': np.mean, \n",
    "    'YDS': np.sum, \n",
    "    'TD': np.sum, \n",
    "    'INTRCPT': np.sum, \n",
    "    'PASSER_HGHT': np.max,  \n",
    "    'PASSER_AGE': np.max, \n",
    "    'PASSER_CAREER_STRT': np.max, \n",
    "    'TGT_HGHT': np.mean, \n",
    "    'TGT_WGHT': np.mean, \n",
    "    'TARGET_PRO_BOWL': np.mean,  \n",
    "    'TGT_AGE': np.mean, \n",
    "    'TGT_DRAFT_SPOT': np.mean, \n",
    "    'TGT_DRAFTED': np.mean, \n",
    "    'TGT_CAREER_STRT': np.mean, \n",
    "    'TGT_FORTY': np.mean,  \n",
    "    'TGT_VERT':np.mean, \n",
    "    'RB_TGT': np.mean,  \n",
    "    'WR_TGT': np.mean, \n",
    "    'TE_TGT': np.mean,  \n",
    "    'TRICK_PLAY': np.mean, \n",
    "    'FIRST_DOWN_CONVERSION': np.mean, \n",
    "    'RED_ZONE_ATTMPT': np.mean, \n",
    "    'RED_ZONE_QB_RAT': np.mean , \n",
    "    'FOURTH_DOWN_SUCCESS': np.mean, \n",
    "    'THIRD_DOWN_SUCCESS': np.mean, \n",
    "    'FOURTH_QTR_PASS_RAT': np.mean,  \n",
    "    'SHOTGUN': np.mean,  \n",
    "    'NO_HUDDLE': np.mean, \n",
    "    'DEF_PENALTY_DCLND': np.sum, \n",
    "    'FREE_PLAY_PASS_RAT': np.mean,  \n",
    "    'SEAS': np.max,  \n",
    "    'GOOD_WEATH': np.mean,  \n",
    "    'DOME_GAME': np.mean,  \n",
    "    'TURF_FIELD': np.mean,                               \n",
    "    'SEAS': np.min,\n",
    "    'POSTSEASON': np.max,\n",
    "    'DIVISIONAL_APPEARANCE': np.max,\n",
    "    'PASSER_PRO_BOWL_LAST_YEAR': np.max,\n",
    "    'RUSH_YDS': np.sum,\n",
    "    'RUSH_SUCCESS': np.mean,\n",
    "    'RUSH_TD': np.sum,\n",
    "    'FUMBLE': np.sum\n",
    "                                   })\n",
    "\n",
    "df_passer_by_season\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd65da1",
   "metadata": {},
   "source": [
    "## Let's take a preliminary look at our data\n",
    "\n",
    "Here, we use Passer Rating as a measure of efficiency, and the number of passes attempted. Let's see what our data looks like once it has been aggregated into its rawest form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77fdbe57",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df_standardized.drop(['PASSER_PRO_BOWL'], axis=1)\n",
    "labels   = df_standardized['PASSER_PRO_BOWL']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0580e8",
   "metadata": {},
   "source": [
    "## Regularization & Feature selection\n",
    "Time to determine which of those features will be used in our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97474336",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lasso \n",
    "model = Lasso()\n",
    "model.fit(features, labels)\n",
    "print(list(zip(features, model.coef_.tolist())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b044c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Ridge()\n",
    "model.fit(features, labels)\n",
    "print(list(zip(features, model.coef_.tolist())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab7eb55",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ElasticNet()\n",
    "model.fit(features, labels)\n",
    "print(list(zip(features, model.coef_.tolist())))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa6b7a8",
   "metadata": {},
   "source": [
    "## Regularization Results:\n",
    "### Lasso: 0 features\n",
    "### Ridge: All features\n",
    "### ElasticNet:  0 features\n",
    "\n",
    "Let's keep all the features we have selected to this point (thanks, Ridge!). After all, we've already removed a lot of highly collerated features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8f62ac",
   "metadata": {},
   "source": [
    "=================================================================================================================\n",
    "\n",
    "## Let's revisit our model data\n",
    "\n",
    "For our training data, we've removed 2017 and those passers with less than 35 pass attempts.\n",
    "We haven't yet identified our training/test data.\n",
    "First, we'll remove 2017 and then standardize our data. We'll carve out the features from the target so we can run them through a classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5589fead",
   "metadata": {},
   "outputs": [],
   "source": [
    "# repull data prior to its earlier standardization\n",
    "model_data = df_passer_by_season_qb_nums_only\n",
    "train_cutoff_dt = 2012\n",
    "\n",
    "#data for modeling , before 2017 data\n",
    "train_model_data = model_data[model_data['SEAS'] < train_cutoff_dt]\n",
    "\n",
    "## standardize data\n",
    "scaler = MinMaxScaler()\n",
    "train_data = scaler.fit_transform(train_model_data)\n",
    "train_model_data = pd.DataFrame(train_data,index=train_data[:,0])\n",
    "\n",
    "## Separate out the features from the target (all standardized now)\n",
    "train_features = train_model_data.iloc[:, 1:41]\n",
    "train_target = train_model_data.iloc[:, 0]\n",
    "\n",
    "print(\"Training data ready to go.. will train model using data before\", train_cutoff_dt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9178ae80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data for testing, 2017 onwards - full season data\n",
    "test_model_data = model_data[model_data['SEAS'] >= train_cutoff_dt]\n",
    "\n",
    "## standardize data\n",
    "scaler = MinMaxScaler()\n",
    "test_data = scaler.fit_transform(test_model_data)\n",
    "test_model_data = pd.DataFrame(test_data)\n",
    "\n",
    "## Separate out the features from the target (all standardized now)\n",
    "test_features = test_model_data.iloc[:, 1:41]\n",
    "test_target = test_model_data.iloc[:, 0]\n",
    "\n",
    "print(\"Testing data ready to go.. will test data based on the\", train_cutoff_dt, \"season and afterwards\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae37410",
   "metadata": {},
   "source": [
    "If we take a look at the shape of our data, you'll see that we have 960 sample quarterbacks in our 17 year span. We'll be training our models using a split sample from the 906 quarterbacks that were playing prior to 2017. After we determine which model is giving us the best results, we can run the full training data (all 906 records) to get a better fit. After that, we can run our model on 2017 data (real results), and start tuning our hyperparameters to see what gets the best results without overfitting our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ad7e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Original Data shape. Rows, Columns :\", model_data.shape)\n",
    "print(\"Training Data shape. Rows, Columns :\", train_features.shape)\n",
    "print(\"Prediction Population Data shape. Rows, Columns :\", test_features.shape)\n",
    "print(\"Training Target shape. Rows, Columns :\", train_target.shape)\n",
    "print(\"Prediction Population Target shape. Rows, Columns :\", test_target.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b6cb107",
   "metadata": {},
   "source": [
    "## Splitting our training data\n",
    "Because we don't have too much data (only ~1,000 records), let's keep the our training split size fairly large. Since are assigning the test size first, the training size is implictly determined by our smaller test size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32a5e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify our data and target \n",
    "x = train_features\n",
    "y = train_target\n",
    "\n",
    "# Create random train and test splits to avoid bais and overfitting\n",
    "splits = tts(x, y, test_size=.2)\n",
    "x_train, x_test, y_train, y_test = splits\n",
    "\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b607a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "results=[]\n",
    "names=[]\n",
    "\n",
    "def fit_model(model, x_train=x_train, x_test=x_test, y_train=y_train, y_test=y_test):\n",
    "    start = time.time()\n",
    "    model.fit(x_train, y_train)\n",
    "    duration = time.time() - start \n",
    "    score = model.score(x_test, y_test)\n",
    "    \n",
    "    print(\"{} fit in {:0.2f} seconds score: {:0.4f}\".format(model.__class__.__name__, duration, score))\n",
    "    #print(model.get_params()) \n",
    "    kfold = model_selection.KFold(n_splits=10, random_state=7)\n",
    "    scoring = 'accuracy'\n",
    "    cv_results = model_selection.cross_val_score(model, x_train, y_train, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    #print(cv_results)\n",
    "    names.append(name)\n",
    "    #msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    #print(msg)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba96cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare models\n",
    "\n",
    "\n",
    "models = []\n",
    "models.append(('LR', LogisticRegression()))\n",
    "#models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "models.append(('RAND', RandomForestClassifier()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('SVM', SVC()))\n",
    "\n",
    "    \n",
    "for name,model in models:\n",
    "    fit_model(model)    \n",
    "    \n",
    "    # boxplot algorithm comparison\n",
    "fig = plt.figure()\n",
    "fig.suptitle('Algorithm Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad8b927",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = test_features\n",
    "y = test_target\n",
    "def predict_model(model):\n",
    "    yhat = model.predict(test_features)\n",
    "    #r2 = r2_score(target_predict, yhat)\n",
    "    #me = mse(target_predict, yhat)\n",
    "    #print(\"r2={:0.3f} MSE={:0.3f}\".format(r2,me))\n",
    "    print(name, model)\n",
    "    print(classification_report(y, yhat))\n",
    "    print(yhat)\n",
    "    \n",
    "for name, model in models:\n",
    "    predict_model(model) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359f566c",
   "metadata": {},
   "source": [
    "## How do those results look?\n",
    "### Logistic Regression & KNN: Results look reasonable.\n",
    "### Decision Tree: Forecasts too many players making the Pro-Bowl.\n",
    "### Random Forest: Pretty good results.\n",
    "### Gaussian & SVM: Predicted nobody made the Pro-Bowl :(\n",
    "\n",
    "Those results are all over the place.. But there is hope after seeing the auto-generated results. Let's take a deeper look at some of these models, and try tuning the hyper-parameters to see if we can get some better results\n",
    "\n",
    "### Let's try tuning KNN's hyperparameters\n",
    "First, we'll start by modifying how many nearest neighbors are used in the algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba689eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = KNeighborsClassifier(n_neighbors = 3)\n",
    "clf.fit(train_features, train_target)\n",
    "#x_train\n",
    "score = clf.score(test_features, test_target)\n",
    "pred_rslt = clf.predict(test_features)\n",
    "\n",
    "print(classification_report(test_target, pred_rslt))\n",
    "\n",
    "##print(\"Predicted:\", pred_rslt)\n",
    "##print(\"Actual : \", y_test)\n",
    "print(\"Top: Predicted 0, Predicted ProBowl\")\n",
    "print(\"Left: Actual 0, Actual ProBowl\")\n",
    "confusion_matrix(test_target, pred_rslt)\n",
    "\n",
    "model_rslt_conf_matx = DataFrame(confusion_matrix(test_target, pred_rslt), index = ['NON_PRO_BOWL', 'ACT_PRO_BOWL'])\n",
    "model_rslt_conf_matx.columns = ['PREDICTED_NON_PRO_BOWLER', 'PREDICTED_PRO_BOWLER']\n",
    "model_rslt_conf_matx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54ab99f",
   "metadata": {},
   "source": [
    "### Let's take a deep dive in the Random Forest Classifier - easily the best performing model so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe2de06",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df_passer_by_season.PASS_ATTEMPT, df_passer_by_season.PASS_RAT , c=df_passer_by_season.PASSER_PRO_BOWL)\n",
    "plt.suptitle('Does this looks like a good classifier problem?', fontsize=20)\n",
    "plt.xlabel('Passes Attempted', fontsize=18)\n",
    "plt.ylabel('Passer Rating', fontsize=16)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4475b3ab",
   "metadata": {},
   "source": [
    "## Removing quarterbacks with small sample sizes\n",
    "\n",
    "Lots of quarterbacks (or other players) attempts a handfull of passes each year. These trick plays are not sustainable over the course of a season, and should be excluded from our classifier. While we are removing those quarterbacks with small sample size, let's also remove the last year of our data, 2017. This will allow us to train a model using 16 years of data, and then test that model on the 2017 data to see how accurate it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1a67d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pass_limit = 35\n",
    "season_limit = 2018\n",
    "\n",
    "#Removing passers with limited pass sample size\n",
    "df_passer_by_season_qb = df_passer_by_season.loc[(df_passer_by_season['PASS_ATTEMPT'] > pass_limit) & (df_passer_by_season['SEAS'] < season_limit)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7acf0be",
   "metadata": {},
   "source": [
    "## Now let's look again after removing outliers\n",
    "\n",
    "Yellow = Pro-Bowler\n",
    "\n",
    "Purple = Non-Pro-Bowler\n",
    "\n",
    "How are we are doing now?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d7d931",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df_passer_by_season_qb.PASS_ATTEMPT, df_passer_by_season_qb.PASS_RAT , c=df_passer_by_season_qb.PASSER_PRO_BOWL)\n",
    "plt.suptitle('Can we identify Pro-Bowlers?', fontsize=20)\n",
    "plt.xlabel('Passes Attempted', fontsize=18)\n",
    "plt.ylabel('Passer Rating', fontsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5c9990",
   "metadata": {},
   "source": [
    "This looks like a much more solveable classifier problem.\n",
    "\n",
    "\n",
    "Now that we think we are going in the right direction, let's take a deeper look at our model training data.\n",
    "## Checking our data for missing values and general quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea97c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_passer_by_season_qb.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3bd913c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check how many null values remain for our sample size\n",
    "df_passer_by_season_qb.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ec14d1",
   "metadata": {},
   "source": [
    "## We've found missing data - let's handle it\n",
    "There are a couple columns that are missing some data. One column in particular, FREE_PLAY_PASS_RAT is missing data for nearly half of the data (482/906 records!). We can safely remove that column because it won't be reliable enough to use.\n",
    "\n",
    "Some columns are only missing a couple records worth of data. Because those columns have been aggregated into percentage columns, we can use the population's mean to fill in that small set of missing data. \n",
    "\n",
    "While we are missing data, let's also remove some label columns so that our data is entirely numeric, and is starting to look model ready."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0bff52",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Removing label columns and columns missing significant data\n",
    "df_passer_by_season_qb_nums_only = df_passer_by_season_qb.drop(['PASSER', 'PASSER_SEAS', 'FREE_PLAY_PASS_RAT'], axis=1)\n",
    "print(\"Removed 3 columns to convert all data to numerical, removing missing 4th down data.\")\n",
    "\n",
    "\n",
    "#Fill in a few missing records with the average\n",
    "df_passer_by_season_qb_nums_only = df_passer_by_season_qb_nums_only.fillna(df_passer_by_season_qb_nums_only.median())\n",
    "df_passer_by_season_qb_nums_only.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb252fd",
   "metadata": {},
   "source": [
    "## We're about to enter Data Science Land!\n",
    "### Let's import some data science packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2564f392",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import sklearn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC \n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import train_test_split as tts \n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7ff284",
   "metadata": {},
   "source": [
    "## Checking correlation between feature attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69cf0467",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = df_passer_by_season_qb_nums_only.corr().abs()\n",
    "corr_matrix\n",
    "high_corr_var=np.where(corr_matrix>0.8)\n",
    "high_corr_var=[(corr_matrix.index[x],corr_matrix.columns[y]) for x,y in zip(*high_corr_var) if x!=y and x<y]\n",
    "print(\"Here are the features that are highly correlated with each other:\")\n",
    "high_corr_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b7dee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(10, 8))\n",
    "corr = df_passer_by_season_qb_nums_only.corr()\n",
    "sns.heatmap(corr, mask=np.zeros_like(corr, dtype=np.bool), cmap=sns.diverging_palette(220, 10, as_cmap=True),\n",
    "            square=True, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e99d8d8",
   "metadata": {},
   "source": [
    "##  Let's standardize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ce8b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "train_data = scaler.fit_transform(df_passer_by_season_qb_nums_only)\n",
    "df_standardized = pd.DataFrame(train_data,index=train_data[:,0])\n",
    "df_standardized.columns = [\n",
    "'PASSER_PRO_BOWL',\n",
    "'PASS_RAT',\n",
    "'PASS_ATTEMPT',\n",
    "'COMP',\n",
    "'PASSER_DRAFT_SPOT',\n",
    "'PASSER_DRAFTED',\n",
    "'DEEP_PASS',\n",
    "'MED_PASS',\n",
    "'SHORT_PASS',\n",
    "'YDS',\n",
    "'TD',\n",
    "'INTRCPT',\n",
    "'PASSER_HGHT',\n",
    "'PASSER_AGE',\n",
    "'PASSER_CAREER_STRT',\n",
    "'TGT_HGHT',\n",
    "'TGT_WGHT',\n",
    "'TARGET_PRO_BOWL',\n",
    "'TGT_AGE',\n",
    "'TGT_DRAFT_SPOT',\n",
    "'TGT_DRAFTED',\n",
    "'TGT_CAREER_STRT',\n",
    "'TGT_FORTY',\n",
    "'TGT_VERT',\n",
    "'RB_TGT',\n",
    "'WR_TGT',\n",
    "'TE_TGT',\n",
    "'TRICK_PLAY',\n",
    "'FIRST_DOWN_CONVERSION',\n",
    "'RED_ZONE_ATTMPT',\n",
    "'RED_ZONE_QB_RAT',\n",
    "'FOURTH_DOWN_SUCCESS',\n",
    "'THIRD_DOWN_SUCCESS',\n",
    "'FOURTH_QTR_PASS_RAT',\n",
    "'SHOTGUN',\n",
    "'NO_HUDDLE',\n",
    "'DEF_PENALTY_DCLND',\n",
    "'SEAS',\n",
    "'GOOD_WEATH',\n",
    "'DOME_GAME',\n",
    "'TURF_FIELD',\n",
    "'POSTSEASON',\n",
    "'DIVISIONAL_APPEARANCE',\n",
    "'PASSER_PRO_BOWL_LAST_YEAR',\n",
    "'RUSH_YDS',\n",
    "'RUSH_SUCCESS',\n",
    "'RUSH_TD',\n",
    "'FUMBLE']\n",
    "\n",
    "df_standardized.head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ae1065",
   "metadata": {},
   "source": [
    "## Now let's rerun that correlation to see what changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509f7cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(10, 8))\n",
    "corr = df_standardized.corr()\n",
    "sns.heatmap(corr, mask=np.zeros_like(corr, dtype=np.bool), cmap=sns.diverging_palette(220, 10, as_cmap=True),\n",
    "            square=True, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73ed053",
   "metadata": {},
   "source": [
    "## Correlation looks the same after standardization\n",
    "\n",
    "Well. Turns out seaborn already does standardize your data (in the background) before running a correlation heatmap.\n",
    "That's ok, we still needed to standardize our data before we run it through any kind of predictive classifier.\n",
    "\n",
    "### Let's take a deeper look at the distribution of our data for each model feature\n",
    "Double click below to expand the chart and look at each individual feature's distribution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f65d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_standardized.plot.box(figsize=(80,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60de09f",
   "metadata": {},
   "source": [
    "## Let's officially define our features and target\n",
    "Until now, we've been looking at both of those combined in one dataframe, without ever calling out which is the target"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
