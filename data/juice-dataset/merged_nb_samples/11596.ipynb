{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab8c66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet18, resnet34\n",
    "\n",
    "arch = resnet34\n",
    "data = dataset.ImageClassifierData.from_paths(PATH, tfms=transforms.tfms_from_model(arch, sz))\n",
    "learn = conv_learner.ConvLearner.pretrained(arch, data, precompute=True)\n",
    "learn.fit(0.01, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7358d470",
   "metadata": {},
   "source": [
    "* The first time the model is run it downloads the model then precomputes activations, so will be slower.\n",
    "* You can see 3 lines of output, since we ran 3 epochs.\n",
    "* The 3 bits of data return for each input is, in order, as follows (00:21:05):\n",
    "  1. Value of the loss function on the training set, which is cross entropy loss (covered later).\n",
    "  2. Loss function on the val set.\n",
    "  3. Accuracy on the validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645d2182",
   "metadata": {},
   "source": [
    "##  00:22:30 - Fast AI Library\n",
    "\n",
    "* Deep learning known for needing lots of compute and lots of data. Not necessarily true.\n",
    "* Fast.AI library takes all of the best practise approachs they can find.\n",
    "  * When papers come out, they implement it in fast.ai.\n",
    "  * Automatically figures out the best way to handle things.\n",
    "* Sits on top of PyTorch.\n",
    "  * Tends to be more flexible than the popular Tensorflow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0638200f",
   "metadata": {},
   "source": [
    "## 00:24:12 - What does the model look like?\n",
    "\n",
    "* Can take a look at validation set \"dependant variable\" using the `val_y` attribute of `data`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee47959",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.val_y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb8e608",
   "metadata": {},
   "source": [
    "* We can confirm that cats is label 0 and dogs is label 1 by examining the order of the `classes` list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67916c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307161ab",
   "metadata": {},
   "source": [
    "* We can get predicitions for the validation set using the `predict` method of the `learn` object.\n",
    "  * Predictions are in log scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94907775",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_preds = learn.predict()\n",
    "log_preds.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d65984d7",
   "metadata": {},
   "source": [
    "* First ten predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02be90ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_preds[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b501bc",
   "metadata": {},
   "source": [
    "* Most models return the log of the predictions, not the probabilty, so you need to call `np.exp(log_preds)` to get actual probabilites."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147f8ffc",
   "metadata": {},
   "source": [
    "## 00:14:20 - Python version note\n",
    "\n",
    "* Course uses Python 3. Will get errors if using Python 2.\n",
    "* Important to switch to Python 3 - most libraries switching to it.\n",
    "\n",
    "## 00:15:05 - Extra steps if not using Fast.AI scripts\n",
    "\n",
    "* Need to download the dogs and cats set to the data directory as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b6380a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f749954",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f4eaf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd data && wget http://files.fast.ai/data/dogscats.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57476f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd data && unzip -q dogscats.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b9c540",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -l data/dogscats/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8bf502",
   "metadata": {},
   "source": [
    "## 00:15:40 - First look at cat pictures\n",
    "\n",
    "* Can use {some_var} to use Python variables in bash syntax:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3849a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls {PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67760af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls {PATH}valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428c387a",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = !ls {PATH}valid/cats | head\n",
    "files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2dd1be6",
   "metadata": {},
   "source": [
    "* Notes on training/validation sets:\n",
    "    * If you are not familiar with train and validation set, checkout [Fast.AI: Practical Machine Learning course](http://forums.fast.ai/t/another-treat-early-access-to-intro-to-machine-learning-videos/6826?source_topic_id=9285&source_topic_id=9594) (00:16:18).\n",
    "    * Fast.AI philosphy: learn things as you need them.\n",
    "\n",
    "* Common way to setup folders for image classification is to assign each image to a \"class\" (ie `dogs` or `cats`) folder.\n",
    "* Take a look at one image at random:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c1acfd",
   "metadata": {},
   "source": [
    "## 00:20:24 - Training our model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a37b73b",
   "metadata": {},
   "source": [
    "* Only 3 lines of code necessary to train a model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298039bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.argmax(log_preds, axis=1)  # Either 0 or 1\n",
    "probs = np.exp(log_preds[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe7fa69",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd0374d",
   "metadata": {},
   "outputs": [],
   "source": [
    "probs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd07c693",
   "metadata": {},
   "source": [
    "* Couple of useful plotting functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f416bc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_by_mask(mask):\n",
    "    return np.random.choice(np.where(mask)[0], 4, replace=False)\n",
    "\n",
    "def rand_by_correct(is_correct):\n",
    "    return rand_by_mask((preds == data.val_y) == is_correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28054823",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_val_with_title(idxs, title):\n",
    "    imgs = np.stack([data.val_ds[x][0] for x in idxs])\n",
    "    title_probs = [probs[x] for x in idxs]\n",
    "    print(title)\n",
    "    return plots(data.val_ds.denorm(imgs), rows=1, titles=title_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef4562d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plots(imgs, figsize=(12, 6), rows=1, titles=None):\n",
    "    f = plt.figure(figsize=figsize)\n",
    "    for i in range(len(imgs)):\n",
    "        sp = f.add_subplot(rows, len(imgs) // rows, i + 1)\n",
    "        sp.axis('Off')\n",
    "        if titles is not None:\n",
    "            sp.set_title(titles[i], fontsize=16)\n",
    "            plt.imshow(imgs[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6134684",
   "metadata": {},
   "source": [
    "## 00:26:10 - Evaluating predictions\n",
    "\n",
    "* Can firstly plot a few correct labels at random (0 is a cat, 1 is a dog):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63581f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_val_with_title(rand_by_correct(True), 'Correctly classified')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8d5a7a",
   "metadata": {},
   "source": [
    "* Can plot a few incorrect labels at random:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77384b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_val_with_title(rand_by_correct(False), 'Incorrectly classified')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b173c2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_by_mask(mask, mult):\n",
    "    idxs = np.where(mask)[0]\n",
    "    return idxs[np.argsort(mult * probs[idxs])[:4]]\n",
    "\n",
    "def most_by_correct(y, is_correct):\n",
    "    mult = -1 if (y==1)==is_correct else 1\n",
    "    return most_by_mask((preds == data.val_y)==is_correct & (data.val_y == y), mult)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0eadd12",
   "metadata": {},
   "source": [
    "* Plot the most incorrect cats (what cats are we most wrong about):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31146099",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_val_with_title(most_by_correct(0, False), 'Most incorrect cats')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da872c5",
   "metadata": {},
   "source": [
    "* Plot the most incorrect dogs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae99ebfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_val_with_title(most_by_correct(1, False), 'Most incorrect dogs')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0234f7a",
   "metadata": {},
   "source": [
    "* Plot the most correct cats:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa57ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_val_with_title(most_by_correct(0, True), 'Most correct cats')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d0e3c9",
   "metadata": {},
   "source": [
    "* Plot the most correct dogs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d493e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_val_with_title(most_by_correct(1, True), 'Most correct dogs')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff710c92",
   "metadata": {},
   "source": [
    "* Plot the most uncertain dogs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b804560",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_uncertain = np.argsort(np.abs(probs -0.5))[:4]\n",
    "plot_val_with_title(most_uncertain, 'Most uncertain predictions')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e569eb2f",
   "metadata": {},
   "source": [
    "## 00:27:45 - Why look at your data?\n",
    "\n",
    "* Always the first thing to do after training model: visualise what it built.\n",
    "* In this example, we get some insight into our dataset.\n",
    "  * Maybe need to use data augmentation? Will learn about it later."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e38330a6",
   "metadata": {},
   "source": [
    "## 00:30:55 - More on top-down approach\n",
    "\n",
    "* You just learn to train a neural network, but you don't know anything about what an NN is.\n",
    "* Gradually going to need to learn more and more problems, as you do so, you'll need more theory and more understanding of the library.\n",
    "* Sometimes called \"the whole game\", inspired by Harvard Professor David Perkins: more like how you'd learn baseball or music.\n",
    "  * Learn to play baseball, before you learn the physics of how a curve ball works."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb5c05d",
   "metadata": {},
   "source": [
    "## 00:33:50 - Course Structure\n",
    "\n",
    "<img src=\"https://i.gyazo.com/f82e1cd62b96c2a5ed86a3e98fa9fd83.gif\" width=\"400px\">\n",
    "\n",
    "* Start by using NN to look at image data.\n",
    "* Then structured data.\n",
    "  * Data that comes from spreadsheets or databases.\n",
    "* Then language data.\n",
    "  * Figure out sentiment of movie reviews.\n",
    "* Then collaborative filtering.\n",
    "  * Figure out how to recommend stuff to users based on what other users liked.\n",
    "\n",
    "* By the end of the course, you'll know how to create a world class:\n",
    "  * Image classifier.\n",
    "  * Structure data analysis program.\n",
    "  * Language classifier.\n",
    "  * Recommendation system.\n",
    "  \n",
    "## 00:35:45 - Plan\n",
    "\n",
    "* Lesson 1:\n",
    "  * Learn how to build an image classifier in a few lines of code.\n",
    "* Lesson 2:\n",
    "  * Learn about different image models.\n",
    "  * Detect multiple things in satellite images (multi-label classification problem).\n",
    "* Lesson 3:\n",
    "  * Structured data.\n",
    "* Lesson 4:\n",
    "  * NLP classifiers.\n",
    "* Lesson 5:\n",
    "  * Recommendation systems using collaborative filtering.\n",
    "  * Finding most similar user to another to find movies they might like.\n",
    "* Lesson 6\n",
    "  * RNNs.\n",
    "  * Generative text.\n",
    "* Lesson 7:\n",
    "  * Find heap maps in images - \"not just if it's a cat but where the cat is\".\n",
    "  * Implementing a ResNet from scratch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d94429",
   "metadata": {},
   "source": [
    "## 00:39:15 - Feedback from previous students\n",
    "  * \"I should have spent the majority of time actually running code from the class.\"\n",
    "    * \"See what comes in, see what comes out.\"\n",
    "  \n",
    "## 00:40:10 - Traditional ML advice compared to top-down approach\n",
    "  * Traditional ML advice differs from Jeremy's approach.\n",
    "    * Example from Hacker News where author who claims the  way to get into ML is to spend years learning maths, C/C++ then start learning ML: https://news.ycombinator.com/item?id=12901536.\n",
    "    \n",
    "## 00:42:42 - Image classifier uses\n",
    "\n",
    "* AlphaGo's recent achievments was made possible by image classification:\n",
    "  * Train of thousands of in-game Go boards with final win or loser labels.\n",
    "* Earlier student got a patent for anti-fraud software by looking at pictures of user's mouse paths to predict fraudulent behaviour.\n",
    "\n",
    "## 00:44:34 - Deep Learning overview\n",
    "\n",
    "* Deep learning is a form of Machine Learning.\n",
    "* Machine learning was invented by [Arthur Samuel](https://en.wikipedia.org/wiki/Arthur_Samuel) who build a system to play checkers.\n",
    "  * Kind of reinforcement learning.\n",
    "  * Arthur predicted that programs would be written by machines, though it's only happening now.\n",
    "    * Traditional ML used to be very hard.\n",
    "* Andy Beck research: worked with pathologists to build features to help predict survival of cells.\n",
    "  * Features were passed into logistic regression to predict survival.\n",
    "  * Worked well, but not flexible; required lots of domain expertise.\n",
    "* What you want out of an algorithm: \n",
    "    1. Infinitely flexible function.\n",
    "    2. All-purpose parameter fitting.\n",
    "    3. Fast and scalable.\n",
    "\n",
    "## 00:48:45 - Neural Networks and the Universal Approximation Theorum\n",
    "\n",
    "* Underlying function that deep learning uses: \"a neural network\".\n",
    "  * Consists of a number of linear layers, interspersed with a number of non-layer layer. \n",
    "    * Gives you a \"universal approximation theorum\".\n",
    "    \n",
    "<img src=\"https://i.gyazo.com/f53030539f06b0697f465b840a05d997.gif\" width=\"400px\">\n",
    "  \n",
    "* Universal approximation theorum: this kind of function can solve any given problem to an arbitrary accuracy as long as it has enough parameters.\n",
    "* Need a way to fit the parameters for said flexible function. Enter Gradient Descent.\n",
    "\n",
    "## 00:49:45 - Gradient Descent\n",
    "\n",
    "* Finds parameters over time that finds parameters that lower some loss function.\n",
    "\n",
    "<img src=\"https://i.gyazo.com/89dad90ea025e69be3feb02e6fd42c09.gif\" width=\"400px\">\n",
    "\n",
    "* GPUs have made finishing gradient descent in a reasonable amount of time possible.\n",
    "* GTX 1080i is 10x faster than faster CPU and costs about \\$700, as opposed to \\$4115.\n",
    "\n",
    "From https://www.karlrupp.net/2013/06/cpu-gpu-and-mic-hardware-characteristics-over-time/\n",
    "\n",
    "<img src=\"https://www.karlrupp.net/wp-content/uploads/2013/06/tdp.png\" width=\"600px\">\n",
    "\n",
    "* Standard neural network do support the universal approximation theorum, they require an exponentially increasing number of parameters.\n",
    "  * Solution: add multiple hidden layers to get super linear scaling. Enter: Deep Learning.\n",
    "  \n",
    "## 00:53:58 - Examples of Deep Learning applications\n",
    "\n",
    "* Started investing in Deep Learning in 2012 (hired Geoffrey Hinton).\n",
    "  * Now used in almost all Google products.\n",
    "* Examples of Deep Learning in products:\n",
    "  * Google Inbox recommending responses.\n",
    "  * Skype translating language in real time.\n",
    "* Paper: [Semantic Style Transfer and Turning Two-Bit Doodles into Fine Artworks](https://arxiv.org/abs/1603.01768).\n",
    "* Detecting cancer using CNNs.\n",
    "* Lots of other examples (00:58:50).\n",
    "\n",
    "## 00:59:14 - Understanding CNNs\n",
    "\n",
    "* Key piece of CNN: convolution.\n",
    "  * Great example of a single convolution: http://setosa.io/ev/image-kernels/\n",
    "  * Basically, applying a filter over an image.\n",
    "  * Neural network actually learns the most important set of filters for your problem.\n",
    "  * Kernel size refers to the dimensions of the filter. In deep learning, it's usually 3x3.\n",
    "* Add non-linear layer.\n",
    "  * Non-linearity: takes an input value and turns it into some other value in a non-linear way.\n",
    "    * Sigmoid.\n",
    "    * Relu: most common type of activation.\n",
    "      * Simply replaces negative values with 0: ``max(0, value)``\n",
    "* Need a way to set the parameters: stochastic gradient descent.\n",
    "  * Basic idea to fit a function:\n",
    "    1. Start with some point at random.\n",
    "    2. Go a little bit to the left and to the right to find out which way is down.\n",
    "      * In other words: you're calculating the derivative of the function at that point: $\\frac{dy}{dx}$\n",
    "    3. Now take a small step in the downwards direction by updating the guess as follows:\n",
    "      $X_{n+1} = X_n + \\frac{dy}{dx} * \\alpha$\n",
    "      * Need to ensure $\\alpha$ aka the \"learning rate\" is a small enough number so you aren't jumping over the minima.\n",
    "* What happens when you combine enough kernels, with enough layers and the SGD algorithm?\n",
    "\n",
    "## 01:08:22 - Visualizing Convolutional Networks\n",
    "\n",
    "* Paper by Matthew D. Zeiler: https://arxiv.org/abs/1311.2901\n",
    "  * For each image, what are examples of filters that activate them?\n",
    "  * Found that earlier layers tend to find things like shapes and textures.\n",
    "  * By 3rd layer, started to find things like text, human faces.\n",
    "  * By the 5th layer, able to recognise animals eyes, dog faces etc.\n",
    "  \n",
    "## 01:11:40 - Setting the learning rate\n",
    "\n",
    "* Couple of numbers passed to the `learn.fit` method. The first is the learning rate.\n",
    "  * How quickly should you walk toward the minima?\n",
    "  * Setting the number well is very important:\n",
    "    * too high = over step the minimia.\n",
    "    * too low = takes too long to converge.\n",
    "* Good idea for setting the learning rate from paper [Cyclical Learning Rates for Training Neural Networks](https://arxiv.org/abs/1506.01186)\n",
    "  * Start by taking a tiny step in the gradient direction.\n",
    "  * Then, take a slightly larger step.\n",
    "  * Repeat until the loss gets worse.\n",
    "  * Find the point where it's dropping the fastest.\n",
    "* Plotting the learning rate against the loss:\n",
    "\n",
    "<img src=\"https://i.gyazo.com/724c9b02059bb7e0822a15500197cc05.gif\">\n",
    "  \n",
    "* Learning rate scheduler is available in Fast.AI, as the lr_find method on a ConvLearner:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d42ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = plt.imread(f'{PATH}valid/cats/{files[0]}')\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d422a9bc",
   "metadata": {},
   "source": [
    "* Note that we're using [Python 3's new f-string syntax](https://cito.github.io/blog/f-strings/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b159cd10",
   "metadata": {},
   "source": [
    "* Mainly interested in underlying data. Let's look at the shape:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebbb04b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7f32e1",
   "metadata": {},
   "source": [
    "* Shape is a 3-dimensional array, also called a \"rank 3 tensor\".\n",
    "* Here are the first 4 rows and columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f38f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "img[:4, :4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ebbf8aa",
   "metadata": {},
   "source": [
    "* Basic project idea: take those numbers from the image and use them to predict whether they represent a cat or a dog based on lots of pictures of cats and dogs (00:19:45).\n",
    "* When the Kaggle competition for cats and dogs was first introduced in 2012, the state of the art was around 80% accuracy."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
