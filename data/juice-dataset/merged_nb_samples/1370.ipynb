{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "949e90b5",
   "metadata": {},
   "source": [
    "Importing pandas library\n",
    "\n",
    "You need to import or load the Pandas library first in order to use it. By \"Importing a library\", it means loading it into the memory and then you can use it. Run the following code to import pandas library:\n",
    "\n",
    "\n",
    "The \"pd\" is an alias or abbreviation which will be used as a shortcut to access or call pandas functions. To access the functions from pandas library, you just need to type pd.function instead of  pandas.function every time you need to apply it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a93594",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755a8d0e",
   "metadata": {},
   "source": [
    "Importing Dataset\n",
    "\n",
    "To read or import data from CSV file, you can use read_csv() function. In the function, you need to specify the file location of your CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee20983",
   "metadata": {},
   "outputs": [],
   "source": [
    "income = pd.read_csv(\"income.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb110e27",
   "metadata": {},
   "source": [
    "Get Variable Names\n",
    "\n",
    "By using income.columnscommand, you can fetch the names of variables of a data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93eaa2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "income.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e71c54",
   "metadata": {},
   "source": [
    "income.columns[0:2] returns first two column names 'Index', 'State'. In python, indexing starts from 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2197089",
   "metadata": {},
   "outputs": [],
   "source": [
    "income.columns[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e3a7d1",
   "metadata": {},
   "source": [
    "Knowing the Variable types\n",
    "\n",
    "You can use the dataFrameName.dtypes command to extract the information of types of variables stored in the data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9aa24a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "income.dtypes "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a78a330",
   "metadata": {},
   "source": [
    "Here 'object' means strings or character variables. 'int64' refers to numeric variables (without decimals).\n",
    "\n",
    "To see the variable type of one variable (let's say \"State\") instead of all the variables, you can use the command below -"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8bb202",
   "metadata": {},
   "source": [
    "Creating a frequency distribution\n",
    "\n",
    "income.Index selects the 'Index' column of 'income' dataset and value_counts( ) creates a frequency distribution. By default ascending = False i.e. it will show the 'Index' having the maximum frequency on the top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1afedd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "income.Index.value_counts(ascending = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7f99c9",
   "metadata": {},
   "source": [
    "To draw the samples\n",
    "income.sample( ) is used to draw random samples from the dataset containing all the columns. Here n = 5 depicts we need 5 columns and frac = 0.1 tells that we need 10 percent of the data as my sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae94e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "income.sample(n = 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24cfbc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "income.sample(frac = 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2caae0",
   "metadata": {},
   "source": [
    "Selecting only a few of the columns\n",
    "To select only a specific columns we use either loc[ ] or iloc[ ] commands. The index or columns to be selected are passed as lists. \"Index\":\"Y2008\" denotes the that all the columns from Index to Y2008 are to be selected.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42631a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "income.loc[:,[\"Index\",\"State\",\"Y2008\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f9625d",
   "metadata": {},
   "outputs": [],
   "source": [
    "income.loc[:,\"Index\":\"Y2008\"]  #Selecting consecutive columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ddd1329",
   "metadata": {},
   "outputs": [],
   "source": [
    "#In the above command both Index and Y2008 are included.\n",
    "income.iloc[:,0:5]  #Columns from 1 to 5 are included. 6th column not included"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c25ab57",
   "metadata": {},
   "source": [
    "The difference between loc and iloc is that loc requires the column(rows) names to be selected while iloc requires the column(rows) indices (position).\n",
    "\n",
    "You can also use the following syntax to select specific variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1daabfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "income[[\"Index\",\"State\",\"Y2008\"]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb4d5265",
   "metadata": {},
   "source": [
    "Renaming the variables\n",
    "We create a dataframe 'data' for information of people and their respective zodiac signs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dcb2e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame({\"A\" : [\"John\",\"Mary\",\"Julia\",\"Kenny\",\"Henry\"], \"B\" : [\"Libra\",\"Capricorn\",\"Aries\",\"Scorpio\",\"Aquarius\"]})\n",
    "data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a12b31",
   "metadata": {},
   "source": [
    "If all the columns are to be renamed then we can use data.columns and assign the list of new column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9cf639",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Renaming all the variables.\n",
    "data.columns = ['Names','Zodiac Signs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf4c3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a92964",
   "metadata": {},
   "source": [
    "If only some of the variables are to be renamed then we can use rename( ) function where the new names are passed in the form of a dictionary.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c68a7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Renaming only some of the variables.\n",
    "data.rename(columns = {\"Names\":\"Cust_Name\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3f97bb",
   "metadata": {},
   "source": [
    "By default in pandas inplace = False which means that no changes are made in the original dataset. Thus if we wish to alter the original dataset we need to define inplace = True.\n",
    "\n",
    "Suppose we want to replace only a particular character in the list of the column names then we can use str.replace( ) function. For example, renaming the variables which contain \"Y\" as \"Year\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df61714b",
   "metadata": {},
   "outputs": [],
   "source": [
    "income.columns = income.columns.str.replace('Y' , 'Year ')\n",
    "income.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d22fa97",
   "metadata": {},
   "source": [
    "Setting one column in the data frame as the index\n",
    "Using set_index(\"column name\") we can set the indices as that column and that column gets removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7e138d",
   "metadata": {},
   "outputs": [],
   "source": [
    "income.sort_values([\"Index\",\"Year 2002\"]) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d926006c",
   "metadata": {},
   "source": [
    "Create new variables\n",
    "Using eval( ) arithmetic operations on various columns can be carried out i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ffde63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#income[\"difference\"] = income.Y2008-income.Y2009\n",
    "\n",
    "#Alternatively\n",
    "income[\"difference\"] = income['Year 2008']-income['Year 2009']\n",
    "income.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1661318e",
   "metadata": {},
   "outputs": [],
   "source": [
    "income.ratio = income['Year 2008']/income['Year 2009']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e761acb0",
   "metadata": {},
   "source": [
    "The above command does not work, thus to create new columns we need to use square brackets.\n",
    "We can also use assign( ) function but this command does not make changes in the original data as there is no inplace parameter. Hence we need to save it in a new dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a80a198",
   "metadata": {},
   "outputs": [],
   "source": [
    "income['ratio'] = income['Year 2008']/income['Year 2009']\n",
    "income.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb00ed99",
   "metadata": {},
   "source": [
    "Finding Descriptive Statistics\n",
    "describe( ) is used to find some statistics like mean,minimum, quartiles etc. for numeric variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ae774f",
   "metadata": {},
   "outputs": [],
   "source": [
    "income.describe() #for numeric variables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7435edd9",
   "metadata": {},
   "source": [
    "To find the total count, maximum occuring string and its frequency we write include = ['object']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9172bfad",
   "metadata": {},
   "outputs": [],
   "source": [
    "income.describe(include = ['object'])  #Only for strings / objects\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c20426",
   "metadata": {},
   "outputs": [],
   "source": [
    "income.columns = income.columns.str.replace('Year ' , 'Y')\n",
    "income.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dddb9af",
   "metadata": {},
   "source": [
    "Mean, median, maximum and minimum can be obtained for a particular column(s) as:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391e19cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "income.set_index(\"Index\",inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db5417a",
   "metadata": {},
   "outputs": [],
   "source": [
    "income.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1bff2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note that the indices have changed and Index column is now no more a column\n",
    "income.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3cd2021",
   "metadata": {},
   "outputs": [],
   "source": [
    "income.reset_index(inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c2fc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "income.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b10918b",
   "metadata": {},
   "source": [
    "reset_index( ) tells us that one should use the by default indices.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3dc443",
   "metadata": {},
   "source": [
    "Removing the columns and rows\n",
    "To drop a column we use drop( ) where the first argument is a list of columns to be removed. \n",
    "\n",
    "By default axis = 0 which means the operation should take place horizontally, row wise. To remove a column we need to set axis = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9663c0",
   "metadata": {},
   "source": [
    " _get_numeric_data also provides utility to select the numeric columns only.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff626016",
   "metadata": {},
   "outputs": [],
   "source": [
    "data3 = iris._get_numeric_data()\n",
    "data3.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8f43b3",
   "metadata": {},
   "source": [
    "For selecting categorical variables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7be5d5b",
   "metadata": {},
   "source": [
    "\n",
    "Concatenating\n",
    "We create 2 dataframes containing the details of the students:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f68ba9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "students = pd.DataFrame({'Names': ['John','Mary','Henry','Augustus','Kenny'],\n",
    "                         'Zodiac Signs': ['Aquarius','Libra','Gemini','Pisces','Virgo']})\n",
    "students2 = pd.DataFrame({'Names': ['John','Mary','Henry','Augustus','Kenny'],\n",
    "                          'Marks' : [50,81,98,25,35]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cbbe86d",
   "metadata": {},
   "source": [
    " using pd.concat( ) function we can join the 2 dataframes:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef295b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([students,students2])  #by default axis = 0\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "facb0d69",
   "metadata": {},
   "source": [
    "By default axis = 0 thus the new dataframe will be added row-wise. If a column is not present then in one of the dataframes it creates NaNs. To join column wise we set axis = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60332405",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([students,students2],axis = 1)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5224e15",
   "metadata": {},
   "source": [
    "Using append function we can join the dataframes row-wise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4043f2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "students.append(students2)  #for rows\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6ba255",
   "metadata": {},
   "source": [
    "Alternatively we can create a dictionary of the two data frames and can use pd.concat to join the dataframes row wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13354669",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = {'x': students, 'y': students2}\n",
    "result = pd.concat(classes)\n",
    "result "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b15ad81",
   "metadata": {},
   "source": [
    "Merging or joining on the basis of common variable.\n",
    "We take 2 dataframes with different number of observations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e8022d",
   "metadata": {},
   "outputs": [],
   "source": [
    "students = pd.DataFrame({'Names': ['John','Mary','Henry','Maria'],\n",
    "                         'Zodiac Signs': ['Aquarius','Libra','Gemini','Capricorn']})\n",
    "students2 = pd.DataFrame({'Names': ['John','Mary','Henry','Augustus','Kenny'],\n",
    "                          'Marks' : [50,81,98,25,35]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c2fdea",
   "metadata": {},
   "source": [
    "Using pd.merge we can join the two dataframes. on = 'Names' denotes the common variable on the basis of which the dataframes are to be combined is 'Names'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1de37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.merge(students, students2, on='Names')  #it only takes intersections\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63da37d6",
   "metadata": {},
   "source": [
    "By default how = \"inner\" thus it takes only the common elements in both the dataframes. If you want all the elements in both the dataframes set how = \"outer\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c71a78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.merge(students, students2, on='Names',how = \"outer\")  #it only takes unions\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0642a8d",
   "metadata": {},
   "source": [
    "To take only intersections and all the values in left df set how = 'left'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b61802e",
   "metadata": {},
   "source": [
    "Calculating the percentiles.\n",
    "Various quantiles can be obtained by using quantile( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193283b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.quantile(0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7836c147",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.quantile([0.1,0.2,0.5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ed18e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.quantile(0.55)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ab54a6",
   "metadata": {},
   "source": [
    "if else in Python\n",
    "We create a new dataframe of students' name and their respective zodiac signs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbeefe5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "students = pd.DataFrame({'Names': ['John','Mary','Henry','Augustus','Kenny'],\n",
    "                         'Zodiac Signs': ['Aquarius','Libra','Gemini','Pisces','Virgo']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406e1351",
   "metadata": {},
   "outputs": [],
   "source": [
    "def name(row):\n",
    "    if row[\"Names\"] in [\"John\",\"Henry\"]:\n",
    "        return \"yes\"\n",
    "    else:\n",
    "        return \"no\"\n",
    "\n",
    "students['flag'] = students.apply(name, axis=1)\n",
    "students"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fcc6e73",
   "metadata": {},
   "source": [
    "Functions in python are defined using the block keyword def , followed with the function's name as the block's name. apply( ) function applies function along rows or columns of dataframe.\n",
    "\n",
    "Note :If using simple 'if else' we need to take care of the indentation . Python does not involve curly braces for the loops and if else.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cfbd8c3",
   "metadata": {},
   "source": [
    "Alternatively, By importing numpy we can use np.where. The first argument is the condition to be evaluated, 2nd argument is the value if condition is True and last argument defines the value if the condition evaluated returns False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c739f8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "students['flag'] = np.where(students['Names'].isin(['John','Henry']), 'yes', 'no')\n",
    "students"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92617f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mname(row):\n",
    "    if row[\"Names\"] == \"John\" and row[\"Zodiac Signs\"] == \"Aquarius\" :\n",
    "        return \"yellow\"\n",
    "    elif row[\"Names\"] == \"Mary\" and row[\"Zodiac Signs\"] == \"Libra\" :\n",
    "        return \"blue\"\n",
    "    elif row[\"Zodiac Signs\"] == \"Pisces\" :\n",
    "        return \"blue\"\n",
    "    else:\n",
    "        return \"black\"\n",
    "\n",
    "students['color'] = students.apply(mname, axis=1)\n",
    "students"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345ab594",
   "metadata": {},
   "source": [
    "We create a list of conditions and their respective values if evaluated True and use np.select where default value is the value if all the conditions is False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ff1c1f",
   "metadata": {},
   "source": [
    "crops.cost.isnull() firstly subsets the 'cost' from the dataframe and returns a logical vector with isnull()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b24f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "crops[crops.cost.isnull()] #shows the rows with NAs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6e73e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "crops[crops.cost.isnull()].Crop #shows the rows with NAs in crops.Crop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9f5382",
   "metadata": {},
   "outputs": [],
   "source": [
    "crops[crops.cost.notnull()].Crop #shows the rows without NAs in crops.Crop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c99e71",
   "metadata": {},
   "source": [
    "To drop all the rows which have missing values in any rows we use dropna(how = \"any\") . By default inplace = False . If how = \"all\" means drop a row if all the elements in that row are missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf613a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "crops.dropna(how = \"any\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3455af26",
   "metadata": {},
   "outputs": [],
   "source": [
    "crops.dropna(how = \"all\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7186fd76",
   "metadata": {},
   "source": [
    "To remove NaNs if any of 'Yield' or'cost' are missing we use the subset parameter and pass a list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb2bfea",
   "metadata": {},
   "outputs": [],
   "source": [
    "crops.dropna(subset = ['Yield',\"cost\"],how = 'any').shape\n",
    "crops.dropna(subset = ['Yield',\"cost\"],how = 'all').shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93bf9c49",
   "metadata": {},
   "source": [
    "Replacing the missing values by \"UNKNOWN\" sub attribute in Column name.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b747c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "crops['cost'].fillna(value =crops.cost.mean(),inplace = True)\n",
    "crops"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c44ae9",
   "metadata": {},
   "source": [
    "Dealing with duplicates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee84485f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame({\"Items\" : [\"TV\",\"Washing Machine\",\"Mobile\",\"TV\",\"TV\",\"Washing Machine\"], \"Price\" : [10000,50000,20000,10000,10000,40000]})\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64578d82",
   "metadata": {},
   "source": [
    "duplicated() returns a logical vector returning True when encounters duplicated.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f64666c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[data.duplicated(),:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ffa25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[data.duplicated(keep = \"first\"),:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bbe7320",
   "metadata": {},
   "source": [
    "By default keep = 'first' i.e. the first occurence is considered a unique value and its repetitions are considered as duplicates.\n",
    "If keep = \"last\" the last occurence is considered a unique value and all its repetitions are considered as duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3995e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "income.drop('Index',axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7034aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Alternatively\n",
    "income.drop(\"Index\",axis = \"columns\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a5b61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "income.drop(['Index','State'],axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b529801b",
   "metadata": {},
   "outputs": [],
   "source": [
    "income.drop(0,axis = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5e09cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "income.drop(0,axis = \"index\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f888f29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "income.drop([0,1,2,3],axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3116e5",
   "metadata": {},
   "source": [
    "Also inplace = False by default thus no alterations are made in the original dataset.  axis = \"columns\"  and axis = \"index\" means the column and row(index) should be removed respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319555e8",
   "metadata": {},
   "source": [
    "Sorting the data\n",
    "To sort the data sort_values( ) function is deployed. By default inplace = False and ascending = True.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce15493",
   "metadata": {},
   "outputs": [],
   "source": [
    "income.sort_values(\"State\",ascending = False)\n",
    "income.sort_values(\"State\",ascending = False,inplace = True)\n",
    "income['Year 2006'].sort_values() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8623134f",
   "metadata": {},
   "source": [
    "We have got duplicated for Index thus we need to sort the dataframe firstly by Index and then for each particular index we sort the values by Y2002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f10911",
   "metadata": {},
   "outputs": [],
   "source": [
    "income.Y2008.mean()\n",
    "income.Y2008.median()\n",
    "income.Y2008.min()\n",
    "income.loc[:,[\"Y2002\",\"Y2008\"]].max()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b525e5",
   "metadata": {},
   "source": [
    "Groupby function\n",
    "To group the data by a categorical variable we use groupby( ) function and hence we can do the operations on each category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150bde5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "income.groupby(\"Index\").Y2008.min()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2918f092",
   "metadata": {},
   "outputs": [],
   "source": [
    "income.groupby(\"Index\")[\"Y2008\",\"Y2010\"].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070bd3b3",
   "metadata": {},
   "source": [
    "agg( ) function is used to find all the functions for a given variable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daddde8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "income.groupby(\"Index\").Y2002.agg([\"count\",\"min\",\"max\",\"mean\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e31b136",
   "metadata": {},
   "outputs": [],
   "source": [
    "income.groupby(\"Index\")[\"Y2002\",\"Y2003\"].agg([\"count\",\"min\",\"max\",\"mean\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c227ed0",
   "metadata": {},
   "source": [
    "The following command finds minimum and maximum values for Y2002 and only mean for Y2003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46f7522",
   "metadata": {},
   "outputs": [],
   "source": [
    "income.groupby(\"Index\").agg({\"Y2002\": [\"min\",\"max\"],\"Y2003\" : \"mean\"})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc01ff85",
   "metadata": {},
   "source": [
    "Filtering\n",
    "To filter only those rows which have Index as \"A\" we write:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405cacc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "income[income.Index == \"A\"]\n",
    "\n",
    "#Alternatively\n",
    "income.loc[income.Index == \"A\",:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da47e99",
   "metadata": {},
   "source": [
    "To select the States having Index as \"A\":\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc79ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "income.loc[income.Index == \"A\",:].State"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42e0bb8",
   "metadata": {},
   "source": [
    "To filter the rows with Index as \"A\" and income for 2002 > 1500000\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab14b6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "income.loc[(income.Index == \"A\") & (income.Y2002 > 1500000),:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ca39b7",
   "metadata": {},
   "source": [
    "To filter the rows with index either \"A\" or \"W\", we can use isin( ) function:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc194b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "income.loc[(income.Index == \"A\") | (income.Index == \"W\"),:]\n",
    "\n",
    "#Alternatively.\n",
    "income.loc[income.Index.isin([\"A\",\"W\"]),:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e0ae597",
   "metadata": {},
   "source": [
    "Alternatively we can use query( ) function and write our filtering criteria:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b82662",
   "metadata": {},
   "outputs": [],
   "source": [
    "income.query('Y2002>1700000 & Y2003 > 1500000')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a317d4",
   "metadata": {},
   "source": [
    "Dealing with missing values\n",
    "We create a new dataframe named 'crops' and to create a NaN value we use np.nan by importing numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf66a3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "mydata = {'Crop': ['Rice', 'Wheat', 'Barley', 'Maize'],\n",
    "        'Yield': [1010, 1025.2, 1404.2, 1251.7],\n",
    "        'cost' : [102, np.nan, 20, 68]}\n",
    "crops = pd.DataFrame(mydata)\n",
    "crops"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e29ec8",
   "metadata": {},
   "source": [
    "isnull( ) returns True and notnull( ) returns False if the value is NaN.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5afb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#crops.isnull()  #same as is.na in R\n",
    "#crops.notnull()  #opposite of previous command.\n",
    "crops.isnull().sum()  #No. of missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc754ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[data.duplicated(keep = \"last\"),:] #last entries are not there,indices have changed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2d91dc",
   "metadata": {},
   "source": [
    "if keep = \"False\" then it considers all the occurences of the repeated observations as duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb38399",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[data.duplicated(keep = False),:]  #all the duplicates, including unique are shown."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259a3840",
   "metadata": {},
   "source": [
    "To drop the duplicates drop_duplicates is used with default inplace = False, keep = 'first' or 'last' or 'False' have the respective meanings as in duplicated( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854e2b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop_duplicates(keep = \"first\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13747a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop_duplicates(keep = \"last\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b4ab27",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop_duplicates(keep = False,inplace = True)  #by default inplace = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d3b947",
   "metadata": {},
   "source": [
    "Creating dummies\n",
    "Now we will consider the iris dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18208e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = pd.read_csv(\"https://sites.google.com/site/pocketecoworld/iris.csv\")\n",
    "iris.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58361217",
   "metadata": {},
   "source": [
    "map( ) function is used to match the values and replace them in the new series automatically created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a18c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.get_dummies(iris.Species,prefix = \"Species\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17c7d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.get_dummies(iris.Species,prefix = \"Species\").iloc[:,0:1]  #1 is not included\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f1285d",
   "metadata": {},
   "outputs": [],
   "source": [
    "species_dummies = pd.get_dummies(iris.Species,prefix = \"Species\").iloc[:,0:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd7a320",
   "metadata": {},
   "source": [
    "with concat( ) function we can join multiple series or dataframes. axis = 1 denotes that they should be joined columnwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c2037a",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = pd.concat([iris,species_dummies],axis = 1)\n",
    "iris.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a2b335",
   "metadata": {},
   "source": [
    "It is usual that for a variable with 'n' categories we creat 'n-1' dummies, thus to drop the first 'dummy' column we write drop_first = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273bb7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.get_dummies(iris,columns = [\"Species\"],drop_first = True).head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88612543",
   "metadata": {},
   "source": [
    "Ranking\n",
    " To create a dataframe of all the ranks we use rank( )\n",
    " \n",
    " Ranking by a specific variable\n",
    "Suppose we want to rank the Sepal.Length for different species in ascending order:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac55b202",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "iris['Rank'] = iris.sort_values(['Sepal.Length'], ascending=[True]).groupby(['Species']).cumcount() + 1\n",
    "iris.head( )\n",
    "\n",
    "#Alternatively\n",
    "iris['Rank2'] = iris['Sepal.Length'].groupby(iris[\"Species\"]).rank(ascending=1)\n",
    "iris.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca0874a",
   "metadata": {},
   "source": [
    "Calculating the Cumulative sum\n",
    "Using cumsum( ) function we can obtain the cu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc96439",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris['cum_sum'] = iris[\"Sepal.Length\"].cumsum()\n",
    "iris.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23bf256c",
   "metadata": {},
   "source": [
    "Cumulative sum by a variable\n",
    "To find the cumulative sum of sepal lengths for different species we use groupby( ) and then use cumsum( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9656f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris[\"cumsum2\"] = iris.groupby([\"Species\"])[\"Sepal.Length\"].cumsum()\n",
    "iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d62ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions = [\n",
    "    (students['Names'] == 'John') & (students['Zodiac Signs'] == 'Aquarius'),\n",
    "    (students['Names'] == 'Mary') & (students['Zodiac Signs'] == 'Libra'),\n",
    "    (students['Zodiac Signs'] == 'Pisces')]\n",
    "choices = ['yellow', 'blue', 'purple']\n",
    "students['color'] = np.select(conditions, choices, default='black')\n",
    "students"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2826c7",
   "metadata": {},
   "source": [
    "Select numeric or categorical columns only\n",
    "To include numeric columns we use select_dtypes( ) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac896f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "income.loc[income.Index == \"A\",\"State\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2e0bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(income.shape[0])\n",
    "print(income.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9012243e",
   "metadata": {},
   "source": [
    "To view only some of the rows\n",
    "\n",
    "By default head( ) shows first 5 rows. If we want to see a specific number of rows we can mention it in the parenthesis. Similarly tail( ) function shows last 5 rows by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f98dee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "income.head(2) #shows first 2 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebf0b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "income.tail() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf6b89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "income.tail(2) #shows last 2 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32bcf573",
   "metadata": {},
   "source": [
    "Alternatively, any of the following commands can be used to fetch first five rows.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b8d1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "income[0:5] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf8b04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "income.iloc[1:4,0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1f7b01",
   "metadata": {},
   "source": [
    "Extract Unique Values\n",
    "\n",
    "The unique() function shows the unique levels or categories in the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d19a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "income.Index.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13916ec",
   "metadata": {},
   "source": [
    "The nunique( ) shows the number of unique values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55ff4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "income.Index.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f54da5",
   "metadata": {},
   "source": [
    "It returns 19 as index column contains distinct 19 values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a1e9fe",
   "metadata": {},
   "source": [
    "Generate Cross Tab\n",
    "\n",
    "pd.crosstab( ) is used to create a bivariate frequency distribution. Here the bivariate frequency distribution is between Index and State columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1473ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(income.Index,income.State)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f612450d",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris[\"setosa\"] = iris.Species.map({\"setosa\" : 1,\"versicolor\":0, \"virginica\" : 0})\n",
    "iris.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c36fbf",
   "metadata": {},
   "source": [
    "To create dummies get_dummies( ) is used. iris.Species.prefix = \"Species\" adds a prefix ' Species' to the new series created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740e0a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "income['State'].dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d24c87d",
   "metadata": {},
   "source": [
    "It returns dtype('O'). In this case, 'O' refers to object i.e. type of variable as character.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaac9a24",
   "metadata": {},
   "source": [
    "Changing the data types\n",
    "\n",
    "Y2008 is an integer. Suppose we want to convert it to float (numeric variable with decimals) we can write:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c30175f",
   "metadata": {},
   "outputs": [],
   "source": [
    "income.Y2008 = income.Y2008.astype(float)\n",
    "income.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52273e6",
   "metadata": {},
   "source": [
    "To view the dimensions or shape of the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8afcdffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "income.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1b2eb2",
   "metadata": {},
   "source": [
    "51 is the number of rows and 16 is the number of columns.\n",
    "\n",
    "You can also use shape[0] to see the number of rows (similar to nrow() in R) and shape[1] for number of columns (similar to ncol() in R). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afcf24d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = iris.select_dtypes(include=[np.number])\n",
    "data1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124326f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.merge(students, students2, on='Names',how = \"left\")\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777b55ea",
   "metadata": {},
   "source": [
    "Similarly how = 'right' takes only intersections and all the values in right df.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
