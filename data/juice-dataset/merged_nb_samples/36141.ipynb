{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b51c96a",
   "metadata": {},
   "source": [
    "# Predict Blood Donations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "febb4004",
   "metadata": {},
   "source": [
    "https://www.drivendata.org/competitions/2/warm-up-predict-blood-donations/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce3dc7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Jupyter Specific\n",
    "%matplotlib inline\n",
    "from IPython.display import display\n",
    "\n",
    "# Import plotly and enable offline mode\n",
    "import plotly.offline as py\n",
    "import plotly.graph_objs as go\n",
    "import plotly.figure_factory as ff\n",
    "py.init_notebook_mode(connected=True)\n",
    "\n",
    "# Machine Learning Library \n",
    "from theano.sandbox import cuda\n",
    "import theano\n",
    "import keras\n",
    "# from keras import backend as K\n",
    "# from keras.utils.data_utils import get_file\n",
    "# from keras.utils import np_utils\n",
    "# from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential, Model\n",
    "# from keras.layers import Input, Embedding, Reshape, merge, LSTM, Bidirectional\n",
    "from keras.layers import TimeDistributed, Activation, SimpleRNN, GRU\n",
    "from keras.layers.core import Flatten, Dense, Dropout, Lambda\n",
    "# from keras.regularizers import l2, activity_l2, l1, activity_l1\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import SGD, RMSprop, Adam\n",
    "# from keras.utils.layer_utils import layer_from_config\n",
    "# from keras.metrics import categorical_crossentropy, categorical_accuracy\n",
    "# from keras.layers.convolutional import *\n",
    "# from keras.preprocessing import image, sequence\n",
    "# from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2334e2",
   "metadata": {},
   "source": [
    "# Grab Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6fa7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDir = './data/BloodDonations/'\n",
    "%mkdir -p $dataDir\n",
    "\n",
    "dataDefintions = [\n",
    "    ('trainingData.csv', 'https://s3.amazonaws.com/drivendata/data/2/public/9db113a1-cdbe-4b1c-98c2-11590f124dd8.csv'),\n",
    "    ('testData.csv', 'https://s3.amazonaws.com/drivendata/data/2/public/5c9fa979-5a84-45d6-93b9-543d1a0efc41.csv'),\n",
    "    #('sampleSubmission', 'https://s3.amazonaws.com/drivendata/data/2/public/BloodDonationSubmissionFormat.csv')\n",
    "]\n",
    "\n",
    "def getFromCSV(filename, url, cacheDir = ''):\n",
    "    '''Download and cache CSV file\n",
    "    Params:\n",
    "        dataDef: tuple of filename and url \n",
    "    '''    \n",
    "    import os\n",
    "    cachePath = cacheDir + filename\n",
    "    if not os.path.isfile(cachePath):\n",
    "        import requests\n",
    "        r = requests.get(url)\n",
    "        with open(cachePath, \"wb\") as f:\n",
    "            f.write(r.content)\n",
    "        print('Downloaded {} from {}'.format(filename, url))\n",
    "    else:\n",
    "        print('Loaded {} from cache'.format(filename))\n",
    "     \n",
    "    return pd.read_csv(cachePath)\n",
    "\n",
    "#for filename, url in dataDefintions:\n",
    "#    df = getCSV(filename, url, dataDir)\n",
    "trainingData = getFromCSV(dataDefintions[0][0], dataDefintions[0][1], dataDir)\n",
    "testData = getFromCSV(dataDefintions[1][0], dataDefintions[1][1], dataDir)\n",
    "len(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6334eb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b48b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingData.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e18b364",
   "metadata": {},
   "source": [
    "# Exploring Training Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3808a3c",
   "metadata": {},
   "source": [
    "Use information about each donor's history\n",
    " * Months since Last Donation: this is the number of monthis since this donor's most recent donation.\n",
    " * Number of Donations: this is the total number of donations that the donor has made.\n",
    " * Total Volume Donated: this is the total amound of blood that the donor has donated in cubuc centimeters.\n",
    " * Months since First Donation: this is the number of months since the donor's first donation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6086c7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "scatterPlot('Number of Donations', 'Months since First Donation')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eafedb6c",
   "metadata": {},
   "source": [
    "# Setup Data for Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66ea0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createValidation(data, prop = 0.8):\n",
    "    msk = np.random.rand(len(data)) < prop\n",
    "    trn = data[msk]\n",
    "    val = data[~msk]\n",
    "    return (trn, val)\n",
    "\n",
    "def createModelData(data):\n",
    "    \n",
    "    #Grab target label if it exists\n",
    "    if 'Made Donation in March 2007' in data.columns:\n",
    "        out = data['Made Donation in March 2007'].as_matrix()\n",
    "        inp = data.drop(['Unnamed: 0','Total Volume Donated (c.c.)', 'Made Donation in March 2007'],axis=1).as_matrix()\n",
    "    else:\n",
    "        out = None\n",
    "        inp = data.drop(['Unnamed: 0', 'Total Volume Donated (c.c.)'],axis=1).as_matrix()\n",
    "    \n",
    "    return (inp, out)\n",
    "\n",
    "def setupData(trainingData, testData):    \n",
    "    training, valid = createValidation(trainingData)\n",
    "    \n",
    "    trn.x, trn.y = createModelData(training)\n",
    "    val.x, val.y = createModelData(valid)\n",
    "    test, _ = createModelData(testData)\n",
    "    return (trn, val, test)\n",
    "(trn, val, test) = setupData(trainingData, testData)\n",
    "display(trn.x, trn.y)\n",
    "# display(val.x, val.y)\n",
    "trn.x.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf40eda",
   "metadata": {},
   "source": [
    "# Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a238cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "linearModel = Sequential([\n",
    "        BatchNormalization(input_shape=(3,)),\n",
    "        Dense(1),\n",
    "        Activation('sigmoid')\n",
    "        ])\n",
    "\n",
    "linearModel.compile(Adam(), loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a674a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainModel(model):\n",
    "    model.fit(trn.x, trn.y, batch_size=64, nb_epoch=10, validation_data=(val.x, val.y))\n",
    "# Perform 1 iteration at low lr\n",
    "linearModel.optimizer.lr = 0.01\n",
    "trainModel(linearModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ccf4a3",
   "metadata": {},
   "source": [
    ",Made Donation in March 2007\n",
    "659,0.5\n",
    "276,0.5\n",
    "263,0.5\n",
    "303,0.5\n",
    "83,0.5\n",
    "500,0.5\n",
    "530,0.5\n",
    "244,0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20751e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createSubmission(model):\n",
    "    pred = np.squeeze(model.predict(test))\n",
    "    ids = testData['Unnamed: 0'].as_matrix()\n",
    "    return np.stack([ids, pred], axis=1)\n",
    "\n",
    "def outputSubmission(filename, subm):\n",
    "    np.savetxt(filename, subm, fmt='%d,%.5f', header=',Made Donation in March 2007', comments='')\n",
    "\n",
    "submissionFile = dataDir + 'submissionLinear.csv'\n",
    "outputSubmission(submissionFile, createSubmission(linearModel) )\n",
    "# subm = createSubmission(linearModel)\n",
    "# np.savetxt(submissionFile, subm, fmt='%d,%.5f', header=',Made Donation in March 2007', comments='')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e9148f",
   "metadata": {},
   "source": [
    "### DriveData Evaluation\n",
    "\n",
    "DriveData uses binary log loss defined as:\n",
    "\n",
    "$$\\textrm{LogLoss} = - \\frac{1}{n} \\sum_{i=1}^n \\left[ y_i \\log(h_i) + (1 - y_i) \\log(1 - h_i)\\right]$$\n",
    "- $n$ is the number of samples in the test set\n",
    "- $h_i$  is the predicted label\n",
    "- $y_i$ is the true label\n",
    "- $log()$ is the natural (base e) logarithm\n",
    "\n",
    "As shown in the plot below, there is a \"infinte\" penality for predicting the wrong label with high confidence, i.e. predicting 0 when it should be 1. A trick to improve kaggle score is to clip the confident predictions.\n",
    "\n",
    "The clipping amount is random "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1250b9",
   "metadata": {},
   "source": [
    "# Lets Create an ensamble model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90722584",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensambleModel():\n",
    "    model =  Sequential([\n",
    "        BatchNormalization(input_shape=(11,)),\n",
    "        Dense(100),\n",
    "        Activation('relu'),\n",
    "        Dense(30),\n",
    "        Activation('relu'),\n",
    "        Dense(1),\n",
    "        Activation('sigmoid')\n",
    "        ])\n",
    "    model.compile(Adam(decay=decay_rate), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    model.fit(trn.x, trn.y, batch_size=256, nb_epoch=epochs, validation_data=(val.x, val.y)) \n",
    "    return model \n",
    "\n",
    "\n",
    "models = [ensambleModel() for i in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b761047a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets get the logloss for the ensamble model on the validation set\n",
    "def ensamblePrediction(models, inp):\n",
    "    avgPred = np.array([np.squeeze(models[i].predict(inp)) for i in range(10)])\n",
    "    return avgPred.mean(axis=0)\n",
    "\n",
    "pred = ensamblePrediction(models, val.x)\n",
    "logLoss(val.y, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4607d2b9",
   "metadata": {},
   "source": [
    "Not as good as expected, but again perhaps a few points better"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6728029c",
   "metadata": {},
   "source": [
    "# Lets add validation data to set and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2bd5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensambleNoCVModel():\n",
    "    x = np.vstack((trn.x, val.x))\n",
    "    y = np.concatenate((trn.y, val.y)) #Different methods as x is 2d vs y is 1d!\n",
    "    \n",
    "    model =  Sequential([\n",
    "        BatchNormalization(input_shape=(11,)),\n",
    "        Dense(100, activation='relu'),\n",
    "        Dense(30, activation='relu'),\n",
    "        Dense(1, activation='sigmoid'),\n",
    "        ])\n",
    "    \n",
    "    epochs = 300\n",
    "    learning_rate = 0.01\n",
    "    decay_rate = learning_rate / epochs\n",
    "    \n",
    "    model.compile(Adam(decay=decay_rate), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    model.fit(x, y, batch_size=256, nb_epoch=epochs, validation_data=(val.x, val.y)) \n",
    "    \n",
    "    return model \n",
    "\n",
    "\n",
    "models = [ensambleNoCVModel() for i in range(10)]\n",
    "pred = ensamblePrediction(models,val.x)\n",
    "logLoss(val.y, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c24d19",
   "metadata": {},
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e02f726",
   "metadata": {},
   "outputs": [],
   "source": [
    "def outputSubmission(filename, pred):\n",
    "    ids = testData['Unnamed: 0'].as_matrix()\n",
    "    subm = np.stack([ids, pred], axis=1)\n",
    "    np.savetxt(filename, subm, fmt='%d,%.5f', header=',Made Donation in March 2007', comments='')\n",
    "\n",
    "outputSubmission(dataDir+'ensambleNoCVModel', ensamblePrediction(models, test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff5bd60",
   "metadata": {},
   "source": [
    "# Semi-Supervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3588f55f",
   "metadata": {},
   "source": [
    "Lets use the ensamble modle to predict the label of the test set and using in training. This works as the test set is about 25% of the training set. we should shuffle the data so that batches don't purely contain test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9be1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#If we guess 0.5 throughout the loss would be:\n",
    "logloss.subs([(y,1), (h, 0.5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33271d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logLoss(y, h):\n",
    "    l = -np.sum(y*np.log(h) + (1-y)*np.log(1-h)) / len(h)\n",
    "    return l\n",
    "\n",
    "logLoss(val.y, np.squeeze(linearModel.predict(val.x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36cde44",
   "metadata": {},
   "source": [
    "# Simple Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b145aa94",
   "metadata": {},
   "source": [
    "Exploring various network architectures\n",
    "\n",
    "| Model | Val Accuracy |\n",
    "|------ |------|\n",
    "|20, 20 | 0.8151|\n",
    "|10     | 0.8151|\n",
    "|32     | 0.8319|\n",
    "|32,32  | 0.8103|\n",
    "|100    | 0.7847|\n",
    "|3      | 0.7414|\n",
    "\n",
    "Tried adding total volume of donation, but as expected no improvement\n",
    "\n",
    "Overall network architecture doesn't seem to have an impact. So lets keep it simple.\n",
    "\n",
    "With feature engineering, a large network seems to work a litte bitter, can be trained easier.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74508bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "NNModel = Sequential([\n",
    "        BatchNormalization(input_shape=(3,)),\n",
    "        Dense(100),\n",
    "        Activation('relu'),\n",
    "        Dense(30),\n",
    "        Activation('relu'),\n",
    "        Dense(1),\n",
    "        Activation('sigmoid')\n",
    "        ])\n",
    "\n",
    "epochs = 300\n",
    "learning_rate = 0.01\n",
    "decay_rate = learning_rate / epochs\n",
    "\n",
    "NNModel.compile(Adam(decay=decay_rate), loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6332ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "NNModel.fit(trn.x, trn.y, batch_size=256, nb_epoch=epochs, validation_data=(val.x, val.y)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471a27ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "trn.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110a4d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "logLoss(val.y, np.squeeze(NNModel.predict(val.x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295d07a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "submissionFile = dataDir + 'submissionNN.csv'\n",
    "outputSubmission(submissionFile, createSubmission(NNModel) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1198f87c",
   "metadata": {},
   "source": [
    "# Lets try some feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa5c185",
   "metadata": {},
   "source": [
    "## Remove Skewness in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de94507",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingData.plot.hist(alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c501c983",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingData['Number of Donations'].plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895be587",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingData['Months since Last Donation'].plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b106f843",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingData['Made Donation in March 2007'].plot.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05025359",
   "metadata": {},
   "source": [
    "We have a lot more examples of people who didn't donate to people who donated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0563c87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "(trainingData['Total Volume Donated (c.c.)'] / trainingData['Number of Donations']).plot.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9997e2e",
   "metadata": {},
   "source": [
    "Everyone donates 250cc per donation!, So it isn't an instresting variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706e552c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatterPlot(xLabel, yLabel):    \n",
    "    trace = go.Scatter(\n",
    "        x=trainingData[xLabel], \n",
    "        y=trainingData[yLabel], \n",
    "        mode='markers',\n",
    "        marker=dict(\n",
    "            size='8',\n",
    "            color = trainingData['Made Donation in March 2007'], #set color equal to a variable\n",
    "            colorscale='RdBu',\n",
    "            showscale=True\n",
    "        ),\n",
    "        )\n",
    "\n",
    "    layout= go.Layout(\n",
    "        title= 'Blood Donations',\n",
    "        hovermode= 'closest',\n",
    "        xaxis= dict(\n",
    "            title= xLabel,\n",
    "            zeroline= False,\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            title= yLabel,\n",
    "        ),\n",
    "        showlegend=False\n",
    "    )\n",
    "    fig= go.Figure(data=[trace], layout=layout)\n",
    "    py.iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46922883",
   "metadata": {},
   "outputs": [],
   "source": [
    "scatterPlot('Number of Donations', 'Months since Last Donation')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee189299",
   "metadata": {},
   "source": [
    "Seems like months since last donation is a better indication than number of donations"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
