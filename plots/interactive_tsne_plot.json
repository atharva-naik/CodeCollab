{
    "x": [
        12.147011756896973,
        -31.376245498657227,
        -25.10859489440918,
        -37.68128204345703,
        36.909507751464844,
        18.316492080688477,
        -17.352783203125,
        -55.88404846191406,
        -10.18618392944336,
        -23.994657516479492,
        -31.20827865600586,
        -40.365081787109375,
        -27.94788360595703,
        -19.591938018798828,
        -24.522480010986328,
        -31.59661293029785,
        10.765389442443848,
        20.648197174072266,
        -63.88099670410156,
        48.400325775146484,
        -31.804147720336914,
        -6.992157936096191,
        15.233508110046387,
        -68.91751098632812,
        13.288599014282227,
        56.30311584472656,
        -25.95418357849121,
        -21.625926971435547,
        38.34086608886719,
        49.13269805908203,
        28.600379943847656,
        54.25541305541992,
        -53.663028717041016,
        -11.649125099182129,
        46.61730194091797,
        -16.26771354675293,
        45.395572662353516,
        -21.549219131469727,
        -21.35699462890625,
        -16.095659255981445,
        -24.31201171875,
        44.552940368652344,
        29.866178512573242,
        -63.47866439819336,
        46.48668670654297,
        -28.188690185546875,
        -10.055830001831055,
        31.840177536010742,
        -69.05262756347656,
        37.84580993652344
    ],
    "y": [
        11.322842597961426,
        2.9475059509277344,
        21.622058868408203,
        5.976254940032959,
        15.698016166687012,
        9.007981300354004,
        27.459861755371094,
        -26.730560302734375,
        -25.437685012817383,
        36.245269775390625,
        22.99312973022461,
        17.964876174926758,
        -32.88582229614258,
        -32.1990966796875,
        29.052297592163086,
        -23.892446517944336,
        -0.6607190370559692,
        -7.618073463439941,
        6.338536262512207,
        15.918193817138672,
        -3.684738874435425,
        25.937501907348633,
        -4.577732086181641,
        21.151765823364258,
        2.7774856090545654,
        2.2017457485198975,
        7.238409519195557,
        14.997719764709473,
        -20.930633544921875,
        1.8327394723892212,
        -27.098857879638672,
        -8.528698921203613,
        -30.064952850341797,
        -20.23845672607422,
        -16.351388931274414,
        10.515750885009766,
        -0.20737633109092712,
        -14.852249145507812,
        -25.270353317260742,
        16.451745986938477,
        -19.007848739624023,
        -23.562122344970703,
        -11.277292251586914,
        2.2792327404022217,
        9.905852317810059,
        -14.509235382080078,
        19.26594352722168,
        -21.22879981994629,
        25.289562225341797,
        -17.078632354736328
    ],
    "text": [
        [
            "query = ''' SELECT * FROM DEC_00_SF3_DP3_with_ann'''\n\nurl = source +\\\n      \"?q= \"+ query\n    \nprint (url)\n\nresult = queryCartoDB_py3(source, query, 'CSV')\nincome2000 = pd.read_csv(io.StringIO(result))",
            "import os, random, cv2\nimport numpy as np\nimport tensorflow as tf\nimport matplotlib.pyplot as plt",
            "import pandas as pd\nimport os\nimport numpy as np\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.preprocessing import MultiLabelBinarizer\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\nfrom sklearn.metrics import r2_score, roc_auc_score\nfrom sklearn.model_selection import train_test_split",
            "js_source_array",
            "texts = yelp[\"text\"]\nstars = yelp[\"stars\"]",
            "tweetCounts = twitterData['Username'].value_counts()\ntweetCounts.head(10)",
            "print ntdict\nbest_nt = max(ntdict, key=ntdict.get)\nprint 'Best parameter: ',best_nt, ntdict[best_nt]\nclfRF_gini = RandomForestClassifier(n_estimators=nt)\nclfRF_gini.fit(X_train,y_train)\npredicted = clfRF_gini.predict(X_test)\nprint 'Accuracy on test set: ',metrics.accuracy_score(y_test,predicted)",
            "import networkx as nx\nG=nx.Graph()\nG.add_node(1)\nG.add_nodes_from([2,3])",
            "Dataset.test_negative_3.plot.scatter(x=0, y=1)",
            "for degree in range(1,6):\n    model = make_pipeline(PolynomialFeatures(degree), Ridge())\n    print(degree, '\\t', cross_val_score(model, X, Pdc2, cv=10, n_jobs=-1).mean())",
            "vec2 = CountVectorizer()\nX1 = vec.fit_transform(corpus2).toarray()\nprint(X1)\ny1= df.iloc[:, 4].values\nprint(y1)",
            "arr = root2array('/project/projectdirs/lux/data/golden/root/Golden_Run03/Golden_150303*.root','golden',selection=combined_cut.GetTitle())\na=list_structures('/project/projectdirs/lux/data/golden/root/Golden_Run03/Golden_150303_WS1.root','golden')\n\nS=dict()\nfor (key, value) in a.items():        \n    S.update(dict([(key, arr[key])]))\n\nsio.savemat('/project/projectdirs/lux/data/platinum/Platinum_Run03_WS', S)",
            "eeg_id = 2\nsplit_eeg = paa_transform(z_eeg, 1500)\nplt.plot(range(split_eeg[:,eeg_id].size),split_eeg[:,eeg_id])\nplt.ylim([-3,3])",
            "import copy \n\n# Scale First Pull feature using the natural logarithm\nscaled_data = copy.deepcopy(data)\nscaled_data['First Pull'] = np.log(scaled_data['First Pull'])\n\n# Produce a scatter matrix for each pair of newly-transformed features\npd.scatter_matrix(scaled_data, alpha = 0.3, figsize = (14,8), diagonal = 'kde');",
            "# Predict using the model\ncost_pred = cost_lm.predict(X)\nprice_pred = price_lm.predict(X)",
            "# Step 4.\n#  add lines connecting adjacent points\n\nplt.scatter(X,Y)\nplt.plot(X,Y)\nplt.show()",
            "min_df = 1",
            "economic_df['article_headline'] = economic_df['article_headline'].apply(nlp_ml_functions.clean_up_article)",
            "cfg = configparser.ConfigParser()\ntry:\n    cfg.read('config.ini')\n    api_key = cfg.get('vr','API_KEY')\n    print(\"API key loaded:\", api_key[0:10], \"***\")\nexcept Exception as e:\n    print(e)\n    print(\"Please make sure that the config.ini file exists.\")",
            "misp.sighting_list(event.attributes[1].id)",
            "PT = mt.PlottingTools()",
            "import datetime\n\n### TODO: Train the model.\ncheckpointer = ModelCheckpoint(filepath='saved_models/weights.best.Xception.hdf5', \n                               verbose=1, save_best_only=True)\nX_start = datetime.datetime.now()\nX_model.fit(train_X, train_targets, \n          validation_data=(valid_X, valid_targets),\n          epochs=20, batch_size=20, callbacks=[checkpointer], verbose=1)\nX_end = datetime.datetime.now()\n# X_time = X_end - X_start\nprint(X_end - X_start)",
            "new_df['Label'].var()",
            "from textblob import TextBlob\n\ndef tokenize(message):\n    message = unicode(message, 'utf8')\n    return TextBlob(message).words",
            "# View dataframe\ndf"
        ],
        [
            "query = ''' SELECT * FROM DEC_00_SF3_DP3_with_ann'''\n\nurl = source +\\\n      \"?q= \"+ query\n    \nprint (url)\n\nresult = queryCartoDB_py3(source, query, 'CSV')\nincome2000 = pd.read_csv(io.StringIO(result))",
            "import os, random, cv2\nimport numpy as np\nimport tensorflow as tf\nimport matplotlib.pyplot as plt",
            "import pandas as pd\nimport os\nimport numpy as np\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.preprocessing import MultiLabelBinarizer\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\nfrom sklearn.metrics import r2_score, roc_auc_score\nfrom sklearn.model_selection import train_test_split",
            "js_source_array",
            "texts = yelp[\"text\"]\nstars = yelp[\"stars\"]",
            "tweetCounts = twitterData['Username'].value_counts()\ntweetCounts.head(10)",
            "print ntdict\nbest_nt = max(ntdict, key=ntdict.get)\nprint 'Best parameter: ',best_nt, ntdict[best_nt]\nclfRF_gini = RandomForestClassifier(n_estimators=nt)\nclfRF_gini.fit(X_train,y_train)\npredicted = clfRF_gini.predict(X_test)\nprint 'Accuracy on test set: ',metrics.accuracy_score(y_test,predicted)",
            "import networkx as nx\nG=nx.Graph()\nG.add_node(1)\nG.add_nodes_from([2,3])",
            "Dataset.test_negative_3.plot.scatter(x=0, y=1)",
            "for degree in range(1,6):\n    model = make_pipeline(PolynomialFeatures(degree), Ridge())\n    print(degree, '\\t', cross_val_score(model, X, Pdc2, cv=10, n_jobs=-1).mean())",
            "vec2 = CountVectorizer()\nX1 = vec.fit_transform(corpus2).toarray()\nprint(X1)\ny1= df.iloc[:, 4].values\nprint(y1)",
            "arr = root2array('/project/projectdirs/lux/data/golden/root/Golden_Run03/Golden_150303*.root','golden',selection=combined_cut.GetTitle())\na=list_structures('/project/projectdirs/lux/data/golden/root/Golden_Run03/Golden_150303_WS1.root','golden')\n\nS=dict()\nfor (key, value) in a.items():        \n    S.update(dict([(key, arr[key])]))\n\nsio.savemat('/project/projectdirs/lux/data/platinum/Platinum_Run03_WS', S)",
            "eeg_id = 2\nsplit_eeg = paa_transform(z_eeg, 1500)\nplt.plot(range(split_eeg[:,eeg_id].size),split_eeg[:,eeg_id])\nplt.ylim([-3,3])",
            "import copy \n\n# Scale First Pull feature using the natural logarithm\nscaled_data = copy.deepcopy(data)\nscaled_data['First Pull'] = np.log(scaled_data['First Pull'])\n\n# Produce a scatter matrix for each pair of newly-transformed features\npd.scatter_matrix(scaled_data, alpha = 0.3, figsize = (14,8), diagonal = 'kde');",
            "# Predict using the model\ncost_pred = cost_lm.predict(X)\nprice_pred = price_lm.predict(X)",
            "# Step 4.\n#  add lines connecting adjacent points\n\nplt.scatter(X,Y)\nplt.plot(X,Y)\nplt.show()",
            "min_df = 1",
            "economic_df['article_headline'] = economic_df['article_headline'].apply(nlp_ml_functions.clean_up_article)",
            "cfg = configparser.ConfigParser()\ntry:\n    cfg.read('config.ini')\n    api_key = cfg.get('vr','API_KEY')\n    print(\"API key loaded:\", api_key[0:10], \"***\")\nexcept Exception as e:\n    print(e)\n    print(\"Please make sure that the config.ini file exists.\")",
            "misp.sighting_list(event.attributes[1].id)",
            "PT = mt.PlottingTools()",
            "import datetime\n\n### TODO: Train the model.\ncheckpointer = ModelCheckpoint(filepath='saved_models/weights.best.Xception.hdf5', \n                               verbose=1, save_best_only=True)\nX_start = datetime.datetime.now()\nX_model.fit(train_X, train_targets, \n          validation_data=(valid_X, valid_targets),\n          epochs=20, batch_size=20, callbacks=[checkpointer], verbose=1)\nX_end = datetime.datetime.now()\n# X_time = X_end - X_start\nprint(X_end - X_start)",
            "new_df['Label'].var()",
            "from textblob import TextBlob\n\ndef tokenize(message):\n    message = unicode(message, 'utf8')\n    return TextBlob(message).words",
            "# View dataframe\ndf"
        ]
    ]
}