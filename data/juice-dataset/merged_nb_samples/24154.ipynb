{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88dad541",
   "metadata": {},
   "source": [
    "# Self-Driving Car Engineer Nanodegree\n",
    "## Project - 5 - Vehicle Detection and Tracking\n",
    "---\n",
    "The goals / steps of this project are the following:\n",
    "\n",
    "* Perform a Histogram of Oriented Gradients (HOG) feature extraction on a labeled training set of images and train a classifier Linear SVM classifier\n",
    "* Optionally, you can also apply a color transform and append binned color features, as well as histograms of color, to your HOG feature vector. \n",
    "* Note: for those first two steps don't forget to normalize your features and randomize a selection for training and testing.\n",
    "* Implement a sliding-window technique and use your trained classifier to search for vehicles in images.\n",
    "* Run your pipeline on a video stream (start with the test_video.mp4 and later implement on full project_video.mp4) and create a heat map of recurring detections frame by frame to reject outliers and follow detected vehicles.\n",
    "* Estimate a bounding box for vehicles detected.\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141ccfb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import time\n",
    "from sklearn.svm import LinearSVC\n",
    "from skimage.feature import hog\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.ndimage.measurements import label\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "from random import shuffle\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38bc0880",
   "metadata": {},
   "source": [
    "## 1. Loading the Data\n",
    "\n",
    "Here we create lists of [vehicles](https://s3.amazonaws.com/udacity-sdc/Vehicle_Tracking/vehicles.zip) and [not-vehicles](https://s3.amazonaws.com/udacity-sdc/Vehicle_Tracking/non-vehicles.zip) images provided by Udacity. Corrisponding folders contain unzilled archives."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34433eac",
   "metadata": {},
   "source": [
    "## 11. Train the Support Vector Classifier and Test the Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45342db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "color_space = 'YCrCb' # Can be RGB, HSV, LUV, HLS, YUV, YCrCb\n",
    "orient = 10  # HOG orientations\n",
    "pix_per_cell = 8 # HOG pixels per cell\n",
    "cell_per_block = 2 # HOG cells per block\n",
    "hog_channel = 'ALL' # Can be 0, 1, 2, or \"ALL\"\n",
    "spatial_size = (32, 32) # Spatial binning dimensions\n",
    "hist_bins = 64   # Number of histogram bins\n",
    "spatial_feat = True # Spatial features on or off\n",
    "hist_feat = True # Histogram features on or off\n",
    "hog_feat = True # HOG features on or off\n",
    "y_start_stop = [350, None] # Min and max in y to search in slide_window()\n",
    "\n",
    "car_features = extract_features(car_images, color_space=color_space, \n",
    "                            spatial_size=spatial_size, hist_bins=hist_bins, \n",
    "                            orient=orient, pix_per_cell=pix_per_cell, \n",
    "                            cell_per_block=cell_per_block, \n",
    "                            hog_channel=hog_channel,\n",
    "                            spatial_feat=spatial_feat, hist_feat=hist_feat,\n",
    "                            hog_feat=hog_feat)\n",
    "notcar_features = extract_features(noncar_images, color_space=color_space, \n",
    "                            spatial_size=spatial_size, hist_bins=hist_bins, \n",
    "                            orient=orient, pix_per_cell=pix_per_cell, \n",
    "                            cell_per_block=cell_per_block, \n",
    "                            hog_channel=hog_channel,\n",
    "                            spatial_feat=spatial_feat, hist_feat=hist_feat,\n",
    "                            hog_feat=hog_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e51e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.vstack((car_features, notcar_features)).astype(np.float64)                        \n",
    "# Fit a per-column scaler\n",
    "X_scaler = StandardScaler().fit(X)\n",
    "# Apply the scaler to X\n",
    "scaled_X = X_scaler.transform(X)\n",
    "\n",
    "# Define the labels vector\n",
    "y = np.hstack((np.ones(len(car_features)), np.zeros(len(notcar_features))))\n",
    "\n",
    "\n",
    "# Split up data into randomized training and test sets\n",
    "#rand_state = np.random.randint(0, 100)\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaled_X, y, test_size=0.2,\n",
    "                                                    random_state=rand_state)\n",
    "\n",
    "print('Using:',orient,'orientations,',pix_per_cell,\n",
    "    'pixels per cell and', cell_per_block,'cells per block')\n",
    "print('Feature vector length:', len(X_train[0]))\n",
    "# Use a linear SVC \n",
    "svc = LinearSVC()\n",
    "# Check the training time for the SVC\n",
    "t=time.time()\n",
    "svc.fit(X_train, y_train)\n",
    "t2 = time.time()\n",
    "print(round(t2-t, 2), 'Seconds to train SVC...')\n",
    "# Check the score of the SVC\n",
    "print('Test Accuracy of SVC = {0:.2f}%'.format(round(svc.score(X_test, y_test)*100, 4)))\n",
    "# Check the prediction time for a single sample\n",
    "t=time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b2fa65",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4,7):\n",
    "    \n",
    "    fname = 'test_images/test{}.jpg'.format(i)\n",
    "    image = mpimg.imread(fname)\n",
    "    draw_image = np.copy(image)\n",
    "\n",
    "    # Uncomment the following line if you extracted training\n",
    "    # data from .png images (scaled 0 to 1 by mpimg) and the\n",
    "    # image you are searching is a .jpg (scaled 0 to 255)\n",
    "    image = image.astype(np.float32)/255\n",
    "\n",
    "    windows =  slide_window(test_img,\n",
    "                            x_start_stop=[600, None],\n",
    "                            y_start_stop=[400, 656], #tune the parameters\n",
    "                            xy_window=(128,128),\n",
    "                            xy_overlap=(.7,.7))\n",
    "\n",
    "    hot_windows = search_windows(image, windows, svc, X_scaler, color_space=color_space, \n",
    "                            spatial_size=spatial_size, hist_bins=hist_bins, \n",
    "                            orient=orient, pix_per_cell=pix_per_cell, \n",
    "                            cell_per_block=cell_per_block, \n",
    "                            hog_channel=hog_channel, spatial_feat=spatial_feat, \n",
    "                            hist_feat=hist_feat, hog_feat=hog_feat)                       \n",
    "\n",
    "    window_img = draw_boxes(draw_image, hot_windows, random_color=True) \n",
    "    \n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(18,9))\n",
    "    plt.tight_layout()\n",
    "    ax1.imshow(draw_image)\n",
    "    ax1.set_title('Original Image', fontsize=30)\n",
    "    ax2.imshow(window_img)\n",
    "    ax2.set_title('Cars found', fontsize=30)\n",
    "    plt.savefig('output_images/Car_Fount_Boxes.png', bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e5eb48",
   "metadata": {},
   "source": [
    "## 12. Adding Heatmaps and Bounding Boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974dd5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_heat(heatmap, bbox_list):\n",
    "    # Iterate through list of bboxes\n",
    "    for box in bbox_list:\n",
    "        # Add += 1 for all pixels inside each bbox\n",
    "        # Assuming each \"box\" takes the form ((x1, y1), (x2, y2))\n",
    "        heatmap[box[0][1]:box[1][1], box[0][0]:box[1][0]] += 1\n",
    "\n",
    "    # Return updated heatmap\n",
    "    return heatmap# Iterate through list of bboxes\n",
    "    \n",
    "def apply_threshold(heatmap, threshold):\n",
    "    # Zero out pixels below the threshold\n",
    "    heatmap[heatmap <= threshold] = 0\n",
    "    # Return thresholded map\n",
    "    return heatmap\n",
    "\n",
    "def draw_labeled_bboxes(img, labels):\n",
    "    # Iterate through all detected cars\n",
    "    for car_number in range(1, labels[1]+1):\n",
    "        # Find pixels with each car_number label value\n",
    "        nonzero = (labels[0] == car_number).nonzero()\n",
    "        # Identify x and y values of those pixels\n",
    "        nonzeroy = np.array(nonzero[0])\n",
    "        nonzerox = np.array(nonzero[1])\n",
    "        # Define a bounding box based on min/max x and y\n",
    "        bbox = ((np.min(nonzerox), np.min(nonzeroy)), (np.max(nonzerox), np.max(nonzeroy)))\n",
    "        # Draw the box on the image\n",
    "        cv2.rectangle(img, bbox[0], bbox[1], (0,176,80), 8)\n",
    "    # Return the image\n",
    "    return img\n",
    "\n",
    "def convert_color(img, conv='RGB2YCrCb'):\n",
    "    if conv == 'RGB2YCrCb':\n",
    "        return cv2.cvtColor(img, cv2.COLOR_RGB2YCrCb)\n",
    "    if conv == 'BGR2YCrCb':\n",
    "        return cv2.cvtColor(img, cv2.COLOR_BGR2YCrCb)\n",
    "    if conv == 'RGB2LUV':\n",
    "        return cv2.cvtColor(img, cv2.COLOR_RGB2LUV)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c82dc78",
   "metadata": {},
   "source": [
    "## 13. Function to Predict using Features Extracted from HOG Sub-Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d57042",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_cars(img, ystart, ystop, scale, svc, X_scaler,\n",
    "              orient, pix_per_cell, cell_per_block,\n",
    "              spatial_size, hist_bins):\n",
    "    \n",
    "    draw_img = np.copy(img)\n",
    "    img = img.astype(np.float32)/255\n",
    "    \n",
    "    img_tosearch = img[ystart:ystop,:,:]\n",
    "    ctrans_tosearch = convert_color(img_tosearch, conv='RGB2YCrCb')\n",
    "    if scale != 1:\n",
    "        imshape = ctrans_tosearch.shape\n",
    "        ctrans_tosearch = cv2.resize(ctrans_tosearch,\n",
    "                                     (np.int(imshape[1]/scale),\n",
    "                                      np.int(imshape[0]/scale)))\n",
    "        \n",
    "    ch1 = ctrans_tosearch[:,:,0]\n",
    "    ch2 = ctrans_tosearch[:,:,1]\n",
    "    ch3 = ctrans_tosearch[:,:,2]\n",
    "\n",
    "    # Define blocks and steps as above\n",
    "    nxblocks = (ch1.shape[1] // pix_per_cell) - cell_per_block + 1\n",
    "    nyblocks = (ch1.shape[0] // pix_per_cell) - cell_per_block + 1 \n",
    "    nfeat_per_block = orient*cell_per_block**2\n",
    "    \n",
    "    # 64 was the orginal sampling rate, with 8 cells and 8 pix per cell\n",
    "    window = 64\n",
    "    nblocks_per_window = (window // pix_per_cell) - cell_per_block + 1\n",
    "    cells_per_step = 2  # Instead of overlap, define how many cells to step\n",
    "    nxsteps = (nxblocks - nblocks_per_window) // cells_per_step\n",
    "    nysteps = (nyblocks - nblocks_per_window) // cells_per_step\n",
    "    \n",
    "    # Compute individual channel HOG features for the entire image\n",
    "    hog1 = get_hog_features(ch1, orient, pix_per_cell, cell_per_block, feature_vec=False)\n",
    "    hog2 = get_hog_features(ch2, orient, pix_per_cell, cell_per_block, feature_vec=False)\n",
    "    hog3 = get_hog_features(ch3, orient, pix_per_cell, cell_per_block, feature_vec=False)\n",
    "    \n",
    "    bbox_list=[] #https://github.com/preritj/Vechicle-Detection-Tracking\n",
    "    for xb in range(nxsteps):\n",
    "        for yb in range(nysteps):\n",
    "            ypos = yb*cells_per_step\n",
    "            xpos = xb*cells_per_step\n",
    "            # Extract HOG for this patch\n",
    "            hog_feat1 = hog1[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel() \n",
    "            hog_feat2 = hog2[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel() \n",
    "            hog_feat3 = hog3[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel() \n",
    "            hog_features = np.hstack((hog_feat1, hog_feat2, hog_feat3))\n",
    "\n",
    "            xleft = xpos*pix_per_cell\n",
    "            ytop = ypos*pix_per_cell\n",
    "\n",
    "            # Extract the image patch\n",
    "            subimg = cv2.resize(ctrans_tosearch[ytop:ytop+window, xleft:xleft+window], (64,64))\n",
    "\n",
    "            # Get color features\n",
    "            spatial_features = bin_spatial(subimg, size=spatial_size)\n",
    "            hist_features = color_hist(subimg, nbins=hist_bins)\n",
    "\n",
    "            # Scale features and make a prediction\n",
    "            test_features = X_scaler.transform(np.hstack((spatial_features,\n",
    "                                                          hist_features,\n",
    "                                                          hog_features)).reshape(1, -1))  \n",
    "            \n",
    "            # Scale features and make a prediction  \n",
    "            test_prediction = svc.predict(test_features)\n",
    "            \n",
    "            if test_prediction == 1:\n",
    "                xbox_left = np.int(xleft*scale)\n",
    "                ytop_draw = np.int(ytop*scale)\n",
    "                win_draw = np.int(window*scale)\n",
    "                cv2.rectangle(draw_img,(xbox_left, ytop_draw+ystart),\n",
    "                              (xbox_left+win_draw,ytop_draw+win_draw+ystart),\n",
    "                              (255,0,0),8)\n",
    "                bbox_list.append(((xbox_left, ytop_draw+ystart), #github.com/preritj\n",
    "                                  (xbox_left+win_draw,ytop_draw+win_draw+ystart)))\n",
    "                \n",
    "    \n",
    "    return bbox_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0312162",
   "metadata": {},
   "source": [
    "## 14. Heatmap Visulization and Video Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2693c904",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,6):\n",
    "    \n",
    "    fname = 'test_images/test{}.jpg'.format(i)\n",
    "    img = mpimg.imread(fname)\n",
    "    \n",
    "\n",
    "    orient=10\n",
    "    pix_per_cell=8\n",
    "    cell_per_block=2\n",
    "    spatial_size=(32, 32)\n",
    "    hist_bins=64\n",
    "    \n",
    "    bbox_list = []\n",
    "    \n",
    "    \n",
    "    ystart = 380\n",
    "    ystop = 550\n",
    "    scale = 1.0\n",
    "    bbox_list.append(find_cars(img, ystart, ystop, scale, svc, X_scaler,\n",
    "                                    orient, pix_per_cell, cell_per_block,\n",
    "                                    spatial_size, hist_bins))\n",
    "    \n",
    "    ystart = 400\n",
    "    ystop = 600\n",
    "    scale = 1.5\n",
    "    bbox_list.append(find_cars(img, ystart, ystop, scale, svc, X_scaler,\n",
    "                                    orient, pix_per_cell, cell_per_block,\n",
    "                                    spatial_size, hist_bins))\n",
    "    \n",
    "    ystart = 400\n",
    "    ystop = 656\n",
    "    scale = 2.0\n",
    "    bbox_list.append(find_cars(img, ystart, ystop, scale, svc, X_scaler,\n",
    "                                    orient, pix_per_cell, cell_per_block,\n",
    "                                    spatial_size, hist_bins))\n",
    "   \n",
    "    bbox_list = [item for sublist in bbox_list for item in sublist] \n",
    "    \n",
    "    out_img = draw_boxes(img, bbox_list, random_color=True)\n",
    "    \n",
    "    heat = np.zeros_like(img[:,:,0]).astype(np.float)\n",
    "    heat = add_heat(heat, bbox_list)\n",
    "    heat = apply_threshold(heat, 2)  \n",
    "\n",
    "    # Find final boxes from heatmap using label function\n",
    "    labels = label(heat)\n",
    "    new_img = draw_labeled_bboxes(np.copy(img), labels)\n",
    "\n",
    "    f, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(18,9))\n",
    "    plt.tight_layout()\n",
    "    ax1.imshow(out_img)\n",
    "    ax1.set_title('Search Boxes', fontsize=30)\n",
    "    ax2.imshow(heat, cmap='hot')\n",
    "    ax2.set_title('Heat Map', fontsize=30)\n",
    "    ax3.imshow(new_img)\n",
    "    ax3.set_title('Bounding Boxes', fontsize=30)\n",
    "    #plt.savefig('output_images/heat_map1.png', bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db4d3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(img):\n",
    "\n",
    "    orient=10\n",
    "    pix_per_cell=8\n",
    "    cell_per_block=2\n",
    "    spatial_size=(32, 32)\n",
    "    hist_bins=64\n",
    "    \n",
    "    bbox_list = []\n",
    "    \n",
    "    ystart = 380\n",
    "    ystop = 550\n",
    "    scale = 1.0\n",
    "    bbox_list.append(find_cars(img, ystart, ystop, scale, svc, X_scaler,\n",
    "                                    orient, pix_per_cell, cell_per_block,\n",
    "                                    spatial_size, hist_bins))\n",
    "    \n",
    "    ystart = 400\n",
    "    ystop = 600\n",
    "    scale = 1.5\n",
    "    bbox_list.append(find_cars(img, ystart, ystop, scale, svc, X_scaler,\n",
    "                                    orient, pix_per_cell, cell_per_block,\n",
    "                                    spatial_size, hist_bins))\n",
    "    \n",
    "    ystart = 400\n",
    "    ystop = 656\n",
    "    scale = 2.0\n",
    "    bbox_list.append(find_cars(img, ystart, ystop, scale, svc, X_scaler,\n",
    "                                    orient, pix_per_cell, cell_per_block,\n",
    "                                    spatial_size, hist_bins))\n",
    "    bbox_list = [item for sublist in bbox_list for item in sublist] \n",
    "    \n",
    "    heat = np.zeros_like(img[:,:,0]).astype(np.float)\n",
    "    heat = add_heat(heat, bbox_list)\n",
    "    heat = apply_threshold(heat, 2)  \n",
    "\n",
    "    # Find final boxes from heatmap using label function\n",
    "    labels = label(heat)\n",
    "    new_img = draw_labeled_bboxes(np.copy(img), labels)\n",
    "    \n",
    "    return new_img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e9299b",
   "metadata": {},
   "source": [
    "## 15. Vehicle Detection and Tracking (Video Output)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
