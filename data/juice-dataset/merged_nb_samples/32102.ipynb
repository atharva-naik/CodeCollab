{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fbd6207b",
   "metadata": {},
   "source": [
    "# Question 1: Propensity score matching\n",
    "\n",
    "In this exercise, you will apply [propensity score matching](http://www.stewartschultz.com/statistics/books/Design%20of%20observational%20studies.pdf), which we discussed in lecture 5 (\"Observational studies\"), in order to draw conclusions from an observational study.\n",
    "\n",
    "We will work with a by-now classic dataset from Robert LaLonde's study \"[Evaluating the Econometric Evaluations of Training Programs](http://people.hbs.edu/nashraf/LaLonde_1986.pdf)\" (1986).\n",
    "The study investigated the effect of a job training program (\"National Supported Work Demonstration\") on the real earnings of an individual, a couple of years after completion of the program.\n",
    "Your task is to determine the effectiveness of the \"treatment\" represented by the job training program.\n",
    "\n",
    "## Dataset description\n",
    "\n",
    "- `treat`: 1 if the subject participated in the job training program, 0 otherwise\n",
    "- `age`: the subject's age\n",
    "- `educ`: years of education\n",
    "- `race`: categorical variable with three possible values: Black, Hispanic, or White\n",
    "- `married`: 1 if the subject was married at the time of the training program, 0 otherwise\n",
    "- `nodegree`: 1 if the subject has earned no school degree, 0 otherwise\n",
    "- `re74`: real earnings in 1974 (pre-treatment)\n",
    "- `re75`: real earnings in 1975 (pre-treatment)\n",
    "- `re78`: real earnings in 1978 (outcome)\n",
    "\n",
    "If you want to brush up your knowledge on propensity scores and observational studies, we highly recommend Rosenbaum's excellent book on the [\"Design of Observational Studies\"](http://www.stewartschultz.com/statistics/books/Design%20of%20observational%20studies.pdf). Even just reading the first chapter (18 pages) will help you a lot.\n",
    "\n",
    "## 1. A naive analysis\n",
    "\n",
    "Compare the distribution of the outcome variable (`re78`) between the two groups, using plots and numbers.\n",
    "To summarize and compare the distributions, you may use the techniques we discussed in lectures 4 (\"Read the stats carefully\") and 6 (\"Data visualization\").\n",
    "\n",
    "What might a naive \"researcher\" conclude from this superficial analysis?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b8682f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from pandas.plotting import scatter_matrix\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import linear_model\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "from networkx.algorithms import bipartite\n",
    "from networkx.algorithms import max_weight_matching\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd8d1db",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\"> First, we load our data into a dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e311471f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lalonde = pd.read_csv('lalonde.csv', index_col=0)\n",
    "lalonde.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83762150",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">We create a *race* column that replaces the *black* and *hisp* columns. It permits to directly access the information: 0 for \"black\", 1 for \"hispanic\", 2 for \"white\" (neither black nor hispanic). We also replace the *nodegree* column by a *degree* column (inverting the boolean value) to make it more consistent with other features such as *married*, where 0 means \"not married\", whereas for *nodegree*, 0 means \"no no degree = degree\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ead5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "lalonde['race'] = 2-lalonde['hispan']-2*lalonde['black'] # black race: 0, hispanic: 1, white: 2\n",
    "lalonde['degree'] = 1+lalonde['nodegree']*-1 # inverting the nodegree column \n",
    "\n",
    "# remove unnecessary columns\n",
    "del lalonde['nodegree']\n",
    "del lalonde['black']\n",
    "del lalonde['hispan']\n",
    "\n",
    "lalonde = lalonde[['treat', 'age', 'educ', 'married', 'race', 'degree', 're74', 're75', 're78']]\n",
    "lalonde.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34b7f6d",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">We also create 2 dataframes, *treat* and *no_treat*, to separate subject according to their completion of the program or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3775cdd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "treat = lalonde[lalonde['treat']==1] # only people who completed the program\n",
    "no_treat = lalonde[lalonde['treat']==0] # only people who did not complete the program\n",
    "treat.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99febc7",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">Let's observe the difference in revenue in 1978 between people who completed the program and those who did not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2993aba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5be954",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\"> It seems we have a little over 18k articles and more than 134k features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166dc8fa",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">We now split the data into training, testing, and validation sets. We use sklearn's builtin function to do so. We supply a predefined seed for the random number generator to ensure determinism across executions. We also ensure that the split is stratified, so that the proportion of categories remains similar in each subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb834061",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, we split 80-20 to get the training set\n",
    "training, remaining = train_test_split(list(range(0, len(newsgroups.data))), train_size=0.8, test_size=0.2, stratify=newsgroups.target, random_state=42)\n",
    "\n",
    "# Next, we split 50-50 on the remaining 20%, so that testing and validation are both 10% of the original dataset\n",
    "testing, validation = train_test_split(remaining, train_size=0.5, test_size=0.5, stratify=list(map(lambda idx: newsgroups.target[idx], remaining)), random_state=42)\n",
    "\n",
    "# Sort\n",
    "training.sort()\n",
    "validation.sort()\n",
    "testing.sort()\n",
    "\n",
    "# Let's print out the sizes of each subset...\n",
    "print('Training size: %d.\\nTesting size: %d\\nValidation size: %d.' % (len(training), len(testing), len(validation)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea53778",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">We create convenience functions to select the associated data, features, and observations from the indices in each subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277605b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_data(subset):\n",
    "    return list(map(lambda idx: newsgroups.data[idx], subset))\n",
    "\n",
    "def select_features(subset):\n",
    "    return vectors[subset, :] # slice on rows, keep all columns\n",
    "\n",
    "def select_observations(subset):\n",
    "    return list(map(lambda idx: newsgroups.target[idx], subset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "023e7889",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">Using the above functions, we extract the features and observations for each subset of the original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70312e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = select_data(training)\n",
    "training_features = select_features(training)\n",
    "training_observations = select_observations(training)\n",
    "testing_data = select_data(testing)\n",
    "testing_features = select_features(testing)\n",
    "testing_observations = select_observations(testing)\n",
    "validation_data = select_data(validation)\n",
    "validation_features = select_features(validation)\n",
    "validation_observations = select_observations(validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130dfe84",
   "metadata": {},
   "source": [
    "## 2. \n",
    "Train a random forest on your training set. Try to fine-tune the parameters of your predictor on your validation set using a simple grid search on the number of estimator \"n_estimators\" and the max depth of the trees \"max_depth\". Then, display a confusion matrix of your classification pipeline. Lastly, once you assessed your model, inspect the `feature_importances_` attribute of your random forest and discuss the obtained results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5798b277",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">Some imports..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4a8c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c2e225",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">We build a simple pipeline which consists in a `TfidfVectorizer` followed by a random `RandomForestClassifier`. This will work as follows:\n",
    "\n",
    "1. <span style=\"color:blue\">Documents fed to the pipeline will be tokenized and converted into a token count matrix.\n",
    "2. <span style=\"color:blue\">The matrix will be converted into a TF-IDF representation (i.e. normalized term frequency times inverse document frequence)\n",
    "3. <span style=\"color:blue\">We feed the output to a random forest classifier which will fit the samples to a series of decision trees.\n",
    "\n",
    "<span style=\"color:blue\">Note: We are building the full pipeline here (i.e. including the first step which we did before) because one may want to perform a grid search for parameters of the TF-IDF vectorizer too (although this is not asked in the question)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c1e05a6",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">We evaluate precision with cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef4e1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = cross_val_score(logistic, X, y, cv=10, scoring = \"precision\")\n",
    "recall = cross_val_score(logistic, X, y, cv=10, scoring = \"recall\")\n",
    "\n",
    "print(\"Precision: %0.2f (+/- %0.2f)\" % (precision.mean(), precision.std() * 2))\n",
    "print(\"Recall: %0.2f (+/- %0.2f)\" % (recall.mean(), recall.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17bf0d23",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\"> Here we use the builtin function `predict_proba` to evaluate the probability that each subject belongs in treat or non treat class. The probability of belonging to the positive class (treat == 1) gives the propensy score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e1b778",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = logistic.predict_proba(X) \n",
    "print(logistic.classes_) # to see which column corresponds to which class, the positive case corresponds to column 1\n",
    "lalonde['propensy_score'] = pd.Series(prediction[:,1], index = lalonde.index)\n",
    "lalonde.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db64fcc",
   "metadata": {},
   "source": [
    "## 4. Balancing the dataset via matching\n",
    "\n",
    "Use the propensity scores to match each data point from the treated group with exactly one data point from the control group, while ensuring that each data point from the control group is matched with at most one data point from the treated group.\n",
    "(Hint: you may explore the `networkx` package in Python for predefined matching functions.)\n",
    "\n",
    "Your matching should maximize the similarity between matched subjects, as captured by their propensity scores.\n",
    "In other words, the sum (over all matched pairs) of absolute propensity-score differences between the two matched subjects should be minimized.\n",
    "\n",
    "After matching, you have as many treated as you have control subjects.\n",
    "Compare the outcomes (`re78`) between the two groups (treated and control).\n",
    "\n",
    "Also, compare again the feature-value distributions between the two groups, as you've done in part 2 above, but now only for the matched subjects.\n",
    "What do you observe?\n",
    "Are you closer to being able to draw valid conclusions now than you were before?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2327e1ba",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\"> In order to match the data from the treated group with exactly one data point from the control group, we use the `networkx` package. The `bipartite` module allows us to create a bipartite graph with two node sets (treated and non treated) and edges that only connect nodes from opposite sets. Nodes correspond to indexes of the lalong dataset. Edges correspond to all possible connections between nodes from the treated side and nodes from the untreated side. Each edge has a weight wich corresponds to `1 - abs(propensy_score(node1) - propensy_score(node2))`. Therefore the weight interval is [0,1], with 1 being the highest weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac50f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.Graph()\n",
    "G.add_nodes_from(lalonde.index[lalonde.treat == 0], bipartite = 0)\n",
    "G.add_nodes_from(lalonde.index[lalonde.treat == 1], bipartite = 1)\n",
    "\n",
    "# Add edges with weight, as the max weight matching function will match with maximum weight, we do 1 - the difference of propensy score\n",
    "# This means the weight is maximum if 1 and minimum if 0.\n",
    "for node0, weight0 in zip(lalonde.index[lalonde.treat == 0], lalonde.propensy_score[lalonde.treat == 0]):\n",
    "    for node1, weigth1 in zip(lalonde.index[lalonde.treat == 1], lalonde.propensy_score[lalonde.treat == 1]):\n",
    "        G.add_edge(node0, node1, weight = 1- abs(weight0 - weigth1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e98d3c7",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">We compute a maximum weight matching (using the `max_weight_matching` function) using edge weights. This matching ensures no node occurs more than once. The `maxcardinality` parameter is set to true in order to compute the maximum-cardinality matching with maximum weight among all maximum-cardinality matchings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2736b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "match = nx.max_weight_matching(G, maxcardinality = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3f73d8",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\"> Once we have the matching, we can extract the two sets of matched nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a3f5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "bottom_nodes, top_nodes = bipartite.sets(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4fb11f",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\"> We now create a new dataset containing only the matched elements. This will allow us to compute the same observations as done in points 1.1 and 1.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c366b92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare outcome re78 between the two groups\n",
    "lalonde_matched = lalonde.loc[list(match.keys())]\n",
    "\n",
    "ax = lalonde_matched.boxplot(column = ['re78'], by = ['treat'] ,figsize=(12,6))\n",
    "ax.set_xlabel('Program completion')\n",
    "ax.set_ylabel('Revenue in 1978')\n",
    "ax.set_title('Revenue in 1978 as a function of program completion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6f1c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for features in ['age', 'educ', 're74', 're75']:\n",
    "    ax = lalonde_matched.boxplot(column = [features], by = ['treat'] ,figsize=(12,6))\n",
    "    ax.set_xlabel('Program completion')\n",
    "    ax.set_ylabel(features)\n",
    "    ax.set_title(features+ ' as a function of program completion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552603c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "treated = lalonde_matched[lalonde_matched['treat']==1]\n",
    "no_treated = lalonde_matched[lalonde_matched['treat']==0]\n",
    "\n",
    "a=0\n",
    "b=0\n",
    "legend = [['black', 'hispanic', 'white'],['not married', 'married'],['no degree', 'degree']]\n",
    "\n",
    "for feature in ['race', 'married', 'degree']:\n",
    "    pie = treated.groupby(feature).count().plot.pie(y='treat', autopct=\"%2f\").legend(labels=legend[a] , loc=\"best\")\n",
    "    plt.title(feature + ' repartition in subjects who completed the program')\n",
    "    a+=1\n",
    "    \n",
    "for feature in ['race', 'married', 'degree']:\n",
    "    pie = no_treated.groupby(feature).count().plot.pie(y='treat', autopct=\"%2f\").legend(labels=legend[b] , loc=\"best\")\n",
    "    plt.title(feature + ' repartition in subjects who did not completed the program')\n",
    "    b+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a0e15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "ax = sns.countplot(x=\"race\", hue=\"treat\", data=lalonde_matched)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f49b875",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">We observe that with the new dataset, the median of *re78* is slightly lower for the tratment group, and the distribution is similar. The age distribution changed for the control group, median age went from 25 to 21 years old. *educ* still has a similar distribution, and *re74* is still higher for the control group. The distribution became less extensive and the median re74 decreased for the control group. Similar observations can be made for *re75*. \n",
    "\n",
    "<span style=\"color:blue\">Marital status and degree obtention still show differences, but are now more similar between groups. There are still huge differences in race repartition between the two groups. We can decrease the bias in this dataset by grouping only subjects of the same race."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6373ab",
   "metadata": {},
   "source": [
    "## 5. Balancing the groups further\n",
    "\n",
    "Based on your comparison of feature-value distributions from part 4, are you fully satisfied with your matching?\n",
    "Would you say your dataset is sufficiently balanced?\n",
    "If not, in what ways could the \"balanced\" dataset you have obtained still not allow you to draw valid conclusions?\n",
    "\n",
    "Improve your matching by explicitly making sure that you match only subjects that have the same value for the problematic feature.\n",
    "Argue with numbers and plots that the two groups (treated and control) are now better balanced than after part 4."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afcb3dea",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">The most problematic feature is the *race* attribute. It can be improved by selecting only the matched elements that have the same race value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943ef090",
   "metadata": {},
   "outputs": [],
   "source": [
    "lalonde_cleaned_index = []\n",
    "l = len(lalonde_matched) -1\n",
    "\n",
    "for i in range(0,l,2):\n",
    "    if lalonde_matched.iloc[i].race == lalonde_matched.iloc[i+1].race:\n",
    "        lalonde_cleaned_index.append(lalonde_matched.iloc[i].name)\n",
    "        lalonde_cleaned_index.append(lalonde_matched.iloc[i+1].name)\n",
    "\n",
    "lalonde_cleaned_index\n",
    "lalonde_cleaned = lalonde_matched.loc[lalonde_cleaned_index]\n",
    "lalonde_cleaned.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126fea10",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\"> Let's see what we now have..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d46121",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('clf', RandomForestClassifier()),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be93c816",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\"> We define the parameters and value ranges we are interested in for the grid search.\n",
    "\n",
    "<span style=\"color:blue\"> For this assignment, we use the following:\n",
    "* <span style=\"color:blue\">`n_estimators`: ranges from $2^0$ to $2^{10}$.\n",
    "* <span style=\"color:blue\">`max_depth`: ranges from 10 to 200 in increments of 10.\n",
    "\n",
    "<span style=\"color:blue\">These values represent a trade-off between grid search execution time and quality of the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bfa56c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'clf__n_estimators': list(map(lambda n: 2**n, range(0,11))),\n",
    "    'clf__max_depth': list(range(10,210,10))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83edc9fe",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">We perform the grid search with 5-fold cross-validation..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb372a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1, verbose=1)\n",
    "\n",
    "print('Starting grid search...')\n",
    "start = time()\n",
    "grid_search.fit(validation_data, validation_observations)\n",
    "end = time()\n",
    "print('Grid search completed in %0.3fs' % (end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ec082a",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">... and the best score we have achieved is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d36c29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb630fc",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">Using the following parameter values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31cd65b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_parameters = grid_search.best_estimator_.get_params()\n",
    "\n",
    "print('''Best values:\n",
    "\\tn_estimators = %d\n",
    "\\tmax_depth = %d''' % (best_parameters['clf__n_estimators'], best_parameters['clf__max_depth']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da0395d",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">Now that we have the parameters fine-tuned, we apply them to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf5cb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.set_params(clf__n_estimators=best_parameters['clf__n_estimators'], clf__max_depth=best_parameters['clf__max_depth'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57090319",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">Let's train the pipeline using our training subset..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d03e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.fit(training_data, training_observations).score(training_data, training_observations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b978d42d",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">And now let's see how well we do on the testing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9a7dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(figsize=(12,8))\n",
    "ax1 = sns.countplot(x=\"race\", hue=\"treat\", data=lalonde_cleaned)\n",
    "\n",
    "fig, ax2 = plt.subplots(figsize=(12,8))\n",
    "ax2 = sns.countplot(x=\"married\", hue=\"treat\", data=lalonde_cleaned)\n",
    "\n",
    "fig, ax3 = plt.subplots(figsize=(12,8))\n",
    "ax3 = sns.countplot(x=\"degree\", hue=\"treat\", data=lalonde_cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79956b18",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\"> Looking at the graphs above, we can see that the two populations are very close with respect to race, education and marriage. We can now plot them again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f663b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.score(testing_data, testing_observations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8012f77",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">We get an accuracy of 66%. Cool :-)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a0708b",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">We now plot the confusion matrix of our pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c18053",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "np.set_printoptions(precision=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae2cb9b",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">Here is a helper function to draw the plot. Adapted from [here](http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767cccc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e128636a",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">Now we compute the confusion matrix. Simply use the trained model to predict classes for the testing data and then compare with the actual ground truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b86429b",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_predicted = pipeline.predict(testing_data)\n",
    "cnf_matrix = confusion_matrix(testing_observations, testing_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe449b7",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">Here comes the plot..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5d7b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,12))\n",
    "plot_confusion_matrix(cnf_matrix, classes=categories, normalize=True, title='Confusion matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5de882",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">The diagonal shows the proportion of correctly classified elements. As we can see, this is pretty good, indicating that the classes of many elements were correctly predicted. Nevertheless, there seems to be a non-trivial amount of confusion between a few classes. We might be able to improve this if we had more data, if we could fine-tune the parameters even better, or if we could refine the features. Unfortunately, this is beyond the scope of this assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e08f345",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">Finally, we take a closer look at the important features. We start with a simple scatter plot of all features along with their importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04ad361",
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in ['age', 'educ', 're74', 're75']:\n",
    "    ax = lalonde_cleaned.boxplot(column = [features], by = ['treat'] ,figsize=(12,6))\n",
    "    ax.set_xlabel('Program completion')\n",
    "    ax.set_ylabel(feature)\n",
    "    ax.set_title(feature + ' as a function of program completion')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b696503d",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">The two populations are now similar according to race, and still pretty similar according to marital status and degree obtention. The current dataset is less biased than before."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829862e8",
   "metadata": {},
   "source": [
    "## 6. A less naive analysis\n",
    "\n",
    "Compare the outcomes (`re78`) between treated and control subjects, as you've done in part 1, but now only for the matched dataset you've obtained from part 5.\n",
    "What do you conclude about the effectiveness of the job training program?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c639ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original boxplots as a reminder \n",
    "ax = lalonde.boxplot(column = ['re78'], by = ['treat'] ,figsize=(12,6))\n",
    "ax.set_xlabel('Program completion')\n",
    "ax.set_ylabel('Revenue in 1978')\n",
    "ax.set_title('Revenue in 1978 as a function of program completion, biased dataset')\n",
    "\n",
    "# Compare outcome re78 between the two groups when the race is set to be the same\n",
    "ax = lalonde_cleaned.boxplot(column = ['re78'], by = ['treat'] ,figsize=(12,6))\n",
    "ax.set_xlabel('Program completion')\n",
    "ax.set_ylabel('Revenue in 1978')\n",
    "ax.set_title('Revenue in 1978 as a function of program completion, clean dataset')\n",
    "\n",
    "lalonde_cleaned.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1430cd09",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">Both distribution are less extensive (mind the scale!), and the median real earning of the treatment group is now higher than for the control group, even if both medians are now lower than in the original dataset. The 25%-quartile is nonzero for the treatment group, meaning that more people now have a job while it was not the case in 1974 and 1975, before the formation program. We can now conclude with reasonable certainty that the program had a positive effect on real earnings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27a27ce",
   "metadata": {},
   "source": [
    "# Question 2: Applied ML\n",
    "\n",
    "We are going to build a classifier of news to directly assign them to 20 news categories. Note that the pipeline that you will build in this exercise could be of great help during your project if you plan to work with text!\n",
    "\n",
    "## 1.\n",
    "\n",
    "Load the 20newsgroup dataset. It is, again, a classic dataset that can directly be loaded using sklearn ([link](http://scikit-learn.org/stable/datasets/twenty_newsgroups.html)).  [TF-IDF](https://en.wikipedia.org/wiki/Tf%E2%80%93idf), short for term frequencyâ€“inverse document frequency, is of great help when if comes to compute textual features. Indeed, it gives more importance to terms that are more specific to the considered articles (TF) but reduces the importance of terms that are very frequent in the entire corpus (IDF). Compute TF-IDF features for every article using [TfidfVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html). Then, split your dataset into a training, a testing and a validation set (10% for validation and 10% for testing). Each observation should be paired with its corresponding label (the article category)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dab15a9",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\"> Let's start with a bunch of imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53b434d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6428ae6",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\"> We get the data, stripping headers, footers, and quotes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17481cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "newsgroups = fetch_20newsgroups(subset='all', remove=('headers', 'footers', 'quotes'))\n",
    "categories = list(newsgroups.target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5184c7",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\"> We then compute the TF-IDF features for all articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe0e909",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = pipeline.steps[1][1]\n",
    "importances = forest.feature_importances_\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.scatter(range(len(importances)), importances)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa43644b",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">As we can see, a large majority of the features have very low importance or no importance at all. There are very few outliers in the plot.\n",
    "\n",
    "<span style=\"color:blue\">Let's see how many features have a score $\\ge 0.001$..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6dbaf7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = lalonde.boxplot(column=['re78'], by=['treat'], figsize=(12,6))\n",
    "ax.set_xlabel('Program completion')\n",
    "ax.set_ylabel('RE in 1978')\n",
    "ax.set_title('Real earnings in 1978 as a function of program completion')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565ed272",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">At first glance, we can observe a similar distribution and an equivalent median between the two groups. A naive interpretation would be that the treatment had no effect on the outcome (real earnings in 1978)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e581ec41",
   "metadata": {},
   "source": [
    "## 2. A closer look at the data\n",
    "\n",
    "You're not naive, of course (and even if you are, you've learned certain things in ADA), so you aren't content with a superficial analysis such as the above.\n",
    "You're aware of the dangers of observational studies, so you take a closer look at the data before jumping to conclusions.\n",
    "\n",
    "For each feature in the dataset, compare its distribution in the treated group with its distribution in the control group, using plots and numbers.\n",
    "As above, you may use the techniques we discussed in class for summarizing and comparing the distributions.\n",
    "\n",
    "What do you observe?\n",
    "Describe what your observations mean for the conclusions drawn by the naive \"researcher\" from his superficial analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a04c42",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">We display several boxplots, one for each feature, grouped by the *treat* feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f5aa6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in ['age', 'educ', 're74', 're75']:\n",
    "    ax = lalonde.boxplot(column=[feature], by=['treat'], figsize=(12,6))\n",
    "    ax.set_xlabel('Program completion')\n",
    "    ax.set_ylabel(feature)\n",
    "    ax.set_title(feature + ' as a function of program completion')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c30cf526",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">We also compute several pie charts for the tertiary/binary features *race*, *married* and *degree*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab2768c",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=0\n",
    "b=0\n",
    "legend = [['black', 'hispanic', 'white'],['not married', 'married'],['no degree', 'degree']]\n",
    "\n",
    "for feature in ['race', 'married', 'degree']:\n",
    "    pie = no_treat.groupby(feature).count().plot.pie(y='treat', autopct=\"%2f\").legend(labels=legend[a] , loc=\"best\")\n",
    "    plt.title(feature + ' repartition in subjects who did not complete the program')\n",
    "    a+=1\n",
    "    \n",
    "for feature in ['race', 'married', 'degree']:\n",
    "    pie = treat.groupby(feature).count().plot.pie(y='treat', autopct=\"%2f\").legend(labels=legend[b] , loc=\"best\")\n",
    "    plt.title(feature + ' repartition in subjects who completed the program')\n",
    "    b+=1    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7a3ad1",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">Regarding age, we can observe an equivalent median, with a larger distribution for the control group. Number of education years show the same median value, with similar distribution across groups. \n",
    "\n",
    "<span style=\"color:blue\">However, there is a clear difference for real earnings in 1974 and 1975. The median of *re74* is 0 for the treatment group and higher for the control group, meaning that probably a lot of people in the treatment group had originally no job. It also has a lower 75-quartile: real earnings were originally much lower for people who ended up following the program years later. The same observation can be made for *re75*, even if the treatment group shows an increased 75-quartile, while the distribution for the control group shrinked. The median is still 0 for the treatment group and lower for the control group.\n",
    "\n",
    "<span style=\"color:blue\">The control group shows great disparity within race, people are mainly white (65%). Marital status is evenly distributed, and 60% of people have no degree. The treatment group shows even more disparity within race, 84% of people being black; marital status and degree obtention are different as well. \n",
    "\n",
    "<span style=\"color:blue\">As a first observation, we could say that the program permitted people to get a job and/or increase their real earnings, but the two groups are too different and biased to draw conclusions with any certainty."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99802909",
   "metadata": {},
   "source": [
    "## 3. A propensity score model\n",
    "\n",
    "Use logistic regression to estimate propensity scores for all points in the dataset.\n",
    "You may use `sklearn` to fit the logistic regression model and apply it to each data point to obtain propensity scores:\n",
    "\n",
    "```python\n",
    "from sklearn import linear_model\n",
    "logistic = linear_model.LogisticRegression()\n",
    "```\n",
    "\n",
    "Recall that the propensity score of a data point represents its probability of receiving the treatment, based on its pre-treatment features (in this case, age, education, pre-treatment income, etc.).\n",
    "To brush up on propensity scores, you may read chapter 3.3 of the above-cited book by Rosenbaum or [this article](https://drive.google.com/file/d/0B4jctQY-uqhzTlpBaTBJRTJFVFE/view).\n",
    "\n",
    "Note: you do not need a train/test split here. Train and apply the model on the entire dataset. If you're wondering why this is the right thing to do in this situation, recall that the propensity score model is not used in order to make predictions about unseen data. Its sole purpose is to balance the dataset across treatment groups.\n",
    "(See p. 74 of Rosenbaum's book for an explanation why slight overfitting is even good for propensity scores.\n",
    "If you want even more information, read [this article](https://drive.google.com/file/d/0B4jctQY-uqhzTlpBaTBJRTJFVFE/view).)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdaf4fc4",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">We create a train the linear regression model. This model will enable us to obtain propensity scores for all points in the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5437b389",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = ['age', 'educ', 'married', 'race', 'degree', 're74', 're75', 're78']\n",
    "X = lalonde[feature_cols]\n",
    "y = lalonde.treat\n",
    "\n",
    "logistic = linear_model.LogisticRegression()\n",
    "logistic.fit(X,y) # train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d91ca1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = TfidfVectorizer().fit_transform(newsgroups.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f42478",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\"> Let's see what that looks like..."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
