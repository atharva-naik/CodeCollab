{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32933bd8",
   "metadata": {},
   "source": [
    "# Intro\n",
    "The goal of this notebook is to build an image classifier for images of building's facades (label 'Facade') or interiors (label 'Flat').\n",
    "\n",
    "Dataset with train images is provided by Happs team (http://namr.com/data/cv/data.zip)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15918939",
   "metadata": {},
   "source": [
    "## Module Imports\n",
    "First of all we need to import all necessary modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7cdccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt \n",
    "\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from keras.layers import Input, Lambda, Dense, BatchNormalization, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D, Dropout\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam, Adagrad, SGD, RMSprop\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f965809",
   "metadata": {},
   "source": [
    "## Initialize common variables\n",
    "We set random seed and some shared variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5d1da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read batch of data\n",
    "bx, by = next(train_iterator)\n",
    "\n",
    "# Show images\n",
    "image_plots(imgs=bx[:20], titles=by[:20], rows=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac728f6",
   "metadata": {},
   "source": [
    "Everything seems to be ok, we have images of interiors and facades as expected. Also we can see that image labels represented in '1-hot-encoded' form, which means that label 'Facade' has code `[1, 0]` and 'Flat' is `[0, 1]`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56586a21",
   "metadata": {},
   "source": [
    "## Validation Dataset\n",
    "In order to evaluate performance of the classifier we are building, we should use validation data. It is not appropriate to evaluate performance on the training data.\n",
    "But in the original data zip file from Happs there are no validation images. \n",
    "\n",
    "There are some possible solutions. First of all, we can split train data into 2 subsets with ratio like 80/20 to construct validation dataset. But in our case, training data is already small and we'll need it all to perform training. \n",
    "\n",
    "Second option is to mine missing data ourselves, and it is that what was done. Custom validation data was copied from internet and saved to `data/val-custom` directory. It is important to remind, that we will *not use validation data* for training. Validation dataset is used only to evalute perfomance of image classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70ae5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use custom validation dataset\n",
    "VAL_PATH = os.path.join(DATA_PATH, 'val-custom')\n",
    "# Create image iterator\n",
    "val_iterator = image_gen.flow_from_directory(VAL_PATH, \n",
    "                                            batch_size=1, \n",
    "                                            target_size=TARGET_SIZE, \n",
    "                                            shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddaf9d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many images per class?\n",
    "class_idx = classes_stat(val_iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d53c1c0",
   "metadata": {},
   "source": [
    "# Building Image Classifier\n",
    "Our task \"to classify images into 2 classes\" is a classical image recognition task where the state-of-the-art solutions are Convolutional Neural Networks (CNN). \n",
    "\n",
    "So we will start with building VGG-like custom CNN."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e785fea",
   "metadata": {},
   "source": [
    "## VGG-like custom CNN\n",
    "Our model will have:\n",
    "- 4 Convolution layers (2 layers with 64 filters, and 2 layers with 32 filters);\n",
    "- Each block of Convolution layers will have one Max Pool layer;\n",
    "- On the top we will put 2 Dense non-linear layers; \n",
    "- 1 Dense softmax layer to output predictions. \n",
    "\n",
    "\n",
    "*Note*: There are no strict theory on how to define hyper-parameters (how many layers-filters-etc do we need), so all parameters below are just some reasonable \"start-with\" values.\n",
    "\n",
    "\n",
    "To build the model we will use Keras framework with Tensorflow backend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421f3bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper to build VGG-like CNN model\n",
    "def build_cnn_model():\n",
    "    # Prepare input for model with custom input shape\n",
    "    input_tensor = Input(shape=INPUT_SHAPE)\n",
    "    \n",
    "    # Conv block 64 filters\n",
    "    x = Convolution2D(64, 3)(input_tensor)\n",
    "    x = Convolution2D(64, 3)(x)\n",
    "    x = MaxPooling2D()(x)\n",
    "    \n",
    "    # Conv block 32 filters\n",
    "    x = Convolution2D(32, 3)(x)\n",
    "    x = Convolution2D(32, 3)(x)\n",
    "    x = MaxPooling2D()(x)\n",
    "    x = Flatten()(x)\n",
    "    \n",
    "    # Dense block for classification\n",
    "    x = Dense(32, activation='relu')(x)\n",
    "    x = Dense(32, activation='relu')(x)\n",
    "    pred_layer = Dense(NUM_CLASSES, activation='softmax', name='predictions')(x)\n",
    "\n",
    "    # Build and compile model\n",
    "    model = Model(inputs=input_tensor, outputs=pred_layer)\n",
    "    model.compile(optimizer=SGD(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7454c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model object\n",
    "model = build_cnn_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e0f70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup variables\n",
    "val_steps = val_iterator.n  # number of val images\n",
    "\n",
    "# Train the model\n",
    "model.fit_generator(train_iterator,\n",
    "                    steps_per_epoch=10, \n",
    "                    epochs=3, \n",
    "                    validation_data=val_iterator, \n",
    "                    validation_steps=val_steps)\n",
    "\n",
    "# Slow down learning rate and continue to train\n",
    "model.optimizer.lr = 1E-5\n",
    "model.fit_generator(train_iterator,\n",
    "                    steps_per_epoch=10, \n",
    "                    epochs=5, \n",
    "                    validation_data=val_iterator, \n",
    "                    validation_steps=val_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa82fffc",
   "metadata": {},
   "source": [
    "Results are not very satisfying: validation loss and accuracy is stagnating around the same level. \n",
    "\n",
    "The fact is that our model has almost 3M parameters and only 50 training images. \n",
    "\n",
    "To deal with that, let's use a *\"data augmentation\"* trick. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0613948f",
   "metadata": {},
   "source": [
    "## Data Augmentation\n",
    "Data augmentation is a technique to add some random transformations (like rotation or zooming) to the original images to generate the new one. Important condition is to keep images realistic enough after transformation. \n",
    "\n",
    "Let's change a bit image generator to add some random transformation into the images. That will allow us to \"strech\" our intial dataset into something bigger!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a02d242",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image generator with random transformations\n",
    "image_trans_gen = ImageDataGenerator(rescale=1./255, \n",
    "                                     channel_shift_range=8,\n",
    "                                     horizontal_flip=True,\n",
    "                                     rotation_range=3, \n",
    "                                     zoom_range=(1.0, 0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44239e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train image iterator with random transformations\n",
    "train_iterator = image_trans_gen.flow_from_directory(TRAIN_PATH, \n",
    "                                               batch_size=BATCH_SIZE, \n",
    "                                               target_size=TARGET_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98fd99ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's plot transformed images\n",
    "bx, by = next(train_iterator)\n",
    "image_plots(imgs=bx[:20], titles=by[:20], rows=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc6724b",
   "metadata": {},
   "source": [
    "Now we can train the model again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65df4d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_cnn_model()\n",
    "\n",
    "# Train the model\n",
    "model.fit_generator(train_iterator,\n",
    "                    steps_per_epoch=10, \n",
    "                    epochs=2, \n",
    "                    validation_data=val_iterator, \n",
    "                    validation_steps=val_steps)\n",
    "\n",
    "# Slow down learning rate and continue to train\n",
    "model.optimizer.lr = 1E-5\n",
    "model.fit_generator(train_iterator,\n",
    "                    steps_per_epoch=10, \n",
    "                    epochs=5, \n",
    "                    validation_data=val_iterator, \n",
    "                    validation_steps=val_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33dfb51",
   "metadata": {},
   "source": [
    "Apparently, our results are better than before, but let's see if we can do better!\n",
    "\n",
    "It could be a chance to try another helpful technique: *transfer learning*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f0b42d",
   "metadata": {},
   "source": [
    "## Transfer Learning\n",
    "Transfert learning is a method of building new neural network when we re-use pre-trained weights of other network (more details about transfert learning: https://cs231n.github.io/transfer-learning/).\n",
    "\n",
    "In out case we will take Convolutional Neural Network VGG16 with weights pre-trained on 'Imagenet' dataset.\n",
    "\n",
    "In 'Imagenet' there are 1000 classes, but we have 2. So we will adapt the top layers of network to produce predictions for 2 classes, and we will train only these added layers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6fc011",
   "metadata": {},
   "source": [
    "## Transfert Learning with VGG16 Network\n",
    "Let's build adapted VGG16 model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b91f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vgg_ft_model():\n",
    "    # Prepare input for model with custom input shape\n",
    "    input_tensor = Input(shape=INPUT_SHAPE)\n",
    "\n",
    "    # Build model with pretrained weights and not top layers\n",
    "    base_model = VGG16(input_shape=INPUT_SHAPE,\n",
    "                           input_tensor=input_tensor,\n",
    "                           weights='imagenet',\n",
    "                           include_top=False)\n",
    "\n",
    "    # Freeze layers so training will not change its weights\n",
    "    for layer in base_model.layers: layer.trainable = False\n",
    "\n",
    "    # Add dense output with num_classes\n",
    "    x = base_model.output\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dropout(0.5, name='drop')(x)\n",
    "    x = Dense(32, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dense(32, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    pred_layer = Dense(NUM_CLASSES, activation='softmax', name='predictions')(x)\n",
    "\n",
    "    # Build model for provided classes\n",
    "    model = Model(inputs=base_model.input, outputs=pred_layer)\n",
    "    model.compile(optimizer=Adam(lr=1E-4), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f207cd25",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_vgg_ft_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6bf479",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "model.fit_generator(train_iterator, \n",
    "                    steps_per_epoch=10, \n",
    "                    epochs=5, \n",
    "                    validation_data=val_iterator, \n",
    "                    validation_steps=val_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925e8258",
   "metadata": {},
   "source": [
    "This model shows much better results! Indeed, combination of data augmentation and transfer learning allows us to train a good model with very few intial training data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7c9130",
   "metadata": {},
   "source": [
    "## Note on Overfitting\n",
    "Sometimes model's perfomance on validation data drops after several epochs. It was the case with both custom CNN and VGG16-based CNN. \n",
    "\n",
    "It is a sign of overfitting, and maybe we could have added 'early stopping' to prevent model from overfitting and save training time, but due to the limit time we will not add this step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de85579",
   "metadata": {},
   "source": [
    "## Save prediction results\n",
    "In the end let's save trained model's weights so we can reuse it later without need to train it again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991642b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed\n",
    "from numpy.random import seed\n",
    "seed(42)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(42)\n",
    "\n",
    "# Global variables\n",
    "BATCH_SIZE = 128\n",
    "TARGET_SIZE=(224, 224)  # Resize input images to that size\n",
    "INPUT_SHAPE = TARGET_SIZE + (3,)\n",
    "NUM_CLASSES = 2  \n",
    "DATA_PATH = './data/'  # Root data path\n",
    "TRAIN_PATH = os.path.join(DATA_PATH, 'train')  # Train data path \n",
    "VAL_PATH = os.path.join(DATA_PATH, 'val')  # Validation data path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c5b516",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c883d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classes_stat(image_iterator):\n",
    "    \"\"\"\n",
    "    Function to print how many items per class has `image_iterator`.\n",
    "    Returns dictionary `class_idx` to match class index to label\n",
    "    \"\"\"\n",
    "    classes = image_iterator.classes\n",
    "    class_idx = {v:k for k, v in image_iterator.class_indices.items()}\n",
    "    for c in np.unique(classes):\n",
    "        count = np.sum(classes==c)\n",
    "        print('Class {} ({}): {} items'.format(c, class_idx[c], count))\n",
    "    return class_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75cafc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_plots(imgs, figsize=(12,8), rows=1, interp=False, titles=None):\n",
    "    \"\"\"\n",
    "    Function to plot images from `imgs` array with optional labels from `titles`.\n",
    "    Images will be plot in one figure with number of `rows`. \n",
    "    \"\"\"\n",
    "    f = plt.figure(figsize=figsize)\n",
    "    cols = len(imgs)//rows if len(imgs) % 2 == 0 else len(imgs)//rows + 1\n",
    "    for i in range(len(imgs)):\n",
    "        sp = f.add_subplot(rows, cols, i+1)\n",
    "        sp.axis('Off')\n",
    "        if titles is not None:\n",
    "            sp.set_title(titles[i], fontsize=12)\n",
    "        plt.imshow(imgs[i], interpolation=None if interp else 'none')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83e9384",
   "metadata": {},
   "source": [
    "# Dataset Exploration\n",
    "Let's check how many images do we have in the training dataset. Also let's plot some of the images to have an idea what kind of content is there."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a61b0fa",
   "metadata": {},
   "source": [
    "## Train Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc480a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create image generator to read images from directory \n",
    "# and rescale pixel values from range [0; 255] to [0;1] \n",
    "image_gen = ImageDataGenerator(rescale=1.0/255)\n",
    "train_iterator = image_gen.flow_from_directory(TRAIN_PATH, \n",
    "                                               batch_size=BATCH_SIZE, \n",
    "                                               target_size=TARGET_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ab12d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many images per class?\n",
    "_ = classes_stat(train_iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19cbd345",
   "metadata": {},
   "source": [
    "Indeed we have 2 classes of images. Also it is clear that our dataset is quite small - 50 images total. That could be a challenge to train an image classifier.\n",
    "\n",
    "To finish with data exploration, we will plot images from one batch of train dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337026fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save weights and model\n",
    "model.save_weights('./vgg16ft_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceaf05da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load saved weights\n",
    "model.load_weights('./vgg16ft_weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ea5fc5",
   "metadata": {},
   "source": [
    "Also let's run prediction of labels on validation dataset and save that as csv file."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
