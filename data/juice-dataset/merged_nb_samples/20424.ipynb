{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4245bc1",
   "metadata": {},
   "source": [
    "### Environment Reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f252ba1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#environment reset\n",
    "\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8153f4a",
   "metadata": {},
   "source": [
    "### Try to Jump!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6425826",
   "metadata": {},
   "source": [
    "### greedy action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0199ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import gym\n",
    "import ppaquette_gym_super_mario\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import gym \n",
    "from wrapper import action_space\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers import Dense, Flatten, Input, Lambda, merge\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.models import Model\n",
    "#from skimage.transform import resize\n",
    "from skimage.color import rgb2gray\n",
    "from collections import deque\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from sum_tree import SumTree\n",
    "import random\n",
    "\n",
    "\n",
    "env = gym.make('ppaquette/meta-SuperMarioBros-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d752c4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "wra_act=action_space\n",
    "\n",
    "#reduce actions\n",
    "env=wra_act.mario_action(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6060ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reduce pixel\n",
    "\n",
    "\n",
    "env=wra_act.ProcessFrame84(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4010e381",
   "metadata": {},
   "source": [
    "### environment reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583464c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs=env.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e056c8",
   "metadata": {},
   "source": [
    "### checking shape of the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0fc676",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "epsilon=0.99\n",
    "def get_action():\n",
    "    \n",
    "\n",
    "    \n",
    "    if np.random.rand() <= epsilon:\n",
    "        return random.choice(actions)\n",
    "    else:\n",
    "        q_value = model.prediction(history)\n",
    "        return np.argmax(q_value[0])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5147a64d",
   "metadata": {},
   "source": [
    "#check "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4319f70",
   "metadata": {},
   "source": [
    "### Check if the get_action is working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d3d3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon= 0.9\n",
    "\n",
    "for i in range(100):\n",
    "    action=get_action()\n",
    "    env.step(action)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d17bde0",
   "metadata": {},
   "source": [
    "### append <s,a,r,s'> at replay memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce18cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(obs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03a9935",
   "metadata": {},
   "source": [
    "### Reshape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2832c707",
   "metadata": {},
   "outputs": [],
   "source": [
    "reshape_obs=np.reshape([obs],(1,84,84,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f45f08",
   "metadata": {},
   "source": [
    "### Make history using the observation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004c0b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "action_size=6\n",
    "epsilon = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72bb01c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_sample(history, action, reward, next_history, done):\n",
    "    #TD ERROR \n",
    "    target=model.predict([history])\n",
    "    old_val = target[0][action]\n",
    "    target_val = target_model.predict(([next_history]))\n",
    "    \n",
    "    if done:\n",
    "        target[0][action] = reward\n",
    "    else:\n",
    "        target[0][action] = reward + discount_factor *  (np.amax(target_val[0]))\n",
    "    error= abs(old_val - target[0][action1])\n",
    "    memory.add(error,(history,action, reward, next_history, done))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a4598c",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.choice(actions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d307ea9",
   "metadata": {},
   "source": [
    "# Samples from replay memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9196450",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model():\n",
    "    if epsilon > epsilon_end:\n",
    "        epsilon -= epsilon_decay_step\n",
    "    mini_batch = memory.sample(batch_size)\n",
    "    \n",
    "    errors= np.zeros(batch_size)\n",
    "    history = np.zeros((self.batch_size, self.state_size[0],\n",
    "                            self.state_size[1], self.state_size[2]))\n",
    "    next_history = np.zeros((self.batch_size, self.state_size[0],\n",
    "                             self.state_size[1], self.state_size[2]))\n",
    "    target = np.zeros((self.batch_size,))\n",
    "    action, reward, dead = [], [], []\n",
    "\n",
    "    for i in range(self.batch_size):\n",
    "            history[i] = np.float32(mini_batch[i][1][0] / 255.)\n",
    "            next_history[i] = np.float32(mini_batch[i][1][3] / 255.)\n",
    "            action.append(mini_batch[i][1][1])\n",
    "            reward.append(mini_batch[i][1][2])\n",
    "            dead.append(mini_batch[i][1][4])\n",
    "\n",
    "    curr_q = self.model.predict(history)\n",
    "    value = self.model.predict(next_history)\n",
    "    target_value = self.target_model.predict(next_history)\n",
    "    for i in range(self.batch_size):\n",
    "            if dead[i]:\n",
    "                target[i] = reward[i]\n",
    "            else:\n",
    "                target[i] = reward[i] + self.discount_factor * \\\n",
    "                                        target_value[i][np.argmax(value[i])]\n",
    "            errors[i] = abs(curr_q[i][action[i]] - target[i])\n",
    "\n",
    "        # TD-error로 priority 업데이트\n",
    "    for i in range(self.batch_size):\n",
    "            idx = mini_batch[i][0]\n",
    "            self.memory.update(idx, errors[i])\n",
    "\n",
    "    loss = optimizer([history, action, target])\n",
    "    avg_loss += loss[0]\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9dd0e2",
   "metadata": {},
   "source": [
    "### Huber Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5deab0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimizer(self):\n",
    "        a = K.placeholder(shape=(None,), dtype='int32')\n",
    "        y = K.placeholder(shape=(None,), dtype='float32')\n",
    "\n",
    "        prediction = self.model.output\n",
    "\n",
    "        a_one_hot = K.one_hot(a, self.action_size)\n",
    "        q_value = K.sum(prediction * a_one_hot, axis=1)\n",
    "        error = K.abs(y - q_value)\n",
    "\n",
    "        quadratic_part = K.clip(error, 0.0, 1.0)\n",
    "        linear_part = error - quadratic_part\n",
    "        loss = K.mean(0.5 * K.square(quadratic_part) + linear_part)\n",
    "\n",
    "        optimizer = RMSprop(lr=0.00025, epsilon=0.01)\n",
    "        updates = optimizer.get_updates(self.model.trainable_weights, [], loss)\n",
    "        train = K.function([self.model.input, a, y], [loss], updates=updates)\n",
    "\n",
    "        return train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c72d162",
   "metadata": {},
   "source": [
    "### Store (sara) at in SumTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd00cfe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Memory:\n",
    "    e = 0.01\n",
    "    a = 0.6\n",
    "\n",
    "    def __init__(self, capacity):\n",
    "        self.tree = SumTree(capacity)\n",
    "        self.capacity = capacity\n",
    "\n",
    "    def _getPriority(self, error):\n",
    "        return (error + self.e) ** self.a\n",
    "\n",
    "    def add(self, error, sample):\n",
    "        p = self._getPriority(error)\n",
    "        self.tree.add(p, sample)\n",
    "\n",
    "    def sample(self, n):\n",
    "        batch = []\n",
    "        segment = self.tree.total() / n\n",
    "\n",
    "        for i in range(n):\n",
    "            a = segment * i\n",
    "            b = segment * (i + 1)\n",
    "\n",
    "            s = random.uniform(a, b)\n",
    "            (idx, p, data) = self.tree.get(s)\n",
    "            batch.append((idx, data))\n",
    "        return batch\n",
    "\n",
    "    def update(self, idx, error):\n",
    "        p = self._getPriority(error)\n",
    "        self.tree.update(idx, p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc75768a",
   "metadata": {},
   "source": [
    "### Update Target Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8162673",
   "metadata": {},
   "outputs": [],
   "source": [
    "history=np.stack((obs,obs,obs,obs), axis = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29be30f",
   "metadata": {},
   "source": [
    "### Reshape the history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3031c365",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = np.reshape([history], (1, 84, 84, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a35b7cb",
   "metadata": {},
   "source": [
    "### append "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd5d095",
   "metadata": {},
   "outputs": [],
   "source": [
    "history=np.append(reshape_obs, history[:,:,:,:3], axis=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf36901f",
   "metadata": {},
   "source": [
    "### Reshape again"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
