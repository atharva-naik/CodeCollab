{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ecaf3f4d",
   "metadata": {},
   "source": [
    "# Introduction to Regularization\n",
    "\n",
    "<a href=\"https://drive.google.com/file/d/1EZ_xqMaYj77vErVnrQmnFOj-VBEoO5uW/view\" target=\"_blank\">\n",
    "     <img src=\"http://www.deltanalytics.org/uploads/2/6/1/4/26140521/screen-shot-2019-01-05-at-4-48-29-pm_orig.png\" width=\"500\" height=\"400\">\n",
    "</a>\n",
    "\n",
    "In the context of regression, regularization refers to techniques to constrain/shrink the coefficient estimates towards zero.  \n",
    "Shrinking the coefficients can 1) improve the fit of the model and 2) reduce the variance of the coefficients.\n",
    "\n",
    "Two common types of regularization are ridge and lasso.  \n",
    "\n",
    "Recall that least squares linear regression minimizes the residual sum of squares (RSS).  In other words, it minimizes\n",
    "\n",
    "$ RSS = \\displaystyle \\sum^{n}_{i=1} (y_i - \\beta_0 - \\sum^{p}_{j=1} \\beta_j x_{ij})^2 $\n",
    "\n",
    "In ridge and lasso, we add a term to the value we are trying to minimize.  \n",
    "\n",
    "In ridge, we minimize \n",
    "\n",
    "$ RSS + \\lambda \\displaystyle \\sum^{p}_{j=1} \\beta_j^2 $\n",
    "\n",
    "In lasso, we minimize\n",
    "\n",
    "$ RSS + \\lambda \\displaystyle \\sum^{p}_{j=1} |\\beta_j| $\n",
    "\n",
    "The $\\lambda$ (pronounced \"lambda\") in the above values is a hyper-parameter which determines how 'strong' the regularization effect is.  Note: sometimes $\\alpha$ (pronounced \"alpha\") is used instead of $\\lambda$.\n",
    "\n",
    "A useful way to use ridge or lasso regression is to run the regression over a range of alphas and see which features maintain a large beta coefficient for the longest. It is these features which have the most predictive power!\n",
    "\n",
    "More in depth information can be found here: [Regularization Regression](https://www.analyticsvidhya.com/blog/2016/01/complete-tutorial-ridge-lasso-regression-python/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947af640",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load python packages\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "sns.set()\n",
    "sns.set(font_scale=1.5)\n",
    "\n",
    "# packages for checking assumptions\n",
    "from scipy import stats as stats\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "import statsmodels.formula.api as sm\n",
    "\n",
    "# packages for regularization\n",
    "from sklearn.linear_model import Lasso\n",
    "from math import pow, sqrt\n",
    "\n",
    "np.random.seed(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6222fc93",
   "metadata": {},
   "source": [
    "2) Load Data\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b59bf70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "path = '../data/'\n",
    "filename = 'loans.csv'\n",
    "df = pd.read_csv(path+filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdcb6f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternatively, if you are using Colab, get the data by git cloning the Delta Analytics repository\n",
    "!git clone https://github.com/DeltaAnalytics/machine_learning_for_good_data\n",
    "df = pd.read_csv(\"machine_learning_for_good_data/loans.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606d49ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b2024f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create indicator variables for country\n",
    "for country in df['location_country_code'].unique():\n",
    "    if country is not np.nan:\n",
    "        df['country_'+country] = np.where(df.location_country_code == country, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e360c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create indicator variables for sector\n",
    "for sect in df['sector'].unique():\n",
    "    df['sector_'+sect] = np.where(df.sector == sect, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bca36ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "# Define the dependent variable\n",
    "y = df['loan_amount']\n",
    "# Define the independent variables\n",
    "X = df[['lender_count', 'sector_Education', 'sector_Clothing', \n",
    "        'sector_Personal Use', 'sector_Retail', 'sector_Transportation', 'sector_Agriculture']]\n",
    "# Add an intercept term to the independent variables\n",
    "X['cnst'] = 1\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model1 = sm.OLS(endog = y_train,exog = X_train).fit()\n",
    "print(model1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14be4ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = np.arange(0.001, 0.502, 0.002)\n",
    "lasso_coefs = []\n",
    "X_train_lasso= X_train[X_train.columns.tolist()] # Select columns / features for model\n",
    "\n",
    "for a in alphas:\n",
    "    lassoreg = Lasso(alpha=a, copy_X=True, normalize=True)\n",
    "    lassoreg.fit(X_train_lasso, y_train)\n",
    "    lasso_coefs.append(lassoreg.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b5b17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_coefs = np.asarray(lasso_coefs).T\n",
    "\n",
    "plt.figure(figsize=(14,10))\n",
    "for coefs, feature in zip(lasso_coefs, X_train_lasso.columns):\n",
    "    plt.plot(alphas, coefs, label = feature)\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f7f8a7",
   "metadata": {},
   "source": [
    "Retail and Transportation go to 0 when alpha is 0.3.  Let's try removing these from the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe1ac3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "# Define the dependent variable\n",
    "y = df['loan_amount']\n",
    "# Define the independent variables\n",
    "X = df[['lender_count', 'sector_Education', 'sector_Clothing', \n",
    "        'sector_Personal Use', 'sector_Agriculture']]\n",
    "# Add an intercept term to the independent variables\n",
    "X['cnst'] = 1\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model2 = sm.OLS(endog = y_train,exog = X_train).fit()\n",
    "print(model2.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41ceb79",
   "metadata": {},
   "source": [
    "Even though we removed two dependent variables from the analysis, our R-squared and adjusted R-squared stayed the same.  This means that the two variables we removed (Transportation and Retail) are less important to loan amount.  The example above shows how we can use regularization for feature selection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25230d3e",
   "metadata": {},
   "source": [
    "# Important facts about regularization\n",
    "\n",
    "Recall that with least squares linear regression, the coefficients are scale equivariant.  In other words, multiplying a feature by a constant $c$ simply leads to a scaling of the least squares coefficient estimate by a factor of 1/$c$. \n",
    "\n",
    "Let's demonstrate this fact by creating a example set of data that has three variables: 1) amount of money made at a restaurant in one day, 2) distance in meters to the nearest university, 3) distance in kilometers to the nearest hospital."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9793d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1234)\n",
    "\n",
    "earnings = np.random.normal(2000, 300, 50)\n",
    "university_distances = np.random.normal(7000,2000,50)\n",
    "hospital_distances = np.random.normal(7,2,50)\n",
    "\n",
    "earnings = [a if a > 0 else -a for a in earnings]\n",
    "university_distances = [a if a > 0 else -a for a in university_distances]\n",
    "hospital_distances = [a if a > 0 else -a for a in hospital_distances]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7283f60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"earnings\": sorted(earnings), \"university\": sorted(university_distances, reverse=True), \n",
    "                   'hospital' : sorted(hospital_distances, reverse=True)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b0a81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0d34c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot distance to nearest university (in meters) vs. earnings\n",
    "ax = sns.regplot(x='earnings', y='university', data=df, fit_reg=False)\n",
    "ax.set_title('Scatter plot of distance to nearest university (in meters) vs earnings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec839b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot distance to nearest hospital (in kilometers) vs. earnings\n",
    "ax = sns.regplot(x='earnings', y='hospital', data=df, fit_reg=False)\n",
    "ax.set_title('Scatter plot of distance to nearest hospital (in kilometers) vs earnings')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c6bcff",
   "metadata": {},
   "source": [
    "Let's run a multivariate linear regression without scaling any variables and compare the results to a model where we standardize the distance variables to both use kilometers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a6285c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = sm.ols(formula = 'earnings ~ university + hospital', data = df).fit()\n",
    "print(model1.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b67c28",
   "metadata": {},
   "source": [
    "The R-squared is 0.938 and the Adjusted R-squared is 0.935.  The coefficients for the intercept, university, and hospital are 3024.1009, -0.0643, and -76.3083.  Now let's scale the university variable to be in kilometers instead of meters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84044462",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scaled = df.copy()\n",
    "df_scaled['university'] = df_scaled['university']/1000\n",
    "\n",
    "df_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e38bb9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = sm.ols(formula = 'earnings ~ university + hospital', data = df_scaled).fit()\n",
    "print(model2.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671ac536",
   "metadata": {},
   "source": [
    "The R-squared is 0.938 and the Adjusted R-squared is 0.935. The coefficients for the intercept, university, and hospital are 3024.1009, -64.3473, and -76.3083.   So we changed the university variable by scaling it by a constant and the resulting coefficient was scaled by the same constant.  The p-values did not change and the coefficients on the other variables did not change.\n",
    "\n",
    "What do you think scaling will do if we incorporate regularization by using lasso or ridge regression?  Do you think scaling will have an effect on the coefficients of the variables?\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3587704a",
   "metadata": {},
   "source": [
    "Let's run lasso on our unscaled data and our scaled data and see what happens."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f8c14d",
   "metadata": {},
   "source": [
    "# Unscaled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de3e474",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['university', 'hospital']]\n",
    "y = df['earnings']\n",
    "\n",
    "alphas = np.arange(0.001, 1, 0.002)\n",
    "lasso_coefs = []\n",
    "X_lasso= X[X.columns.tolist()] # Select columns / features for model\n",
    "\n",
    "for a in alphas:\n",
    "    lassoreg = Lasso(alpha=a, copy_X=True, normalize=True)\n",
    "    lassoreg.fit(X_lasso, y)\n",
    "    lasso_coefs.append(lassoreg.coef_)\n",
    "    \n",
    "lasso_coefs = np.asarray(lasso_coefs).T\n",
    "\n",
    "plt.figure(figsize=(14,10))\n",
    "for coefs, feature in zip(lasso_coefs, X_lasso.columns):\n",
    "    plt.plot(alphas, coefs, label = feature)\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b83ced",
   "metadata": {},
   "source": [
    "The above plot shows the coefficients for the university and hospital variables at 0 and approximately -75, respectively.  Would you keep or drop these variables from your model?  Why?\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623e1b0c",
   "metadata": {},
   "source": [
    "# Scaled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0791d371",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_scaled[['university', 'hospital']]\n",
    "y = df_scaled['earnings']\n",
    "\n",
    "alphas = np.arange(0.001, 1, 0.002)\n",
    "lasso_coefs = []\n",
    "X_lasso= X[X.columns.tolist()] # Select columns / features for model\n",
    "\n",
    "for a in alphas:\n",
    "    lassoreg = Lasso(alpha=a, copy_X=True, normalize=True)\n",
    "    lassoreg.fit(X_lasso, y)\n",
    "    lasso_coefs.append(lassoreg.coef_)\n",
    "    \n",
    "lasso_coefs = np.asarray(lasso_coefs).T\n",
    "\n",
    "plt.figure(figsize=(14,10))\n",
    "for coefs, feature in zip(lasso_coefs, X_lasso.columns):\n",
    "    plt.plot(alphas, coefs, label = feature)\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92041332",
   "metadata": {},
   "source": [
    "The above plot shows the coefficient for the university and hospital variables are at around -64 and -76, respectively.  Would you keep or drop these variables from your model?  Why?\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57b78ab",
   "metadata": {},
   "source": [
    "Clearly, scaling affects the coefficients and thus affects the results of lasso regression.  Thus, it is best to apply regularization techniques like ridge and lasso after standardizing the predictors.  You can standardize the predictors by applying the following formula:\n",
    "\n",
    "$ \\tilde{x}_{ij} = \\frac{x_{ij}}{\\sqrt{\\frac{1}{n} \\sum_{i=1}^{n} (x_{ij} - \\bar{x}_{j})^2}} $\n",
    "\n",
    "So now let's take the unscaled data and make a new dataset where we standardize the predictors."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
