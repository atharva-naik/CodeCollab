{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15ff5949",
   "metadata": {},
   "source": [
    "In scikit-learn a random split into training and test sets can be quickly computed with the **train_test_split** helper function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd31525",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "from sklearn import svm\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "iris.data.shape, iris.target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e700a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.4, random_state=0)\n",
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c547e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76e5397",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC(kernel='linear', C=1).fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc7bf46",
   "metadata": {},
   "source": [
    "# Computing cross-validated metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea018f62",
   "metadata": {},
   "source": [
    "The simplest way to use cross-validation is to call the **cross_val_score** helper function on the estimator and the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918f5f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "clf = svm.SVC(kernel='linear', C=1)\n",
    "scores = cross_val_score(clf, iris.data, iris.target, cv=5)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32a57a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy: %0.2f(+/- %0.2f)' % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b35d925",
   "metadata": {},
   "source": [
    "By default, the score computed at each CV iteration is the ```score``` method of the estimator. It is possible to change this by using the **scoring** parameter:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe78ceae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "scores = cross_val_score(clf, iris.data, iris.target, cv=5, scoring='f1_macro')\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b52f337a",
   "metadata": {},
   "source": [
    "When the ```cv``` argument is an integer, ```cross_val_score``` uses the ```KFold``` or ```StratifiedKFold``` strategies by default, the latter being used if the estimator derives from ```ClassifierMixin```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9cd3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "n_samples = iris.data.shape[0]\n",
    "cv = ShuffleSplit(n_splits=3, test_size=0.3, random_state=0)\n",
    "cross_val_score(clf, iris.data, iris.target, cv=cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a930115a",
   "metadata": {},
   "source": [
    "The ```cross_validate``` function differs from ```cross_val_score``` in two ways\n",
    "* It allows specifying multiple metrics for evaluation\n",
    "* It returns a dict containing training scores, fit-times and score-times in addition to the test score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186f492b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "scoring = ['precision_macro', 'recall_macro']\n",
    "clf = svm.SVC(kernel='linear', C=1, random_state=0)\n",
    "scores = cross_validate(clf, iris.data, iris.target, scoring=scoring, cv=5, return_train_score=False)\n",
    "sorted(scores.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61fc031e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores['test_recall_macro']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2ac8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.scorer import make_scorer\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "scoring = {'prec_macro': 'precision_macro', 'rec_micro': make_scorer(recall_score, average='macro')}\n",
    "scores = cross_validate(clf, iris.data, iris.target, scoring=scoring, cv=5, return_train_score=True)\n",
    "sorted(scores.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472087f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores['train_rec_micro']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb171a2",
   "metadata": {},
   "source": [
    "The function ```cross_val_predict``` has a similar interface to ```cross_val_score```, but returns, for each element in the input, the prediction that was obtained for that element when it was in the test set. Only cross-validation strategies that assign all elements to a test set **exactly once** can be used (otherwise, an exception is raised)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22d9acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "predicted = cross_val_predict(clf, iris.data, iris.target, cv=10)\n",
    "metrics.accuracy_score(iris.target, predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226e1cd7",
   "metadata": {},
   "source": [
    "# Cross validation iterators"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23bfc49",
   "metadata": {},
   "source": [
    "## KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c88686",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "X = [\"a\", \"b\", \"c\", \"d\"]\n",
    "kf = KFold(n_splits=2)\n",
    "for train, test in kf.split(X):\n",
    "    print(\"%s %s\" % (train, test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c76778b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[0., 0.], [1., 1.], [-1., -1.], [2., 2.]])\n",
    "y = np.array([0, 1, 0, 1])\n",
    "X_train, X_test, y_train, y_test = X[train], X[test], y[train], y[test]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728d1b4d",
   "metadata": {},
   "source": [
    "## RepeatedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a201599",
   "metadata": {},
   "source": [
    "```RepeatedKFold``` repeats K-Fold n times. It can be used when one requires to run ```KFold``` n times, producing different splits in each repetition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f81dead",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "X = np.array([[1, 2], [3, 4], [1, 2], [3, 4]])\n",
    "random_state = 12883823\n",
    "rkf = RepeatedKFold(n_splits=2, n_repeats=3, random_state=random_state)\n",
    "for train, test in rkf.split(X):\n",
    "    print(\"%s %s\" % (train, test))            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406e3953",
   "metadata": {},
   "source": [
    "Similarly, ```RepeatedStratifiedKFold``` repeats Stratified K-Fold n times with different randomization in each repetition."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126d4171",
   "metadata": {},
   "source": [
    "## LeaveOneOut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e0037a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import LeaveOneOut\n",
    "\n",
    "X = [1, 2, 3, 4]\n",
    "loo = LeaveOneOut()\n",
    "for train, test in loo.split(X):\n",
    "    print(\"%s %s\" % (train, test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7975ff2d",
   "metadata": {},
   "source": [
    "## LeavePOut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d79c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import LeavePOut\n",
    "\n",
    "X = np.ones(4)\n",
    "lpo = LeavePOut(p=2)\n",
    "for train, test in lpo.split(X):\n",
    "    print(\"%s %s\" % (train, test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdff7c7a",
   "metadata": {},
   "source": [
    "## ShuffleSplit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6269d8ac",
   "metadata": {},
   "source": [
    "Samples are first shuffled and then split into a pair of train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd8cf60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "X = np.arange(5)\n",
    "ss = ShuffleSplit(n_splits=3, test_size=0.25, random_state=0)\n",
    "for train_index, test_index in ss.split(X):\n",
    "    print(\"%s %s\" % (train_index, test_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615806bc",
   "metadata": {},
   "source": [
    "Some classification problems can exhibit a large imbalance in the distribution of the target classes: for instance there could be several times more negative samples than positive samples. In such cases it is recommended to use stratified sampling as implemented in ```StratifiedKFold``` and ```StratifiedShuffleSplit``` to ensure that relative class frequencies is approximately preserved in each train and validation fold."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0639285",
   "metadata": {},
   "source": [
    "## StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157c9130",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "X = np.ones(10)\n",
    "y = [0, 0, 0, 0, 1, 1, 1, 1, 1, 1]\n",
    "skf = StratifiedKFold(n_splits=3)\n",
    "for train, test in skf.split(X, y):\n",
    "    print(\"%s %s\" % (train, test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59f0a84",
   "metadata": {},
   "source": [
    "```RepeatedStratifiedKFold``` can be used to repeat Stratified K-Fold n times with different randomization in each repetition. ```StratifiedShuffleSplit``` is a variation of *ShuffleSplit*, which returns stratified splits."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e5f77d",
   "metadata": {},
   "source": [
    "## GroupKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59fa4a47",
   "metadata": {},
   "source": [
    "```GroupKFold``` is a variation of k-fold which ensures that the same group is not represented in both testing and training sets.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83dc9220",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "X = [0.1, 0.2, 2.2, 2.4, 2.3, 4.55, 5.8, 8.8, 9, 10]\n",
    "y = [\"a\", \"b\", \"b\", \"b\", \"c\", \"c\", \"c\", \"d\", \"d\", \"d\"]\n",
    "groups = [1, 1, 1, 2, 2, 2, 3, 3, 3, 3]\n",
    "\n",
    "gkf = GroupKFold(n_splits=3)\n",
    "for train, test in gkf.split(X, y, groups=groups):\n",
    "    print(\"%s %s\" % (train, test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f28d54",
   "metadata": {},
   "source": [
    "## LeaveOneGroupOut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d82440b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "\n",
    "X = [1, 5, 10, 50, 60, 70, 80]\n",
    "y = [0, 1, 1, 2, 2, 2, 2]\n",
    "groups = [1, 1, 2, 2, 3, 3, 3]\n",
    "\n",
    "logo = LeaveOneGroupOut()\n",
    "for train, test in logo.split(X, y, groups=groups):\n",
    "    print(\"%s %s\" % (train, test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1624c039",
   "metadata": {},
   "source": [
    "## LeavePGroupOut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28fa297",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import LeavePGroupsOut\n",
    "\n",
    "X = np.arange(6)\n",
    "y = [1, 1, 1, 2, 2, 2]\n",
    "\n",
    "groups = [1, 1, 2, 2, 3, 3]\n",
    "lpgo = LeavePGroupsOut(n_groups=2)\n",
    "for train, test in lpgo.split(X, y, groups=groups):\n",
    "    print(\"%s %s\" % (train, test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f932a3ea",
   "metadata": {},
   "source": [
    "## GroupShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e771079",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "\n",
    "X = [0.1, 0.2, 2.2, 2.4, 2.3, 4.55, 5.8, 0.001]\n",
    "y = [\"a\", \"b\", \"b\", \"b\", \"c\", \"c\", \"c\", \"a\"]\n",
    "groups = [1, 1, 2, 2, 3, 3, 4, 4]\n",
    "gss = GroupShuffleSplit(n_splits=4, test_size=0.5, random_state=0)\n",
    "for train, test in gss.split(X, y, groups=groups):\n",
    "    print(\"%s %s\" % (train, test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3bb9c59",
   "metadata": {},
   "source": [
    "## TimeSeriesSplit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7741ae4",
   "metadata": {},
   "source": [
    "```TimeSeriesSplit``` is a variation of k-fold which returns first $k$ folds as train set and the $(k+1)$th fold as test set."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
