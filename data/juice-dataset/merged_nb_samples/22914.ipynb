{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7e67811",
   "metadata": {},
   "source": [
    "# Simple Linear Regression\n",
    "\n",
    "We will show how to use linear regression to find a best fit line through an artificial 2D scatter plot generated from a line with Gaussian noise added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae33298",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style=\"ticks\", palette=\"muted\", color_codes=True)\n",
    "\n",
    "from stattools.glm import LinearRegression\n",
    "from stattools.visualization import abline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1060ffdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set NumPy random number generator seed for replicability\n",
    "np.random.seed(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c60f490",
   "metadata": {},
   "source": [
    "## Create Some Artificial Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b3494d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100\n",
    "slope = 3\n",
    "intercept = 2\n",
    "\n",
    "x = np.random.uniform(0, 10, n)\n",
    "y = slope * x + intercept + np.random.normal(0, 10, n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a390c2",
   "metadata": {},
   "source": [
    "## The Ordinary Least Squares Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15efd485",
   "metadata": {},
   "source": [
    "### Fitting the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d56963",
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "model = LinearRegression().fit(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c81bb5",
   "metadata": {},
   "source": [
    "### Plotting the Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ff9fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get intercept (a) and slope (b) of model\n",
    "a = model.intercept\n",
    "b = model.coef[0]\n",
    "\n",
    "# Plot the regression line\n",
    "plt.figure()\n",
    "plt.scatter(x, y, c=\"b\", alpha=0.7, edgecolor=\"k\")\n",
    "abline(intercept, slope, lw=3, c=\"k\", label=f\"Actual: y = {intercept} + {slope}x\")\n",
    "abline(a, b, lw=3, c=\"r\", label=f\"Prediction: y = {a:.3f} + {b:.3f}x\")\n",
    "plt.title(\"OLS Regression\")\n",
    "plt.legend(loc=\"best\", frameon=True, shadow=True)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8e2a3e",
   "metadata": {},
   "source": [
    "### Mean Squared Error\n",
    "\n",
    "To evaluate this model's performance, we compute its *mean squared error* on the data set:\n",
    "$$\n",
    "\\mathrm{MSE} = \\frac{1}{n} \\sum_{i=1}^n \\left(y_i - \\widehat{y}_i\\right)^2.\n",
    "$$\n",
    "Here $n$ is the number of observations, $y_i$ is the $i$th observed value, and $\\widehat{y}_i$ is the least squares estimate corresponding to the $i$th data point.\n",
    "A good regressor achieves an MLE close to zero."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
