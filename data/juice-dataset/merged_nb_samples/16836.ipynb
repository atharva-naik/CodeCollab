{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1994388",
   "metadata": {},
   "source": [
    "# Sample Diagnostic\n",
    "\n",
    "Example of a diagnostic showing how the COSIMA cookbook works."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6145cc3f",
   "metadata": {},
   "source": [
    "An objective of the COSIMA cookbook is to catalogue useful diagnostics for ocean and ice models.  Certain\n",
    "tools and patterns are used extensively in these examples.  While the diagnostic itself should be portable\n",
    "to another framework, there are some conventions used throughout that require explanation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42fc09f",
   "metadata": {},
   "source": [
    "## Background of a diagnostic notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf2fac5",
   "metadata": {},
   "source": [
    "Each diagnostic is written up as a Jupyter notebook with the extension `.ipynb`.  The first cell in the notebook\n",
    "must be a Markdown cell with a header and a one-line description.  This cell is used by sphinx-nbgallery to collect\n",
    "all of the diagnostics together the http://cosima-cookbook.readthedocs.io site. \n",
    "\n",
    "In this first section, a brief background on the theory of the diagnostic is presented. For this worked example, we will be calculating the eddy kinetic energy (see the Kinetic Energy notebook).  While in real diagnostic notebook, commentary about the diagnostic is presented, here we provide commentary about the technical aspects of how these diagnostics have been implemented.\n",
    "\n",
    "### A note on names\n",
    "- The project's long name is \"COSIMA Cookbook\".\n",
    "- The GitHub project name is \"cosima-cookbook\".\n",
    "- The Python package is called \"cosima_cookbook\". \n",
    "\n",
    "This conventions appears to be consistent with other Python based projects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c291735f",
   "metadata": {},
   "source": [
    "### Python import statements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099aac7e",
   "metadata": {},
   "source": [
    "Early in the notebook, there is a code cell that imports all of the needed Python packages.  Internal to cosima_cookbook, other packages may also be important. But, if they are needed in this notebook, they must be\n",
    "imported explicitly into the namespace."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aff7e37",
   "metadata": {},
   "source": [
    "#### Example of a import cell block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0a8295",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = pd.DataFrame(list(db['ncfiles'].all()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb82b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3867fb1",
   "metadata": {},
   "source": [
    "Files seen before but now not found on disk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6f67cd",
   "metadata": {},
   "source": [
    "Notice that, unlike the find command above, the glob has only identified .nc files that with in the\n",
    "__configuration__/__experiment__/__run__ directory structure.\n",
    "\n",
    "We want to produce an index over all of these NetCDF files. Once we do that, we can build our diagnostics by first\n",
    "querying that index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dea5484",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = [cosima_cookbook.index_ncfile(fn[0]) for fn in ncfiles[:15]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d368052",
   "metadata": {},
   "source": [
    "index_ncfile() returns a list of dictionaries describing each variable in an the NetCDF file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc793e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows[0][:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed032d70",
   "metadata": {},
   "source": [
    "The list comprehension gives back a list of lists.  To continue, we first flatten this list of lists:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb59d622",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = [item for sublist in rows for item in sublist]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7dc1d1",
   "metadata": {},
   "source": [
    "Finally, we can convert this dictionary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f38288",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import cosima_cookbook as cc\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aee0dfa",
   "metadata": {},
   "source": [
    "For static plots, the plotting package matplotlib is used. The inline statement tells Jupyter to place those plots within the notebook file.\n",
    "\n",
    "It is common to import standard packages with abbreviated package names such as plt, np, pd, and xr. XArray is for\n",
    "named arrays and can be thought of as layer that sits above the netCDF4 package.\n",
    "\n",
    "The package tqdm is for progress bars."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beeb8c35",
   "metadata": {},
   "source": [
    "These diagnostics are usually very memory and/or computationally expensive.  We leverage the `dask` library http://dask.pydata.org and its related package `distributed` https://distributed.readthedocs.io."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9b6301",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output* directories\n",
    "# match the parent and grandparent directory to configuration/experiment\n",
    "m = re.compile('(.*)/(.*)/(.*)/(output\\d+)/.*\\.nc')\n",
    "\n",
    "def index_variables(ncfile):\n",
    "\n",
    "    matched = m.match(ncfile)\n",
    "    if matched is None:\n",
    "        return []\n",
    "    \n",
    "    if not os.path.exists(ncfile):\n",
    "        return []\n",
    "    \n",
    "    try: \n",
    "        with netCDF4.Dataset(ncfile) as ds:\n",
    "            ncvars = [ {'ncfile': ncfile,\n",
    "                   'rootdir': matched.group(1),\n",
    "                   'configuration': matched.group(2),\n",
    "                   'experiment' : matched.group(3),\n",
    "                   'run' : matched.group(4),\n",
    "                   'basename' : os.path.basename(ncfile),\n",
    "                   'variable' : v.name\n",
    "                   } for v in ds.variables.values()]\n",
    "    except:\n",
    "        return []\n",
    "    \n",
    "    return ncvars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1882d4f0",
   "metadata": {},
   "source": [
    "Parallel approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b089561f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.bag\n",
    "from distributed.diagnostics.progressbar import progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ffab8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "bag = dask.bag.from_sequence(files_to_add)\n",
    "bag = bag.map(index_variables).flatten()\n",
    "ncvars = bag.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08604ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(ncvars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf30def4",
   "metadata": {},
   "outputs": [],
   "source": [
    "db['ncfiles'].insert_many(ncvars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a4271d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e792e89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ce85ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2071ee0",
   "metadata": {},
   "source": [
    "So this gives us a nice index for all variables over all NetCDF files.  However, since we have tens of thousands of ncfiles, generating this index can be slow.  To improve performance, we can use a dask bag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8d70e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "bag = dask.bag.from_sequence([_[0] for _ in ncfiles],npartitions=1000)\n",
    "rows = bag.map(cosima_cookbook.index_ncfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac212d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "futures = client.compute(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d721823e",
   "metadata": {},
   "outputs": [],
   "source": [
    "futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5dfbb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f172bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "progress(futures)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1cdb0f",
   "metadata": {},
   "source": [
    "To actually get the computation to occur, we can conver the bag into a list.  This takes a few minutes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6b975e",
   "metadata": {},
   "source": [
    "As before, we convert the list of lists to a single list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea3dace",
   "metadata": {},
   "source": [
    "Finally, we can put this all into a pandas DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc5ef14",
   "metadata": {},
   "source": [
    "__Runs__ may change which variables they saved and at what temporal resolution over the course of an __experiment__.  Rather than trying to enumerate the variables _a priori_, we can a data discovery approach using a glob."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ae4a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "directoriesToSearch = ['/g/data3/hh5/tmp/cosima/', \n",
    "                      ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a01cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import netCDF4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fadc7351",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataset\n",
    "import re\n",
    "import os\n",
    "import fnmatch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34432461",
   "metadata": {},
   "source": [
    "Build index of all NetCDF files found in directories to search. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b077a637",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "m = re.compile('.*\\.nc$')\n",
    "\n",
    "ncfiles = []\n",
    "for directoryToSearch in directoriesToSearch:\n",
    "    for root, dirs, filenames in os.walk(directoryToSearch):\n",
    "        for filename in filenames:\n",
    "            if m.match(filename) is not None:\n",
    "                ncfiles.append(os.path.join(root, filename))\n",
    "\n",
    "print(len(ncfiles))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7bb991",
   "metadata": {},
   "source": [
    "We can persist this index by storing it in a sqlite database placed in a centrally available location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750fa07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cosima_cookbook_dir = '/g/data1/v45/cosima-cookbook'\n",
    "if not os.path.exists(cosima_cookbook_dir):\n",
    "    os.mkdir(cosima_cookbook_dir)\n",
    "\n",
    "database_file = '/{}/cosima-cookbook.db'.format(cosima_cookbook_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b93abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.remove(database_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc69c2b7",
   "metadata": {},
   "source": [
    "The use of the `dataset` module hides the details of working with SQL directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62eb16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = dataset.connect('sqlite://' + database_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2d9b96",
   "metadata": {},
   "source": [
    "In this database is a single table listing all variables in NetCDF4 seen previously."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2c2453",
   "metadata": {},
   "source": [
    "The above steps are implemented in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46b9170",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = cosima_cookbook.build_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79d1ae5",
   "metadata": {},
   "source": [
    "Here are all of the unique experiments found in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1d66a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "expts = df.experiment.unique()\n",
    "expts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd280b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "expts[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c2b419",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beff6077",
   "metadata": {},
   "source": [
    "## Calculation of EKE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7b9d8c",
   "metadata": {},
   "source": [
    "Let's choose a specific experiment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ba3d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(list(db['ncfiles'].distinct('configuration', 'experiment')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d9c965",
   "metadata": {},
   "outputs": [],
   "source": [
    "db['ncfiles'].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6110f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "expt = 'KDS75'\n",
    "expt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84cd90d4",
   "metadata": {},
   "source": [
    "To calculate the eddy kinetic energy, we are going to consider only  portions of simulations which have 5-day average velocities saved, which means directories with `ocean__*.nc` files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f4ecda",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls {datadir}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31d5f12",
   "metadata": {},
   "source": [
    "The data directory contains several model __configurations__ (mom01v5 or mom025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab80a86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls {datadir}/mom01v5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736c7130",
   "metadata": {},
   "source": [
    "Each configuration contains a number of __experiments__ (KDS75 or KDS75_wind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9fa97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls {datadir}/mom01v5/KDS75_salt10days"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf768bf",
   "metadata": {},
   "source": [
    "Which are each made up of a set of several __runs__ (e.g. output266)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeaf96c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls {datadir}/mom01v5/KDS75_salt10days/output266"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec393794",
   "metadata": {},
   "source": [
    "The actual model out in stored in NetCDF4 files (denoted by the extention .nc). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f032a66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = os.path.join(datadir, 'mom01v5/KDS75_salt10days/output266/ocean.nc')\n",
    "xr.open_dataset(fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa17b9c6",
   "metadata": {},
   "source": [
    "There are many, many such NetCDF4 files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90692d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!find {datadir} -name '*.nc' | wc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607e6aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "import distributed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec5c1a3",
   "metadata": {},
   "source": [
    "By default, we create a collection of workers -- one work for each core. The memory is set as 70% of the total memory of the node. Beyond that, distributed will start caching results locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f928de81",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = distributed.Client()\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec88c81",
   "metadata": {},
   "source": [
    "You see above that there is a URL for the Dashboard. This is a very useful tool for inspecting the progress of a dask\n",
    "calculation. If you are running the VDI over VNC you should be able to click on the link to make the dashboard open in another tab.  \n",
    "\n",
    "If you are running this notebook over a SSH tunnel, you will also have to tunnel the port for the dashboard to your local machine. Here's some code which generates the need string.  Run that command on your local machine. Then the link above should work.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1470f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "params = {'host': os.environ['HOSTNAME'],\n",
    "          'user': os.environ['USER'],\n",
    "          'port': client.scheduler_info()['services']['bokeh']}\n",
    "\n",
    "tunnel_cmd = \"ssh {host}.nci.org.au -l {user} -L {port}:127.0.0.1:{port}\".format(**params)\n",
    "print(tunnel_cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34556dd2",
   "metadata": {},
   "source": [
    "### Organization of the model data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3263e772",
   "metadata": {},
   "source": [
    "By default, all of the model output is assumed to stored in the directory given by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3df68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_records(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce53b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cosima_cookbook.netcdf_index\n",
    "cosima_cookbook.netcdf_index.directoriesToSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5bf8f92",
   "metadata": {},
   "source": [
    "This global variable may be changed if needed.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153c31b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = cosima_cookbook.netcdf_index.directoriesToSearch[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de53da86",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_already_seen = set([_['ncfile'] for _ in db['ncfiles'].distinct('ncfile')])\n",
    "print(len(files_already_seen))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c133b6eb",
   "metadata": {},
   "source": [
    "NetCDF files found on disk not seen before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd45bd7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = db.query('SELECT ncfile FROM ncfiles \\\n",
    "                WHERE experiment = \"KDS75\" \\\n",
    "                AND basename LIKE \"%ocean__%\" \\\n",
    "                AND variable = \"u\" \\\n",
    "                ORDER BY ncfile \\\n",
    "               ')\n",
    "ncfiles = [row['ncfile'] for row in res]\n",
    "ncfiles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ef58de",
   "metadata": {},
   "source": [
    "Using our index of ncfiles, we search for such nc files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6063b4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_to_add = set(ncfiles) - set(files_already_seen)\n",
    "print(len(files_to_add))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074a5d57",
   "metadata": {},
   "source": [
    "For these new files, we can determine their configuration, experiment, and run. Using NetCDF4 to get list of all variables in each file."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
