{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75bf0bc0",
   "metadata": {},
   "source": [
    "### Groups in Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e86d904",
   "metadata": {},
   "source": [
    "We often want to calculate summary statistics grouped by subsets or attributes within fields of our data.\n",
    "**For example, we might want to calculate the average weight of all individuals in each plot.**\n",
    "\n",
    "We can calculate basic statistics for all records in a single column using the syntax below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd416200",
   "metadata": {},
   "outputs": [],
   "source": [
    "surveys['weight'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4e07f4",
   "metadata": {},
   "source": [
    "Let's break that last command down.\n",
    "\n",
    "1. First, we asked for the `weight` column in the `surveys` table.\n",
    "2. Second, we called the `describe()` method on that column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4a81de",
   "metadata": {},
   "source": [
    "**We can also extract a specific statistic.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2c60f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "surveys['weight'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf358cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "surveys['weight'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7604255f",
   "metadata": {},
   "source": [
    "If we want to summarize by one or more variables, for example, `sex`, we can use Pandas' `groupby()` method.\n",
    "Once we've created a grouped DataFrame, we can quickly calculated summary statistics by a group of our choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c842385a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group data by sex\n",
    "grouped_by_sex = surveys.groupby('sex')\n",
    "\n",
    "# Summary statistics for all numeric columns, grouped by sex\n",
    "grouped_by_sex.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d513f79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_by_sex.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cccf86eb",
   "metadata": {},
   "source": [
    "### Quickly Creating Summary Counts in Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f033ecd2",
   "metadata": {},
   "source": [
    "Let's count the number of samples for each species.\n",
    "We can do this in a few ways, but we'll use `groupby()` combined with a `count()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90b03cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "surveys['hindfoot_length'] / surveys['hindfoot_length'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a47d32",
   "metadata": {},
   "source": [
    "## Basic Plotting with Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1478a8",
   "metadata": {},
   "source": [
    "We can also visualize summary statistics using Pandas.\n",
    "**First, we'll fire off an iPython \"magic\" function that will allow us to  view plots inline in the Jupyter Notebook.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8012219f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b6a581",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a quick bar chart\n",
    "species_counts.plot(kind = 'bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57fe6d60",
   "metadata": {},
   "source": [
    "This plot is kind of cramped and hard to read; we can make it slightly bigger by specifying a new weight and height (in inches)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33e5a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "species_counts.plot(figsize=(9, 6), kind = 'bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136d020f",
   "metadata": {},
   "source": [
    "### Challenge: Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594c11f2",
   "metadata": {},
   "source": [
    "1. Create a plot of the average weight in each species.\n",
    "2. Create a plot of total males and total females across the entire dataset.\n",
    "\n",
    "*Note:* Some of the species have no weight measurements; they are entered as `NaN`, which stands for \"not a number\" and refers to missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580983f0",
   "metadata": {},
   "source": [
    "### Multiple Grouping in Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b6e52d6",
   "metadata": {},
   "source": [
    "Let's make a *stacked bar plot,* with the total number of individuals on the Y axis and the stacked variable being `sex`. The plot should show total count by sex for each survey plot."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9516cf46",
   "metadata": {},
   "source": [
    "First, we'll calculate the total number of individual in each unique pair of `plot_id` and `sex`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181e39cc",
   "metadata": {},
   "source": [
    "### Slicing Subsets of Rows and Columns with Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e0f05b",
   "metadata": {},
   "source": [
    "We can select specific ranges of our data in both the row and column directions using either **label-based** or **integer-based indexing.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9c45e7",
   "metadata": {},
   "source": [
    "To select a subset of rows and columns, we can use the `iloc()` method (for \"index location\"). For example, **we can select the month, day, and year columns (columns, 2, 3, 4) in the first three rows, like this:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f948ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "surveys.iloc[0:3,1:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ff8407",
   "metadata": {},
   "source": [
    "**Note that the order of terms in the square brackets is rows first, then columns.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef26393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the same columns but all the rows\n",
    "surveys.iloc[:,1:4].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f12e6ec",
   "metadata": {},
   "source": [
    "**Here, the colon character in place of the row index indicates we want \"all\" elements (rows).**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64416ce4",
   "metadata": {},
   "source": [
    "We can select multiple, discontiguous rows by passing a list of the row indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f5af51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select all columns for rows of index values 0, 10\n",
    "surveys.iloc[[0, 10], :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b49df9",
   "metadata": {},
   "source": [
    "If we want to select columns by column names, we need to use the `loc()` method in place of `iloc()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ca04c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "surveys.loc[0, ['species_id', 'plot_id', 'weight']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba29697",
   "metadata": {},
   "source": [
    "When we use `loc()`, we can also index using integers, but with one essential difference: **`loc()` indexes on row or column labels, not the position along the table's rows or columns.**\n",
    "\n",
    "For example, compare the outputs:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9aa35e",
   "metadata": {},
   "source": [
    "A **list** is Python's built-in data structure for handling general, ordered sequences. Each element can be accessed by its index. **Note that, in Python, we start counting from zero, not from one.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98fbc9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = [1, 2, 3]\n",
    "numbers[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9badf7f",
   "metadata": {},
   "source": [
    "The square brackets are used to **slice** a sequence by one or more indices. Above, we have asked for the first (the zeroth) element of the `numbers` sequence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "009cbc59",
   "metadata": {},
   "source": [
    "A `for` loop is a useful way of accessing the elements of a sequence one at a time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9db532",
   "metadata": {},
   "outputs": [],
   "source": [
    "for number in numbers:\n",
    "    print(number)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d8a336",
   "metadata": {},
   "source": [
    "**Indentation is very important in Python.** Note that the second line in the above example is indented. This is Python's way of marking a block of code. It's standard to indent by 4 spaces."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d28d6b",
   "metadata": {},
   "source": [
    "To add elements to the end of a list, we can use the `append()` method:`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada2d1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers.append(4)\n",
    "print(numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b50a84",
   "metadata": {},
   "source": [
    "Note that there is no output associated with the `append()` method; the `numbers` sequence is modified in place so we don't need to assign the result to a variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "facc6334",
   "metadata": {},
   "source": [
    "**Methods are a way to interact with an object in Python.** We can invoke a method using the dot, followed by the method name and a list of arguments in parentheses. To find out what methods are available for an object, we can use the built-in `help()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83a72c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b21949",
   "metadata": {},
   "source": [
    "We can also access a list of methods using `dir`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0b089c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_sex_count = surveys.groupby(('plot_id', 'sex'))['record_id'].count()\n",
    "plot_sex_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b548573",
   "metadata": {},
   "source": [
    "Next, we use the `unstack()` method on our grouped data to figure out the total count that each sex contributes to each plot.\n",
    "Here, `unstack()` simply rearranges the rows and columns into a more convenient format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28429d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_plot = plot_sex_count.unstack().plot(kind = 'bar', stacked = True)\n",
    "my_plot.set_title('Total weight by plot and sex')\n",
    "my_plot.set_ylabel('Weight (grams)')\n",
    "my_plot.set_xlabel('Plot ID')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458b79e7",
   "metadata": {},
   "source": [
    "# Transforming Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e161ae",
   "metadata": {},
   "source": [
    "**Up to this point, we have learned:**\n",
    "\n",
    "- The basic data types in Python;\n",
    "- How to read a CSV file into Python using pandas;\n",
    "- How tabular data in pandas are represented using a DataFrame;\n",
    "- How to check the data type of each column in a DataFrame;\n",
    "- How to summarize numerical data in a DataFrame;\n",
    "- How to group data according to the unique values of a column;\n",
    "- How to create basic plots of grouped, summarized data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e533db2",
   "metadata": {},
   "source": [
    "**Often, once we've pulled in data and done some basic data cleaning, we want to transform our data to make it more useful for our analysis.** For instance, we might find that:\n",
    "\n",
    "- The numeric values in one or more columns are not in the right units, e.g., we want pounds instead of kilograms.\n",
    "- A text column has keys written one way and we want them written another way.\n",
    "- We want to combine two or more columns; or, we want to split one column into multiple columns.\n",
    "\n",
    "Some of these objectives are perhaps best handled in OpenRefine, as we saw. However, we can also transform our data easily enough with Python and Pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9716cff6",
   "metadata": {},
   "source": [
    "## Converting Units"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dedba9a",
   "metadata": {},
   "source": [
    "In our `surveys` data, the animal weights are in grams. What if our collaborator says she needs the weights in kilograms?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a23001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of our original data\n",
    "surveys_converted = surveys.copy()\n",
    "\n",
    "# Create a new column in this table\n",
    "surveys_converted['weight_kg'] = surveys_converted.weight / 1000\n",
    "surveys_converted.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20cb2da6",
   "metadata": {},
   "source": [
    "**Note that when we call for a column as an attribute, it is read-only.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f11fe2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "species_counts = surveys.groupby('species_id')['record_id'].count()\n",
    "species_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec1235b",
   "metadata": {},
   "source": [
    "Again, let's break this down:\n",
    "\n",
    "1. We group the rows of the `surveys` DataFrame by the unique values in one of its columns: `species_id`.\n",
    "2. Second, we ask for the column `record_id` in the output from the last part.\n",
    "3. Third, we call the `count()` method on this column. Because the data are grouped by `species_id`, we get a count within each unique value of `species_id`, not a count of all the rows in the table."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca026aac",
   "metadata": {},
   "source": [
    "### Challenge: Understanding Grouped DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017c6d28",
   "metadata": {},
   "source": [
    "1. In that last command, we asked for the `record_id` column. Try asking for a different column in the square brackets. Do you get a different result? Why or why not?\n",
    "2. How can we get a count of just the records with `species_id` set to `DO`? *Hint: You can build on the last command we executed; think about Dictionaries and key-value pairs.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f491ffd8",
   "metadata": {},
   "source": [
    "### Basic Math on DataFrame Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748c29f8",
   "metadata": {},
   "source": [
    "We can perform quick mathematical transformations on the values of a column in a straightforward way.\n",
    "For instance, we might normalize the measured hindfoot lengths by their mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36400b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6549555c",
   "metadata": {},
   "source": [
    "### Tuples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c698681b",
   "metadata": {},
   "source": [
    "A tuple is similar to a list in that it's an ordered sequence of elements. However, tuples can not be changed once created; they are \"immutable.\" Tuples are created by placing comma-separated values inside parentheses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a216b009",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_tuple = (1,2,3)\n",
    "another_tuple = ('rabbit', 'mongoose', 'platypus')\n",
    "still_a_tuple = (1,)\n",
    "\n",
    "# Note that lists use square brackets\n",
    "a_list = [1,2,3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001abad5",
   "metadata": {},
   "source": [
    "### Challenge: Tuples and Lists"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc7ea44",
   "metadata": {},
   "source": [
    "## Subsetting Data Using Criteria"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296fee61",
   "metadata": {},
   "source": [
    "Most importantly, we can also select a subset of our data based on certain criteria. For example, we can select all of the rows of our data that match observations in the year 2002."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8384ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "surveys[surveys.year == 2002].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0212e70",
   "metadata": {},
   "source": [
    "Or, we can select all rows that do not match observations from 2002."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c491b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "surveys[surveys.year != 2002].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf51902",
   "metadata": {},
   "source": [
    "**We can combine criteria using logical operators.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b0b386",
   "metadata": {},
   "outputs": [],
   "source": [
    "surveys[(surveys.year >= 1980) & (surveys.year <= 1985)].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00007d8a",
   "metadata": {},
   "source": [
    "### Challenge: Filtering Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e104fbc7",
   "metadata": {},
   "source": [
    "1. Filter the `surveys` table to observations of female members of the `DO` species. How many are there? What is their average weight?\n",
    "2. Look at the help documentation for the `isin()` function (Hint: `?surveys.year.isin`). Use this function to filter the `surveys` DataFrame to those rows that match the three species: `OL`, `OT`, `OX`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd0bb99",
   "metadata": {},
   "source": [
    "## Using Masks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4aecdc",
   "metadata": {},
   "source": [
    "Earlier, we saw that our data contain some missing values, filled in with `NaN` or \"not a number.\"\n",
    "We'll next learn how to handle NaNs when they appear in our data using masks.\n",
    "A mask can be useful to locate where a particular subset values exist (or don't exist)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f433db75",
   "metadata": {},
   "source": [
    "To start, we can use the Pandas function `isnull()` to find places in our `surveys` DataFrame where there are null or NaN values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037c2262",
   "metadata": {},
   "source": [
    "For this lesson, we will be using the [Portal Project Teaching Database](https://figshare.com/articles/Portal_Project_Teaching_Database/1314459), a subset of data from Ernst et al.'s (2009) [long-term monitoring and experimental manipulation of a Chihuahuan desert ecosystem near Portal, Arizona, U.S.A.](http://www.esapubs.org/archive/ecol/E090/118/default.htm).\n",
    "**We are studying the species and weight of animals caught in plots in our study area.**\n",
    "The dataset is stored as a comma-separated variable (CSV) file: each row holds information for a single animal, and the columns reprsent:\n",
    "\n",
    "Column          | Description\n",
    "----------------|--------------------------------------\n",
    "record_id       | Unique ID for the observation\n",
    "month           | Month of observation\n",
    "day             | Day of observation\n",
    "year            | Year of observation\n",
    "plot_id         | ID of a particular plot\n",
    "species_id      | 2-letter code identifying the species\n",
    "sex             | Sex of animal (\"M\",\"F\")\n",
    "hindfoot_length | Length of the hindfoot in millimeters\n",
    "weight          | Weight of the animal in grams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124b908f",
   "metadata": {},
   "source": [
    "## About Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5aa4dbb",
   "metadata": {},
   "source": [
    "A library in Python contains a set of tools (called functions) that perform tasks on our data.\n",
    "Importing a library is like getting a piece of lab equipment out of a storage locker and setting it up on the bench for use in a project.\n",
    "Once a library is set up, it can be used to perform many tasks.\n",
    "**One of the libraries we'll be using in this lesson is the Python Data Analysis Library, or `pandas`.**\n",
    "`pandas` adds a number of things to base Python including more sophisticated data structures and tools to connect to other libraries like `matplotlib` for producing data visualizations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c2f9cd",
   "metadata": {},
   "source": [
    "Python doesn't initially load all of the libraries that we have installed; we have to tell Python to import the librar(ies) that we want to use in any particular session.\n",
    "**To import a library, we use the syntax:** `import libraryName`.\n",
    "Because all of the tools in that library will be known by the name we import, we have the option to give it a shorter name.\n",
    "We'll do that here with Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a33836a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99b0412",
   "metadata": {},
   "source": [
    "Each time we call a function that's in the Pandas library, we use the syntax `libraryName.functionName`.\n",
    "This ensures that Python can find the tool or function we're asking for.\n",
    "Most Pandas users abbreviate the library name to `pd` and because this is such a popular convention, you can often find help on the internet by searching for a particular function in the `pd` **namespace.**\n",
    "**For instance, I'll look up support for the `pd.read_csv()` function on the Google search engine.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15bde1f7",
   "metadata": {},
   "source": [
    "## Reading CSV Data in Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4378c864",
   "metadata": {},
   "source": [
    "Tabular data, like those stored in CSV, tab-delimited, or fixed-width formats, can be read into Python using Pandas and stored in a Pandas `DataFrame`.\n",
    "If you've used the R programming language before, you'll be familiar with DataFrames."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4676fc",
   "metadata": {},
   "source": [
    "### Data Frames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc7e6a7",
   "metadata": {},
   "source": [
    "**A DataFrame is a 2-dimensional, tabular data structure that can store different types of data across multiple columns.**\n",
    "It is structurally identical to a spreadsheet in this way or, as we'll see, a table in a SQL database.\n",
    "We can read in our survey data as a DataFrame using the `pd.read_csv()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e0b393",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('ecology-surveys.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2eb1e6a",
   "metadata": {},
   "source": [
    "When we run this command, Pandas finds the CSV file, opens it, and reads in the contents, line-by-line, as rows in a new DataFrame, which it then prints out.\n",
    "We can see that:\n",
    "\n",
    "- There were 33,549 rows parsed.\n",
    "- Each has 9 columns.\n",
    "\n",
    "**The first column is the index of the DataFrame.**\n",
    "The index is used to identify the position of the data, but it is not an actual column of the DataFrame.\n",
    "\n",
    "We can see from this output that Pandas read the file properly, but it hasn't saved the DataFrame to memory.\n",
    "**We need to assign the DataFrame to a variable.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fdfdde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.isnull(surveys)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4653920",
   "metadata": {},
   "source": [
    "We can use the `any()` function to ask if there are any null values in a given row. Here, the `axis` argument specifies the axis along which to look for true values (values that are null); 1 indicates a look along the rows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb9a8a6",
   "metadata": {},
   "source": [
    "The use of the `apply()` function here is part of a general practice called **function application.** We can also apply a function to our entire DataFrame along one of its two axes. **For instance, we can use this to count how many non-null values are in each of the columns.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06744d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "surveys.weight.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d968b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "surveys.apply(lambda column: column.count(), axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28be4341",
   "metadata": {},
   "source": [
    "We can also apply functions across the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c98079a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns True or False depending on whether weight is null\n",
    "surveys.apply(lambda row: pd.notnull(row.weight), axis = 1).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188dedbb",
   "metadata": {},
   "source": [
    "# Indexing and Slicing Python DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0c035c",
   "metadata": {},
   "source": [
    "**Now, we'll explore how to access different parts of our data, including querying subsets of the data based on certain criteria.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43aa4d38",
   "metadata": {},
   "source": [
    "## Indexing and Slicing in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b173bfe",
   "metadata": {},
   "source": [
    "### Selecting Data Using Labels (Column Headings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c0fc29",
   "metadata": {},
   "source": [
    "We use square brackets, `[]`, to select a subset of a Python object. For example, we can select all of the data from a column named `species_id`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25859da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "surveys['species_id']\n",
    "surveys.species_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdce503a",
   "metadata": {},
   "source": [
    "We can pass a list of column names, too, as an index to select columns in a specified order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072411f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "surveys.loc[[0, 10, 50000], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3cab9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "surveys.iloc[[0, 10, 50000], :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb76cef",
   "metadata": {},
   "source": [
    "### Challenge: Slicing Rows and Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f396ad18",
   "metadata": {},
   "source": [
    "What happens when you type:\n",
    "\n",
    "1. &nbsp;`surveys[0:3]`\n",
    "2. &nbsp;`surveys[:5]`\n",
    "3. &nbsp;`surveys[-1:]`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47896de1",
   "metadata": {},
   "source": [
    "To review...\n",
    "\n",
    "**To index by rows in Pandas:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99fa93a2",
   "metadata": {},
   "source": [
    "In the last example, we saw how we can build functions that call other functions we've built in the past. **In this way, we can develop sophisticated data processing workflows piece-by-piece, based on code we already know works.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69b2709",
   "metadata": {},
   "source": [
    "### Challenge: Writing Reusable Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ccd3af",
   "metadata": {},
   "source": [
    "1. What type of object corresponds to a variable declared as `None`? (Hint: Create a variable set to `None` and use the function `type()`).\n",
    "2. What happens if you only call `multiple_years_to_csv()` with `all_data` and an `end_year` (that is, without providing a `start_year`)?  Can you write the function call with only a value for `end_year`?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485a9b09",
   "metadata": {},
   "source": [
    "# Answering Questions with Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3431ca89",
   "metadata": {},
   "source": [
    "There are many questions we ask about tabular data that we can answer with Pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e936ee1e",
   "metadata": {},
   "source": [
    "## Validating Assumptions about Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce3d376",
   "metadata": {},
   "source": [
    "How many animals of each species were caught in each plot? We can create a **cross-tabulation** of the `species_id` and `plot_id` fields as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c4a8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(surveys.species_id, surveys.plot_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8dd69d",
   "metadata": {},
   "source": [
    "## Sorting on Values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "659a4e23",
   "metadata": {},
   "source": [
    "We might ask what the heaviest animals in our dataset are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e902f920",
   "metadata": {},
   "outputs": [],
   "source": [
    "surveys.sort_values(by = 'weight', ascending = False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc52d278",
   "metadata": {},
   "source": [
    "We might also ask for the last observation in our data. We could assume that the data in the table are in chronological order and simply look at the last row; however, there are many reasons why this may not be the case. **We want to sort the data with date descending. We don't have a single date field but we can sort by multiple fields to achieve the same effect.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f2eef9",
   "metadata": {},
   "source": [
    "Other examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee04e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First three rows, starting index optional\n",
    "surveys[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afeb8003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the last element (last row)\n",
    "surveys[-1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42fd291",
   "metadata": {},
   "source": [
    "We can also reassign values within subset of our DataFrame. Before we do that, let's make a copy of our DataFrame so as not to modify our original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b31401",
   "metadata": {},
   "outputs": [],
   "source": [
    "surveys_copy = surveys\n",
    "surveys_copy[0:3] = 0\n",
    "surveys_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7459ad52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm that the original is unchanged\n",
    "surveys.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5528b251",
   "metadata": {},
   "source": [
    "### Oops: Referencing versus Copying Objects in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b148590",
   "metadata": {},
   "source": [
    "**We thought that we were creating a copy of the `surveys` DataFrame.** However, when we assign a variable such as `y = x`, this doesn't create a copy of `x`; rather, it creates a new variable `y` that refers to the same object that `x` refers to. This means there is only one object (the DataFrame), and both `x` and `y` refer to it. Thus, when we modify `surveys_copy`, the object that is modified is the same object `surveys` points to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802f1728",
   "metadata": {},
   "outputs": [],
   "source": [
    "surveys = pd.read_csv('ecology-surveys.csv')\n",
    "surveys_copy = surveys.copy()\n",
    "surveys_copy[0:3] = 0\n",
    "surveys.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6414fe",
   "metadata": {},
   "source": [
    "## Automating Data Processing with For Loops"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ab8044",
   "metadata": {},
   "source": [
    "As one example of how we can automate data processing with for loops, let's imagine that we want to split our large `surveys` table into separate files, one for each survey year. **We'll start by making a new directory to hold the output files for each year.**\n",
    "\n",
    "We can use Python's `os` library to manipulate files and folders on our computer's file system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c49b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.mkdir('yearly_files')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e0a093",
   "metadata": {},
   "source": [
    "The command `os.mkdir` is equivalent to the `mkdir` command in the Unix shell, which you may have seen if you use a GNU/Linux or Mac computer. To confirm that we just created the `yearly_files` folder, we can ask Python to list the contents of our current directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c68155c",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir('.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6048ffb7",
   "metadata": {},
   "source": [
    "**In previous lessons, we saw how to use the Pandas library to load a table into memory as a DataFrame, how to select a subset of the data using some criteria, and how to write the DataFrame to a CSV file.** \n",
    "\n",
    "Let's now write a script that performs those three steps for just the year 2002."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb42052d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the data into a DataFrame\n",
    "surveys = pd.read_csv('ecology-surveys.csv')\n",
    "\n",
    "# Select only data for 2002\n",
    "surveys2002 = surveys[surveys.year == 2002]\n",
    "\n",
    "# Write the new DataFrame to a CSV file\n",
    "surveys2002.to_csv('yearly_files/surveys_2002.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea54633d",
   "metadata": {},
   "source": [
    "**One way we could create a file for every year would be to change this Python script for each year.** This would be tedious, however, and tedium is what we're trying to avoid by using Python! Moreover, if we are changing our code frequently, we're likely to introduce an error at some point. \n",
    "\n",
    "**What we really want to do is to rewrite this script so that it is more general and can create all the files we need in one run.**\n",
    "\n",
    "Let's start by writing a loop that simply prints the names of the files we want to create; files denoted by each year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859abc95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can get the years in our data...\n",
    "surveys.year"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b97b2c",
   "metadata": {},
   "source": [
    "But we want only the unique years... How do we do that again?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd927821",
   "metadata": {},
   "outputs": [],
   "source": [
    "surveys.year.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc871a22",
   "metadata": {},
   "source": [
    "Putting this into a loop, we can generate filenames for each year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ed7ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_tuple = ('a', 'b', 'c', 'd')\n",
    "a_list = ['a', 'b', 'c', 'd']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09db2b10",
   "metadata": {},
   "source": [
    "1. What happens when you try to re-assign the first value in each of the following examples?\n",
    "```py\n",
    "a_tuple[0] = 5\n",
    "a_list[0] = 5\n",
    "```\n",
    "2. Type `type(a_tuple)` into Python; what is the object's type?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a358fd74",
   "metadata": {},
   "source": [
    "## Dictionaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00301497",
   "metadata": {},
   "source": [
    "A **dictionary** is a container that holds key-value pairs. It is a data structure that is also referred to, in other programming languages, as an **associative array.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71db7ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {'tbsp': 'tablespoon', 'tsp': 'teaspoon'}\n",
    "mapping['tbsp']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6ce91e",
   "metadata": {},
   "source": [
    "Dictionaries are similar to lists in that we can store multiple things inside them. While we index lists with numeric indices, we index dictionaries with **keys.** A key is a unique identifier for a value in the dictionary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a068a3",
   "metadata": {},
   "source": [
    "**Keys must be a particular data type; they must be hashable, therefore, only strings and numeric types are acceptable.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cedf325",
   "metadata": {},
   "outputs": [],
   "source": [
    "code_book = {1: 'Valid', 2: 'Invalid'}\n",
    "code_book[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b874677d",
   "metadata": {},
   "outputs": [],
   "source": [
    "{[1,2]: 'Valid/Invalid'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee2f77d",
   "metadata": {},
   "source": [
    "**Another way we can create dictionaries is using the `dict()` function.** Here, we give the `dict()` function a list of key-value pairs, represented as tuples. The first element in the tuple is the key, the second element is the value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d80e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.weight.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e659aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "surveys.weight.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364fa3f5",
   "metadata": {},
   "source": [
    "**So, in general, it's better to leave `NaN` values as `NaN` and to subset the data to remove them, rather than re-coding them.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf66ab8",
   "metadata": {},
   "source": [
    "## Indexing by Date and Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42c1214",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6104cac6",
   "metadata": {},
   "source": [
    "# Combining Multiple Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f528936a",
   "metadata": {},
   "source": [
    "At this point, we have learned:\n",
    "\n",
    "- About zero-based indexing in Python;\n",
    "- How to manipulate and extract data using column headings and index locations;\n",
    "- How to employ slicing to select subsets of a DataFrame;\n",
    "- How to re-assign values within a DataFrame;\n",
    "- How to create a copy of a DataFrame;\n",
    "- How to query subsets of a DataFrame that match certain criteria using logical operators;\n",
    "- How to interpret NaN values and best practices for missing data;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c58ac74",
   "metadata": {},
   "source": [
    "In many situations, the data we want to use come in multiple files. We often need to combine these files into a single DataFrame in order to analyze the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47fd3a16",
   "metadata": {},
   "source": [
    "Let's load a second table into our session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3199e279",
   "metadata": {},
   "outputs": [],
   "source": [
    "surveys = pd.read_csv('ecology-surveys.csv')\n",
    "species = pd.read_csv('ecology-species.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8842cc1f",
   "metadata": {},
   "source": [
    "## Concatenating DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b1491d0",
   "metadata": {},
   "source": [
    "We can use the `concat` function in Pandas to append either columns or rows from one DataFrame to another. Let's create subsets of our data to see how this works..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8438e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "surveys[0:3]\n",
    "surveys.iloc[0:3]\n",
    "surveys.iloc[0:3,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b077f6",
   "metadata": {},
   "source": [
    "**To index by columns (and rows) in Pandas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c8a988",
   "metadata": {},
   "outputs": [],
   "source": [
    "surveys[['month', 'day', 'year']]\n",
    "surveys.loc[0:3, ['month', 'day', 'year']]\n",
    "surveys.iloc[0:3, 1:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27c9d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c960b02",
   "metadata": {},
   "source": [
    "The result of an inner join of `surveys_sub` and `species` is a new DataFrame that contains the combined set of columns from `surveys_sub` and `species`.\n",
    "\n",
    "**Note that the result of this merge is only 19 rows, whereas `surveys_sub` started with 20 rows.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f279264",
   "metadata": {},
   "source": [
    "### Left Joins"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972c91fa",
   "metadata": {},
   "source": [
    "If there are rows in `surveys_sub` with a `species_id` that is not found in the `species` lookup table, then they are not included in the merged output. What if we want to add information from `species` to `surveys_sub` without losing any of the information from `surveys`? **A left join returns all of the rows from the left DataFrame while joining only whatever rows in the right data frame match.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3663777",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Because there is only one shared column, we can neglect giving any column mames\n",
    "merged_left = pd.merge(left = surveys_sub, right = species, how = 'left')\n",
    "merged_left.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e3b3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_left"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aaade34",
   "metadata": {},
   "source": [
    "### Other Joins"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c42267",
   "metadata": {},
   "source": [
    "- A **right (outer) join** is similar to a left join except that it takes all rows from the right data frame and only matching rows from the left.\n",
    "- A **full (outer) join** returns all pairwise combinations of the two matching columns. This type is rarely used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772925f4",
   "metadata": {},
   "source": [
    "### Challenges: Joins"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240b097b",
   "metadata": {},
   "source": [
    "Create a new data frame by joining the contents of `surveys` and `species`. Then, calculate and plot the distribution of `taxa` by `plot_id`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a2c77c",
   "metadata": {},
   "source": [
    "# Automating Data Workflows with Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59fa3153",
   "metadata": {},
   "source": [
    "So far, we've used Python and the Pandas library to explore and manipulate individual datasets by hand, much like we would do in a spreadsheet. **The advantage of using a programming environment like Python, though, comes from its ability to automate data processing through the use of loops and functions.**\n",
    "\n",
    "Let's remind ourselves of how loops work."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f87eaa",
   "metadata": {},
   "source": [
    "## Writing Data to a CSV File"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4211f8e7",
   "metadata": {},
   "source": [
    "We can use the `to_csv()` method to export a DataFrame to a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aefe6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "vertical_stack.to_csv('out.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e1ca48",
   "metadata": {},
   "source": [
    "## Joining DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae440527",
   "metadata": {},
   "source": [
    "**Note:** Use [this webpage](http://blog.codinghorror.com/a-visual-explanation-of-sql-joins/) as a graphical reference for this segment.\n",
    "\n",
    "When we concatenated our DataFrames, we simply added them together, stacking them either vertically or horizontally. **Another way to combine DataFrames is to use columns in each dataset that contain common values (a common identifier).** Combining DataFrames in this way is referred to as a **join.**\n",
    "\n",
    "Joining data frames in this way is especially useful when one DataFrame serves as a **lookup table,** containing additional data that we want to include in the other. **For example, the `species` table we imported is a lookup table. It contains additional information about each `species_id`.**\n",
    "\n",
    "To better understand how this works, let's create a subset of the surveys table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa042d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "surveys_sub = surveys.tail(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541fff54",
   "metadata": {},
   "source": [
    "### Identifying Join Keys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7e31bf",
   "metadata": {},
   "source": [
    "When we join two tables together, they must share a common key. Usually, it is a field that uniquely identifies the records in one of the two tables. **In this example, it is the `species_id` field that the tables share.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8cdd6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "surveys_sub.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e5867a",
   "metadata": {},
   "outputs": [],
   "source": [
    "species.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87cc07bb",
   "metadata": {},
   "source": [
    "### Inner Joins"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2ec129",
   "metadata": {},
   "source": [
    "The most common type of join is called an **inner join.** An inner join combines two DataFrames based on a shared key and returns a new DataFrame that contains *only* those rows that have matching values in *both* of the original DataFrames.\n",
    "\n",
    "The Pandas function for performing joins is called `merge()`; by default, it performs an inner join."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ab7bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First 10 rows of surveys\n",
    "surveys_first10 = surveys.head(10)\n",
    "\n",
    "# Last 10 rows of surveys\n",
    "surveys_last10 = surveys.tail(10)\n",
    "surveys_last10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b878dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the index so that we can concatenate properly\n",
    "surveys_last10 = surveys_last10.reset_index(drop = True)\n",
    "surveys_last10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61663295",
   "metadata": {},
   "source": [
    "When we concatenate DataFrames, we need to specify the axis. With `axis=0`, we are stacking DataFrames on top of one another (row-wise). Pandas will automatically detect that the column names are the same and stack them accordingly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8feb6e6a",
   "metadata": {},
   "source": [
    "What do each of these lines of code return?\n",
    "\n",
    "1. &nbsp;`grades[0]`\n",
    "2. &nbsp;`grades[len(grades)]`\n",
    "3. &nbsp;`grades[4]`\n",
    "\n",
    "Why do (2) and (3) return errors?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71697927",
   "metadata": {},
   "source": [
    "### Slicing Subsets of Rows in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13fc476",
   "metadata": {},
   "source": [
    "**Slicing using the `[]` operator selects a set of rows and/or columns from a DataFrame.** To slice out a set of rows, we use the following syntax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d27778f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the first three rows; rows 0,1,2 (but NOT 3)\n",
    "surveys[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4ef556",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiple_years_to_csv(all_data, start_year=None, end_year=None):\n",
    "    '''\n",
    "    Writes separate CSV files for each year of data.\n",
    "    Arguments:\n",
    "        all_data      The DataFrame with multi-year data\n",
    "        start_year    The first year of data we want\n",
    "        end_year      The last year of data we want\n",
    "    '''\n",
    "    if start_year is None:\n",
    "        start_year = min(all_data.year)\n",
    "        \n",
    "    if end_year is None:\n",
    "        end_year = max(all_data.year)\n",
    "    \n",
    "    # Because range() generates a sequence up to bubt *not* including\n",
    "    #     the last number, we add 1\n",
    "    for year in range(start_year, end_year + 1):\n",
    "        one_year_to_csv(all_data, year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69cd4660",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_years_to_csv(surveys)\n",
    "os.listdir('yearly_files/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17932bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in surveys.year.unique():\n",
    "    filename = 'yearly_files/surveys_%s.csv' % str(year)\n",
    "    print(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38cf972e",
   "metadata": {},
   "source": [
    "**A few things to note about this code:**\n",
    "\n",
    "- We are looping over the years in the `year` column of our DataFrame. Because `year` is an integer, we need to convert it to a string before we can make it part of a filename. This is what the built-in `str()` function does.\n",
    "- Python allows us to embed text strings in other text strings through **string formatting.** Here, we use a special formatting character, `%s`, to denote where in the text string we want to embed some other text. The `%` operator is then followed by the string we want to embed.\n",
    "\n",
    "**Now, we have everything we need to create these separate files by year.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbcce443",
   "metadata": {},
   "outputs": [],
   "source": [
    "surveys = pd.read_csv('ecology-surveys.csv')\n",
    "\n",
    "for year in surveys.year.unique():\n",
    "    # Select data for the given year\n",
    "    surveys_in_year = surveys[surveys.year == year]\n",
    "    \n",
    "    # Write the subdataset to a new file\n",
    "    filename = 'yearly_files/surveys_%s.csv' % str(year)\n",
    "    surveys_in_year.to_csv(filename)\n",
    "    \n",
    "os.listdir('yearly_files')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625a4543",
   "metadata": {},
   "source": [
    "### Challenge: Automation with For Loops"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f710f1",
   "metadata": {},
   "source": [
    "1. Some of the surveys we saved are missing data; they have `NaN` values in one or more columns. **Modify our `for` loop so that the entries with null values are not included in the yearly files.** \n",
    "2. **What happens if there are no data for a year in the sequence?** You can generate a list of years for the `for` loop to use with, e.g., `range(1970, 1980)`.\n",
    "3. Let's say you only want to look at data from a given multiple of years. **How would you modify your loop in order to generate a data file for only every 5th year, starting from 1977?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4294a0",
   "metadata": {},
   "source": [
    "## Building Reusable Code with Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a2cd64",
   "metadata": {},
   "source": [
    "Suppose that separating large data files into individual yearly files is a task that we frequently have to perform. We could write a `for` loop like the one above every time we needed to do it but that would be time-consuming and error-prone. **A more elegant solution would be to create a resuable tool that performs this task with minimum input from the user.**\n",
    "\n",
    "To achieve this, we'll encapsulate the code we've written so far into a function. As we've seen, functions are reusable, self-contained pieces of code that are called with a single command. **The first part of writing a function is envisioning how it will be used; how it will be called by the user.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07920cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_year_to_csv(all_data, the_year):\n",
    "    '''\n",
    "    Writes a CSV files for data from a given year.\n",
    "    Arguments:\n",
    "        all_data    The DataFrame will multi-year data\n",
    "        the_year    The year to write, an integer\n",
    "    '''\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7489fae7",
   "metadata": {},
   "source": [
    "Some things to note about this function:\n",
    "\n",
    "- Our function takes two arguments, `the_year` and `all_data`.\n",
    "- We've included a **docstring** in our function. The docstring is any string that comes on the line immediately after the function definition. It can be a single-line string but it is most commonly a multi-line string, indicated by three quote symbols in order.\n",
    "- **It doesn't do anything yet.** We wanted to set up the function first so that we have an end goal in mind; functions have to have a body of code so we used the keyword `pass` here, which is a special Python command that says, \"do nothing.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834e08ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "?one_year_to_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926c98f5",
   "metadata": {},
   "source": [
    "Now, let's populate the body of this function with the code we wrote before, making the necessary changes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42547fd5",
   "metadata": {},
   "source": [
    "Let's perform some summary statistics to further verify that the data we imported look okay.\n",
    "First, let's remind ourselves what is in our data and what values we might use to group the data by in calculating summary statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42718229",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the column names\n",
    "surveys.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5fe2d37",
   "metadata": {},
   "source": [
    "Let's get a list of all the species.\n",
    "The `pd.unique()` function tells us all of the unique values in the `species_id` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1066c83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.unique(surveys['species_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c4c3af",
   "metadata": {},
   "source": [
    "**Note the bracket notation we've used here. This is how we access a column by name in a Pandas DataFrame.**\n",
    "It's just like how we accessed the value in a Dictionary by its key name."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09c7f1d",
   "metadata": {},
   "source": [
    "### Challenge: Unique Levels for a Column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669df441",
   "metadata": {},
   "source": [
    "1. Create a list of unique plot IDs found in the survey data; assign the list of unique IDs to a variable called `plot_names`. **How many unique plots are there in the data? How many unique species are in the data?**\n",
    "2. What is the difference between `len(plot_names)` and `plot_names.shape`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d19094",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.isnull(surveys).any(axis=1).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d16453",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.isnull(surveys).any(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb089c79",
   "metadata": {},
   "source": [
    "To select the rows where there are null values, we can use the mask as an index to subset our data, as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03c31e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "surveys[pd.isnull(surveys).any(axis=1)].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e806b338",
   "metadata": {},
   "source": [
    "**How can we select rows where there are NO null values?** We can invert the mask using the tilde operator, `~`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b933563a",
   "metadata": {},
   "outputs": [],
   "source": [
    "surveys[~pd.isnull(surveys).any(axis=1)].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae98ad20",
   "metadata": {},
   "source": [
    "## Dealing with Missing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d98cd5c",
   "metadata": {},
   "source": [
    "It is sometimes hard to know why data values are missing. Was it because of a data entry error? Was there some condition in the field that prevented observation of a particular variable?\n",
    "\n",
    "Moreover, we need a way of representing missing data that is clear and unambiguous. If we encode missing values as zeroes, for instance, are we sure that zero won't be interpreted as a real value?\n",
    "\n",
    "For text data, an empty string usually suffices for blank values. However, numeric data fields can't hold an empty string; they have to either hold some number or a special value called `NaN`, which stands for \"not a number.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f096f068",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_year_to_csv(all_data, the_year):\n",
    "    '''\n",
    "    Writes a CSV files for data from a given year.\n",
    "    Arguments:\n",
    "        all_data    The DataFrame will multi-year data\n",
    "        the_year    The year to write, an integer\n",
    "    '''\n",
    "    # Select data for the given year\n",
    "    data_in_year = all_data[all_data.year == the_year]\n",
    "    \n",
    "    # Write the subdataset to a new file\n",
    "    filename = 'yearly_files/surveys_%s.csv' % str(the_year)\n",
    "    data_in_year.to_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712d02f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_year_to_csv(surveys, 2002)\n",
    "os.listdir('yearly_files')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a202fe6",
   "metadata": {},
   "source": [
    "This is a great start, but what we really want to do is create files for multiple years without having to request each year one at a time. Let's write another function that replicates the `for` loop we wrote earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bab6281",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiple_years_to_csv(all_data, start_year, end_year):\n",
    "    '''\n",
    "    Writes separate CSV files for each year of data.\n",
    "    Arguments:\n",
    "        all_data      The DataFrame with multi-year data\n",
    "        start_year    The first year of data we want\n",
    "        end_year      The last year of data we want\n",
    "    '''\n",
    "    # Because range() generates a sequence up to but *not* including\n",
    "    #     the last number, we add 1\n",
    "    for year in range(start_year, end_year + 1):\n",
    "        one_year_to_csv(all_data, year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab1ee6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_years_to_csv(surveys, 1977, 2002)\n",
    "os.listdir('yearly_files')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1f7ef0",
   "metadata": {},
   "source": [
    "We can add optional arguments to help make this function even easier to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf78401",
   "metadata": {},
   "outputs": [],
   "source": [
    "surveys = pd.read_csv('ecology-surveys.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f6379c",
   "metadata": {},
   "source": [
    "Note that when we do variable assignment, Python does not display anything on the screen.\n",
    "The output of the `pd.read_csv()` function, our table, instead of being displayed on the screen is not \"captured\" in the variable named `surveys`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45783272",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(surveys)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe40b28",
   "metadata": {},
   "source": [
    "## Manipulating Data in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1dfe28",
   "metadata": {},
   "source": [
    "One of the first things we might do after importing any kind of data in any environment is to make sure that are our data--the individual fields or columns--are represented in the right way; by the right data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef20fc3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "animals = ['LIONS', 'TIGERS', 'BEARS']\n",
    "\n",
    "for creature in animals:\n",
    "    print(creature.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c0f669",
   "metadata": {},
   "source": [
    "A powerful Python idiom that we can use here is the **list comprehension:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8c95b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(surveys[pd.isnull(surveys.weight)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5dd427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of null values, in this case, is the same as number of non-zero values\n",
    "len(surveys.weight) - len(surveys[surveys.weight > 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8616afe",
   "metadata": {},
   "source": [
    "We can replace all the `NaN` values in our `weight` column using the `fillna()` method. Here, we use data management best practices, copying our original data so that we don't modify it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4600f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = surveys.copy()\n",
    "df.weight = df.weight.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7de75c",
   "metadata": {},
   "source": [
    "However, `NaN` and zero will yield different results in analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0e5366",
   "metadata": {},
   "source": [
    "Chooses the \"truth-y\" value between the two:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5e031d",
   "metadata": {},
   "outputs": [],
   "source": [
    "True or False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be715cb1",
   "metadata": {},
   "source": [
    "`True` and `False`, with the first letter capitalized, are special values in Python that mean just what they say."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b33c77e",
   "metadata": {},
   "source": [
    "## Sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea417fcb",
   "metadata": {},
   "source": [
    "Much of Python's expressive power and flexibility comes from the way it handles **sequences.** A sequence could be a sequence of characters in a text string or a sequence of numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b7d0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert grams to pounds\n",
    "surveys_converted.weight_lbs = surveys_converted.weight * 0.00220462\n",
    "surveys_converted.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e1a431",
   "metadata": {},
   "source": [
    "## Transforming Values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec33343",
   "metadata": {},
   "source": [
    "We can affect a more general transformation of a column's values. Let's say that, for whatever reason, we want the text strings in `species_id` to be lower-case, not upper-case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9f4e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "surveys.species_id.apply(lambda x: x.lower()).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba66c427",
   "metadata": {},
   "source": [
    "**What happened?** When Pandas imports a DataFrame and sees categorical data, like `species_id` here, it often treats the categorical data like numeric data in the background, assigning a numeric key to each unique categorical value. **We need to explicitly tell Pandas to treat this value like a string.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7bb8a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "surveys.species_id.apply(lambda x: str(x).lower()).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08b6c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiple_years_to_csv(all_data, start_year=1997, end_year=2002):\n",
    "    '''\n",
    "    Writes separate CSV files for each year of data.\n",
    "    Arguments:\n",
    "        all_data      The DataFrame with multi-year data\n",
    "        start_year    The first year of data we want\n",
    "        end_year      The last year of data we want\n",
    "    '''\n",
    "    # Because range() generates a sequence up to but *not* including\n",
    "    #     the last number, we add 1\n",
    "    for year in range(start_year, end_year + 1):\n",
    "        one_year_to_csv(all_data, year)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929c8c3d",
   "metadata": {},
   "source": [
    "But what if the years 1997 and 2002 are not in the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e589923",
   "metadata": {},
   "outputs": [],
   "source": [
    "vertical_stack = pd.concat([surveys_first10, surveys_last10], axis = 0)\n",
    "vertical_stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b08bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In order to avoid duplication of index values\n",
    "vertical_stack.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff708a8",
   "metadata": {},
   "source": [
    "### Challenge: Viewing DataFrames in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0696be",
   "metadata": {},
   "source": [
    "Try executing each code sample below and see what is returned.\n",
    "\n",
    "- `surveys.columns`\n",
    "- `surveys.head()`\n",
    "- `surveys.head(15)`\n",
    "- `surveys.tail()`\n",
    "- `surveys.shape`\n",
    "\n",
    "Take note of the output of `surveys.shape`; what format does it return?\n",
    "\n",
    "**Finally, what is the difference between the code samples that end in parentheses and those that do not?**\n",
    "\n",
    "Each of the code samples above has us calling some **attribute** or **method** on the surveys DataFrame.\n",
    "\n",
    "- **Methods** are functions that belong to an object in Python, like a DataFrame. Just like the functions we saw earlier, functions take zero or more arguments that go inside the parentheses. Even if we have no arguments to provide, we still have to use the parentheses to get the function to do its work. **In general, a method is a function that belongs to an object.**\n",
    "- **Attributes** are a more general concept; an attribute is anything that belongs to an object in Python, including methods. Attributes that are not methods, however, don't need to be called with parentheses.\n",
    "\n",
    "If we think of a person, an attribute is something that belongs to that person or describes that person, like hair color or number of siblings.\n",
    "A method is something that person does, like bake a pie or go for a run."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3742784f",
   "metadata": {},
   "source": [
    "## Calculating Statistics in a Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768f3598",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in code_book.items():\n",
    "    print(key, '->', value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7e1cde",
   "metadata": {},
   "source": [
    "Alternatively:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4d6eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in code_book.keys():\n",
    "    print(key, '->', code_book[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61fb3bb",
   "metadata": {},
   "source": [
    "### Challenge: Reassignment in a Dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7732de42",
   "metadata": {},
   "source": [
    "How can we change a value in our dictionary? Try to reassign one of the values in the `code_book` dictionary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896d9997",
   "metadata": {},
   "source": [
    "You may have noticed that a dictionary sometimes returns its items in a different order than you expected. **Dictionaries are intrinsically unordered; they do not retain the order of their items.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfdf9679",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2747888",
   "metadata": {},
   "source": [
    "One of the chief reasons we program computers to do things for us is because computers are very good at tedious tasks (and humans are not). A block of Python code that does the same thing every time is best defined as **function** in Python. **A function is a series of fixed Python statements, with or without input arguments, that are assigned a name so that we can easily call them over and over again.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03819dc",
   "metadata": {},
   "source": [
    "We've already seen the built-in `print()` and `help()` functions. Now let's see how to write our own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ced451a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pow10(exponent):\n",
    "    result = 10 ** exponent\n",
    "    return result\n",
    "\n",
    "pow10(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adda3ef3",
   "metadata": {},
   "source": [
    "Key things to note about this example:\n",
    "\n",
    "- We define a function using the `def` command followed by the name of the function and any arguments its takes, written just like we would call the function (recall the `print()` and `help()` functions);\n",
    "- The **body** of the function is indented;\n",
    "- We use the `return` command to indicate what the result of the function , or its **return value**, should be. If we don't `return` anything, the function's body is still executed, but we don't necessarily see any output when the function is called."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17eaba8b",
   "metadata": {},
   "source": [
    "**How can we make a more general version of the function `pow10()`?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05fed694",
   "metadata": {},
   "source": [
    "### Jupyter Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90084de",
   "metadata": {},
   "source": [
    "For this lesson, we'll be using the Python interpreter that is embedded in Jupyter Notebook. Jupyter Notebook is a fancy, browser-based environment for **literate programming,** the combination of Python scripts with rich text for telling a story about the task you set out to do with Python. This is a powerful way for collecting the code, the analysis, the context, and the results in a single place.\n",
    "\n",
    "The Python interpreter we'll interact with in Jupyter Notebook is the same interpreter we could use from the command line. To launch Jupyter Notebook:\n",
    "\n",
    "- In GNU/Linux or Mac OS X, launch the Terminal and type: `jupyter notebook`; then press ENTER.\n",
    "- In Windows, launch the Command Prompt and type `jupyter notebook`; then press ENTER."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96fda1ad",
   "metadata": {},
   "source": [
    "Let's try out the Python interpreter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a064198",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Hello, world!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb888e2",
   "metadata": {},
   "source": [
    "Alternatively, we could save that one line of Python code to a text file with a `*.py` file extension and then execute that file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7313041b",
   "metadata": {},
   "source": [
    "## Python Data Types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4d3210",
   "metadata": {},
   "source": [
    "### Strings, Integers, and Floats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5f7ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'Data Carpentry' # A character string\n",
    "number = 42 # An integer number\n",
    "pi = 3.14159265 # A floating-point number or \"float\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0277e2",
   "metadata": {},
   "source": [
    "Here, we've assigned data to **variables** using the **assignment operator** or equal sign. **The process of assignment takes a value and stores it under a name that we make up.** This way, we can use that stored value again by calling its name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8741f166",
   "metadata": {},
   "outputs": [],
   "source": [
    "number"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd9eec9",
   "metadata": {},
   "source": [
    "Note that to recover a variable's stored value, we simply type the name of the variable and hit `Enter`. (This only works in interactive mode; if we wrote a script and want it to print out a value, we have to use the `print()` function.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb2dab0",
   "metadata": {},
   "source": [
    "Variable names can only include letters, the underscore, and numbers. However, variable names cannot start with numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4595acd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict([(1, 'Valid'), (2, 'Invalid')])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481fbd75",
   "metadata": {},
   "source": [
    "Using `for` loops with dictionaries is a little more complicated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703dfa0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pow(exponent, base=10):\n",
    "    result = base ** exponent\n",
    "    return result\n",
    "\n",
    "pow(2, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b25a5eb1",
   "metadata": {},
   "source": [
    "Here, the function `pow()` can be used to calculate powers of any base, not just base 10. By default, it will calculate powers of 10, because the argument `base` has a default argument of 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b760db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pow(2, base = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497955ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "pow(base = 10, exponent = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68ce1bb",
   "metadata": {},
   "source": [
    "`pow()` is actually a function already built into Python, so we didn't need to write this function, but it demonstrates how you can create more flexible functions using default arguments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf79de3",
   "metadata": {},
   "source": [
    "### Challenge: Writing Your First Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f7a2cd",
   "metadata": {},
   "source": [
    "To convert from temperatures in Fahrenheight to Celsius, we first subtract $32$ and then multiple by $5/9$. Write a function that converts temperatures from Fahrenheit to Celsius."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef0c762",
   "metadata": {},
   "source": [
    "### Lambda Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c56f819",
   "metadata": {},
   "source": [
    "Another type of function in Python is the lambda function. This is a special, one-line function that is generally used for transforming inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657f3111",
   "metadata": {},
   "outputs": [],
   "source": [
    "5 == 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f459497",
   "metadata": {},
   "source": [
    "i.e., is it True *and* True?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eba615b",
   "metadata": {},
   "outputs": [],
   "source": [
    "True and True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6315457",
   "metadata": {},
   "outputs": [],
   "source": [
    "grades[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6596edf1",
   "metadata": {},
   "source": [
    "![](./slicing-slicing.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9b34a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "grades[1:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e8c0e9",
   "metadata": {},
   "source": [
    "### Challenge: Slicing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c1170c",
   "metadata": {},
   "source": [
    "**For this lesson to run smoothly, let's make sure everyone is in the same directory.** In the Jupyter Notebook file tree, navigate to your Desktop. We'll create a new Notebook here to use for the rest of the lesson."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5981bd1",
   "metadata": {},
   "source": [
    "## About the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d546007",
   "metadata": {},
   "outputs": [],
   "source": [
    "[creature.lower() for creature in animals]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7919fd",
   "metadata": {},
   "source": [
    "Similarly, a **dictionary comprehension** is another quick way to transform data in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715ad7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict((creature, creature.lower()) for creature in animals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56fbcca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "surveys.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af448120",
   "metadata": {},
   "source": [
    "Here, `int64` refers to integer type; it cannot store decimal numbers. `float64` stores decimal numbers with 64-bit precision. `object` refers to character strings, or text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0b8e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = pd.merge(left = surveys_sub, right = species, left_on = 'species_id', right_on = 'species_id')\n",
    "merged.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96bc467",
   "metadata": {},
   "outputs": [],
   "source": [
    "surveys[['species_id', 'plot_id']]\n",
    "surveys[['plot_id', 'species_id']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b0b379",
   "metadata": {},
   "source": [
    "### Extracting a Range of Data with Slicing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ff12c6",
   "metadata": {},
   "source": [
    "Recall that in Python, we start counting from zero instead of one. This means that the first element in an object is located at position zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ece1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "grades = [88, 72, 93, 94]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69f00af",
   "metadata": {},
   "source": [
    "![](./slicing-indexing.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9396f63",
   "metadata": {},
   "source": [
    "As with [the Data Carpentry ecology lesson](http://www.datacarpentry.org/python-ecology-lesson/license/), this lesson is licensed for open use under the [CC BY 4.0 license](https://creativecommons.org/licenses/by/4.0/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e703e152",
   "metadata": {},
   "source": [
    "# Introduction to the Python Programming Language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f289396",
   "metadata": {},
   "source": [
    "Python is a general purpose programming language that allows for the rapid development of scientific workflows. Python's main advantages are:\n",
    "\n",
    "- It is open-source software, supported by the [Python Software Foundation](https://www.python.org/psf/);\n",
    "- It is available on all platforms, including Windows, Mac OS X, and GNU/Linux;\n",
    "- It can be used to program any kind of task (it is a *general purpose* language);\n",
    "- It supports multiple *programming paradigms* (a fancy term computer scientists use to describe the different ways people like to design software);\n",
    "- **Most importantly, it has a large and diverse community of users who share Python code they've already written to do a wide variety of things.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b1d964",
   "metadata": {},
   "source": [
    "## The Python Interpreter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cbc3954",
   "metadata": {},
   "source": [
    "The only language that computers really understand is machine language, or binary: ones and zeros. Anything we tell computers to do has to be translated to binary for computers to execute.\n",
    "\n",
    "Python is what we call an *interpreted language.* This means that computers can translate Python to machine code as they are reading it. This distinguishes Python from languages like C, C++, or Java, which have to be *compiled* to machine code *before* they are run. The details aren't important to us; **what is important is that we can use Python in two ways:**\n",
    "\n",
    "- We can use the Python interpreter in **interactive mode;**\n",
    "- Or, we can use execute Python code that is stored in a text file, called a script."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
