{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "018849bc",
   "metadata": {},
   "source": [
    "#Agenda\n",
    "\n",
    "- Define the problem and the approach\n",
    "- <p style=\"color: red\">Data basics: loading data, looking at your data, basic commands</p>\n",
    "- Handling missing values\n",
    "- Intro to scikit-learn\n",
    "- Grouping and aggregating data\n",
    "- Feature selection\n",
    "- Fitting and evaluating a model\n",
    "- Deploying your work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07097729",
   "metadata": {},
   "source": [
    "##In this notebook you will\n",
    "\n",
    "- Learn how to load data into Python\n",
    "- Learn the basics of working with data in `pandas`\n",
    "- Clean and manage your data\n",
    "- Wrangle missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dcbf79c",
   "metadata": {},
   "source": [
    "##Reading from a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c11ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pylab as pl\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37007d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4a10df",
   "metadata": {},
   "source": [
    "We're going to use the <code>read_csv</code> function in pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc56ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "?pd.read_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991b4683",
   "metadata": {},
   "outputs": [],
   "source": [
    "! head -n 2 ./data/credit-training.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64ac907",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/credit-training.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01fd1763",
   "metadata": {},
   "source": [
    "##What is <code>df</code>?\n",
    "Our data is represented by a DataFrame. You can think of data frames as a giant spreadsheet which you can program. It's a collection of series (or columns) with a common set of commands that make managing data in Python super easy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d6d612",
   "metadata": {},
   "source": [
    "##Handling Missing Values\n",
    "One of the most frustrating parts of data science can be handling null or missing data. pandas has a lot of built in features for making is super easy to handle missing data. The first thing we need to do is determine which fields have missing data. To do that we're going to use `pd.melt`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55594cae",
   "metadata": {},
   "source": [
    "###[Long vs. Wide Data](http://en.wikipedia.org/wiki/Wide_and_narrow_data)\n",
    "Depending on the problem you're solving, you may need to rotate between having your data in wide/long format.\n",
    "\n",
    "Wide data is probably what you think of when the work \"spreadsheet\" comes to mind. We're talking about data in which each row represents 1 datapoint and each value is in a particular column. This is well suited for things like modeling and producing summary statistics.\n",
    "\n",
    "I often find that having data in `long` format is often best for doing the same task against multiple variables. Things like plotting distributions of each variable, making frequency tables, or, in our case, determining what portion of a dataframe's variables are null."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207691ca",
   "metadata": {},
   "source": [
    "###pd.melt()\n",
    "For converting data from `wide` to `long` format.\n",
    "```\n",
    ">>> df\n",
    "A B C\n",
    "a 1 2\n",
    "b 3 4\n",
    "c 5 6\n",
    "\n",
    ">>> pd.melt(df, id_vars=['A'], value_vars=['B'])\n",
    "A variable value\n",
    "a B        1\n",
    "b B        3\n",
    "c B        5\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccea32be",
   "metadata": {},
   "outputs": [],
   "source": [
    "?pd.melt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56062bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# By not specifying id_vars, we're going to melt EVERYTHING\n",
    "df_lng = pd.melt(df)\n",
    "# now our data is a series of (key, value) rows. \n",
    "#think of when you've done this in Excel so that you can\n",
    "#create a pivot table \n",
    "df_lng.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf14e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "null_variables = df_lng.value.isnull()\n",
    "null_variables.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91af023",
   "metadata": {},
   "outputs": [],
   "source": [
    "# crosstab creates a frequency table between 2 variables\n",
    "# it's going to automatically enumerate the possibilities between\n",
    "# the two Series and show you a count of occurrences \n",
    "#in each possible bucket\n",
    "pd.crosstab(df_lng.variable, null_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f093387",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's abstract that code into a function so we can easily \n",
    "# recalculate it\n",
    "def print_null_freq(df):\n",
    "    \"\"\"\n",
    "    for a given DataFrame, calculates how many values for \n",
    "    each variable is null and prints the resulting table to stdout\n",
    "    \"\"\"\n",
    "    df_lng = pd.melt(df)\n",
    "    null_variables = df_lng.value.isnull()\n",
    "    return pd.crosstab(df_lng.variable, null_variables)\n",
    "print_null_freq(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94a3408",
   "metadata": {},
   "source": [
    "####Use pd.melt to create a data frame in the following format:\n",
    "```\n",
    "     serious_dlqin2yrs variable\t  value\n",
    "0\t                1\t age\t    45\n",
    "1\t                0\t age\t    40\n",
    "2\t                0\t age\t    38\n",
    "3\t                0\t age\t    30\n",
    "4\t                0\t age\t    49\n",
    "...\t                ...\t ...\t    ...\n",
    "299999              1\t debt_ratio 0.423\n",
    "300000              0\t debt_ratio 0.8923\n",
    "```\n",
    "Only include values for `age` and `debt_ratio`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d8c190",
   "metadata": {},
   "outputs": [],
   "source": [
    "melted = pd.melt(..., id_vars=[...], value_vars=[...])\n",
    "\n",
    "print len(melted)==300000\n",
    "print melted.variable.unique()==np.array(['age', 'debt_ratio'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956fd709",
   "metadata": {},
   "source": [
    "###Filling NA's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782a8907",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series([1, 2, None, 4])\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b7f586",
   "metadata": {},
   "outputs": [],
   "source": [
    "s.fillna(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb05059",
   "metadata": {},
   "outputs": [],
   "source": [
    "s.ffill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd23262",
   "metadata": {},
   "outputs": [],
   "source": [
    "s.bfill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58562815",
   "metadata": {},
   "outputs": [],
   "source": [
    "s.fillna(s.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27572698",
   "metadata": {},
   "source": [
    "If you look at `df` you can see that there are 2 columns which don't have a full 150,000 values: `monthly_income` and `number_of_dependents`. In order to incorporate these variables into our analysis, we need to specify how to treat these missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2edd4d0a",
   "metadata": {},
   "source": [
    "For number_of_dependents let's keep things simple and intuitive. if someone didn't specify how many dependents they had then let's assume it's becasue they don't have any to begin with."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0d93dd",
   "metadata": {},
   "source": [
    "Taking a look at `monthly_income` we see that it's a bit more complicated than `number_of_dependents`. We have a few options for replacing missing data. We could do something like set it to the mean or median or the dataset but this might skew our distribution. We could also set it to 0 but this might not be right either. Instead we're going to use a technique called imputation. We'll go into this more after we take a look at `scikit-learn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b2e871",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['DebtRatio']\n",
    "df.DebtRatio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e24e0d1",
   "metadata": {},
   "source": [
    "###head(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33e850f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb5f5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e986f251",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.SeriousDlqin2yrs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6251d37a",
   "metadata": {},
   "source": [
    "###tail(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e54052a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a6f3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.RevolvingUtilizationOfUnsecuredLines.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1ab768",
   "metadata": {},
   "source": [
    "###describe(percentile_width=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b4a856",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ab6b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.age.describe(percentile_width=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96e3796",
   "metadata": {},
   "source": [
    "###unqiue() and nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed94d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.NumberOfDependents.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831e9996",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.NumberOfDependents.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea22454a",
   "metadata": {},
   "source": [
    "###pd.value_counts(values_to_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc10649",
   "metadata": {},
   "outputs": [],
   "source": [
    "def camel_to_snake(column_name):\n",
    "    \"\"\"\n",
    "    converts a string that is camelCase into snake_case\n",
    "    Example:\n",
    "        print camel_to_snake(\"javaLovesCamelCase\")\n",
    "        > java_loves_camel_case\n",
    "    See Also:\n",
    "        http://stackoverflow.com/questions/1175208/elegant-python-function-to-convert-camelcase-to-camel-case\n",
    "    \"\"\"\n",
    "    s1 = re.sub('(.)([A-Z][a-z]+)', r'\\1_\\2', column_name)\n",
    "    return re.sub('([a-z0-9])([A-Z])', r'\\1_\\2', s1).lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51192bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "camel_to_snake(\"javaLovesCamelCase\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675db997",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = [camel_to_snake(col) for col in df.columns]\n",
    "df.columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea78bb91",
   "metadata": {},
   "source": [
    "##Slicing and Indexing Data\n",
    "pandas (like R) uses a system of boolean indexing. What this means is that when selecting particular rows or columns in your dataset..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2c966a",
   "metadata": {},
   "source": [
    "###Grabbing columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b05019",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['monthly_income'].head()\n",
    "df.monthly_income.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573bca41",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['monthly_income', 'serious_dlqin2yrs']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703b80f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_i_want = ['monthly_income', 'serious_dlqin2yrs']\n",
    "df[columns_i_want].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c64b4cc",
   "metadata": {},
   "source": [
    "##Adding Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6636cae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.newcolumn = 1\n",
    "# this will throw an error\n",
    "df['newcolumn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb3a3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['one'] = 1\n",
    "df.one.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25125703",
   "metadata": {},
   "source": [
    "###Removing a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7020dded",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.value_counts(df.NumberOfDependents)\n",
    "df.NumberOfDependents.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb8d11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.value_counts(df.NumberOfDependents, ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ddc6183",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.value_counts(df.NumberOfDependents, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def66cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#chain value_counts together with head() to give you the top 3\n",
    "pd.value_counts(df.NumberOfDependents).head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7efb1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.value_counts(df.NumberOfDependents).plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3105c774",
   "metadata": {},
   "source": [
    "##pd.crosstab(rows, cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10c5203",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(df.NumberOfTimes90DaysLate, df.SeriousDlqin2yrs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699ab22b",
   "metadata": {},
   "source": [
    "####Use `pd.crosstab` to make a table that contains customer's ages in the lefthand column and the number of dependents they have in the right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b6f98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(df.age, df.NumberOfDependents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1852899",
   "metadata": {},
   "source": [
    "##Basic Cleanliness"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf974e4",
   "metadata": {},
   "source": [
    "Let's fix for formatting of the column names. I personally like snake_case (and so does Python). I found [this handy function](http://stackoverflow.com/questions/1175208/elegant-python-function-to-convert-camelcase-to-camel-case) on stackoverflow for converting camelCase to snake_case.\n",
    "\n",
    "Now we can apply the camel_to_snake function on each column name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93778eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load https://gist.github.com/glamp/6529725/raw/e38ffd2fc4cb840be21098486ffe5df991946736/camel_to_snake.py"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
