{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac5cbcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_train_perf(predictors_Tensor, outcome_Tensor_binary, classifier, 0.0025, True,\n",
    "                -0.05, 1.05, 'Observed Label', 'Probability of Label 1', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e86ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predicted probabilities as binary values\n",
    "classifier_pred = np.round(classifier(Variable(predictors_Tensor, requires_grad = False)).data.numpy())\n",
    "\n",
    "# Determine if those predictions are right\n",
    "number_correct_preds = (classifier_pred == outcome_Tensor_binary.numpy())\n",
    "\n",
    "# Get the accuracy of those predictions\n",
    "train_accuracy = (sum(number_correct_preds) / len(number_correct_preds))[0]\n",
    "\n",
    "\n",
    "# Lets get it in words\n",
    "'Training set accuracy is: ' + str(train_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2930ba58",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_classifier_pred = np.round(classifier(Variable(cv_predictors_Tensor, requires_grad = False)).data.numpy())\n",
    "\n",
    "number_correct_cv_preds = (cv_classifier_pred == cv_outcome_Tensor_binary.numpy())\n",
    "\n",
    "cv_accuracy = (sum(number_correct_cv_preds) / len(number_correct_cv_preds))[0]\n",
    "\n",
    "\n",
    "'Cross-validation set accuracy is: ' + str(cv_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13110d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_classifier_pred = np.round(classifier(Variable(test_predictors_Tensor, requires_grad = False)).data.numpy())\n",
    "\n",
    "number_correct_test_preds = (test_classifier_pred == test_outcome_Tensor_binary.numpy())\n",
    "\n",
    "test_accuracy = (sum(number_correct_test_preds) / len(number_correct_test_preds))[0]\n",
    "\n",
    "\n",
    "'Test set accuracy is: ' + str(test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1af610",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the false positive and true positive rates using scikit-learn\n",
    "fpr_a, tpr_a, _ = roc_curve(y_true = test_outcome_Tensor_binary.numpy(),\n",
    "                            y_score = classifier(Variable(test_predictors_Tensor, requires_grad = False)).data.numpy())\n",
    "\n",
    "# Calculate the area under the curve\n",
    "area_under = auc(x = fpr_a,\n",
    "                 y = tpr_a)\n",
    "\n",
    "\n",
    "# Plot it all\n",
    "plt.plot(fpr_a, tpr_a, 'deeppink')\n",
    "plt.plot(fpr_a, fpr_a, 'black')\n",
    "plt.xlabel('False Positive Rate', size = 14)\n",
    "plt.ylabel('True Positive Rate', size = 14)\n",
    "plt.title('ROC/AUC Test Set Performance', size = 16)\n",
    "plt.text(0.26, 0.05, 'Area under Curve = %s'%(area_under), size = 13)\n",
    "axes = plt.gca()\n",
    "axes.set_xlim([0, 1])\n",
    "axes.set_ylim([0, 1]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca94cb4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(test_outcome_Tensor_binary.numpy(),\n",
    "            classifier(Variable(test_predictors_Tensor, requires_grad = False)).data.numpy(),\n",
    "            alpha = 0.0075,\n",
    "            facecolor = 'k')\n",
    "axes = plt.gca()\n",
    "plt.xticks([0, 1], ['\\nNo damage', '\\nDamage'])\n",
    "plt.xlim(-0.05, 1.05)\n",
    "plt.ylim(0, 1)\n",
    "axes.grid(False)\n",
    "axes.set_xlabel('True Outcome', size = 14)\n",
    "axes.set_ylabel('Predicted Probability of Damage', size = 14)\n",
    "plt.axhline(y = 0.5, color = 'red', linestyle = '--')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507528c3",
   "metadata": {},
   "source": [
    "## 3. Get and evaluate the test set expected values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23afad58",
   "metadata": {},
   "source": [
    "Import the data to undo model-needed processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a780711",
   "metadata": {},
   "outputs": [],
   "source": [
    "unproc_tor_df = pd.read_csv(\"/home/jeremydiaz/tornadoesr/data/raw/tor_data_with_derived.csv\")\n",
    "\n",
    "mean_log_dam = np.mean(np.log(unproc_tor_df['DAMAGE_PROPERTY'] + 1))\n",
    "stand_dev_log_dam = np.std(np.log(unproc_tor_df['DAMAGE_PROPERTY'] + 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ede6ff",
   "metadata": {},
   "source": [
    "Computations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd622583",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conditional predictions\n",
    "# Get the model-scale predictions\n",
    "test_conditional_predictions_raw = model(Variable(test_predictors_Tensor, requires_grad = False))\n",
    "\n",
    "# Convert to numpy\n",
    "test_conditional_predictions = test_conditional_predictions_raw.data.numpy()\n",
    "\n",
    "# Convert that to natural-log-scale\n",
    "test_conditional_predictions = (test_conditional_predictions * stand_dev_log_dam) + mean_log_dam\n",
    "\n",
    "# Convert that to natural scale \n",
    "test_conditional_predictions = np.exp(test_conditional_predictions)\n",
    "\n",
    "# Convert that to log-10 scale\n",
    "test_conditional_predictions = np.log10(test_conditional_predictions)\n",
    "\n",
    "\n",
    "# Probabilities\n",
    "test_probabilities_raw = classifier(Variable(test_predictors_Tensor, requires_grad = False))\n",
    "\n",
    "# Convert to numpy\n",
    "test_probabilities = test_probabilities_raw.data.numpy()\n",
    "\n",
    "\n",
    "# Expected values\n",
    "test_expected_values = test_conditional_predictions * test_probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca5604a",
   "metadata": {},
   "source": [
    "Save them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c43c6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the observed damages in the same scale\n",
    "test_df['DAMAGE_PROPERTY'] = (test_df['DAMAGE_PROPERTY'] * stand_dev_log_dam) + mean_log_dam\n",
    "# Convert that to natural scale \n",
    "test_df['DAMAGE_PROPERTY'] = np.exp(test_df['DAMAGE_PROPERTY'])\n",
    "# Convert that to log-10 scale\n",
    "test_df['DAMAGE_PROPERTY'] = np.log10(test_df['DAMAGE_PROPERTY'])\n",
    "\n",
    "\n",
    "\n",
    "# Get those expected values into the grid DataFrame and save it\n",
    "test_ev_df = pd.DataFrame(test_expected_values)\n",
    "test_ev_df.columns = ['EXPECTED_VALUE']\n",
    "test_df = pd.concat([test_ev_df, test_df], axis = 1)\n",
    "test_df.to_csv('test_with_expectated_values.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd4da04",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['JITTER'] = np.random.uniform(low = 0.05, high = 0.75, size = len(test_df['DAMAGE_PROPERTY']))\n",
    "\n",
    "test_df.loc[test_df.DAMAGE_PROPERTY != test_df.DAMAGE_PROPERTY.min(), 'JITTER'] *= 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50346504",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['PROB'] = test_probabilities\n",
    "\n",
    "plt.scatter(test_df['DAMAGE_PROPERTY'] + test_df['JITTER'],\n",
    "            test_df['EXPECTED_VALUE'],\n",
    "            c = test_df['PROB'])\n",
    "plt.ylabel('Expected Value', size = 14)\n",
    "plt.xlabel('Observed Value', size = 14)\n",
    "axes = plt.gca()\n",
    "axes.grid(False)\n",
    "axes.set_xlim([-0.1, 9.5])\n",
    "axes.set_ylim([-0.1, 9.5])\n",
    "plt.plot([-0.5, 9.5], [-0.5, 9.5], c = 'grey', linestyle = '--');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a676b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "log10_predictions = torch.from_numpy(test_df['EXPECTED_VALUE'].values)\n",
    "log10_observed = torch.from_numpy(test_df['DAMAGE_PROPERTY'].values).float()\n",
    "\n",
    "test_observed_mean_log10 = (sum(test_df['DAMAGE_PROPERTY']) / len(test_df['DAMAGE_PROPERTY']))\n",
    "    \n",
    "test_outcomes_mean_log10 = np.repeat(test_observed_mean_log10, len(test_df['DAMAGE_PROPERTY']))\n",
    "    \n",
    "test_outcomes_mean_log10 = Variable(torch.from_numpy(test_outcomes_mean_log10).float())\n",
    "\n",
    "\n",
    "loss_fn = torch.nn.MSELoss(size_average = False)\n",
    "TSS = loss_fn(test_outcomes_mean_log10, Variable(log10_observed))\n",
    "RSS = loss_fn(Variable(log10_predictions), Variable(log10_observed))\n",
    "\n",
    "R_squared = 1 - (RSS / TSS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dca36df",
   "metadata": {},
   "outputs": [],
   "source": [
    "log10_MSE = (RSS.data.numpy()[0] / len(test_df['DAMAGE_PROPERTY']))\n",
    "print(\"MSE in log-10 scale is %0.6f\" % log10_MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f66606",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"R-sqaured in log-10 scale is %0.6f\" % R_squared.data.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4551b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(test_conditional_predictions,\n",
    "            test_df['EXPECTED_VALUE'],\n",
    "            facecolor = 'none',\n",
    "            edgecolor = 'k',\n",
    "            alpha = 0.2)\n",
    "axes = plt.gca()\n",
    "axes.set_xlim([0, 8])\n",
    "axes.set_ylim([0, 8])\n",
    "plt.xlabel(\"Conditional Predictions\", size = 15)\n",
    "plt.ylabel(\"Expected Value\", size = 15)\n",
    "plt.plot([-1, 9.5], [-1, 9.5]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dedb7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(test_conditional_predictions,\n",
    "            test_probabilities,\n",
    "            facecolor = 'none',\n",
    "            edgecolor = 'k',\n",
    "            alpha = 0.2)\n",
    "axes = plt.gca()\n",
    "plt.xlabel(\"Conditional Prediction\", size = 15)\n",
    "plt.ylabel(\"Probability of Damage\", size = 15)\n",
    "axes.set_xlim([0, 8])\n",
    "axes.set_ylim([0, 1.05]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb9340d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Having to use very low alpha values because there are %0.6f\" % int(len(test_conditional_predictions))\n",
    "      + \" data points\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5e58c5",
   "metadata": {},
   "source": [
    "## 4. Get the expected values for 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae551c5",
   "metadata": {},
   "source": [
    "Get the gridded and cities DataFrames of assumed storm characteristics, true geographic values, and potential dates/times"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
