{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae6dd39d",
   "metadata": {},
   "source": [
    "**1. Load the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4d26dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import scipy.stats as stats\n",
    "from tools.datasets import get_prudential\n",
    "\n",
    "data, labels, continuous, discrete, dummy, categorical, _ = get_prudential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de4a11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check target values\n",
    "labels.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6dd247c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at some properties of the target variable\n",
    "labels.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219e261b",
   "metadata": {},
   "source": [
    "Check the distribution of the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98cbe45",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc47552",
   "metadata": {},
   "source": [
    "From the description (link to source), we know that the target is an ordinal variable from 1 to 8 and the evaluation metric is quadratic weighed kappa. Even though the ordering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d104a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for missing values\n",
    "data[categorical].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8f68f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics.cramer import categorical_relation_with\n",
    "\n",
    "top = categorical_relation_with(data, 'Response', categorical + dummy)\n",
    "top_categorical = top[0].sort_values(ascending=False).index[0:10]\n",
    "top[1].sort_values(ascending=False)[0:10] # print "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f528493",
   "metadata": {},
   "source": [
    "Medical Keyword 32 and 45 seem to be unrelated ("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e95163",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics.cramer import cross_categorical\n",
    "\n",
    "v, p = cross_categorical(data, sorted(list(top_categorical)) + ['Response'])\n",
    "sns.heatmap(v, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f88e6f3c",
   "metadata": {},
   "source": [
    "Medical history 33 is strongly correlated with medical keyword 23, maybe the keyword is always present for the patients with something specific in their medical history. We can drop the keyword too. We can see that medical history 4 and keywords 15 and 3 have a significant correlation with Response."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef12d604",
   "metadata": {},
   "source": [
    "**3. Discrete **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa287ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[discrete].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825902a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[discrete].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8818ea04",
   "metadata": {},
   "source": [
    "Quite a lot comparing to the set size (59k), except medical history 1, most of the values are missing or not present. Maybe they refer to some specific illness or test that not everyone needed to pass. Before doing anything about them, let's check the distibutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46fe45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "fig, axes = plt.subplots(int(math.ceil(len(discrete)/3)), 3, figsize=(15,12))\n",
    "for attr in discrete:\n",
    "    clean = data[attr].dropna()\n",
    "    sns.distplot(clean, bins=40, ax=axes[int(i/3)][i%3]).set_title(attr)\n",
    "    axes[int(i/3)][i%3].set_ylim(0.00001,0.005)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2699cd84",
   "metadata": {},
   "source": [
    "Two significant peaks at the edges, maybe the values were clipped to 240. let's check if these are 240 and 0 that take most of these samples or is it distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa539ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "for attr in discrete:\n",
    "    print(\"{}, nan: {}\".format(attr, data[attr].isnull().sum()))\n",
    "    print(dict(data[attr].value_counts().nlargest(20)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de39aae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import BINNER_CONFIG\n",
    "from transformers.custom_binner import CustomBinner\n",
    "binner = CustomBinner(BINNER_CONFIG)\n",
    "\n",
    "data = binner.transform(data)\n",
    "new_cols = list(set(data.columns) - set(discrete + categorical + dummy + continuous + ['Id', 'Response']))\n",
    "# check new columns for correlations\n",
    "\n",
    "top = categorical_relation_with(data, 'Response', new_cols)\n",
    "top_categorical = top[0].sort_values(ascending=False).index[0:10]\n",
    "top[0].sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50991be5",
   "metadata": {},
   "source": [
    "Medical history 15 might be usefull. Three lowest are not relevant (to delete)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4507c7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics.cat_to_num import apply_across\n",
    "\n",
    "# apply_across(data, new_cols, ['Response'], stats.spearmanr)\n",
    "# experimentally it seams that filling missing\n",
    "pd.Series([stats.spearmanr( data['Response'], data[col].fillna(300))[0] for col in discrete], index=discrete).sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1924e98b",
   "metadata": {},
   "source": [
    "Binning seems to work, but filling missing values makes sense too. Let's check it later on the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1084c801",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(apply_across(data[['Response'] + discrete].fillna(-1), ['Response'], discrete, stats.kruskal))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce82cd81",
   "metadata": {},
   "source": [
    "All seem to have some influence. p < 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3a7b4d",
   "metadata": {},
   "source": [
    "**4. Continuous **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c823ae45",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data[continuous].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d423eb",
   "metadata": {},
   "source": [
    "There are some missing values amond the variables, handle later. All seem to be normalized to range 0-1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86de4f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "fig, axes = plt.subplots(int(math.ceil(len(continuous)/3)), 3, figsize=(15,12))\n",
    "# plt.figure()\n",
    "for attr in continuous:\n",
    "    clean = data[attr].dropna()\n",
    "    sns.distplot(clean, bins=20, ax=axes[int(i/3)][i%3]).set_title(attr)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8846eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for now just use the simplest approach, and add na flags\n",
    "from transformers.fill_missing_transformer import FillNaTransformer\n",
    "\n",
    "fill_with_zero = ['Employment_Info_4', 'Insurance_History_5']\n",
    "fill_with_median = [ x for x in continuous if x not in fill_with_zero]\n",
    "\n",
    "filler = FillNaTransformer(median=fill_with_median, zero=fill_with_zero, nan_flag=continuous)\n",
    "filler.fit(data)\n",
    "data = filler.transform(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745a9f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot to check result\n",
    "i = 0\n",
    "fig, axes = plt.subplots(int(math.ceil(len(continuous)/3)), 3, figsize=(15,12))\n",
    "# plt.figure()\n",
    "for attr in continuous:\n",
    "    clean = data[attr].dropna()\n",
    "    sns.distplot(clean, bins=20, ax=axes[int(i/3)][i%3], kde=None).set_title(attr)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97ccc96",
   "metadata": {},
   "source": [
    "Doesn't look that good, but let's leave it like that for now. Most of the variables are more or less normally distributed. Some of the features are evidently skewed, let's check it and fix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33db689",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data[continuous].apply(lambda x: stats.skew(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afff0433",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.box_cox import BoxCoxTransformer\n",
    "# tune those,\n",
    "lambdas_per_column = {\n",
    "    'Product_Info_4': 0.5,\n",
    "    'Ht': 1.2,\n",
    "    'Wt': 0.5,\n",
    "    'BMI': 0.6,\n",
    "    'Employment_Info_1': 0.5,\n",
    "    'Employment_Info_4': 0.5,\n",
    "    'Employment_Info_6': 0.5,\n",
    "    'Insurance_History_5': 0.5,\n",
    "    'Family_Hist_2': 0.7,\n",
    "    'Family_Hist_3': 2,\n",
    "    'Family_Hist_4': 0.7,\n",
    "    'Family_Hist_5': 2\n",
    "}\n",
    "boxcox = BoxCoxTransformer(lambdas_per_column)\n",
    "data = boxcox.transform(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed030593",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "fig, axes = plt.subplots(int(math.ceil(len(continuous)/3)), 3, figsize=(15,12))\n",
    "# plt.figure()\n",
    "for attr in continuous:\n",
    "    clean = data[attr].dropna()\n",
    "    sns.distplot(clean, bins=20, ax=axes[int(i/3)][i%3], kde=None).set_title(attr)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49763d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data[continuous].apply(lambda x: stats.skew(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e487c25a",
   "metadata": {},
   "source": [
    "Looks much better, still not perfect, but quite ok."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0203d0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from statistics.cat_to_num import spearman_with\n",
    "# sns.heatmap(apply_across(data, ['Response'], continuous, stats.spearmanr))\n",
    "from statistics.cat_to_num import spearman_with\n",
    "\n",
    "correlation = spearman_with(data, 'Response', continuous)\n",
    "correlation = pd.Series({col: res for col, res in correlation.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66815a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation.sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208fa170",
   "metadata": {},
   "source": [
    "Most correlated are BMI, Wt, Ins_Age, Ht and Product_Info_4."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
